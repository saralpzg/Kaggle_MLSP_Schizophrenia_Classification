{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8322fc15",
   "metadata": {},
   "source": [
    "# Optimización de un modelo de Random Forest\n",
    "\n",
    "Este notebook recoge los resultados de la búsqueda del mejor modelo de clasificación mediante Random Forest. El método entrena varios árboles de decisión (de clasificación en este caso) en submuestras de los datos y combina sus resultados para mejorar su precisión.\n",
    "\n",
    "Para buscar el mejor modelo posible, se tratará de buscar los mejores hiperparámetros para:\n",
    "\n",
    "* El número de árboles del bosque.\n",
    "* La profundidad máxima que alcanzan estos.\n",
    "* Función para evaluar una nueva división de una rama.\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7e06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data partition\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Parameter tunning libraries\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Accuracy function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Model\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72bd4e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>0.216620</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.353800</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.133020</td>\n",
       "      <td>-0.035222</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257114</td>\n",
       "      <td>0.597229</td>\n",
       "      <td>1.220756</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>-0.435494</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>1.090910</td>\n",
       "      <td>-0.448562</td>\n",
       "      <td>-0.508497</td>\n",
       "      <td>0.350434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.410730</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.242260</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>0.599790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050862</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>0.609465</td>\n",
       "      <td>1.181878</td>\n",
       "      <td>-2.279469</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>-0.012693</td>\n",
       "      <td>-1.244346</td>\n",
       "      <td>-1.080442</td>\n",
       "      <td>-0.788502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.318170</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.539922</td>\n",
       "      <td>-1.495822</td>\n",
       "      <td>1.643866</td>\n",
       "      <td>1.687780</td>\n",
       "      <td>1.521086</td>\n",
       "      <td>-1.988432</td>\n",
       "      <td>-0.267471</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>1.104566</td>\n",
       "      <td>-1.067206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.112830</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0.202750</td>\n",
       "      <td>0.191420</td>\n",
       "      <td>-0.056662</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.593326</td>\n",
       "      <td>1.063052</td>\n",
       "      <td>0.434726</td>\n",
       "      <td>1.604964</td>\n",
       "      <td>-0.359736</td>\n",
       "      <td>0.210107</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>-0.323557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "2       0  0.245850  0.216620 -0.124680 -0.353800  0.161500 -0.002032   \n",
       "13      1  0.410730 -0.031925  0.210700  0.242260  0.320100 -0.419290   \n",
       "53      1  0.070919  0.034179 -0.011755  0.019158  0.024645 -0.032022   \n",
       "41      0  0.087377 -0.052462 -0.007835 -0.112830  0.389380  0.216080   \n",
       "74      0  0.202750  0.191420 -0.056662 -0.157780  0.244040  0.039780   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "2  -0.133020 -0.035222  0.259040  ...  -0.257114   0.597229   1.220756   \n",
       "13 -0.187140  0.168450  0.599790  ...  -0.050862   0.870602   0.609465   \n",
       "53  0.004620  0.318170  0.212550  ...  -1.539922  -1.495822   1.643866   \n",
       "41  0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "74 -0.001503  0.001056 -0.048222  ...   0.044457   0.593326   1.063052   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "2   -0.059213  -0.435494  -0.092971   1.090910  -0.448562  -0.508497   \n",
       "13   1.181878  -2.279469  -0.013484  -0.012693  -1.244346  -1.080442   \n",
       "53   1.687780   1.521086  -1.988432  -0.267471   0.510576   1.104566   \n",
       "41  -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "74   0.434726   1.604964  -0.359736   0.210107   0.355922   0.730287   \n",
       "\n",
       "    SBM_map75  \n",
       "2    0.350434  \n",
       "13  -0.788502  \n",
       "53  -1.067206  \n",
       "41  -0.260920  \n",
       "74  -0.323557  \n",
       "\n",
       "[5 rows x 411 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de entrenamiento\n",
    "trainFNC = pd.read_csv(\"../data/train_FNC.csv\")\n",
    "trainSBM = pd.read_csv(\"../data/train_SBM.csv\")\n",
    "train_labels = pd.read_csv(\"../data/train_labels.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "train = pd.merge(left=trainFNC, right=trainSBM, left_on=\"Id\", right_on=\"Id\")\n",
    "data = pd.merge(left=train_labels, right=train, left_on=\"Id\", right_on=\"Id\")\n",
    "data.drop(\"Id\", inplace=True, axis=1)\n",
    "\n",
    "# Shuffle de los datos de train\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aff9c0",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23072a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee01f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de test\n",
    "testFNC = pd.read_csv(\"../data/test_FNC.csv\")\n",
    "testSBM = pd.read_csv(\"../data/test_SBM.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "test_kaggle = pd.merge(left=testFNC, right=testSBM, left_on=\"Id\", right_on=\"Id\")\n",
    "test_kaggle.drop(\"Id\", inplace=True, axis=1)\n",
    "test_kaggle.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35943d37",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a62bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, param_grid):\n",
    "    '''Función para realizar el entrenamiento y la búsqueda de hiperparámetros'''\n",
    "    np.random.seed()\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=4)\n",
    "    # cv = 4 porque así: el conjunto de validation tiene un 0.25 del tamaño de train y: 0.25 * 0.8 = 0.2 ~ 20% datos\n",
    "    #                    el conjunto de train tiene un 0.75 del tamaño de train y: 0.75 * 0.8 = 0.6 ~ 60% datos\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Parámetros óptimos:\", grid_search.best_params_)\n",
    "    print(\"Modelo óptimo:\", grid_search.best_estimator_)\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea643d",
   "metadata": {},
   "source": [
    "Primera prueba de resultados, probando con valores concretos para el número de árboles y la profundidad de los mismos (parámetros ``n_estimators`` y ``max_depth`` respectivamente) y utilizando el método ``GridSearchCV`` de ``sklearn`` para realizar la búsqueda:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13868007",
   "metadata": {},
   "source": [
    "Segunda prueba, con un rango más amplio de valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e45fd463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 600}\n",
      "Modelo óptimo: RandomForestClassifier(criterion='entropy', max_depth=4, n_estimators=600,\n",
      "                       random_state=0)\n",
      "Accuracy: 72.22%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": range(50, 1050, 50),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1, 21)\n",
    "}\n",
    "model_RF_opt = train_model(model_RF, param_grid_RF)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF = model_RF_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a26819",
   "metadata": {},
   "source": [
    "Curiosamente, pudimos observar que si reducíamos el anterior espacio de búsqueda, podíamos obtener mejores resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20893856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 750}\n",
      "Modelo óptimo: RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=750,\n",
      "                       random_state=0)\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF2 = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 10, 15, 20, None]\n",
    "}\n",
    "model_RF_opt2 = train_model(model_RF, param_grid_RF2)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF2 = model_RF_opt2.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89f857",
   "metadata": {},
   "source": [
    "La explicación a este suceso es que, pese a que hemos fijado una semilla en cada modelo en su declaración, una vez se ejecuta algo de código sobre ese modelo, el random state cambia. Esto unido a la inestabilidad del problema y los datos, que son muy sensibles a cualquier alteración dan lugar a este tipo de resultados.\n",
    "\n",
    "En definitiva, fijar una semilla en estos casos lo que va a permitir es que los resultados de una celda, esto es un modelo concreto con unos hiperparámetros concretos, sean reproducibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8136e2",
   "metadata": {},
   "source": [
    "La librería ``optuna`` es un framework específico para la optimización de hiperparámetros, repetiremos el proceso de búsqueda anterior utilizando esta librería en base a 2 métodos de búsqueda de hiperparámetros:\n",
    "\n",
    "* **GridSampler:** equivalente a la anterior búsqueda de grid de sklearn. Lo usaremos para que los resultados sean comparables.\n",
    "* **TPE:** algoritmo para hacer una \"búsqueda inteligente\" de hiperparámetros. Debería ahorrar intentos de combinaciones haciendo una selección inteligente de las pruebas. En nuestro caso le permitiremos probar un 10% del número de combinaciones posibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30805995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveRF_Grid(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy\n",
    "    '''\n",
    "    n_estimators =  trial.suggest_int(\"n_estimators\", 50, 1000)\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 20)\n",
    "    \n",
    "    modelRF_optuna = RandomForestClassifier(criterion = criterion, max_depth = max_depth, n_estimators = n_estimators, \n",
    "                                            random_state=0)\n",
    "    \n",
    "    modelRF_optuna.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_RF_optuna = modelRF_optuna.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_RF_optuna)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c081a8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\n",
    "    \"n_estimators\": range(50, 1001, 50), \n",
    "    \"criterion\": [\"gini\", \"entropy\"], \n",
    "    \"max_depth\": range(1, 21)\n",
    "}\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study_Grid = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_Grid.optimize(objectiveRF_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe6dd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=7, values=[0.8888888888888888], datetime_start=datetime.datetime(2022, 6, 11, 23, 12, 10, 710916), datetime_complete=datetime.datetime(2022, 6, 11, 23, 12, 13, 897665), params={'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 7}, distributions={'n_estimators': IntUniformDistribution(high=1000, low=50, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy')), 'max_depth': IntUniformDistribution(high=20, low=1, step=1)}, user_attrs={}, system_attrs={'search_space': OrderedDict([('criterion', ['entropy', 'gini']), ('max_depth', [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]), ('n_estimators', [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000])]), 'grid_id': 137}, intermediate_values={}, trial_id=7, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_Grid.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436e6ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelRF_optuna_Grid = RandomForestClassifier(criterion=\"entropy\", max_depth=7, n_estimators=900, random_state=0)  \n",
    "modelRF_optuna_Grid.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF_optuna_Grid = modelRF_optuna_Grid.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_optuna_Grid)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884dd5c9",
   "metadata": {},
   "source": [
    "El método GridSampler no permite fijar semilla por lo que los resultados que devuelve serán diferentes en cuanto a parámetros aunque en cualquier caso tendrán la misma precisión en la partición de test.\n",
    "\n",
    "Para probar TPE es necesario redefinir la función objetivo sobre la que se crea el estudio, ya que GridSampler definía dentro de la función el espacio en el que se tomaban los parámetros mientras que los valores exactos a probar los define fuera de la misma. Sin embargo, TPE define en la misma función objetivo los valores a tomar, por lo que hay que incluir los pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6be802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveRF_TPE(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy\n",
    "    '''\n",
    "    n_estimators =  trial.suggest_int(\"n_estimators\", 50, 1000, 50) # optuna incluye en el rango el máximo y el mínimo\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 20)\n",
    "    \n",
    "    modelRF_optuna = RandomForestClassifier(criterion = criterion, max_depth = max_depth, n_estimators = n_estimators, \n",
    "                                            random_state=0)\n",
    "    \n",
    "    modelRF_optuna.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_RF_optuna = modelRF_optuna.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_RF_optuna)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5be75c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba con TPE\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0)  # Asegurar los reproducibilidad de los resultados\n",
    "study_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_TPE.optimize(objectiveRF_TPE, n_trials=80)\n",
    "# n_trials = (20 x 2 x 20) * 0.1 = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7673bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=2, values=[0.8888888888888888], datetime_start=datetime.datetime(2022, 6, 12, 0, 18, 30, 267412), datetime_complete=datetime.datetime(2022, 6, 12, 0, 18, 31, 790904), params={'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}, distributions={'n_estimators': IntUniformDistribution(high=1000, low=50, step=50), 'criterion': CategoricalDistribution(choices=('gini', 'entropy')), 'max_depth': IntUniformDistribution(high=20, low=1, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_TPE.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d98263de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelRF_optuna_TPE = RandomForestClassifier(criterion=\"entropy\", max_depth=11, n_estimators=1000, random_state=0)  \n",
    "modelRF_optuna_TPE.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF_optuna_TPE = modelRF_optuna_TPE.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_optuna_TPE)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f5046",
   "metadata": {},
   "source": [
    "La librería ``optuna`` ha permitido obtener mejores resultados.\n",
    "\n",
    "El código anterior, aunque realiza una búsqueda sobre el mismo rango de parámetros usados para el segundo intento con ``sklearn``, no está aplicando cross-validation an el entrenamiento. La siguiente celda sí lo implementa mediante el método ``OptunaSearchCV`` de ``optuna``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66d49f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\AppData\\Local\\Temp\\ipykernel_2928\\2766480869.py:11: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(model_RF, param_grid_RF, cv=4, n_trials=800, random_state=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptunaSearchCV(cv=4, estimator=RandomForestClassifier(random_state=0),\n",
       "               n_trials=800,\n",
       "               param_distributions={'criterion': CategoricalDistribution(choices=('gini', 'entropy')),\n",
       "                                    'max_depth': IntUniformDistribution(high=20, low=1, step=1),\n",
       "                                    'n_estimators': IntUniformDistribution(high=1000, low=50, step=50)},\n",
       "               random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": optuna.distributions.IntUniformDistribution(50, 1000, 50),\n",
    "    \"criterion\": optuna.distributions.CategoricalDistribution([\"gini\", \"entropy\"]),\n",
    "    \"max_depth\": optuna.distributions.IntUniformDistribution(1, 20)\n",
    "}\n",
    "\n",
    "optuna_search = optuna.integration.OptunaSearchCV(model_RF, param_grid_RF, cv=4, n_trials=800, random_state=0)\n",
    "# n_trials = 20 x 2 x 20 = 800\n",
    "optuna_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c2308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=12, n_estimators=750,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optunaCV_opt = optuna_search.best_estimator_\n",
    "optunaCV_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "046e5dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Predicción en partición de test\n",
    "y_pred_RF = optunaCV_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b325de",
   "metadata": {},
   "source": [
    "En este caso, aplicar cross-validation no mejora los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205fb34",
   "metadata": {},
   "source": [
    "# Create submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "def create_submission(pred, test_id=testFNC[\"Id\"]):\n",
    "    '''\n",
    "    Función para generar un csv con las predicciones de un modelo para participar en la competición de Kaggle\n",
    "    '''\n",
    "    submissionDF = pd.DataFrame(list(zip(test_id, pred)), columns=[\"Id\", \"Probability\"])\n",
    "    print(submissionDF.shape) # Comprobación del tamaño, debe ser: (119748, 2)\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y_%Hh%Mmin\")\n",
    "    current_path = pathlib.Path().resolve()\n",
    "    parent_path = current_path.parent\n",
    "    submissionDF.to_csv(f\"{parent_path}\\submissions\\MLSP_submission_RF_{current_time}.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a3ec8",
   "metadata": {},
   "source": [
    "# Anexo\n",
    "\n",
    "Para la optimización de los modelos con ``optuna``, se han probado dos métodos de \"sampler\": GridSampler y TPE, siendo este último algoritmo de especial interés ya que, si resulta ser efectivo, al hacer una búsqueda inteligente de los hiperparámetros más adecuados podría ahorrar mucho tiempo y recursos de computación respecto a cualquiera de las otras alternativas vistas en este trabajo.\n",
    "\n",
    "Para comprobar la eficacia de este modelo vamos a realizar una prueba en la que compararemos 4 combinaciones de los hiperparámetros de manera aleatoria y 4 combinaciones (iteraciones) con este algoritmo de Optuna. Si TPE es eficaz, lo que se espera es que los resultados de este algoritmo mejoren los resultados de la búsqueda aleatoria y que cada iteración sea mejor que la anterior.\n",
    "\n",
    "### Resultados prueba aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1369028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [850, 800, 450, 300],\n",
       " 'criterion': ['entropy', 'gini', 'entropy', 'gini'],\n",
       " 'max_depth': [10, 12, 19, 11]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "random_params = {}\n",
    "for key in param_grid_RF.keys():\n",
    "    random_params[key] = random.choices(param_grid_RF[key], k=4)\n",
    "    \n",
    "random_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f51fb62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba aleatoria 0 ------ Accuracy: 88.89%\n",
      "Prueba aleatoria 1 ------ Accuracy: 72.22%\n",
      "Prueba aleatoria 2 ------ Accuracy: 83.33%\n",
      "Prueba aleatoria 3 ------ Accuracy: 72.22%\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    # Definir y entrenar el modelo\n",
    "    modelRF_random = RandomForestClassifier(criterion=random_params[\"criterion\"][i], max_depth=random_params[\"max_depth\"][i], \n",
    "                                            n_estimators=random_params[\"n_estimators\"][i], random_state=0)  \n",
    "    modelRF_random.fit(X_train, y_train)\n",
    "\n",
    "    # Predicción en partición de test\n",
    "    y_pred_RF_random = modelRF_random.predict(X_test)\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    accuracy = accuracy_score(y_test, y_pred_RF_random)\n",
    "    print(\"Prueba aleatoria {} ------ Accuracy: {:0.2f}%\".format(i, accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273fee1",
   "metadata": {},
   "source": [
    "### Resultados prueba con Optuna + TPE sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eef1207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 15:32:09,324]\u001b[0m A new study created in memory with name: no-name-672a364b-1857-4f1e-b409-a04a92b6924c\u001b[0m\n",
      "\u001b[32m[I 2022-06-19 15:32:10,024]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 550, 'criterion': 'gini', 'max_depth': 11}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n",
      "\u001b[32m[I 2022-06-19 15:32:10,607]\u001b[0m Trial 1 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 450, 'criterion': 'gini', 'max_depth': 18}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n",
      "\u001b[32m[I 2022-06-19 15:32:12,217]\u001b[0m Trial 2 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-06-19 15:32:13,180]\u001b[0m Trial 3 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 600, 'criterion': 'gini', 'max_depth': 2}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prueba con TPE\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0)  # Asegurar los reproducibilidad de los resultados\n",
    "study_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_TPE.optimize(objectiveRF_TPE, n_trials=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b466cb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=2, values=[0.8888888888888888], datetime_start=datetime.datetime(2022, 6, 19, 15, 29, 42, 216973), datetime_complete=datetime.datetime(2022, 6, 19, 15, 29, 43, 671369), params={'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}, distributions={'n_estimators': IntUniformDistribution(high=1000, low=50, step=50), 'criterion': CategoricalDistribution(choices=('gini', 'entropy')), 'max_depth': IntUniformDistribution(high=20, low=1, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_TPE.best_trial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
