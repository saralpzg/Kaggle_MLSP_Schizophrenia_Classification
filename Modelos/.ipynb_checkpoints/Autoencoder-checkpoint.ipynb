{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37aec554",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Un modelo de autoencoder se descompone a su vez en dos modelos de redes neuronales. La primera, el encoder, tiene el objetivo de comprimir la información de los datos; la segunda, el decoder, trata de reconstruir la información original a partir de los datos comprimidos. \n",
    "\n",
    "La motivación para el estudio de un encoder en este problema es:\n",
    "1. Una vez entrenado el autoencoder completo, podemos separar las dos redes neuronales subyacentes y utilizar la parte encoder (con alguna modificación) para probar su rendimiento como modelo de red de clasificación.\n",
    "2. Para los datos de test proporcionados por la competición de Kaggle (no se dispone de la clasificación verdadera), el encoder puede ayudar a \"recrear\" sus etiquetas.\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1832fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models\n",
    "\n",
    "# Cargar los datos\n",
    "from data_and_submissions import *\n",
    "\n",
    "# Métodos para los entrenamientos con CV\n",
    "from train_cv_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb1ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data()\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1cda16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 410)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tot = pd.concat((X_train, X_test), axis=0)\n",
    "X_train_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e95fe1",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "\n",
    "Para crear el autoencoder, se utilizarán redes simétricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6e6334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1404/1404 [==============================] - 7s 4ms/step - loss: 0.1411 - val_loss: 0.1272\n",
      "Epoch 2/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.1208 - val_loss: 0.1164\n",
      "Epoch 3/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.1154 - val_loss: 0.1174\n",
      "Epoch 4/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.1136 - val_loss: 0.1120\n",
      "Epoch 5/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.1108 - val_loss: 0.1107\n",
      "Epoch 6/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1083 - val_loss: 0.1078\n",
      "Epoch 7/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1074 - val_loss: 0.1093\n",
      "Epoch 8/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1063 - val_loss: 0.1052\n",
      "Epoch 9/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1047 - val_loss: 0.1057\n",
      "Epoch 10/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1043 - val_loss: 0.1069\n",
      "Epoch 11/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1040 - val_loss: 0.1049\n",
      "Epoch 12/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1037 - val_loss: 0.1033\n",
      "Epoch 13/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1027 - val_loss: 0.1026\n",
      "Epoch 14/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1021 - val_loss: 0.1029\n",
      "Epoch 15/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1018 - val_loss: 0.1017\n",
      "Epoch 16/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1015 - val_loss: 0.1018\n",
      "Epoch 17/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1013 - val_loss: 0.1014\n",
      "Epoch 18/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1011 - val_loss: 0.1005\n",
      "Epoch 19/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1009 - val_loss: 0.1004\n",
      "Epoch 20/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1007 - val_loss: 0.1009\n",
      "Epoch 21/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1006 - val_loss: 0.1002\n",
      "Epoch 22/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1004 - val_loss: 0.1027\n",
      "Epoch 23/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1003 - val_loss: 0.1010\n",
      "Epoch 24/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1001 - val_loss: 0.1012\n",
      "Epoch 25/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1000 - val_loss: 0.0997\n",
      "Epoch 26/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0998 - val_loss: 0.1001\n",
      "Epoch 27/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0997 - val_loss: 0.1002\n",
      "Epoch 28/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0996 - val_loss: 0.0995\n",
      "Epoch 29/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0995 - val_loss: 0.0999\n",
      "Epoch 30/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0993 - val_loss: 0.1000\n",
      "Epoch 31/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0988 - val_loss: 0.0983\n",
      "Epoch 32/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0979 - val_loss: 0.0973\n",
      "Epoch 33/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0977 - val_loss: 0.0991\n",
      "Epoch 34/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0975 - val_loss: 0.0969\n",
      "Epoch 35/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0974 - val_loss: 0.0975\n",
      "Epoch 36/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0972 - val_loss: 0.0991\n",
      "Epoch 37/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.0971 - val_loss: 0.0979\n",
      "Epoch 38/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0970 - val_loss: 0.0972\n",
      "Epoch 39/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0969 - val_loss: 0.0966\n",
      "Epoch 40/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0968 - val_loss: 0.0963\n",
      "Epoch 41/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0967 - val_loss: 0.0977\n",
      "Epoch 42/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0966 - val_loss: 0.0972\n",
      "Epoch 43/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0966 - val_loss: 0.0963\n",
      "Epoch 44/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0965 - val_loss: 0.0955\n",
      "Epoch 45/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0964 - val_loss: 0.0971\n",
      "Epoch 46/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0964 - val_loss: 0.0970\n",
      "Epoch 47/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0964 - val_loss: 0.0971\n",
      "Epoch 48/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0963 - val_loss: 0.0960\n",
      "Epoch 49/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0963 - val_loss: 0.0963\n",
      "Epoch 50/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0962 - val_loss: 0.0974\n",
      "Epoch 51/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0962 - val_loss: 0.0955\n",
      "Epoch 52/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0961 - val_loss: 0.0965\n",
      "Epoch 53/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0961 - val_loss: 0.0953\n",
      "Epoch 54/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0960 - val_loss: 0.0963\n",
      "Epoch 55/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0960 - val_loss: 0.0959\n",
      "Epoch 56/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0959 - val_loss: 0.0966\n",
      "Epoch 57/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0959 - val_loss: 0.0955\n",
      "Epoch 58/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0958 - val_loss: 0.0957\n",
      "Epoch 59/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0958 - val_loss: 0.0965\n",
      "Epoch 60/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0958 - val_loss: 0.0961\n",
      "Epoch 61/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0957 - val_loss: 0.0960\n",
      "Epoch 62/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0957 - val_loss: 0.0966\n",
      "Epoch 63/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0954 - val_loss: 0.0941\n",
      "Epoch 64/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0945 - val_loss: 0.0944\n",
      "Epoch 65/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0943 - val_loss: 0.0933\n",
      "Epoch 66/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0942 - val_loss: 0.0954\n",
      "Epoch 67/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0941 - val_loss: 0.0936\n",
      "Epoch 68/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0941 - val_loss: 0.0937\n",
      "Epoch 69/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0940 - val_loss: 0.0945\n",
      "Epoch 70/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0940 - val_loss: 0.0938\n",
      "Epoch 71/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0939 - val_loss: 0.0933\n",
      "Epoch 72/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0939 - val_loss: 0.0951\n",
      "Epoch 73/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0939 - val_loss: 0.0944\n",
      "Epoch 74/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0939 - val_loss: 0.0944\n",
      "Epoch 75/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0938 - val_loss: 0.0938\n",
      "Epoch 76/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0938 - val_loss: 0.0935\n",
      "Epoch 77/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0938 - val_loss: 0.0939\n",
      "Epoch 78/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0937 - val_loss: 0.0940\n",
      "Epoch 79/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0937 - val_loss: 0.0946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0937 - val_loss: 0.0939\n",
      "Epoch 81/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0937 - val_loss: 0.0938\n",
      "Epoch 82/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0937 - val_loss: 0.0942\n",
      "Epoch 83/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0936 - val_loss: 0.0938\n",
      "Epoch 84/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0936 - val_loss: 0.0944\n",
      "Epoch 85/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0936 - val_loss: 0.0940\n",
      "Epoch 86/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0936 - val_loss: 0.0941\n",
      "Epoch 87/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0935 - val_loss: 0.0933\n",
      "Epoch 88/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.0935 - val_loss: 0.0938\n",
      "Epoch 89/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0935 - val_loss: 0.0934\n",
      "Epoch 90/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0935 - val_loss: 0.0936\n",
      "Epoch 91/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0935 - val_loss: 0.0936\n",
      "Epoch 92/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0935 - val_loss: 0.0928\n",
      "Epoch 93/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0934 - val_loss: 0.0948\n",
      "Epoch 94/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0934 - val_loss: 0.0946\n",
      "Epoch 95/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0934 - val_loss: 0.0940\n",
      "Epoch 96/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0934 - val_loss: 0.0940\n",
      "Epoch 97/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0934 - val_loss: 0.0946\n",
      "Epoch 98/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0934 - val_loss: 0.0940\n",
      "Epoch 99/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.0934 - val_loss: 0.0937\n",
      "Epoch 100/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.0933 - val_loss: 0.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb310052b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "input_layer = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded = layers.Dense(200, activation=\"relu\")(input_layer)\n",
    "encoded = layers.Dense(100, activation=\"relu\")(encoded)\n",
    "encoded = layers.Dense(50, activation=\"relu\")(encoded)\n",
    "# Capas red decoder\n",
    "decoded = layers.Dense(50, activation=\"relu\")(encoded)\n",
    "decoded = layers.Dense(100, activation=\"relu\")(decoded)\n",
    "decoded = layers.Dense(200, activation=\"relu\")(decoded)\n",
    "decoded = layers.Dense(410, activation=\"linear\")(decoded)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = models.Model(input_layer, decoded)\n",
    "\n",
    "# Compilar y entrenar el autoencoder\n",
    "autoencoder.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "autoencoder.fit(test_kaggle, test_kaggle, epochs=100, batch_size=64, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c774fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747650e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = models.load_model(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946dc7",
   "metadata": {},
   "source": [
    "Evaluación del autoencoder, se utilizarán métricas como:\n",
    "\n",
    "* MSE = $\\frac{1}{n} \\sum_{i=1}^{n} (Y_{true}^{i} - Y_{pred}^{i})^{2}$\n",
    "* MAPE = $\\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{Y_{true}^{i} - Y_{pred}^{i}}{Y_{true}^{i}} \\right|$\n",
    "\n",
    "donde $Y_{true}$ es el valor real, $Y_{pred}$ el valor de la predicción y $n$ el número de predicciones.\n",
    "\n",
    "La anterior fórmula realiza el cálculo para dos \"listas de valores\", por ejemplo, podemos calcular el error MAPE por muestra o por feature. Para el valor del error de la predicción total, se debe promediar el error obtenido para todas las filas/columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbc232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import MeanSquaredError, MeanAbsolutePercentageError\n",
    "\n",
    "# Definición de las métricas\n",
    "mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "mape = MeanAbsolutePercentageError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a20e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: tf.Tensor(315.31876, shape=(), dtype=float32)\n",
      "MSE: tf.Tensor(0.08369573, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ERROR SOBRE X_train_tot (etiquetados)\n",
    "X_train_tot_pred = autoencoder.predict(X_train_tot)\n",
    "\n",
    "print(\"MAPE:\", mape(X_train_tot, X_train_tot_pred))\n",
    "print(\"MSE:\", mse(X_train_tot, X_train_tot_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1e672",
   "metadata": {},
   "source": [
    "El error es bastante elevado. Vamos a comprobar cómo se distribuyen los valores de error MAPE en cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e45bf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 410)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_tmp = np.abs((X_train_tot - X_train_tot_pred) / X_train_tot)\n",
    "mape_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "532afe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(mape_tmp.mean(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4a96a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08292682926829269"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mape_tmp.mean(axis=0) < 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dace6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_tmp.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd17d6",
   "metadata": {},
   "source": [
    "La anterior expresión indica que únicamente en torno al 8% de las variables en X_train, tienen un error de MAPE que es inferior al 100%. \n",
    "\n",
    "Podíamos pensar que la primera barra en el anterior histograma esconde una gran concentración de valores con errores inferiores al 100% y que el valor final queda desviado por aquellos con valores muy superiores, sin embargo, esta última comprobación lo desmiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52107fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: tf.Tensor(426.45328, shape=(), dtype=float32)\n",
      "MSE: tf.Tensor(0.09347953, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ERROR SOBRE test_kaggle (no etiquetados)\n",
    "test_kaggle_pred = autoencoder.predict(test_kaggle)\n",
    "\n",
    "print(\"MAPE:\", mape(test_kaggle, test_kaggle_pred))\n",
    "print(\"MSE:\", mse(test_kaggle, test_kaggle_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90c952",
   "metadata": {},
   "source": [
    "Sobre el conjunto de entrenamiento ``test_kaggle``, vamos a seleccionar 100 veces 86 muestras y a promediar los valores de desviación típica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f9d3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 415.7068786621094 +- 354.8747253417969\n"
     ]
    }
   ],
   "source": [
    "samples_num = 100\n",
    "mape_samples = []\n",
    "\n",
    "for _ in range(samples_num):\n",
    "    \n",
    "    args = np.random.choice(a=np.arange(0, test_kaggle.shape[0]), size=86, replace=False)\n",
    "\n",
    "    test_kaggle_reduc = test_kaggle.iloc[args, :]\n",
    "\n",
    "    y_pred_kaggle_reduc = autoencoder.predict(test_kaggle_reduc)\n",
    "    tmp_mape = mape(test_kaggle_reduc, y_pred_kaggle_reduc)\n",
    "    mape_samples.append(tmp_mape)\n",
    "    \n",
    "print(f'MAPE: {np.mean(mape_samples)} +- {np.std(mape_samples)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692b393",
   "metadata": {},
   "source": [
    "El valor del MAPE en ``test_kaggle`` es también muy elevado, con grandes desviaciones entre muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c74a80",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Pasamos al problema de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4813a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = layers.Input(shape=(410,))\n",
    "encoder = encoder_input\n",
    "for layer in autoencoder.layers[1:4]:\n",
    "    encoder = layer(encoder)\n",
    "encoder = models.Model(inputs=encoder_input, outputs=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "462c9a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 410)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               82200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,350\n",
      "Trainable params: 107,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa99fd",
   "metadata": {},
   "source": [
    "Una vez hemos entrenado la red autoencoder, el componente encoder de la misma ya contará con unos pesos entrenados con el objetivo de comprimir los datos de entrada. Por tanto, podemos considerar de manera independiente esta red encoder y volver a entrenarla como una red para clasificación, con la ventaja de que se parte de un modelo inicializado no con unos pesos aleatorios, sino unos pesos optimizados para un problema similar.\n",
    "\n",
    "Para hacer esto es necesario añadir previamente una capa final de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ec1b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_classification = models.Sequential()\n",
    "encoder_classification.add(encoder)\n",
    "encoder_classification.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9630a1",
   "metadata": {},
   "source": [
    "Incluso es posible congelar los pesos de todas las capas del encoder original, ya entrenados \"para un problema similar\", y modificar solamente los pesos de la capa final de clasificación, utilizando los datos de train (etiquetados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96a1a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 284ms/step - loss: 0.7143 - acc: 0.4902 - val_loss: 0.7079 - val_acc: 0.3529\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7089 - acc: 0.4314 - val_loss: 0.7043 - val_acc: 0.4118\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7057 - acc: 0.4510 - val_loss: 0.7020 - val_acc: 0.4118\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7036 - acc: 0.4706 - val_loss: 0.6999 - val_acc: 0.4706\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7019 - acc: 0.5098 - val_loss: 0.6981 - val_acc: 0.4706\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7001 - acc: 0.4902 - val_loss: 0.6968 - val_acc: 0.4706\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7013 - acc: 0.4706 - val_loss: 0.6965 - val_acc: 0.4706\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6985 - acc: 0.4902 - val_loss: 0.6957 - val_acc: 0.5294\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6982 - acc: 0.4510 - val_loss: 0.6953 - val_acc: 0.5294\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6972 - acc: 0.4510 - val_loss: 0.6946 - val_acc: 0.5294\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6964 - acc: 0.4706 - val_loss: 0.6939 - val_acc: 0.5294\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6960 - acc: 0.4706 - val_loss: 0.6930 - val_acc: 0.6471\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6956 - acc: 0.4314 - val_loss: 0.6928 - val_acc: 0.6471\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6944 - acc: 0.4510 - val_loss: 0.6921 - val_acc: 0.6471\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6938 - acc: 0.4510 - val_loss: 0.6918 - val_acc: 0.6471\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6932 - acc: 0.4510 - val_loss: 0.6913 - val_acc: 0.6471\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6938 - acc: 0.4314 - val_loss: 0.6906 - val_acc: 0.6471\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6924 - acc: 0.4510 - val_loss: 0.6900 - val_acc: 0.7059\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6913 - acc: 0.5294 - val_loss: 0.6896 - val_acc: 0.7059\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6910 - acc: 0.5294 - val_loss: 0.6891 - val_acc: 0.7059\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6905 - acc: 0.4902 - val_loss: 0.6886 - val_acc: 0.6471\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6897 - acc: 0.4706 - val_loss: 0.6883 - val_acc: 0.6471\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6893 - acc: 0.5490 - val_loss: 0.6880 - val_acc: 0.6471\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6892 - acc: 0.5294 - val_loss: 0.6875 - val_acc: 0.6471\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6884 - acc: 0.5686 - val_loss: 0.6873 - val_acc: 0.6471\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6880 - acc: 0.5686 - val_loss: 0.6871 - val_acc: 0.6471\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6880 - acc: 0.5490 - val_loss: 0.6867 - val_acc: 0.6471\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6874 - acc: 0.5882 - val_loss: 0.6864 - val_acc: 0.6471\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6867 - acc: 0.5882 - val_loss: 0.6862 - val_acc: 0.6471\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6866 - acc: 0.5882 - val_loss: 0.6859 - val_acc: 0.5882\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6864 - acc: 0.6078 - val_loss: 0.6859 - val_acc: 0.6471\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6858 - acc: 0.6078 - val_loss: 0.6858 - val_acc: 0.6471\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6862 - acc: 0.6078 - val_loss: 0.6858 - val_acc: 0.6471\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6853 - acc: 0.6078 - val_loss: 0.6856 - val_acc: 0.6471\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6850 - acc: 0.6078 - val_loss: 0.6853 - val_acc: 0.6471\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6844 - acc: 0.6078 - val_loss: 0.6852 - val_acc: 0.6471\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6841 - acc: 0.6078 - val_loss: 0.6849 - val_acc: 0.5882\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6836 - acc: 0.6078 - val_loss: 0.6847 - val_acc: 0.5882\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6832 - acc: 0.6078 - val_loss: 0.6845 - val_acc: 0.5882\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6831 - acc: 0.6078 - val_loss: 0.6843 - val_acc: 0.5882\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6823 - acc: 0.6078 - val_loss: 0.6841 - val_acc: 0.5882\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6819 - acc: 0.6078 - val_loss: 0.6840 - val_acc: 0.5882\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6818 - acc: 0.6078 - val_loss: 0.6838 - val_acc: 0.5882\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6814 - acc: 0.6078 - val_loss: 0.6836 - val_acc: 0.5882\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6820 - acc: 0.6078 - val_loss: 0.6834 - val_acc: 0.5882\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6806 - acc: 0.5882 - val_loss: 0.6833 - val_acc: 0.5882\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6802 - acc: 0.5686 - val_loss: 0.6832 - val_acc: 0.5882\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6802 - acc: 0.5686 - val_loss: 0.6830 - val_acc: 0.5882\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6795 - acc: 0.5686 - val_loss: 0.6828 - val_acc: 0.5882\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6792 - acc: 0.5686 - val_loss: 0.6828 - val_acc: 0.5882\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6794 - acc: 0.5686 - val_loss: 0.6826 - val_acc: 0.6471\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6788 - acc: 0.5882 - val_loss: 0.6825 - val_acc: 0.6471\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6786 - acc: 0.5686 - val_loss: 0.6824 - val_acc: 0.6471\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6780 - acc: 0.5882 - val_loss: 0.6822 - val_acc: 0.6471\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6782 - acc: 0.5686 - val_loss: 0.6821 - val_acc: 0.6471\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6774 - acc: 0.5882 - val_loss: 0.6820 - val_acc: 0.6471\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6771 - acc: 0.5882 - val_loss: 0.6819 - val_acc: 0.6471\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6771 - acc: 0.6078 - val_loss: 0.6817 - val_acc: 0.6471\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6763 - acc: 0.5882 - val_loss: 0.6816 - val_acc: 0.6471\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6770 - acc: 0.5686 - val_loss: 0.6815 - val_acc: 0.6471\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6757 - acc: 0.5882 - val_loss: 0.6814 - val_acc: 0.6471\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6757 - acc: 0.5882 - val_loss: 0.6813 - val_acc: 0.6471\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6757 - acc: 0.5882 - val_loss: 0.6812 - val_acc: 0.6471\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6752 - acc: 0.5882 - val_loss: 0.6811 - val_acc: 0.6471\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6747 - acc: 0.6078 - val_loss: 0.6810 - val_acc: 0.6471\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6743 - acc: 0.5882 - val_loss: 0.6810 - val_acc: 0.6471\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6739 - acc: 0.5882 - val_loss: 0.6808 - val_acc: 0.6471\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6736 - acc: 0.5882 - val_loss: 0.6807 - val_acc: 0.6471\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6732 - acc: 0.5882 - val_loss: 0.6806 - val_acc: 0.6471\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6729 - acc: 0.6078 - val_loss: 0.6804 - val_acc: 0.6471\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6727 - acc: 0.6078 - val_loss: 0.6802 - val_acc: 0.6471\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6721 - acc: 0.6078 - val_loss: 0.6801 - val_acc: 0.6471\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6717 - acc: 0.6078 - val_loss: 0.6800 - val_acc: 0.6471\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6713 - acc: 0.6078 - val_loss: 0.6799 - val_acc: 0.6471\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6709 - acc: 0.6078 - val_loss: 0.6797 - val_acc: 0.6471\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6704 - acc: 0.6078 - val_loss: 0.6795 - val_acc: 0.6471\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6701 - acc: 0.6078 - val_loss: 0.6795 - val_acc: 0.6471\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6695 - acc: 0.6078 - val_loss: 0.6793 - val_acc: 0.6471\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6691 - acc: 0.6078 - val_loss: 0.6793 - val_acc: 0.6471\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6696 - acc: 0.6078 - val_loss: 0.6792 - val_acc: 0.6471\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6683 - acc: 0.6275 - val_loss: 0.6791 - val_acc: 0.7059\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6679 - acc: 0.6275 - val_loss: 0.6790 - val_acc: 0.7059\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6684 - acc: 0.6078 - val_loss: 0.6789 - val_acc: 0.7059\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6674 - acc: 0.6471 - val_loss: 0.6788 - val_acc: 0.7059\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6673 - acc: 0.6471 - val_loss: 0.6786 - val_acc: 0.7059\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6665 - acc: 0.6471 - val_loss: 0.6785 - val_acc: 0.7059\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6672 - acc: 0.6471 - val_loss: 0.6784 - val_acc: 0.6471\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6659 - acc: 0.6275 - val_loss: 0.6783 - val_acc: 0.7059\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6656 - acc: 0.6275 - val_loss: 0.6782 - val_acc: 0.7059\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6652 - acc: 0.6471 - val_loss: 0.6781 - val_acc: 0.7059\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6649 - acc: 0.6471 - val_loss: 0.6780 - val_acc: 0.7059\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6647 - acc: 0.6471 - val_loss: 0.6779 - val_acc: 0.7059\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6654 - acc: 0.6471 - val_loss: 0.6778 - val_acc: 0.7059\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6644 - acc: 0.6275 - val_loss: 0.6777 - val_acc: 0.7059\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6644 - acc: 0.6471 - val_loss: 0.6776 - val_acc: 0.7059\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6634 - acc: 0.6471 - val_loss: 0.6775 - val_acc: 0.7059\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6631 - acc: 0.6471 - val_loss: 0.6774 - val_acc: 0.7059\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6641 - acc: 0.6471 - val_loss: 0.6773 - val_acc: 0.7059\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6626 - acc: 0.6471 - val_loss: 0.6771 - val_acc: 0.7059\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6625 - acc: 0.6471 - val_loss: 0.6770 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6723 - acc: 0.5556\n",
      "Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Congelar los pesos de todas las capas a excepción de la última\n",
    "for layer in encoder_classification.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Entrenar el modelo\n",
    "encoder_classification.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "encoder_classification.fit(X_train, y_train, epochs=100, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = encoder_classification.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1913fc",
   "metadata": {},
   "source": [
    "Tras unas pocas iteraciones, descongelamos todas las capas y hacemos unas pocas épocas más entrenando y actualizando los pesos para el modelo completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f79e6127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.6560 - acc: 0.7059 - val_loss: 0.6500 - val_acc: 0.7059\n",
      "Epoch 2/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5549 - acc: 0.8627 - val_loss: 0.6373 - val_acc: 0.7059\n",
      "Epoch 3/15\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4569 - acc: 0.8824 - val_loss: 0.6135 - val_acc: 0.7647\n",
      "Epoch 4/15\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3606 - acc: 0.9412 - val_loss: 0.6048 - val_acc: 0.7059\n",
      "Epoch 5/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2737 - acc: 1.0000 - val_loss: 0.6244 - val_acc: 0.7059\n",
      "Epoch 6/15\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2036 - acc: 1.0000 - val_loss: 0.6248 - val_acc: 0.6471\n",
      "Epoch 7/15\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1889 - acc: 0.9608 - val_loss: 0.6251 - val_acc: 0.5294\n",
      "Epoch 8/15\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1302 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 0.7059\n",
      "Epoch 9/15\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0872 - acc: 1.0000 - val_loss: 0.6287 - val_acc: 0.7059\n",
      "Epoch 10/15\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0673 - acc: 1.0000 - val_loss: 0.6456 - val_acc: 0.7059\n",
      "Epoch 11/15\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0516 - acc: 1.0000 - val_loss: 0.6765 - val_acc: 0.7059\n",
      "Epoch 12/15\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.7184 - val_acc: 0.7059\n",
      "Epoch 13/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.7076 - val_acc: 0.7059\n",
      "Epoch 14/15\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.7414 - val_acc: 0.7059\n",
      "Epoch 15/15\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.7338 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5340 - acc: 0.7778\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Descongelar los pesos de todas las capas a excepción de la última\n",
    "for layer in encoder_classification.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Entrenar el modelo\n",
    "encoder_classification.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "encoder_classification.fit(X_train, y_train, epochs=15, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy_encoder_classification = encoder_classification.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy_encoder_classification * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d4c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_classification.save(\"encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e613064d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_pre_train_encoder = encoder_classification.predict(test_kaggle)\n",
    "y_pred_pre_train_encoder = np.around(y_pred_pre_train_encoder, decimals=0).ravel()\n",
    "\n",
    "create_submission(y_pred_pre_train_encoder, \"NN_pre_train_autoencoder1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69276e22",
   "metadata": {},
   "source": [
    "El objetivo es poder comparar con la misma configuración de red que la encoder sin utilizar los pesos pre-entrenados de esta y observar si hay mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd893f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/115\n",
      "2/2 [==============================] - 1s 146ms/step - loss: 0.6693 - acc: 0.5098 - val_loss: 0.6605 - val_acc: 0.5882\n",
      "Epoch 2/115\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4618 - acc: 0.8824 - val_loss: 0.6751 - val_acc: 0.7059\n",
      "Epoch 3/115\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3048 - acc: 0.9608 - val_loss: 0.6953 - val_acc: 0.7059\n",
      "Epoch 4/115\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1893 - acc: 0.9804 - val_loss: 0.7126 - val_acc: 0.7647\n",
      "Epoch 5/115\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1170 - acc: 1.0000 - val_loss: 0.7912 - val_acc: 0.7647\n",
      "Epoch 6/115\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0785 - acc: 1.0000 - val_loss: 0.7260 - val_acc: 0.6471\n",
      "Epoch 7/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0511 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 0.5294\n",
      "Epoch 8/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.8056 - val_acc: 0.7647\n",
      "Epoch 9/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.7504 - val_acc: 0.6471\n",
      "Epoch 10/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.7798 - val_acc: 0.7059\n",
      "Epoch 11/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.8141 - val_acc: 0.7059\n",
      "Epoch 12/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.8731 - val_acc: 0.7647\n",
      "Epoch 13/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.8361 - val_acc: 0.6471\n",
      "Epoch 14/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.8772 - val_acc: 0.7059\n",
      "Epoch 15/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8699 - val_acc: 0.7059\n",
      "Epoch 16/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.9101 - val_acc: 0.7059\n",
      "Epoch 17/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.9444 - val_acc: 0.7647\n",
      "Epoch 18/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9446 - val_acc: 0.7059\n",
      "Epoch 19/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9507 - val_acc: 0.7059\n",
      "Epoch 20/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.9587 - val_acc: 0.7059\n",
      "Epoch 21/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.9892 - val_acc: 0.7059\n",
      "Epoch 22/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.9875 - val_acc: 0.7059\n",
      "Epoch 23/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.9866 - val_acc: 0.7059\n",
      "Epoch 24/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 9.0909e-04 - acc: 1.0000 - val_loss: 1.0305 - val_acc: 0.7647\n",
      "Epoch 25/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7.7527e-04 - acc: 1.0000 - val_loss: 1.0220 - val_acc: 0.7059\n",
      "Epoch 26/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 6.6360e-04 - acc: 1.0000 - val_loss: 1.0279 - val_acc: 0.7059\n",
      "Epoch 27/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 5.7166e-04 - acc: 1.0000 - val_loss: 1.0731 - val_acc: 0.7647\n",
      "Epoch 28/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.9303e-04 - acc: 1.0000 - val_loss: 1.0816 - val_acc: 0.7059\n",
      "Epoch 29/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.2080e-04 - acc: 1.0000 - val_loss: 1.0976 - val_acc: 0.7647\n",
      "Epoch 30/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.6369e-04 - acc: 1.0000 - val_loss: 1.1087 - val_acc: 0.7647\n",
      "Epoch 31/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.1627e-04 - acc: 1.0000 - val_loss: 1.0774 - val_acc: 0.7059\n",
      "Epoch 32/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.7655e-04 - acc: 1.0000 - val_loss: 1.1090 - val_acc: 0.7647\n",
      "Epoch 33/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.3353e-04 - acc: 1.0000 - val_loss: 1.1250 - val_acc: 0.7647\n",
      "Epoch 34/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.0175e-04 - acc: 1.0000 - val_loss: 1.1378 - val_acc: 0.7647\n",
      "Epoch 35/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.7746e-04 - acc: 1.0000 - val_loss: 1.1766 - val_acc: 0.7647\n",
      "Epoch 36/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5307e-04 - acc: 1.0000 - val_loss: 1.1649 - val_acc: 0.8235\n",
      "Epoch 37/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3158e-04 - acc: 1.0000 - val_loss: 1.1762 - val_acc: 0.8235\n",
      "Epoch 38/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1439e-04 - acc: 1.0000 - val_loss: 1.1882 - val_acc: 0.8235\n",
      "Epoch 39/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.9930e-05 - acc: 1.0000 - val_loss: 1.2040 - val_acc: 0.8235\n",
      "Epoch 40/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 8.7287e-05 - acc: 1.0000 - val_loss: 1.2140 - val_acc: 0.8235\n",
      "Epoch 41/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 7.6753e-05 - acc: 1.0000 - val_loss: 1.2289 - val_acc: 0.8235\n",
      "Epoch 42/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 6.6743e-05 - acc: 1.0000 - val_loss: 1.2334 - val_acc: 0.8235\n",
      "Epoch 43/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.8153e-05 - acc: 1.0000 - val_loss: 1.2421 - val_acc: 0.8235\n",
      "Epoch 44/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 5.0445e-05 - acc: 1.0000 - val_loss: 1.2615 - val_acc: 0.8235\n",
      "Epoch 45/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.4469e-05 - acc: 1.0000 - val_loss: 1.2803 - val_acc: 0.8235\n",
      "Epoch 46/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.8873e-05 - acc: 1.0000 - val_loss: 1.2871 - val_acc: 0.8235\n",
      "Epoch 47/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.3714e-05 - acc: 1.0000 - val_loss: 1.2888 - val_acc: 0.8235\n",
      "Epoch 48/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.9351e-05 - acc: 1.0000 - val_loss: 1.3006 - val_acc: 0.8235\n",
      "Epoch 49/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.5925e-05 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.8235\n",
      "Epoch 50/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.2679e-05 - acc: 1.0000 - val_loss: 1.3078 - val_acc: 0.8235\n",
      "Epoch 51/115\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9890e-05 - acc: 1.0000 - val_loss: 1.3200 - val_acc: 0.8235\n",
      "Epoch 52/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.7367e-05 - acc: 1.0000 - val_loss: 1.3332 - val_acc: 0.8235\n",
      "Epoch 53/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.5276e-05 - acc: 1.0000 - val_loss: 1.3545 - val_acc: 0.8235\n",
      "Epoch 54/115\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.3623e-05 - acc: 1.0000 - val_loss: 1.3302 - val_acc: 0.8235\n",
      "Epoch 55/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1923e-05 - acc: 1.0000 - val_loss: 1.3651 - val_acc: 0.8235\n",
      "Epoch 56/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0437e-05 - acc: 1.0000 - val_loss: 1.3611 - val_acc: 0.8235\n",
      "Epoch 57/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 9.3209e-06 - acc: 1.0000 - val_loss: 1.3616 - val_acc: 0.8235\n",
      "Epoch 58/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.1329e-06 - acc: 1.0000 - val_loss: 1.4058 - val_acc: 0.8235\n",
      "Epoch 59/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.1535e-06 - acc: 1.0000 - val_loss: 1.3867 - val_acc: 0.8235\n",
      "Epoch 60/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 6.3501e-06 - acc: 1.0000 - val_loss: 1.4234 - val_acc: 0.8235\n",
      "Epoch 61/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.6073e-06 - acc: 1.0000 - val_loss: 1.4211 - val_acc: 0.8235\n",
      "Epoch 62/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 4.9681e-06 - acc: 1.0000 - val_loss: 1.4391 - val_acc: 0.8235\n",
      "Epoch 63/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.4195e-06 - acc: 1.0000 - val_loss: 1.4541 - val_acc: 0.8235\n",
      "Epoch 64/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.8758e-06 - acc: 1.0000 - val_loss: 1.4368 - val_acc: 0.8235\n",
      "Epoch 65/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.4163e-06 - acc: 1.0000 - val_loss: 1.4705 - val_acc: 0.8235\n",
      "Epoch 66/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.0136e-06 - acc: 1.0000 - val_loss: 1.4726 - val_acc: 0.8235\n",
      "Epoch 67/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.6696e-06 - acc: 1.0000 - val_loss: 1.4833 - val_acc: 0.8235\n",
      "Epoch 68/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3741e-06 - acc: 1.0000 - val_loss: 1.4731 - val_acc: 0.8235\n",
      "Epoch 69/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.1013e-06 - acc: 1.0000 - val_loss: 1.5017 - val_acc: 0.8235\n",
      "Epoch 70/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8568e-06 - acc: 1.0000 - val_loss: 1.5054 - val_acc: 0.8235\n",
      "Epoch 71/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6485e-06 - acc: 1.0000 - val_loss: 1.5266 - val_acc: 0.8235\n",
      "Epoch 72/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.4561e-06 - acc: 1.0000 - val_loss: 1.5191 - val_acc: 0.8235\n",
      "Epoch 73/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2867e-06 - acc: 1.0000 - val_loss: 1.5250 - val_acc: 0.8235\n",
      "Epoch 74/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1402e-06 - acc: 1.0000 - val_loss: 1.5370 - val_acc: 0.8235\n",
      "Epoch 75/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0109e-06 - acc: 1.0000 - val_loss: 1.5459 - val_acc: 0.8235\n",
      "Epoch 76/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 9.0304e-07 - acc: 1.0000 - val_loss: 1.5627 - val_acc: 0.8235\n",
      "Epoch 77/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 8.0273e-07 - acc: 1.0000 - val_loss: 1.5694 - val_acc: 0.8235\n",
      "Epoch 78/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7.1617e-07 - acc: 1.0000 - val_loss: 1.5684 - val_acc: 0.8235\n",
      "Epoch 79/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 6.4340e-07 - acc: 1.0000 - val_loss: 1.5763 - val_acc: 0.8235\n",
      "Epoch 80/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 5.8612e-07 - acc: 1.0000 - val_loss: 1.5682 - val_acc: 0.8235\n",
      "Epoch 81/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.1891e-07 - acc: 1.0000 - val_loss: 1.5983 - val_acc: 0.8235\n",
      "Epoch 82/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.6103e-07 - acc: 1.0000 - val_loss: 1.6143 - val_acc: 0.8235\n",
      "Epoch 83/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.1284e-07 - acc: 1.0000 - val_loss: 1.6132 - val_acc: 0.8235\n",
      "Epoch 84/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.6864e-07 - acc: 1.0000 - val_loss: 1.6312 - val_acc: 0.8235\n",
      "Epoch 85/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.3675e-07 - acc: 1.0000 - val_loss: 1.6614 - val_acc: 0.8235\n",
      "Epoch 86/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.0140e-07 - acc: 1.0000 - val_loss: 1.6562 - val_acc: 0.8235\n",
      "Epoch 87/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.7313e-07 - acc: 1.0000 - val_loss: 1.6785 - val_acc: 0.8235\n",
      "Epoch 88/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.4393e-07 - acc: 1.0000 - val_loss: 1.6712 - val_acc: 0.8235\n",
      "Epoch 89/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.1880e-07 - acc: 1.0000 - val_loss: 1.6813 - val_acc: 0.8235\n",
      "Epoch 90/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.9830e-07 - acc: 1.0000 - val_loss: 1.6928 - val_acc: 0.8235\n",
      "Epoch 91/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.8013e-07 - acc: 1.0000 - val_loss: 1.6994 - val_acc: 0.8235\n",
      "Epoch 92/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6470e-07 - acc: 1.0000 - val_loss: 1.7166 - val_acc: 0.8235\n",
      "Epoch 93/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5197e-07 - acc: 1.0000 - val_loss: 1.7270 - val_acc: 0.8235\n",
      "Epoch 94/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3877e-07 - acc: 1.0000 - val_loss: 1.7034 - val_acc: 0.8235\n",
      "Epoch 95/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2558e-07 - acc: 1.0000 - val_loss: 1.7084 - val_acc: 0.8235\n",
      "Epoch 96/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1337e-07 - acc: 1.0000 - val_loss: 1.7173 - val_acc: 0.8235\n",
      "Epoch 97/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0333e-07 - acc: 1.0000 - val_loss: 1.7283 - val_acc: 0.8235\n",
      "Epoch 98/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 9.4769e-08 - acc: 1.0000 - val_loss: 1.7571 - val_acc: 0.8235\n",
      "Epoch 99/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 8.6968e-08 - acc: 1.0000 - val_loss: 1.7564 - val_acc: 0.8235\n",
      "Epoch 100/115\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 8.0738e-08 - acc: 1.0000 - val_loss: 1.7418 - val_acc: 0.8235\n",
      "Epoch 101/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 7.2858e-08 - acc: 1.0000 - val_loss: 1.7559 - val_acc: 0.8235\n",
      "Epoch 102/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.7201e-08 - acc: 1.0000 - val_loss: 1.7734 - val_acc: 0.8235\n",
      "Epoch 103/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 6.1381e-08 - acc: 1.0000 - val_loss: 1.7806 - val_acc: 0.8235\n",
      "Epoch 104/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 5.6480e-08 - acc: 1.0000 - val_loss: 1.7856 - val_acc: 0.8235\n",
      "Epoch 105/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.2409e-08 - acc: 1.0000 - val_loss: 1.7968 - val_acc: 0.8235\n",
      "Epoch 106/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.8561e-08 - acc: 1.0000 - val_loss: 1.8040 - val_acc: 0.8235\n",
      "Epoch 107/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.4462e-08 - acc: 1.0000 - val_loss: 1.7960 - val_acc: 0.8235\n",
      "Epoch 108/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.1380e-08 - acc: 1.0000 - val_loss: 1.7946 - val_acc: 0.8235\n",
      "Epoch 109/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.8501e-08 - acc: 1.0000 - val_loss: 1.8029 - val_acc: 0.8235\n",
      "Epoch 110/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.5565e-08 - acc: 1.0000 - val_loss: 1.8077 - val_acc: 0.8235\n",
      "Epoch 111/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.3097e-08 - acc: 1.0000 - val_loss: 1.8297 - val_acc: 0.8235\n",
      "Epoch 112/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.0843e-08 - acc: 1.0000 - val_loss: 1.8331 - val_acc: 0.8235\n",
      "Epoch 113/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.9146e-08 - acc: 1.0000 - val_loss: 1.8365 - val_acc: 0.8235\n",
      "Epoch 114/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.7477e-08 - acc: 1.0000 - val_loss: 1.8442 - val_acc: 0.8235\n",
      "Epoch 115/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.5902e-08 - acc: 1.0000 - val_loss: 1.8488 - val_acc: 0.8235\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6085 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "no_pre_train = models.Sequential()\n",
    "no_pre_train.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "no_pre_train.add(layers.Dense(100, activation=\"relu\"))\n",
    "no_pre_train.add(layers.Dense(50, activation=\"relu\"))\n",
    "no_pre_train.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "no_pre_train.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "no_pre_train.fit(X_train, y_train, epochs=115, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy_no_pre_train = no_pre_train.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy_no_pre_train * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "adce72f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_no_pre_train = no_pre_train.predict(test_kaggle)\n",
    "y_pred_no_pre_train = np.around(y_pred_no_pre_train, decimals=0).ravel()\n",
    "\n",
    "create_submission(y_pred_no_pre_train, \"NN_no_pre_train1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f58ea6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_acc = [accuracy_no_pre_train, accuracy_encoder_classification]\n",
    "xaxis = [\"Accuracy de la red\\n sin pre-entrenar\", \"Accuracy de la red\\n pre-entrenando con autoencoder\"]\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "barlist = plt.bar(xaxis, results_acc, width=0.15)\n",
    "barlist[0].set_color(\"r\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364e970",
   "metadata": {},
   "source": [
    "**Vamos a probar con una configuración de autoencoder más compleja**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a3da54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1778 - val_loss: 0.1727\n",
      "Epoch 2/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.1672 - val_loss: 0.1634\n",
      "Epoch 3/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1604 - val_loss: 0.1585\n",
      "Epoch 4/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.1564 - val_loss: 0.1551\n",
      "Epoch 5/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1532 - val_loss: 0.1525\n",
      "Epoch 6/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1508 - val_loss: 0.1500\n",
      "Epoch 7/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1485 - val_loss: 0.1478\n",
      "Epoch 8/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1468 - val_loss: 0.1475\n",
      "Epoch 9/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1458 - val_loss: 0.1473\n",
      "Epoch 10/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.1451 - val_loss: 0.1474\n",
      "Epoch 11/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1446 - val_loss: 0.1459\n",
      "Epoch 12/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1440 - val_loss: 0.1456\n",
      "Epoch 13/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1434 - val_loss: 0.1452\n",
      "Epoch 14/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1426 - val_loss: 0.1431\n",
      "Epoch 15/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1415 - val_loss: 0.1436\n",
      "Epoch 16/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1408 - val_loss: 0.1429\n",
      "Epoch 17/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1401 - val_loss: 0.1409\n",
      "Epoch 18/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1393 - val_loss: 0.1409\n",
      "Epoch 19/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1384 - val_loss: 0.1404\n",
      "Epoch 20/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1376 - val_loss: 0.1388\n",
      "Epoch 21/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1369 - val_loss: 0.1409\n",
      "Epoch 22/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1362 - val_loss: 0.1390\n",
      "Epoch 23/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1356 - val_loss: 0.1364\n",
      "Epoch 24/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1350 - val_loss: 0.1361\n",
      "Epoch 25/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1343 - val_loss: 0.1354\n",
      "Epoch 26/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.1338 - val_loss: 0.1360\n",
      "Epoch 27/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1333 - val_loss: 0.1369\n",
      "Epoch 28/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1328 - val_loss: 0.1346\n",
      "Epoch 29/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1323 - val_loss: 0.1337\n",
      "Epoch 30/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1319 - val_loss: 0.1345\n",
      "Epoch 31/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1317 - val_loss: 0.1329\n",
      "Epoch 32/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1313 - val_loss: 0.1321\n",
      "Epoch 33/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1308 - val_loss: 0.1318\n",
      "Epoch 34/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1307 - val_loss: 0.1312\n",
      "Epoch 35/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1306 - val_loss: 0.1301\n",
      "Epoch 36/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1304 - val_loss: 0.1308\n",
      "Epoch 37/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.1300 - val_loss: 0.1307\n",
      "Epoch 38/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1301 - val_loss: 0.1312\n",
      "Epoch 39/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1297 - val_loss: 0.1299\n",
      "Epoch 40/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1290 - val_loss: 0.1308\n",
      "Epoch 41/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1290 - val_loss: 0.1311\n",
      "Epoch 42/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1287 - val_loss: 0.1295\n",
      "Epoch 43/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1282 - val_loss: 0.1286\n",
      "Epoch 44/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1275 - val_loss: 0.1293\n",
      "Epoch 45/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1273 - val_loss: 0.1282\n",
      "Epoch 46/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1267 - val_loss: 0.1288\n",
      "Epoch 47/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1263 - val_loss: 0.1282\n",
      "Epoch 48/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.1265 - val_loss: 0.1281\n",
      "Epoch 49/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1269 - val_loss: 0.1277\n",
      "Epoch 50/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1268 - val_loss: 0.1280\n",
      "Epoch 51/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1268 - val_loss: 0.1260\n",
      "Epoch 52/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1261 - val_loss: 0.1278\n",
      "Epoch 53/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1257 - val_loss: 0.1263\n",
      "Epoch 54/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1256 - val_loss: 0.1278\n",
      "Epoch 55/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1263 - val_loss: 0.1289\n",
      "Epoch 56/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1261 - val_loss: 0.1262\n",
      "Epoch 57/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1258 - val_loss: 0.1281\n",
      "Epoch 58/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1262 - val_loss: 0.1269\n",
      "Epoch 59/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.1257 - val_loss: 0.1277\n",
      "Epoch 60/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.1257 - val_loss: 0.1263\n",
      "Epoch 61/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1259 - val_loss: 0.1262\n",
      "Epoch 62/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1263 - val_loss: 0.1261\n",
      "Epoch 63/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1271 - val_loss: 0.1278\n",
      "Epoch 64/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1265 - val_loss: 0.1273\n",
      "Epoch 65/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1256 - val_loss: 0.1262\n",
      "Epoch 66/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1263 - val_loss: 0.1301\n",
      "Epoch 67/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1262 - val_loss: 0.1270\n",
      "Epoch 68/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1266 - val_loss: 0.1273\n",
      "Epoch 69/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1266 - val_loss: 0.1265\n",
      "Epoch 70/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1273 - val_loss: 0.1287\n",
      "Epoch 71/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1263 - val_loss: 0.1262\n",
      "Epoch 72/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1265 - val_loss: 0.1275\n",
      "Epoch 73/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1265 - val_loss: 0.1296\n",
      "Epoch 74/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1275 - val_loss: 0.1293\n",
      "Epoch 75/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1274 - val_loss: 0.1310\n",
      "Epoch 76/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1271 - val_loss: 0.1287\n",
      "Epoch 77/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1276 - val_loss: 0.1289\n",
      "Epoch 78/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1270 - val_loss: 0.1284\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1273 - val_loss: 0.1283\n",
      "Epoch 80/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1272 - val_loss: 0.1279\n",
      "Epoch 81/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1274 - val_loss: 0.1289\n",
      "Epoch 82/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1277 - val_loss: 0.1268\n",
      "Epoch 83/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1278 - val_loss: 0.1292\n",
      "Epoch 84/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1276 - val_loss: 0.1299\n",
      "Epoch 85/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1279 - val_loss: 0.1283\n",
      "Epoch 86/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1273 - val_loss: 0.1291\n",
      "Epoch 87/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1278 - val_loss: 0.1282\n",
      "Epoch 88/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1269 - val_loss: 0.1273\n",
      "Epoch 89/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1277 - val_loss: 0.1274\n",
      "Epoch 90/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1274 - val_loss: 0.1287\n",
      "Epoch 91/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1276 - val_loss: 0.1299\n",
      "Epoch 92/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1276 - val_loss: 0.1283\n",
      "Epoch 93/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1272 - val_loss: 0.1298\n",
      "Epoch 94/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1290 - val_loss: 0.1282\n",
      "Epoch 95/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1279 - val_loss: 0.1301\n",
      "Epoch 96/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1282 - val_loss: 0.1295\n",
      "Epoch 97/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1282 - val_loss: 0.1283\n",
      "Epoch 98/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1320\n",
      "Epoch 99/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.1286 - val_loss: 0.1312\n",
      "Epoch 100/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1274 - val_loss: 0.1290\n",
      "Epoch 101/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1273 - val_loss: 0.1264\n",
      "Epoch 102/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1276 - val_loss: 0.1279\n",
      "Epoch 103/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1284 - val_loss: 0.1284\n",
      "Epoch 104/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1282 - val_loss: 0.1296\n",
      "Epoch 105/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1301\n",
      "Epoch 106/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.1285 - val_loss: 0.1324\n",
      "Epoch 107/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1293 - val_loss: 0.1290\n",
      "Epoch 108/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1290 - val_loss: 0.1301\n",
      "Epoch 109/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1290 - val_loss: 0.1282\n",
      "Epoch 110/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1285 - val_loss: 0.1304\n",
      "Epoch 111/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1290 - val_loss: 0.1284\n",
      "Epoch 112/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1288 - val_loss: 0.1305\n",
      "Epoch 113/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.1291 - val_loss: 0.1277\n",
      "Epoch 114/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1309\n",
      "Epoch 115/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1286 - val_loss: 0.1306\n",
      "Epoch 116/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1285 - val_loss: 0.1320\n",
      "Epoch 117/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1302 - val_loss: 0.1294\n",
      "Epoch 118/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1287 - val_loss: 0.1307\n",
      "Epoch 119/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1288 - val_loss: 0.1299\n",
      "Epoch 120/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1289 - val_loss: 0.1314\n",
      "Epoch 121/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1284 - val_loss: 0.1282\n",
      "Epoch 122/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1287 - val_loss: 0.1296\n",
      "Epoch 123/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1289 - val_loss: 0.1310\n",
      "Epoch 124/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1299 - val_loss: 0.1330\n",
      "Epoch 125/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1306 - val_loss: 0.1310\n",
      "Epoch 126/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1296 - val_loss: 0.1307\n",
      "Epoch 127/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1293 - val_loss: 0.1350\n",
      "Epoch 128/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1303 - val_loss: 0.1327\n",
      "Epoch 129/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1298 - val_loss: 0.1307\n",
      "Epoch 130/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1296 - val_loss: 0.1309\n",
      "Epoch 131/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1293 - val_loss: 0.1289\n",
      "Epoch 132/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1289 - val_loss: 0.1308\n",
      "Epoch 133/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1285 - val_loss: 0.1292\n",
      "Epoch 134/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1287 - val_loss: 0.1305\n",
      "Epoch 135/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1298\n",
      "Epoch 136/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1286 - val_loss: 0.1292\n",
      "Epoch 137/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1283 - val_loss: 0.1304\n",
      "Epoch 138/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1281 - val_loss: 0.1305\n",
      "Epoch 139/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1280 - val_loss: 0.1291\n",
      "Epoch 140/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1281 - val_loss: 0.1293\n",
      "Epoch 141/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1287 - val_loss: 0.1315\n",
      "Epoch 142/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1296 - val_loss: 0.1306\n",
      "Epoch 143/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1312\n",
      "Epoch 144/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1284 - val_loss: 0.1289\n",
      "Epoch 145/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1280 - val_loss: 0.1292\n",
      "Epoch 146/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1285 - val_loss: 0.1310\n",
      "Epoch 147/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1284 - val_loss: 0.1301\n",
      "Epoch 148/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1280 - val_loss: 0.1273\n",
      "Epoch 149/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1279 - val_loss: 0.1288\n",
      "Epoch 150/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1279 - val_loss: 0.1296\n",
      "Epoch 151/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1286 - val_loss: 0.1297\n",
      "Epoch 152/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1282 - val_loss: 0.1285\n",
      "Epoch 153/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1280 - val_loss: 0.1284\n",
      "Epoch 154/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1281 - val_loss: 0.1314\n",
      "Epoch 155/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1280 - val_loss: 0.1270\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1282 - val_loss: 0.1306\n",
      "Epoch 157/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1279 - val_loss: 0.1286\n",
      "Epoch 158/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1276 - val_loss: 0.1303\n",
      "Epoch 159/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1275\n",
      "Epoch 160/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1275 - val_loss: 0.1293\n",
      "Epoch 161/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1275 - val_loss: 0.1288\n",
      "Epoch 162/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1285 - val_loss: 0.1315\n",
      "Epoch 163/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1289 - val_loss: 0.1295\n",
      "Epoch 164/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1280 - val_loss: 0.1296\n",
      "Epoch 165/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1285 - val_loss: 0.1298\n",
      "Epoch 166/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1284 - val_loss: 0.1265\n",
      "Epoch 167/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1280 - val_loss: 0.1287\n",
      "Epoch 168/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1292 - val_loss: 0.1322\n",
      "Epoch 169/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1285 - val_loss: 0.1295\n",
      "Epoch 170/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1287 - val_loss: 0.1319\n",
      "Epoch 171/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1290 - val_loss: 0.1307\n",
      "Epoch 172/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1289 - val_loss: 0.1322\n",
      "Epoch 173/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1307\n",
      "Epoch 174/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1286 - val_loss: 0.1310\n",
      "Epoch 175/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1285 - val_loss: 0.1335\n",
      "Epoch 176/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1292 - val_loss: 0.1284\n",
      "Epoch 177/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1282\n",
      "Epoch 178/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1291 - val_loss: 0.1302\n",
      "Epoch 179/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.1294 - val_loss: 0.1303\n",
      "Epoch 180/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1286 - val_loss: 0.1343\n",
      "Epoch 181/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1286 - val_loss: 0.1288\n",
      "Epoch 182/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1283 - val_loss: 0.1298\n",
      "Epoch 183/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1291 - val_loss: 0.1301\n",
      "Epoch 184/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1294 - val_loss: 0.1323\n",
      "Epoch 185/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1292 - val_loss: 0.1327\n",
      "Epoch 186/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1295 - val_loss: 0.1320\n",
      "Epoch 187/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1294 - val_loss: 0.1305\n",
      "Epoch 188/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1294 - val_loss: 0.1284\n",
      "Epoch 189/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1296 - val_loss: 0.1309\n",
      "Epoch 190/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1291 - val_loss: 0.1307\n",
      "Epoch 191/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1290 - val_loss: 0.1284\n",
      "Epoch 192/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1294 - val_loss: 0.1306\n",
      "Epoch 193/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1288 - val_loss: 0.1298\n",
      "Epoch 194/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1293 - val_loss: 0.1296\n",
      "Epoch 195/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.1290 - val_loss: 0.1290\n",
      "Epoch 196/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1285 - val_loss: 0.1286\n",
      "Epoch 197/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1290 - val_loss: 0.1301\n",
      "Epoch 198/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.1284 - val_loss: 0.1325\n",
      "Epoch 199/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1294 - val_loss: 0.1281\n",
      "Epoch 200/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.1293 - val_loss: 0.1298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb3390dc70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "input_layer2 = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded2 = layers.Dense(300, activation=\"relu\")(input_layer2)\n",
    "encoded2 = layers.Dense(250, activation=\"relu\")(encoded2)\n",
    "encoded2 = layers.Dense(200, activation=\"relu\")(encoded2)\n",
    "encoded2 = layers.Dense(150, activation=\"relu\")(encoded2)\n",
    "encoded2 = layers.Dense(100, activation=\"relu\")(encoded2)\n",
    "encoded2 = layers.Dense(50, activation=\"relu\")(encoded2)\n",
    "# Capas red decoder\n",
    "decoded2 = layers.Dense(50, activation=\"relu\")(encoded2)\n",
    "decoded2 = layers.Dense(100, activation=\"relu\")(decoded2)\n",
    "decoded2 = layers.Dense(150, activation=\"relu\")(decoded2)\n",
    "decoded2 = layers.Dense(200, activation=\"relu\")(decoded2)\n",
    "decoded2 = layers.Dense(250, activation=\"relu\")(decoded2)\n",
    "decoded2 = layers.Dense(300, activation=\"relu\")(decoded2)\n",
    "decoded2 = layers.Dense(410, activation=\"linear\")(decoded2)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder2 = models.Model(input_layer2, decoded2)\n",
    "\n",
    "# Compilar y entrenar el autoencoder\n",
    "autoencoder2.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "autoencoder2.fit(test_kaggle, test_kaggle, epochs=200, batch_size=64, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cac4d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2.save(\"autoencoder2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f747b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2 = models.load_model(\"autoencoder2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b26090fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: tf.Tensor(367.13974, shape=(), dtype=float32)\n",
      "MSE: tf.Tensor(0.121041566, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ERROR SOBRE X_train_tot (etiquetados)\n",
    "X_train_tot_pred = autoencoder2.predict(X_train_tot)\n",
    "\n",
    "print(\"MAPE:\", mape(X_train_tot, X_train_tot_pred))\n",
    "print(\"MSE:\", mse(X_train_tot, X_train_tot_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11ef5c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 410)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_tmp = np.abs((X_train_tot - X_train_tot_pred) / X_train_tot)\n",
    "mape_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f05e55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(mape_tmp.mean(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d99e659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03414634146341464"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mape_tmp.mean(axis=0) < 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5379c7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: tf.Tensor(452.5427, shape=(), dtype=float32)\n",
      "MSE: tf.Tensor(0.12940164, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ERROR SOBRE test_kaggle (no etiquetados)\n",
    "test_kaggle_pred = autoencoder2.predict(test_kaggle)\n",
    "\n",
    "print(\"MAPE:\", mape(test_kaggle, test_kaggle_pred))\n",
    "print(\"MSE:\", mse(test_kaggle, test_kaggle_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fca423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 434.28009033203125 +- 313.5392150878906\n"
     ]
    }
   ],
   "source": [
    "samples_num = 100\n",
    "mape_samples = []\n",
    "\n",
    "for _ in range(samples_num):\n",
    "    \n",
    "    args = np.random.choice(a=np.arange(0, test_kaggle.shape[0]), size=86, replace=False)\n",
    "\n",
    "    test_kaggle_reduc = test_kaggle.iloc[args, :]\n",
    "\n",
    "    y_pred_kaggle_reduc = autoencoder2.predict(test_kaggle_reduc)\n",
    "    tmp_mape = mape(test_kaggle_reduc, y_pred_kaggle_reduc)\n",
    "    mape_samples.append(tmp_mape)\n",
    "    \n",
    "print(f'MAPE: {np.mean(mape_samples)} +- {np.std(mape_samples)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7608b",
   "metadata": {},
   "source": [
    "En este caso, aumentar la complejidad del autoencoder no mejora excesivamente los resultados.\n",
    "\n",
    "Vamos a ver si se observa algún tipo de mejoría en los resultados de la red de clasificación (encoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebcb4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input2 = layers.Input(shape=(410,))\n",
    "encoder2 = encoder_input2\n",
    "for layer in autoencoder2.layers[1:7]:\n",
    "    encoder2 = layer(encoder2)\n",
    "encoder2 = models.Model(inputs=encoder_input2, outputs=encoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88afd9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 410)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               123300    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 250)               75250     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 200)               50200     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,050\n",
      "Trainable params: 299,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f591180",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_clasificacion2 = models.Sequential()\n",
    "encoder_clasificacion2.add(encoder2)\n",
    "encoder_clasificacion2.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e3d717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 5s 656ms/step - loss: 1.9184 - acc: 0.5098 - val_loss: 1.2401 - val_acc: 0.7059\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1.7995 - acc: 0.5098 - val_loss: 1.1947 - val_acc: 0.6471\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.7178 - acc: 0.5098 - val_loss: 1.1591 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.6495 - acc: 0.5098 - val_loss: 1.1319 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5925 - acc: 0.5098 - val_loss: 1.1096 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.5412 - acc: 0.5098 - val_loss: 1.0903 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.4982 - acc: 0.5294 - val_loss: 1.0741 - val_acc: 0.6471\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.4548 - acc: 0.5098 - val_loss: 1.0642 - val_acc: 0.6471\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.4227 - acc: 0.4902 - val_loss: 1.0541 - val_acc: 0.6471\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.3909 - acc: 0.5098 - val_loss: 1.0466 - val_acc: 0.5882\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.3624 - acc: 0.5098 - val_loss: 1.0403 - val_acc: 0.5882\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.3394 - acc: 0.5294 - val_loss: 1.0346 - val_acc: 0.5882\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.3151 - acc: 0.5294 - val_loss: 1.0293 - val_acc: 0.6471\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.2892 - acc: 0.5490 - val_loss: 1.0260 - val_acc: 0.6471\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.2678 - acc: 0.5686 - val_loss: 1.0239 - val_acc: 0.6471\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2475 - acc: 0.5686 - val_loss: 1.0203 - val_acc: 0.6471\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2383 - acc: 0.5686 - val_loss: 1.0178 - val_acc: 0.6471\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.2235 - acc: 0.5882 - val_loss: 1.0156 - val_acc: 0.6471\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2103 - acc: 0.5882 - val_loss: 1.0140 - val_acc: 0.6471\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1984 - acc: 0.5882 - val_loss: 1.0125 - val_acc: 0.6471\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1903 - acc: 0.5882 - val_loss: 1.0104 - val_acc: 0.6471\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1785 - acc: 0.6275 - val_loss: 1.0087 - val_acc: 0.6471\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1670 - acc: 0.6275 - val_loss: 1.0080 - val_acc: 0.6471\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1578 - acc: 0.6471 - val_loss: 1.0077 - val_acc: 0.6471\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 1.1478 - acc: 0.6275 - val_loss: 1.0064 - val_acc: 0.6471\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1391 - acc: 0.6275 - val_loss: 1.0051 - val_acc: 0.6471\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1368 - acc: 0.6078 - val_loss: 1.0023 - val_acc: 0.6471\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1259 - acc: 0.6078 - val_loss: 1.0013 - val_acc: 0.6471\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1186 - acc: 0.6078 - val_loss: 1.0012 - val_acc: 0.6471\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 1.1130 - acc: 0.6078 - val_loss: 0.9984 - val_acc: 0.6471\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1102 - acc: 0.6078 - val_loss: 1.0010 - val_acc: 0.6471\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1006 - acc: 0.6078 - val_loss: 1.0017 - val_acc: 0.6471\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0979 - acc: 0.6078 - val_loss: 1.0047 - val_acc: 0.6471\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0913 - acc: 0.6275 - val_loss: 1.0064 - val_acc: 0.6471\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0848 - acc: 0.6275 - val_loss: 1.0021 - val_acc: 0.6471\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0802 - acc: 0.6078 - val_loss: 1.0016 - val_acc: 0.6471\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0759 - acc: 0.6078 - val_loss: 0.9972 - val_acc: 0.6471\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.0713 - acc: 0.6078 - val_loss: 0.9953 - val_acc: 0.6471\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0672 - acc: 0.6078 - val_loss: 0.9907 - val_acc: 0.6471\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0610 - acc: 0.6078 - val_loss: 0.9872 - val_acc: 0.6471\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0567 - acc: 0.6078 - val_loss: 0.9870 - val_acc: 0.6471\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0518 - acc: 0.6078 - val_loss: 0.9818 - val_acc: 0.6471\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0492 - acc: 0.6078 - val_loss: 0.9745 - val_acc: 0.6471\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0445 - acc: 0.6078 - val_loss: 0.9676 - val_acc: 0.6471\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0401 - acc: 0.6078 - val_loss: 0.9619 - val_acc: 0.6471\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.0315 - acc: 0.6078 - val_loss: 0.9592 - val_acc: 0.6471\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0278 - acc: 0.6078 - val_loss: 0.9569 - val_acc: 0.6471\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.0254 - acc: 0.6078 - val_loss: 0.9507 - val_acc: 0.6471\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0187 - acc: 0.6078 - val_loss: 0.9504 - val_acc: 0.6471\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0136 - acc: 0.6078 - val_loss: 0.9500 - val_acc: 0.6471\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0121 - acc: 0.6078 - val_loss: 0.9435 - val_acc: 0.6471\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0065 - acc: 0.6078 - val_loss: 0.9429 - val_acc: 0.6471\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0000 - acc: 0.6078 - val_loss: 0.9377 - val_acc: 0.6471\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.9991 - acc: 0.6078 - val_loss: 0.9391 - val_acc: 0.6471\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.9914 - acc: 0.6078 - val_loss: 0.9332 - val_acc: 0.6471\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9874 - acc: 0.6078 - val_loss: 0.9320 - val_acc: 0.6471\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.9838 - acc: 0.6078 - val_loss: 0.9304 - val_acc: 0.6471\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.9807 - acc: 0.6078 - val_loss: 0.9222 - val_acc: 0.6471\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.9736 - acc: 0.6078 - val_loss: 0.9179 - val_acc: 0.6471\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.9753 - acc: 0.6078 - val_loss: 0.9110 - val_acc: 0.6471\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9658 - acc: 0.6078 - val_loss: 0.9062 - val_acc: 0.6471\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9614 - acc: 0.6078 - val_loss: 0.9033 - val_acc: 0.6471\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 52ms/step - loss: 0.9591 - acc: 0.6078 - val_loss: 0.8975 - val_acc: 0.6471\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9556 - acc: 0.6078 - val_loss: 0.8982 - val_acc: 0.6471\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9516 - acc: 0.6078 - val_loss: 0.8933 - val_acc: 0.6471\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.9473 - acc: 0.6078 - val_loss: 0.8881 - val_acc: 0.6471\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9457 - acc: 0.6078 - val_loss: 0.8821 - val_acc: 0.6471\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.9387 - acc: 0.6078 - val_loss: 0.8799 - val_acc: 0.6471\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9348 - acc: 0.6078 - val_loss: 0.8788 - val_acc: 0.6471\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9318 - acc: 0.6078 - val_loss: 0.8778 - val_acc: 0.6471\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.9295 - acc: 0.6078 - val_loss: 0.8717 - val_acc: 0.6471\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9233 - acc: 0.6078 - val_loss: 0.8678 - val_acc: 0.6471\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9194 - acc: 0.6078 - val_loss: 0.8657 - val_acc: 0.6471\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.9142 - acc: 0.6078 - val_loss: 0.8640 - val_acc: 0.6471\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9112 - acc: 0.6078 - val_loss: 0.8603 - val_acc: 0.6471\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.9063 - acc: 0.6078 - val_loss: 0.8573 - val_acc: 0.6471\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.9033 - acc: 0.6078 - val_loss: 0.8525 - val_acc: 0.6471\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8972 - acc: 0.6078 - val_loss: 0.8512 - val_acc: 0.6471\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8942 - acc: 0.6078 - val_loss: 0.8491 - val_acc: 0.6471\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8919 - acc: 0.6078 - val_loss: 0.8503 - val_acc: 0.6471\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8851 - acc: 0.6078 - val_loss: 0.8483 - val_acc: 0.6471\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8828 - acc: 0.6078 - val_loss: 0.8422 - val_acc: 0.6471\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8848 - acc: 0.6078 - val_loss: 0.8441 - val_acc: 0.6471\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8738 - acc: 0.6078 - val_loss: 0.8388 - val_acc: 0.6471\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8700 - acc: 0.6078 - val_loss: 0.8352 - val_acc: 0.6471\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8675 - acc: 0.6078 - val_loss: 0.8342 - val_acc: 0.6471\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.8661 - acc: 0.6078 - val_loss: 0.8278 - val_acc: 0.6471\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8592 - acc: 0.6078 - val_loss: 0.8250 - val_acc: 0.6471\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8560 - acc: 0.6078 - val_loss: 0.8236 - val_acc: 0.6471\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8530 - acc: 0.6078 - val_loss: 0.8228 - val_acc: 0.6471\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8496 - acc: 0.6078 - val_loss: 0.8200 - val_acc: 0.6471\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8466 - acc: 0.6078 - val_loss: 0.8154 - val_acc: 0.6471\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8424 - acc: 0.6078 - val_loss: 0.8102 - val_acc: 0.6471\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8407 - acc: 0.6275 - val_loss: 0.8114 - val_acc: 0.6471\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8379 - acc: 0.6078 - val_loss: 0.8129 - val_acc: 0.6471\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8312 - acc: 0.6078 - val_loss: 0.8110 - val_acc: 0.6471\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8294 - acc: 0.6078 - val_loss: 0.8105 - val_acc: 0.6471\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8320 - acc: 0.6078 - val_loss: 0.8042 - val_acc: 0.6471\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8215 - acc: 0.6275 - val_loss: 0.8024 - val_acc: 0.6471\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8245 - acc: 0.6275 - val_loss: 0.8044 - val_acc: 0.6471\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0039 - acc: 0.5556\n",
      "Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Congelar los pesos de todas las capas a excepción de la última\n",
    "for layer in encoder_clasificacion2.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Entrenar el modelo\n",
    "encoder_clasificacion2.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "encoder_clasificacion2.fit(X_train, y_train, epochs=100, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = encoder_clasificacion2.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef566bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2/2 [==============================] - 12s 1s/step - loss: 0.8294 - acc: 0.6078 - val_loss: 0.8819 - val_acc: 0.4706\n",
      "Epoch 2/15\n",
      "2/2 [==============================] - 1s 363ms/step - loss: 0.9482 - acc: 0.5882 - val_loss: 0.9035 - val_acc: 0.5882\n",
      "Epoch 3/15\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5651 - acc: 0.7451 - val_loss: 0.7633 - val_acc: 0.6471\n",
      "Epoch 4/15\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3117 - acc: 0.8431 - val_loss: 0.7735 - val_acc: 0.6471\n",
      "Epoch 5/15\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2729 - acc: 0.8431 - val_loss: 0.7867 - val_acc: 0.6471\n",
      "Epoch 6/15\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2737 - acc: 0.8824 - val_loss: 0.7244 - val_acc: 0.6471\n",
      "Epoch 7/15\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2190 - acc: 0.9412 - val_loss: 0.9827 - val_acc: 0.4706\n",
      "Epoch 8/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2071 - acc: 0.9412 - val_loss: 0.8128 - val_acc: 0.6471\n",
      "Epoch 9/15\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1655 - acc: 0.9412 - val_loss: 0.8008 - val_acc: 0.6471\n",
      "Epoch 10/15\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.1285 - acc: 1.0000 - val_loss: 0.8149 - val_acc: 0.6471\n",
      "Epoch 11/15\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.1213 - acc: 0.9804 - val_loss: 0.8701 - val_acc: 0.7059\n",
      "Epoch 12/15\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0993 - acc: 1.0000 - val_loss: 0.8138 - val_acc: 0.6471\n",
      "Epoch 13/15\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0873 - acc: 1.0000 - val_loss: 0.9433 - val_acc: 0.5882\n",
      "Epoch 14/15\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0843 - acc: 1.0000 - val_loss: 0.8418 - val_acc: 0.6471\n",
      "Epoch 15/15\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0594 - acc: 1.0000 - val_loss: 0.8730 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1405 - acc: 0.5556\n",
      "Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Descongelar los pesos de todas las capas a excepción de la última\n",
    "for layer in encoder_clasificacion2.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Entrenar el modelo\n",
    "encoder_clasificacion2.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "encoder_clasificacion2.fit(X_train, y_train, epochs=15, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy_encoder_clasificacion2 = encoder_clasificacion2.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy_encoder_clasificacion2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "358a4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_clasificacion2.save(\"encoder2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fcb73b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_pre_train_encoder2 = encoder_clasificacion2.predict(test_kaggle)\n",
    "y_pred_pre_train_encoder2 = np.around(y_pred_pre_train_encoder2, decimals=0).ravel()\n",
    "\n",
    "create_submission(y_pred_pre_train_encoder2, \"NN_pre_train_autoencoder2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aae118",
   "metadata": {},
   "source": [
    "Red sin pre-entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "574fa0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/115\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.6886 - acc: 0.5098 - val_loss: 0.6569 - val_acc: 0.5882\n",
      "Epoch 2/115\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6410 - acc: 0.5294 - val_loss: 0.6890 - val_acc: 0.5882\n",
      "Epoch 3/115\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.5060 - acc: 0.7647 - val_loss: 0.7015 - val_acc: 0.7059\n",
      "Epoch 4/115\n",
      "2/2 [==============================] - 1s 106ms/step - loss: 0.2672 - acc: 0.9216 - val_loss: 1.0483 - val_acc: 0.7059\n",
      "Epoch 5/115\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.2531 - acc: 0.9216 - val_loss: 0.7821 - val_acc: 0.7647\n",
      "Epoch 6/115\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0724 - acc: 1.0000 - val_loss: 0.8761 - val_acc: 0.7647\n",
      "Epoch 7/115\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.9357 - val_acc: 0.7647\n",
      "Epoch 8/115\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.0722 - val_acc: 0.7647\n",
      "Epoch 9/115\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.1005 - val_acc: 0.7647\n",
      "Epoch 10/115\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.1301 - val_acc: 0.7647\n",
      "Epoch 11/115\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.1710 - val_acc: 0.7647\n",
      "Epoch 12/115\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.2232 - val_acc: 0.7647\n",
      "Epoch 13/115\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.2658 - val_acc: 0.7647\n",
      "Epoch 14/115\n",
      "2/2 [==============================] - 0s 259ms/step - loss: 9.1661e-04 - acc: 1.0000 - val_loss: 1.3022 - val_acc: 0.7647\n",
      "Epoch 15/115\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 7.0584e-04 - acc: 1.0000 - val_loss: 1.3250 - val_acc: 0.7647\n",
      "Epoch 16/115\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.5042e-04 - acc: 1.0000 - val_loss: 1.3559 - val_acc: 0.7647\n",
      "Epoch 17/115\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 4.4291e-04 - acc: 1.0000 - val_loss: 1.3869 - val_acc: 0.7647\n",
      "Epoch 18/115\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.5953e-04 - acc: 1.0000 - val_loss: 1.4141 - val_acc: 0.7647\n",
      "Epoch 19/115\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2.9168e-04 - acc: 1.0000 - val_loss: 1.4433 - val_acc: 0.7647\n",
      "Epoch 20/115\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.3566e-04 - acc: 1.0000 - val_loss: 1.4684 - val_acc: 0.7647\n",
      "Epoch 21/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.9117e-04 - acc: 1.0000 - val_loss: 1.4941 - val_acc: 0.7647\n",
      "Epoch 22/115\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.5894e-04 - acc: 1.0000 - val_loss: 1.5143 - val_acc: 0.7647\n",
      "Epoch 23/115\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.3297e-04 - acc: 1.0000 - val_loss: 1.5261 - val_acc: 0.7647\n",
      "Epoch 24/115\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.1326e-04 - acc: 1.0000 - val_loss: 1.5643 - val_acc: 0.7647\n",
      "Epoch 25/115\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9.4585e-05 - acc: 1.0000 - val_loss: 1.5786 - val_acc: 0.7647\n",
      "Epoch 26/115\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 8.0807e-05 - acc: 1.0000 - val_loss: 1.5837 - val_acc: 0.7647\n",
      "Epoch 27/115\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.7214e-05 - acc: 1.0000 - val_loss: 1.6110 - val_acc: 0.7647\n",
      "Epoch 28/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.6928e-05 - acc: 1.0000 - val_loss: 1.6343 - val_acc: 0.7647\n",
      "Epoch 29/115\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 4.8536e-05 - acc: 1.0000 - val_loss: 1.6564 - val_acc: 0.7647\n",
      "Epoch 30/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.1561e-05 - acc: 1.0000 - val_loss: 1.6830 - val_acc: 0.7647\n",
      "Epoch 31/115\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.5801e-05 - acc: 1.0000 - val_loss: 1.6856 - val_acc: 0.7647\n",
      "Epoch 32/115\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.0266e-05 - acc: 1.0000 - val_loss: 1.7046 - val_acc: 0.7647\n",
      "Epoch 33/115\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 2.5852e-05 - acc: 1.0000 - val_loss: 1.7306 - val_acc: 0.7647\n",
      "Epoch 34/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.2004e-05 - acc: 1.0000 - val_loss: 1.7477 - val_acc: 0.7647\n",
      "Epoch 35/115\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 1.9068e-05 - acc: 1.0000 - val_loss: 1.7800 - val_acc: 0.7647\n",
      "Epoch 36/115\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.6423e-05 - acc: 1.0000 - val_loss: 1.7902 - val_acc: 0.7647\n",
      "Epoch 37/115\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.4133e-05 - acc: 1.0000 - val_loss: 1.8139 - val_acc: 0.7647\n",
      "Epoch 38/115\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.2139e-05 - acc: 1.0000 - val_loss: 1.8289 - val_acc: 0.7647\n",
      "Epoch 39/115\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0526e-05 - acc: 1.0000 - val_loss: 1.8409 - val_acc: 0.7647\n",
      "Epoch 40/115\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 9.1986e-06 - acc: 1.0000 - val_loss: 1.8601 - val_acc: 0.7647\n",
      "Epoch 41/115\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 8.1170e-06 - acc: 1.0000 - val_loss: 1.8876 - val_acc: 0.7647\n",
      "Epoch 42/115\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 7.1142e-06 - acc: 1.0000 - val_loss: 1.9082 - val_acc: 0.7647\n",
      "Epoch 43/115\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 6.2272e-06 - acc: 1.0000 - val_loss: 1.9201 - val_acc: 0.7647\n",
      "Epoch 44/115\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 5.4181e-06 - acc: 1.0000 - val_loss: 1.9486 - val_acc: 0.7647\n",
      "Epoch 45/115\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.7331e-06 - acc: 1.0000 - val_loss: 1.9573 - val_acc: 0.7647\n",
      "Epoch 46/115\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.1919e-06 - acc: 1.0000 - val_loss: 1.9825 - val_acc: 0.7647\n",
      "Epoch 47/115\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.6782e-06 - acc: 1.0000 - val_loss: 1.9931 - val_acc: 0.7647\n",
      "Epoch 48/115\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.2367e-06 - acc: 1.0000 - val_loss: 2.0155 - val_acc: 0.7647\n",
      "Epoch 49/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.8579e-06 - acc: 1.0000 - val_loss: 2.0425 - val_acc: 0.7647\n",
      "Epoch 50/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.4821e-06 - acc: 1.0000 - val_loss: 2.0530 - val_acc: 0.7647\n",
      "Epoch 51/115\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.1791e-06 - acc: 1.0000 - val_loss: 2.0589 - val_acc: 0.7647\n",
      "Epoch 52/115\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.9096e-06 - acc: 1.0000 - val_loss: 2.0731 - val_acc: 0.7647\n",
      "Epoch 53/115\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.6846e-06 - acc: 1.0000 - val_loss: 2.0933 - val_acc: 0.7647\n",
      "Epoch 54/115\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.4843e-06 - acc: 1.0000 - val_loss: 2.0966 - val_acc: 0.7647\n",
      "Epoch 55/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3065e-06 - acc: 1.0000 - val_loss: 2.1115 - val_acc: 0.7647\n",
      "Epoch 56/115\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1562e-06 - acc: 1.0000 - val_loss: 2.1274 - val_acc: 0.7647\n",
      "Epoch 57/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0108e-06 - acc: 1.0000 - val_loss: 2.1321 - val_acc: 0.7647\n",
      "Epoch 58/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 8.9515e-07 - acc: 1.0000 - val_loss: 2.1711 - val_acc: 0.7647\n",
      "Epoch 59/115\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 7.8420e-07 - acc: 1.0000 - val_loss: 2.1785 - val_acc: 0.7647\n",
      "Epoch 60/115\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 7.0636e-07 - acc: 1.0000 - val_loss: 2.2113 - val_acc: 0.7647\n",
      "Epoch 61/115\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.1825e-07 - acc: 1.0000 - val_loss: 2.2152 - val_acc: 0.7647\n",
      "Epoch 62/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 29ms/step - loss: 5.5016e-07 - acc: 1.0000 - val_loss: 2.2357 - val_acc: 0.7647\n",
      "Epoch 63/115\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 4.9145e-07 - acc: 1.0000 - val_loss: 2.2501 - val_acc: 0.7647\n",
      "Epoch 64/115\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 4.3842e-07 - acc: 1.0000 - val_loss: 2.2545 - val_acc: 0.7647\n",
      "Epoch 65/115\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.9269e-07 - acc: 1.0000 - val_loss: 2.2677 - val_acc: 0.7647\n",
      "Epoch 66/115\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.5123e-07 - acc: 1.0000 - val_loss: 2.2821 - val_acc: 0.7647\n",
      "Epoch 67/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.1365e-07 - acc: 1.0000 - val_loss: 2.2962 - val_acc: 0.7647\n",
      "Epoch 68/115\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 2.7883e-07 - acc: 1.0000 - val_loss: 2.3075 - val_acc: 0.7647\n",
      "Epoch 69/115\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.4870e-07 - acc: 1.0000 - val_loss: 2.3246 - val_acc: 0.7647\n",
      "Epoch 70/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2195e-07 - acc: 1.0000 - val_loss: 2.3341 - val_acc: 0.7647\n",
      "Epoch 71/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.9996e-07 - acc: 1.0000 - val_loss: 2.3554 - val_acc: 0.7647\n",
      "Epoch 72/115\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.7799e-07 - acc: 1.0000 - val_loss: 2.3582 - val_acc: 0.7647\n",
      "Epoch 73/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.5826e-07 - acc: 1.0000 - val_loss: 2.3757 - val_acc: 0.7647\n",
      "Epoch 74/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.4239e-07 - acc: 1.0000 - val_loss: 2.3760 - val_acc: 0.7647\n",
      "Epoch 75/115\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.2727e-07 - acc: 1.0000 - val_loss: 2.3922 - val_acc: 0.7647\n",
      "Epoch 76/115\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.1465e-07 - acc: 1.0000 - val_loss: 2.4082 - val_acc: 0.7647\n",
      "Epoch 77/115\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0271e-07 - acc: 1.0000 - val_loss: 2.4169 - val_acc: 0.7647\n",
      "Epoch 78/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.2484e-08 - acc: 1.0000 - val_loss: 2.4180 - val_acc: 0.7647\n",
      "Epoch 79/115\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 8.3282e-08 - acc: 1.0000 - val_loss: 2.4315 - val_acc: 0.7647\n",
      "Epoch 80/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 7.6683e-08 - acc: 1.0000 - val_loss: 2.4285 - val_acc: 0.7647\n",
      "Epoch 81/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 6.8546e-08 - acc: 1.0000 - val_loss: 2.4436 - val_acc: 0.7647\n",
      "Epoch 82/115\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.2263e-08 - acc: 1.0000 - val_loss: 2.4655 - val_acc: 0.7647\n",
      "Epoch 83/115\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.6888e-08 - acc: 1.0000 - val_loss: 2.4752 - val_acc: 0.7647\n",
      "Epoch 84/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 5.1780e-08 - acc: 1.0000 - val_loss: 2.4880 - val_acc: 0.7647\n",
      "Epoch 85/115\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.7555e-08 - acc: 1.0000 - val_loss: 2.5038 - val_acc: 0.7647\n",
      "Epoch 86/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.3197e-08 - acc: 1.0000 - val_loss: 2.5106 - val_acc: 0.7647\n",
      "Epoch 87/115\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.9583e-08 - acc: 1.0000 - val_loss: 2.5310 - val_acc: 0.7647\n",
      "Epoch 88/115\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.6332e-08 - acc: 1.0000 - val_loss: 2.5395 - val_acc: 0.7647\n",
      "Epoch 89/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.3423e-08 - acc: 1.0000 - val_loss: 2.5531 - val_acc: 0.7647\n",
      "Epoch 90/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.1114e-08 - acc: 1.0000 - val_loss: 2.5679 - val_acc: 0.7647\n",
      "Epoch 91/115\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 2.8800e-08 - acc: 1.0000 - val_loss: 2.5782 - val_acc: 0.7647\n",
      "Epoch 92/115\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 2.6734e-08 - acc: 1.0000 - val_loss: 2.5937 - val_acc: 0.7647\n",
      "Epoch 93/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.4783e-08 - acc: 1.0000 - val_loss: 2.6115 - val_acc: 0.7647\n",
      "Epoch 94/115\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 2.3187e-08 - acc: 1.0000 - val_loss: 2.6116 - val_acc: 0.7647\n",
      "Epoch 95/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.1303e-08 - acc: 1.0000 - val_loss: 2.6172 - val_acc: 0.7647\n",
      "Epoch 96/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.9404e-08 - acc: 1.0000 - val_loss: 2.6315 - val_acc: 0.7647\n",
      "Epoch 97/115\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.8039e-08 - acc: 1.0000 - val_loss: 2.6340 - val_acc: 0.7647\n",
      "Epoch 98/115\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.6567e-08 - acc: 1.0000 - val_loss: 2.6452 - val_acc: 0.7647\n",
      "Epoch 99/115\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.5325e-08 - acc: 1.0000 - val_loss: 2.6609 - val_acc: 0.7647\n",
      "Epoch 100/115\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.4633e-08 - acc: 1.0000 - val_loss: 2.6700 - val_acc: 0.7647\n",
      "Epoch 101/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.3697e-08 - acc: 1.0000 - val_loss: 2.6838 - val_acc: 0.7647\n",
      "Epoch 102/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2929e-08 - acc: 1.0000 - val_loss: 2.7013 - val_acc: 0.7647\n",
      "Epoch 103/115\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.2200e-08 - acc: 1.0000 - val_loss: 2.7219 - val_acc: 0.7647\n",
      "Epoch 104/115\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1788e-08 - acc: 1.0000 - val_loss: 2.7434 - val_acc: 0.7647\n",
      "Epoch 105/115\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.1497e-08 - acc: 1.0000 - val_loss: 2.7645 - val_acc: 0.7647\n",
      "Epoch 106/115\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1241e-08 - acc: 1.0000 - val_loss: 2.7816 - val_acc: 0.7647\n",
      "Epoch 107/115\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1009e-08 - acc: 1.0000 - val_loss: 2.7917 - val_acc: 0.7647\n",
      "Epoch 108/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0636e-08 - acc: 1.0000 - val_loss: 2.7956 - val_acc: 0.7647\n",
      "Epoch 109/115\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9.9512e-09 - acc: 1.0000 - val_loss: 2.8077 - val_acc: 0.7647\n",
      "Epoch 110/115\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 9.8032e-09 - acc: 1.0000 - val_loss: 2.8086 - val_acc: 0.7647\n",
      "Epoch 111/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 9.1476e-09 - acc: 1.0000 - val_loss: 2.8180 - val_acc: 0.7647\n",
      "Epoch 112/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 8.7218e-09 - acc: 1.0000 - val_loss: 2.8324 - val_acc: 0.7647\n",
      "Epoch 113/115\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 8.5252e-09 - acc: 1.0000 - val_loss: 2.8498 - val_acc: 0.7647\n",
      "Epoch 114/115\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 8.3955e-09 - acc: 1.0000 - val_loss: 2.8578 - val_acc: 0.7647\n",
      "Epoch 115/115\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 8.2259e-09 - acc: 1.0000 - val_loss: 2.8695 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.1371 - acc: 0.7778\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "no_pre_train2 = models.Sequential()\n",
    "no_pre_train2.add(layers.Dense(300, activation=\"relu\", input_shape=(410,)))\n",
    "no_pre_train2.add(layers.Dense(250, activation=\"relu\"))\n",
    "no_pre_train2.add(layers.Dense(200, activation=\"relu\"))\n",
    "no_pre_train2.add(layers.Dense(150, activation=\"relu\"))\n",
    "no_pre_train2.add(layers.Dense(100, activation=\"relu\"))\n",
    "no_pre_train2.add(layers.Dense(50, activation=\"relu\"))\n",
    "no_pre_train2.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "no_pre_train2.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "no_pre_train2.fit(X_train, y_train, epochs=115, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy_no_pre_train2 = no_pre_train2.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy_no_pre_train2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b396d1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_no_pre_train2 = no_pre_train2.predict(test_kaggle)\n",
    "y_pred_no_pre_train2 = np.around(y_pred_no_pre_train2, decimals=0).ravel()\n",
    "\n",
    "create_submission(y_pred_no_pre_train2, \"NN_no_pre_train2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "302fcfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_acc = [accuracy_no_pre_train2, accuracy_encoder_clasificacion2]\n",
    "xaxis = [\"Accuracy de la red\\n sin pre-entrenar\", \"Accuracy de la red\\n pre-entrenando con autoencoder\"]\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "barlist = plt.bar(xaxis, results_acc, width=0.15)\n",
    "barlist[0].set_color(\"r\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
