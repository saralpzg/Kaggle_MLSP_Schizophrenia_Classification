{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99f259b",
   "metadata": {},
   "source": [
    "# Optimización de un modelo de red neuronal (fully-connected)\n",
    "\n",
    "Este notebook recoge los resultados de la búsqueda del mejor modelo de clasificación mediante una red neuronal densa o fully-connected, ya que el uso de redes convolucionales no parece adecuado para un problema de datos tabulares.\n",
    "\n",
    "Para buscar el mejor modelo posible, se tratará de buscar los mejores hiperparámetros para el número de capas ocultas de la red, su anchura (número de neuronas), posible introducción de términos de regularización, optimizadores, ...\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40286d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías de optimización de hiperparámetros\n",
    "import optuna\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar los datos\n",
    "from data_and_submissions import *\n",
    "\n",
    "# Métodos para los entrenamientos con CV\n",
    "from train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea4b44",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3014e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data()\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1493353",
   "metadata": {},
   "source": [
    "# Prueba: efectividad preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cf423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d73d9",
   "metadata": {},
   "source": [
    "### Sin aplicar preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229ebc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_no_preprocess(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    Se va a utilizar para estudiar si las redes tienen un mejor funcionamiento si se escalan sus datos\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7d1592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:44,475]\u001b[0m A new study created in memory with name: no-name-81588589-8ab2-4318-8613-5e76a6c6d570\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:50,490]\u001b[0m Trial 0 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:52,110]\u001b[0m Trial 1 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:53,899]\u001b[0m Trial 2 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:55,292]\u001b[0m Trial 3 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 50, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:56,756]\u001b[0m Trial 4 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:59,197]\u001b[0m Trial 5 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:01,585]\u001b[0m Trial 6 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:03,246]\u001b[0m Trial 7 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:05,566]\u001b[0m Trial 8 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:07,384]\u001b[0m Trial 9 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:10,681]\u001b[0m Trial 10 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:12,839]\u001b[0m Trial 11 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:15,169]\u001b[0m Trial 12 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:17,460]\u001b[0m Trial 13 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:19,079]\u001b[0m Trial 14 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_no_preprocess = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_no_preprocess.optimize(objective_no_preprocess, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b989dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.4444444477558136], datetime_start=datetime.datetime(2022, 7, 3, 13, 1, 44, 477414), datetime_complete=datetime.datetime(2022, 7, 3, 13, 1, 50, 490850), params={'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_no_preprocess.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a955780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 366ms/step - loss: 0.6823 - acc: 0.5686 - val_loss: 0.6734 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4921 - acc: 0.8431 - val_loss: 0.9328 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4662 - acc: 0.7255 - val_loss: 0.6614 - val_acc: 0.7059\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1876 - acc: 1.0000 - val_loss: 0.6741 - val_acc: 0.6471\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0767 - acc: 1.0000 - val_loss: 0.8513 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.7580 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.7779 - val_acc: 0.5882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.8797 - val_acc: 0.7647\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.8762 - val_acc: 0.7059\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.9029 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6104 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_no_preprocess = models.Sequential()\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_no_preprocess.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_no_preprocess.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_no_preprocess.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483038e5",
   "metadata": {},
   "source": [
    "### Escalando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18948b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "preprocess = StandardScaler()\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a3405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_preprocess(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    Se va a utilizar para estudiar si las redes tienen un mejor funcionamiento si se escalan sus datos\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train_processed, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test_processed, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7712f7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:50,414]\u001b[0m A new study created in memory with name: no-name-ff3ad585-c237-465a-8fb9-9935c75b19d1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:51,978]\u001b[0m Trial 0 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:53,211]\u001b[0m Trial 1 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:55,057]\u001b[0m Trial 2 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:56,179]\u001b[0m Trial 3 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 50, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:57,315]\u001b[0m Trial 4 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:58,889]\u001b[0m Trial 5 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:59,978]\u001b[0m Trial 6 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:01,203]\u001b[0m Trial 7 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:02,811]\u001b[0m Trial 8 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:04,726]\u001b[0m Trial 9 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:06,515]\u001b[0m Trial 10 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:08,401]\u001b[0m Trial 11 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:09,645]\u001b[0m Trial 12 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:11,405]\u001b[0m Trial 13 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:12,714]\u001b[0m Trial 14 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_preprocess = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_preprocess.optimize(objective_preprocess, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f51d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.4444444477558136], datetime_start=datetime.datetime(2022, 7, 3, 13, 2, 50, 414191), datetime_complete=datetime.datetime(2022, 7, 3, 13, 2, 51, 977516), params={'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_preprocess.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8624554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 261ms/step - loss: 0.6690 - acc: 0.5686 - val_loss: 0.8292 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3761 - acc: 0.8627 - val_loss: 0.7716 - val_acc: 0.7059\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.1697 - acc: 0.9412 - val_loss: 0.6257 - val_acc: 0.8235\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0484 - acc: 1.0000 - val_loss: 0.6701 - val_acc: 0.7647\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.6927 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7372 - val_acc: 0.8235\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6386 - acc: 0.6111\n",
      "Accuracy: 61.11%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_no_preprocess = models.Sequential()\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_no_preprocess.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_no_preprocess.fit(X_train_processed, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_no_preprocess.evaluate(X_test_processed, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a45eb",
   "metadata": {},
   "source": [
    "Lo anterior muestra que el uso de los datos escalados puede hacer que, aún habiéndose escogido la misma infraestructura de red en el proceso de optimización, la misma red entrenada sobre los datos escalados pierde en accuracy más de un 20% frente a la entrenada con los datos sin aplicar ningún tipo de preprocesado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61745a4",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb208b",
   "metadata": {},
   "source": [
    "Para redes neuronales, compararemos los resultados obtenidos construyendo redes a partir de librerías distintas.\n",
    "\n",
    "**Comenzamos con ``MLPClassifier`` de ``sklearn`` y búsqueda de hiperparámetros con ``GridSearchCV``:**\n",
    "\n",
    "Documentación: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b4b39",
   "metadata": {},
   "source": [
    "El método debe recibir arquitecturas de red pre-definidas, por lo que probaremos topologías variadas en cuanto a profundidad, ancho y número de capas.\n",
    "\n",
    "_NOTA: el parámetro ``learning_rate`` sólo se aplica cuando el solver que se esté utilizando sea el \"sgd\", el cual toma el valor constamte por defecto. Podría resultar de especial utilidad cuando toma el valor \"adaptive\", en ese caso mantiene el valor del learning_rate constante mientras la curva de pérdida siga decreciendo, en el momento en que haya dos épocas consecutivas en las que no decrece un mínimo el valor de loss, el learning_rate se divide entre 5._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d163caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_MLPC = MLPClassifier(max_iter=1000, random_state=0)\n",
    "param_grid_MLPC = {\n",
    "    \"hidden_layer_sizes\": [(100, 200, 100, 1), (100, 100, 100, 100, 1), (200, 200, 100, 50, 1), (100, 250, 250, 100, 1)],\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"], # solver \"lbfgs\" no permite hacer los plots más abajo\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"] # únicamente válido junto con el solver \"sgd\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2733f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv_results_MLPC = train_GridSearchCV(model_MLPC, param_grid_MLPC, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d305580c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96fdd2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt = MLPClassifier(activation=\"relu\", hidden_layer_sizes=(100, 250, 250, 100, 1), solver=\"adam\",\n",
    "                               max_iter=1000, random_state=0)\n",
    "model_MLPC_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC = model_MLPC_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b89f6b",
   "metadata": {},
   "source": [
    "_COMPROBACIÓN: la función de activación elegida sólo afecta a las capas ocultas y no a la capa de clasificación en la salida._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8455bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logistic'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLPC_opt.out_activation_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6075466",
   "metadata": {},
   "source": [
    "Las anteriores celdas de código muestran un \"warning\" indicando que el método de computación alcanza el número máximo de iteraciones (épocas de entrenamiento) sin haber llegado a converger.\n",
    "\n",
    "El criterio para considerar que ha habido convergencia está definido en la documentación como: la reducción del valor de la función de loss es inferior a 1e-4 por un número de etapas determinado. \n",
    "\n",
    "La anterior condición por tanto no se está cumpliendo en nuestro entrenamiento, así que vamos a pintar la evolución de la función de pérdida para determinar si estamos cortando el entrenamiento demasiado pronto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a417d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.plot(model_MLPC_opt.loss_curve_)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3d32f",
   "metadata": {},
   "source": [
    "La anterior curva de loss parece tener una tendencia aún claramente descendiente cuando es cortada en la época número 1000. Se va a repetir el entrenamiento incrementando este valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c41d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_MLPC2 = MLPClassifier(max_iter=1500, random_state=0)\n",
    "cv_results_MLPC2 = train_GridSearchCV(model_MLPC2, param_grid_MLPC, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1316b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'identity',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'identity',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'identity',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC2[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC2, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1039b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt2 = MLPClassifier(activation=\"tanh\", hidden_layer_sizes=(200, 200, 100, 50, 1), solver=\"adam\",\n",
    "                                max_iter=1500, random_state=0)\n",
    "model_MLPC_opt2.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC2 = model_MLPC_opt2.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c9b4ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.plot(model_MLPC_opt2.loss_curve_)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af707e",
   "metadata": {},
   "source": [
    "Al aumentar el número de épocas, los resultados varían y el modelo que se retorna ahora como óptimo necesita solamente 25 épocas para converger.\n",
    "\n",
    "Sin embargo, sorprende que este último modelo que ha resultado generar predicciones con un mejor accuracy y que no sobrepasan el primer tope de 1000 iteraciones no haya sido el elegido en la primera búsqueda. Vamos a comparar las precisiones que han alcanzado cada uno de los modelos en el entrenamiento en cada una de las repeticiones de cross-validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb8248d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = {'activation': 'relu',\n",
    "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
    "  'learning_rate': 'constant',\n",
    "  'solver': 'adam'}\n",
    "\n",
    "result2 = {'activation': 'identity',\n",
    "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
    "  'learning_rate': 'constant',\n",
    "  'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd9170b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(cv_results_MLPC[\"params\"]):\n",
    "    if item == result1:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "for i, item in enumerate(cv_results_MLPC[\"params\"]):\n",
    "    if item == result2:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "171e0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO OPT (1000 iter) - Accuracy en primer entrenamiento: 0.6764705882352942\n",
      "MODELO OPT (1500 iter) - Accuracy en primer entrenamiento: 0.676470588235294\n"
     ]
    }
   ],
   "source": [
    "print(\"MODELO OPT (1000 iter) - Accuracy en primer entrenamiento:\", cv_results_MLPC[\"mean_test_score\"][91])\n",
    "print(\"MODELO OPT (1500 iter) - Accuracy en primer entrenamiento:\", cv_results_MLPC[\"mean_test_score\"][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5397be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(cv_results_MLPC2[\"params\"]):\n",
    "    if item == result1:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "for i, item in enumerate(cv_results_MLPC2[\"params\"]):\n",
    "    if item == result2:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21cca501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO OPT (1000 iter) - Accuracy en segundo entrenamiento: 0.6617647058823529\n",
      "MODELO OPT (1500 iter) - Accuracy en segundo entrenamiento: 0.676470588235294\n"
     ]
    }
   ],
   "source": [
    "print(\"MODELO OPT (1000 iter) - Accuracy en segundo entrenamiento:\", cv_results_MLPC2[\"mean_test_score\"][91])\n",
    "print(\"MODELO OPT (1500 iter) - Accuracy en segundo entrenamiento:\", cv_results_MLPC2[\"mean_test_score\"][13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d4a85",
   "metadata": {},
   "source": [
    "Se observa que en la primera prueba de ``GridSearchCV`` ambos modelos tienen una accuracy prácticamente idéntica durante el entrenamiento, aunque al no terminar de converger el primero (visto con las 1000 iteraciones), finalmente su accuracy tiene un decimal más y por ser en definitiva mayor, es el único modelo escogido. Sin embargo, al aumentar el margen de iteraciones, mientras que el segundo modelo (1500 iteraciones) no cambia su accuracy, el primero sigue entrenando y el valor final de precisión del entrenamiento en este segundo caso decrece.\n",
    "\n",
    "Por tanto, el óptimo hasta este momento y de acuerdo a las pruebas anteriores es el modelo obtenido en la segunda prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14ede2",
   "metadata": {},
   "source": [
    "La librería ``sklearn`` permite implementar un tercer optimizador, lbfgs, que no se ha incluído en las pruebas anteriores ya que no permite dibujar la curva de loss para hacer las anteriores comprobaciones. Por tanto, vamos ahora a probar y comparar los resultados manualmente incluyendo este optimizador.\n",
    "\n",
    "El solver ``sgd`` no se ha elegido en ninguna de las anteriores pruebas. Como en esta ocasión queremos comprobar si el solver ``lbfgs`` incrementa el accuracy frente a los resultados anteriores, prescindiremos del solver ``sgd`` y la optimización del tipo de learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f906f2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_MLPC3 = MLPClassifier(max_iter=1000, random_state=0)\n",
    "param_grid_MLPC3 = {\n",
    "    \"hidden_layer_sizes\": [(100, 200, 100, 1), (100, 100, 100, 100, 1), (200, 200, 100, 50, 1), (100, 250, 250, 100, 1)],\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"adam\", \"lbfgs\"]\n",
    "}\n",
    "cv_results_MLPC3 = train_GridSearchCV(model_MLPC3, param_grid_MLPC3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8e26327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC3[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC3, top_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f027b",
   "metadata": {},
   "source": [
    "Si volvemos a utilizar el máximo de 1000 iteraciones, el óptimo es el mismo obtenido en el primer caso. Vamos a repetir el intento ahora con 1500 épocas de máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83e7f5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_MLPC4 = MLPClassifier(max_iter=1500, random_state=0)\n",
    "cv_results_MLPC4 = train_GridSearchCV(model_MLPC4, param_grid_MLPC3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce5d8de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'identity',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC4[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC4, top_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df63b0",
   "metadata": {},
   "source": [
    "Nuevamente, se obtiene el mismo resultado que en el caso anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b5a47",
   "metadata": {},
   "source": [
    "**Usando la librería \"keras\"**\n",
    "\n",
    "Ahora utilizaremos la librería de ``keras``, por su mayor flexibilidad para intentar mejorar los resultados de la red neuronal.\n",
    "\n",
    "Comenzaremos repitiendo la búsqueda de hiperparámetros, ya que la propia librería de ``keras`` dispone de integración con otras que nos permitirán hacer una búsqueda algo más exhaustiva por ejemplo en cuanto al número de capas y neuronas en estas. Concretamente, vamos a utilizar ``optuna``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be2b93",
   "metadata": {},
   "source": [
    "Documentación:\n",
    "* https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html\n",
    "* https://optuna.org/\n",
    "\n",
    "Para reducir el coste computacional tomaremos de base resultados como la función de activación óptima: \"relu\", que hemos podido obtener con ``GridSearchCV``. Como por el contrario usando ``sklearn`` no hemos podido utilizar el optimizador RMSProp, vamos a probarlo también con ``optuna`` + ``keras`` para ver si mejora nuestros resultados.\n",
    "\n",
    "Búsqueda mediante la librería ``optuna`` probando 2 métodos de búsqueda de hiperparámetros:\n",
    "\n",
    "* **GridSampler:** equivalente a la anterior búsqueda de grid de sklearn. Lo usaremos para que los resultados sean comparables.\n",
    "* **TPE:** algoritmo para hacer una \"búsqueda inteligente\" de hiperparámetros. Debería ahorrar intentos de combinaciones haciendo una selección inteligente de las pruebas. En nuestro caso le permitiremos probar un 10% del número de combinaciones posibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1709fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_Grid(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea2fd41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 69.7862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 494.8482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 90.9870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6170 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 46.6576 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1258 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.0294 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 288.5728 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.6504 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5933 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 142.8663 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.7270 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2352 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 732.1923 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9942 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 732.3811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.6588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.2272 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.1639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 224.2741 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.3318 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.6441 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 38.8776 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.8652 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 31.4210 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.8353 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 283.0709 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.2802 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 462.0315 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.4848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3916 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3652 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0576 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 232.9863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3720 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2907 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.4828 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.3721 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0270 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6038 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9345 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.0564 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8681 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 411.3890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.2255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.2553 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 591.0481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1300 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.3877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 435.2255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 218.0949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5549 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 51.4952 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 628.0460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 276.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0364 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5098 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 10.2154 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 551.9952 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 35.4658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.3061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.7974 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6659 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 150.4092 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0846 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3682 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6708 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.2005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 383.4137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24.8128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 10.0530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 101.1976 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 254.7336 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.5362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 380.0765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 161.8851 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4697 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.5357 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.1960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 63.4781 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3094 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8384 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2383 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4806 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6706 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 588.7714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 242.4113 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 20.1233 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.5470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.2171 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7145 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8092 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3873 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6143 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 180.3341 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7283 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1899 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6565 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0854 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0933 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 381.4561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.3826 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 117.1806 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 771.4830 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0413 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.1277 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.8549 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.3919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.9966 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 216.1447 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1558 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.8059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1814 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0802 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.6196 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 209.2242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8551 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0810 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 234.7029 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6774 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 360.6982 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.6033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.3702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1051 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8516 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.4473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 218.3366 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6855 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.5115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0882 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.2897 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 115.8655 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1136 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.6916 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.6263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8085 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 192.4828 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 72.6795 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1117 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 629.6932 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8179 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.0301 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.9024 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5773 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.4599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0699 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0216 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 297.8686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1908 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7155 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3681 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.4110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24.8290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0568 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0516 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.8019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.9179 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.7893 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0288 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0288 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 388.1685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8568 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.4332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.1948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 327.6502 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.1641 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 126.6884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.5980 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 589.3439 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 627.9904 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 82.8663 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0236 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7951 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1390 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3529 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.6607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1341 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.9130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0267 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4193 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.7141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 273.9431 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.5759 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 45.1692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.0296 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3774 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3183 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5889 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0552 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.8691 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1376 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 162.8195 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 231.7535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.8422 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.7158 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 11.8654 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0356 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 386.6068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 70.1661 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.2903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.5446 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 494.7401 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4182 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3943 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6693 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3764 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.9301 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 170.0324 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 563.5418 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 77.1727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.0279 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 27.7409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.1132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.5386 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.7288 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.7496 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 52.1238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3100 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1858 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 383.1945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2384 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5298 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 918.4977 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 806.2645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.4076 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0458 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2912 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 176.8786 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 295.7862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2798 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8655 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 630.8490 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.8968 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 449.9582 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 70.4571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 106.7683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 461.6073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 78.3074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4663 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3697 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0389 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.6139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.3079 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 386.6426 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.1763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1413 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 373.6326 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.8725 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 53.4174 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 481.6244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5780 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2364 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 344.3321 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.8337 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.9184 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2874 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 299.8762 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 93.0416 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 773.1860 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6446 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2387 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0805 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 104.9414 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.3710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.7277 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 71.2332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.4580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9933 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 73.2355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7846 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1854 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0219 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0594 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.6462 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.7532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 231.3163 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.3688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0868 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7325 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 35.0124 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 508.2970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.1658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.0418 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 300.7625 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1053 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 13.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0267 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8660 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 10.6286 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 266.8074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8124 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 129.0731 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3733 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 505.3738 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.3382 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 478.3732 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 24.6135 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 509.7088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 147.7648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6453 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 22.2363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1281 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 528.6433 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 10.6356 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 23.0539 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.3355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.7298 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 34.5808 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 28.0114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5623 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.2861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.3630 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 164.7875 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.0396 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6698 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.0170 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.1012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.5049 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7951 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8908 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.3020 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1306 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.6821 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2393 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 859.4082 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 344.3083 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.0208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 192.7466 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 147.2730 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2882 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5516 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3576 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.4086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.1361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 695.1699 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6675 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.2250 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1310 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 167.0466 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0567 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 447.0075 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 192.3036 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 294.6945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8338 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 17.8281 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0462 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 223.1450 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7179 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.9938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1299 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 117.4040 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1055 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0584 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.5311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 81.9195 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.7667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.5973 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 227.0244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 95.2476 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8186 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0320 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 400.9089 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8004 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0814 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3726 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 222.7061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.0634 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.2573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1014 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 210.8700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 553.8110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 191.5216 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.4792 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.1793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3778 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1055 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 217.7917 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 498.3109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.3415 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.3289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6499 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 158.4293 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 100.9655 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0145 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0459 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 117.5754 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.0284 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 384.1049 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.8417 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2978 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 85.8562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 11.0784 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 509.1703 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1749 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.2072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.1657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 99.5962 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1387 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2246 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 216.9650 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1146 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6513 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2364 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5950 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2587 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0464 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8584 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 22.2576 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 627.3275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5226 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4641 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.6997 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 77.2795 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 162.6875 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 653.4517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 74.8117 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0663 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0808 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.2515 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.2957 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.0748 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 862.0706 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.1322 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 56.3965 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2968 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.3158 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 296.2159 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.5905 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 237.3076 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.3737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.1683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 13.0275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 336.7122 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8796 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 71.9861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 44.7825 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9454 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 654.6995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 807.4084 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1322 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0141 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 220.3938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 108.6753 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 44.6657 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 248.9508 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0860 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2605 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.0318 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0559 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 385.9670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 658.9546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 10.5634 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 560.6653 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2258 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 473.0182 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 26.6783 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0236 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 345.0347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 31.2988 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 45.1455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0728 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7939 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 209.7509 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3611 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 42.3096 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.0450 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 93.0434 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 375.1656 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8804 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7901 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6093 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.7245 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.0917 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1055 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 289.3942 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.5490 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 67.0743 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6511 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 320.9239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.3617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 56.3270 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1151 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 102.0612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 18.1379 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 103.3161 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 386.5034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8210 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.1117 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 314.4137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 772.4337 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 380.4077 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2782 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 48.8736 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8346 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 319.5580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.4989 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0496 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.2561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2511 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 58.2774 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 53.7045 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 731.9684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 25.8197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3719 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0518 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 171.7440 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4539 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8126 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 350.8772 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 657.9562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 208.2182 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.6036 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 612.2811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.1315 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0824 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 115.8639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 328.9264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0271 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 582.5518 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 320.2159 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.7584 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.9820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.3374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 303.6425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.1832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 357.5805 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 43.7573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6836 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4442 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3954 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 274.6381 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 247.0477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 57.0915 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 650.1208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 63.1919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 262.9255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.8493 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2905 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.0340 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.9637 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 222.1335 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 68.6861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0024 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.6402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 693.4355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.1074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6953 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5511 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.0064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1381 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 120.6959 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 156.3316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 33.3289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3074 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.4754 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 64.2256 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.7163 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 414.6489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 318.8993 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.6624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9633 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0564 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.1727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 124.7944 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.2647 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 346.5601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.5134 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2739 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0578 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 43.9433 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4637 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2338 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 302.6353 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6015 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.8253 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8689 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 68.9024 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.9784 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8052 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5421 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 742.8333 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.4505 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 20.2253 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.7003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1442 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.7168 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6656 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3602 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3093 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 621.9305 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 561.3339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.5736 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 297.9754 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 358.2672 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8024 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.9889 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8198 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 603.7072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.6626 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 320.4260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 24.7005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 302.9044 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.6069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1381 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.9160 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 399.5609 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7842 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2252 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1528 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 92.3793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.4210 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.9785 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 77.2416 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.3368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9085 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.7748 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 731.8297 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0749 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 414.5133 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6488 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 157.1971 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3795 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.2620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3507 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0378 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 692.6232 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 310.3976 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 498.1464 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0921 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 106.5792 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.8951 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3549 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 106.2220 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 284.6522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 40.0908 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5541 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 266.1101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0456 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 915.2061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.4116 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0528 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6501 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 630.7289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 18.8778 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0544 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 77.7881 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.4164 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5575 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 448.8741 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 284.1711 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2531 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5495 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 411.8541 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.6396 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7738 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.1537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0690 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.5081 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4689 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1389 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4682 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8000 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0187 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.9538 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0474 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 413.3782 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 436.9133 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6823 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1891 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.9164 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.5513 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0582 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.9427 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3600 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.8809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 461.2187 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.8205 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 86.8282 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.1119 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 78.0554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 32.5845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 771.5895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7022 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.6522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1632 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.4171 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.1170 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.1157 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.0624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.0011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 513.6729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.7782 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 19.6507 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3350 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 34.2834 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.8503 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 283.1481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 492.4922 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.0625 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.6518 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3983 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2063 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 94.8535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.6407 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.6016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 232.9322 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8779 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 177.8770 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.7754 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6527 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 77.2852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 305.1858 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8750 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2712 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.4957 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 239.6675 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 50.6449 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.7512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8094 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 209.0406 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 483.5680 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 101.6833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 61.7479 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 176.9864 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5974 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.9275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1302 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5211 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 134.8825 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.5496 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8112 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0458 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 85.8132 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 288.4691 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 10.5466 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 58.5347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.0197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.6488 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0186 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1383 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2736 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 85.4422 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 90.0100 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 58.8548 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5930 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7936 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.4491 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 32.3497 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.3088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 288.3137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.0430 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 591.2877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 496.9238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2351 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.7502 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.2537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4659 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 149.9510 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 50.3708 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 34.2859 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 511.2776 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4677 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 386.0549 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6930 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8785 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.2515 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.2659 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 44.5576 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 85.8679 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0514 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 157.4583 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8478 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.9500 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3698 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 48.2859 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.6522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.0206 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 126.2284 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.5879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.2748 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1249 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.6613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 195.5307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 412.1829 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 271.9011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0859 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4584 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5446 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 410.6285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0906 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 284.7461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.6107 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2605 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0822 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3795 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.4661 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4543 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0300 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 339.3152 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 317.0583 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 494.2000 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.2925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4465 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0320 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 131.7733 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 269.6621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0947 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 82.9629 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0495 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 302.7757 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.9851 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4480 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 178.9972 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 208.5619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 123.2645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0358 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 122.2102 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1390 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.9755 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2886 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 23.8112 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9992 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 262.8895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.2479 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 162.2162 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9741 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0259 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.9562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7954 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0963 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 420.3334 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0296 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 380.7231 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.7041 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.4208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 27.5069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.7275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5775 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5298 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4677 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.1114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 13.0412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 739.8173 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3968 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6538 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.4613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 659.3408 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0538 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 498.8090 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 293.2215 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6805 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0697 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.9598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 654.3632 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.6016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 92.2143 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4299 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.2162 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 205.4382 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 415.7329 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9874 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4635 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5835 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1429 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1386 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3795 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3712 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 264.9201 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.1364 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.0314 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0706 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 31.9304 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.6737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2358 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 124.1631 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6083 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.0909 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7958 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0675 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 479.3258 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0868 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 607.0055 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 478.4772 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 379.2328 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1647 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6525 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.4847 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 34.3342 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0283 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.6701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5844 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 589.1368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 34.2970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5326 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 506.3586 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 498.2726 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 12.8796 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5638 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 402.6284 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5117 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 87.7788 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3085 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1379 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 345.1914 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 10.4076 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 652.5826 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2883 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.2949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 115.7522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3258 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.3191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0468 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 57.2909 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.7833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.1057 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1406 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0951 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5113 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8466 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 505.3926 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5083 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2586 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 205.5238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.5412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0095 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0926 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6689 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.6015 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5550 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 12.5180 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.4751 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 204.6872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.4740 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 772.2203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.0421 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 124.8805 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1417 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 612.9396 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 221.7035 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0801 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0811 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0551 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.4574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 364.1409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 48.5669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.5947 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9331 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.2027 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 500.5953 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2181 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2859 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6801 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 69.6865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3547 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.8522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0112 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 188.2402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 17.8733 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 293.0750 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 250.9314 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3567 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 355.9678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 10.5068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.6236 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1896 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 48.4713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 11.8977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.2676 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 17.6250 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 209.5395 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.3302 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.0083 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 177.1897 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 28.2014 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 179.2687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2343 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6697 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 189.1410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 52.5995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 55.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2605 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 25.0728 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2892 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 93.7200 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.8027 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.0591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0293 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 321.0723 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 512.3847 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.4314 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8490 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2931 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 657.5074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.4429 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.9960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 28.0619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 11.7721 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 918.8510 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 14.4799 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 25.2409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5343 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8319 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 508.7013 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0664 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.7089 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5587 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0394 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 448.1431 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1052 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 63.2591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 380.9827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1279 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 57.2094 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 17.7236 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 283.1898 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.8913 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1303 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3633 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.0752 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0359 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5947 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.5485 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.7051 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.6601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.7413 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 39.3709 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 11.3795 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 75.0410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 588.7197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 739.0349 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5751 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.9581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 508.6827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 917.9735 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 79.4336 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 63.7281 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.3215 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 172.4202 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 506.1798 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 35.1316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.3763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6682 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1309 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1030 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.2115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 61.1911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0597 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0500 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.7575 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.4560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7031 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1112 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6719 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.4894 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.1104 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8090 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 77.5562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.2672 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.7736 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1397 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 238.3613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.9548 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.0257 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.4774 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8334 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 102.0114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 107.0969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 40.5615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1158 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0672 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.5307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5302 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2792 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 34.2046 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 11.3711 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.2903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4568 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3698 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6399 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 48.6848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0940 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8214 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.1471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3577 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.0152 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3662 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 125.9535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.8273 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 305.1812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 179.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.4995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 414.3945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7479 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 310.9599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.3347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.2125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 629.4733 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 769.3695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1154 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2282 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1049 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8842 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 208.7260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 150.6068 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1310 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 224.6582 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5629 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 128.9569 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.7490 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.6033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6444 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9981 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5160 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 506.9110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8097 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2705 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 61.8561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.4076 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 13.0293 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.6668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5744 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 61.1832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5633 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 128.5038 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4344 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2600 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 237.2491 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 614.4294 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 732.5709 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 410.4579 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 116.9221 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8146 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3699 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 557.2472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 337.3820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0503 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5551 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 22.3833 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0516 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.1222 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 309.0876 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.4286 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2929 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5805 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5859 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.6910 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 54.2072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.2801 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 170.2341 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.7688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 274.1425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 385.4321 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8045 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2559 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.1816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 53.1732 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6696 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.2194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 50.8524 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.3337 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.5281 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 240.7460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3171 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0089 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 287.9664 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.1546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1063 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7558 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.6688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.8115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 126.7176 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.8719 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6049 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3549 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1058 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1893 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6048 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 464.9872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 454.7866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1063 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0407 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.9417 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8954 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.5362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 386.6743 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 339.5243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.4751 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5201 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.6802 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 733.3398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1584 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3699 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1396 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6501 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.7230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8503 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2356 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 589.6174 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 209.1500 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2773 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 512.1397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6924 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.4687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1875 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6084 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.3617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 806.1194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2564 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7841 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 449.4206 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.8499 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 248.8892 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.6724 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 147.6217 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0907 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.1484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 523.6567 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.1306 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.8295 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 281.6943 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 562.9070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2759 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.3411 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.6371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5504 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.4335 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3247 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 446.5077 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 159.1580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.2373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.3802 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 500.3373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 533.0150 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8921 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 283.2298 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0364 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1411 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 178.8217 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 265.9313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.0377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0198 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1065 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.5816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 298.1224 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5196 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 355.1729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0706 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4625 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0696 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.2739 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6942 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0528 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 232.8080 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 149.1466 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 309.1033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 441.7204 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 509.5497 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7722 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.6018 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 557.2870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1136 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 156.5488 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.1346 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.9920 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 115.8295 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0044 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8755 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.3327 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1876 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7880 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 805.1394 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1418 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5623 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.1738 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.6345 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 746.7522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.8166 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2965 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0990 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 387.8458 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1067 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.9339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 352.4612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0174 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.5873 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9589 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.7276 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.7968 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5127 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 446.8248 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.6487 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0535 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": range(2, 6), \n",
    "                \"n_units\": range(50, 300, 50),\n",
    "                \"dropout\": np.arange(0, 0.6, 0.1),\n",
    "                \"kernel_regularizer\": [0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                \"optimizer\": [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study_Grid = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_Grid.optimize(objectiveNN_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5691260b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'Adam'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_Grid.get_trials())\n",
    "models_same_acc_OptunaSearchCV(study_Grid.get_trials(), top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d211270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 139.4926 - acc: 0.4706 - val_loss: 134.7087 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 133.7013 - acc: 0.5490 - val_loss: 129.0795 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 128.1192 - acc: 0.4902 - val_loss: 123.6406 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 122.7152 - acc: 0.5098 - val_loss: 118.3928 - val_acc: 0.6471\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 117.4984 - acc: 0.5098 - val_loss: 113.3357 - val_acc: 0.6471\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 112.4597 - acc: 0.5294 - val_loss: 108.4679 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 107.6321 - acc: 0.4902 - val_loss: 103.7876 - val_acc: 0.6471\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 102.9661 - acc: 0.6078 - val_loss: 99.2924 - val_acc: 0.6471\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 98.5190 - acc: 0.5490 - val_loss: 94.9779 - val_acc: 0.7059\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 94.2291 - acc: 0.5490 - val_loss: 90.8405 - val_acc: 0.7059\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 90.1191 - acc: 0.5098 - val_loss: 86.8759 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 86.9221 - acc: 0.5000\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Grid = models.Sequential()\n",
    "modelFC_optuna_Grid.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.L2(1), input_shape=(410,)))\n",
    "modelFC_optuna_Grid.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_Grid.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_Grid.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_Grid.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_Grid.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_Grid.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Grid.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb2cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_TPE(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6846d5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:03,525]\u001b[0m A new study created in memory with name: no-name-262720fd-e329-4af5-ba03-a4375bab514a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:04,691]\u001b[0m Trial 0 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 371.5739 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:06,425]\u001b[0m Trial 1 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 244.1016 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:07,708]\u001b[0m Trial 2 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:08,763]\u001b[0m Trial 3 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:09,629]\u001b[0m Trial 4 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0, 'kernel_regularizer': 0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 319.1033 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:10,740]\u001b[0m Trial 5 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.4, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 221.2820 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:11,641]\u001b[0m Trial 6 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.30000000000000004, 'kernel_regularizer': 1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:12,672]\u001b[0m Trial 7 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 160.8905 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:13,483]\u001b[0m Trial 8 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'kernel_regularizer': 1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 656.5302 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:14,564]\u001b[0m Trial 9 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.4, 'kernel_regularizer': 1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:15,642]\u001b[0m Trial 10 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:16,950]\u001b[0m Trial 11 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.5, 'kernel_regularizer': 0, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 772.2708 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:18,463]\u001b[0m Trial 12 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.30000000000000004, 'kernel_regularizer': 1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:19,480]\u001b[0m Trial 13 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.5, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 511.3837 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:20,825]\u001b[0m Trial 14 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:21,839]\u001b[0m Trial 15 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 627.1524 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:23,250]\u001b[0m Trial 16 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.2, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:24,341]\u001b[0m Trial 17 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:25,747]\u001b[0m Trial 18 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 627.6735 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:27,222]\u001b[0m Trial 19 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.1, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:28,221]\u001b[0m Trial 20 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.1, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:29,565]\u001b[0m Trial 21 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:30,641]\u001b[0m Trial 22 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:31,614]\u001b[0m Trial 23 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:32,572]\u001b[0m Trial 24 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 50, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:33,875]\u001b[0m Trial 25 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:35,133]\u001b[0m Trial 26 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:36,430]\u001b[0m Trial 27 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:38,279]\u001b[0m Trial 28 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:39,349]\u001b[0m Trial 29 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:40,704]\u001b[0m Trial 30 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.5, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:41,989]\u001b[0m Trial 31 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:43,355]\u001b[0m Trial 32 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.4, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:44,466]\u001b[0m Trial 33 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.5, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:45,618]\u001b[0m Trial 34 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.5, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 511.7257 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:47,108]\u001b[0m Trial 35 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:48,197]\u001b[0m Trial 36 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:49,298]\u001b[0m Trial 37 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:50,444]\u001b[0m Trial 38 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'kernel_regularizer': 0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:51,556]\u001b[0m Trial 39 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.4, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:52,808]\u001b[0m Trial 40 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:53,911]\u001b[0m Trial 41 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:54,843]\u001b[0m Trial 42 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:55,851]\u001b[0m Trial 43 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:56,907]\u001b[0m Trial 44 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:58,061]\u001b[0m Trial 45 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.4, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:17:59,311]\u001b[0m Trial 46 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:18:00,709]\u001b[0m Trial 47 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:18:02,247]\u001b[0m Trial 48 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'kernel_regularizer': 0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 305.7816 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-04 12:18:03,465]\u001b[0m Trial 49 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_TPE.optimize(objectiveNN_TPE, n_trials=50)\n",
    "# n_trials = (4 x 5 x 6 x 6 x 3) * 0.1 = 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9563b3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 4,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_TPE.get_trials())\n",
    "models_same_acc_OptunaSearchCV(study_TPE.get_trials(), top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d14b938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 224ms/step - loss: 0.7196 - acc: 0.5490 - val_loss: 0.6869 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6767 - acc: 0.5490 - val_loss: 0.6867 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7110 - acc: 0.5294 - val_loss: 0.6864 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6930 - acc: 0.5294 - val_loss: 0.6861 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7326 - acc: 0.5490 - val_loss: 0.6860 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7760 - acc: 0.4314 - val_loss: 0.6854 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7205 - acc: 0.4444\n",
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE = models.Sequential()\n",
    "modelFC_optuna_TPE.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.L2(0.0001), input_shape=(410,)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.L2(0.0001)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.L2(0.0001)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.L2(0.0001)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8da59",
   "metadata": {},
   "source": [
    "Veamos si podemos obtener mejores resultados cambiando la última capa con activación sigmoide por una activación softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "443bedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# En primer lugar, hay que adaptar los datos\n",
    "NUM_CLASSES = 2\n",
    "y_train_softmax = np_utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_softmax = np_utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b767209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveSoftmax_Grid(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación softmax\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b70e2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8867 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.0443 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8842 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 537.0402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.4254 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2188 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3094 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7560 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6560 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6352 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.6166 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6783 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6028 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5842 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6872 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 209.4733 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.9434 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2144 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7103 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 143.4724 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.3781 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8826 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7211 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5273 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 635.4772 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2736 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8921 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8523 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6610 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 733.0455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.2291 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9630 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7034 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8705 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5447 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.1725 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 224.8471 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.6269 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.3250 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.2538 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7499 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5025 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.1480 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2376 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6625 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6308 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 261.7139 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.1570 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 462.6800 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.9111 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7663 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9623 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8964 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7293 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 221.5957 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1465 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9391 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5688 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7287 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8977 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 53.2578 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.8217 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0059 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5836 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6440 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9480 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6029 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2914 - accuracy: 0.2222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.8148 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6166 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2559 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.0339 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5425 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 253.9886 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.1651 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7298 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.4643 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2118 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 512.4433 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7629 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8183 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.0579 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5832 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 366.4344 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 218.6974 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1416 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 51.7747 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 552.6921 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6790 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 180.3332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7221 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5710 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0750 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1867 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2813 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6764 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 611.3619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4590 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 25.9757 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6083 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 18.9228 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.3283 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.3355 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 119.4134 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6917 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6839 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3450 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.5238 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7092 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5563 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5295 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 309.9215 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.4873 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1802 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6286 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5522 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.7996 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 241.2989 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6747 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7505 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.6954 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 351.1821 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8053 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1396 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 162.4711 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1008 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9779 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4821 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7757 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6875 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.6545 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.5489 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5746 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8467 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9172 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8567 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1358 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 589.3948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 293.6705 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6853 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.0961 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6836 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0123 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4986 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 231.9344 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7080 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0222 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2355 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4838 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7115 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8128 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7404 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9156 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2207 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.4810 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6939 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2155 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2982 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6766 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7772 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6618 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 334.8988 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.2071 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8028 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.8627 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5658 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 650.0652 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5984 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6325 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7078 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7053 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7015 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.4273 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.9266 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.0295 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.6153 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6403 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6799 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6039 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 232.2648 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7357 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8325 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0805 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8416 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5462 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5549 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.1169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.6866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6532 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2885 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8405 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2510 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 212.3811 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2751 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1687 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7182 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 307.2395 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.7683 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9748 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6961 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.3500 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8273 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4019 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.6479 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 218.9034 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9075 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.7692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7228 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.9050 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 136.7720 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6833 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7243 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.9074 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2859 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6226 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5031 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 174.3693 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.7957 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3477 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 630.3688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4933 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.7331 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0697 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8035 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6092 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3358 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5784 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.6562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7683 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6356 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5214 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2677 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6841 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6750 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 317.0602 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6070 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7995 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4122 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9504 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3279 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5885 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.2548 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7065 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4285 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 9.1603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.5155 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.2139 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 9.9971 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6605 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7046 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.2606 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7177 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6903 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 298.4877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1713 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.0206 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2695 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4368 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 250.0892 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3588 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.1431 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6125 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 117.4176 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2953 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 556.6973 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 441.7192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5933 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 80.2516 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5806 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6330 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6605 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6379 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4695 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8181 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7448 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7524 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8689 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.9274 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7751 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.9472 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7247 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2045 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5711 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1222 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7937 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.5222 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 330.4181 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7255 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8153 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7817 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.4543 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6608 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4718 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1299 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7853 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.4635 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7340 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5735 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6012 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7040 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7861 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7216 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3084 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6765 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.2817 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6516 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7988 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8458 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 163.4521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5342 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 232.3995 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2277 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8342 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.8069 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6956 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.0976 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.4319 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5798 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2675 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5223 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 317.1424 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6776 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0034 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7800 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 36.5086 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 75.5172 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.5857 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 563.5345 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8716 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5121 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7512 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4196 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0921 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8844 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 80.9788 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 196.9132 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4904 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 464.5279 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 72.2938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7734 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7603 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7743 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1860 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.3831 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.4360 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.0628 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6924 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6076 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 347.0634 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.3543 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7728 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.0688 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6772 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.2188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6704 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0164 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8304 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 326.9392 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9403 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6596 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0634 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 810.3595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2969 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 806.6618 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 21.7103 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6066 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9906 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6130 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7058 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6104 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 118.7733 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6028 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 273.4521 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8510 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9421 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9782 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5274 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 521.0297 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5167 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0094 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2381 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7676 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7560 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7591 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 312.6117 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5943 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6039 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6880 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5075 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3223 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 70.4967 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 107.5480 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 462.2503 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5618 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.7512 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0269 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7045 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7792 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0066 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7243 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9375 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.6794 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5860 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6757 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.2397 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 387.7975 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8436 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6876 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 324.1488 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.0561 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.0548 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 510.7808 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8875 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9927 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8503 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 344.8448 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.3869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.9237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8281 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 319.1987 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9296 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 107.1107 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 690.5070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5558 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7081 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7297 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6085 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8769 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6560 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 105.6947 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4719 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7566 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4885 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6183 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.9497 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.7290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.3776 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6747 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4107 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.6986 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3446 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3065 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8917 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7734 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7250 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.1832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8017 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.2734 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 188.5826 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5126 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.5255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5356 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6160 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4776 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.9372 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6499 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 508.9452 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.8429 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5139 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7907 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 14.3481 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8070 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.2886 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6541 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 13.6935 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7990 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6370 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5360 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3008 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 246.5856 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5456 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6896 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8084 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 109.5175 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7183 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4847 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 311.8547 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6682 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 377.2771 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.0834 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 510.3871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 136.9198 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.3036 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.7386 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1072 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 564.1598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.3167 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8739 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5578 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.7375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5750 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0558 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 162.3816 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.7177 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6634 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6659 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.4763 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.3620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1431 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8302 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.3127 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7302 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6744 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 142.0981 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.1541 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6589 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3772 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.7264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.1242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.0897 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7152 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9143 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5869 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5968 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.5701 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8232 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0340 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2820 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9326 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7714 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0562 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 915.7045 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5805 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 196.2117 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4346 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 221.7141 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6001 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 98.9975 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0148 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7665 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9880 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0935 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0482 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6167 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8172 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 652.7383 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7447 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2718 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.1932 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6360 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8237 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 195.2606 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0176 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6637 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7539 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6399 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6270 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7739 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 447.5934 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 155.3244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5097 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6866 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 385.0049 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6790 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3848 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.9899 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6904 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5892 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 108.3848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.3973 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1160 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.8009 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7133 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 92.7922 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.5307 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0065 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5751 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.1378 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7908 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 80.6674 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5268 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.2835 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1854 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 80.0704 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6986 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6975 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5990 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 89.6103 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5037 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0576 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6534 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3306 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5594 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1426 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2059 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 355.5435 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6372 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3545 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6993 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3993 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5526 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0031 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8259 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7040 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5399 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 284.4939 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5988 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.9418 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.9300 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5835 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5971 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 153.3098 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9938 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6787 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 651.6195 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 218.1441 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.6568 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 17.6874 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0168 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6949 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9380 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 204.8104 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6515 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7562 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 427.2111 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.7636 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7026 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.1107 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1503 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 213.7136 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.8322 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7334 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6549 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7019 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 97.2660 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6145 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7350 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6916 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3551 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 293.9474 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.7619 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8896 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7831 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 67.9318 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2055 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5747 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7228 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 419.5901 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1159 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.5263 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 91.2116 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6603 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6361 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.0614 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8235 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5037 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6627 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 250.9415 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6574 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5499 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7167 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6353 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2585 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6199 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6646 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7457 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1590 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8491 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7585 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.1318 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5840 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1384 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.7448 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 588.5208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7090 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7925 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0630 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9566 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7002 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5656 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5875 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8532 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8746 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.9502 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 72.0117 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 163.3671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 473.5829 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.7982 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7941 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6080 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 237.3777 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1070 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9962 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7713 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7907 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 809.6971 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5624 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6819 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.6651 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1272 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.6617 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 355.2050 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1771 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7720 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 196.4521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4027 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.3886 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7965 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.1885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6637 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 222.3569 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6339 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6751 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6590 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 59.9842 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7738 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.4612 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6528 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4880 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5495 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7228 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 437.6110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8437 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 585.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5125 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0604 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6855 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7849 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5803 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0082 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6420 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8167 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 207.2886 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4907 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 109.3415 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9337 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.5734 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7148 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7976 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8957 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7913 - accuracy: 0.3889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5580 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7954 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6840 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9732 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.3888 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5970 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6777 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7478 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7452 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8720 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5902 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.6338 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7347 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 440.5575 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7378 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8722 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 561.3057 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8309 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 473.6815 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.7208 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6962 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.9611 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 345.6956 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.5858 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5999 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.0871 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1418 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3053 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7293 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6854 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 210.3029 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0754 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5708 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5970 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.4433 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6899 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0755 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.0922 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 310.6752 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5122 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6378 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3717 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5262 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2803 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.0443 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.5275 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7744 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 210.0481 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5688 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.4221 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2583 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9464 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 321.5074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.3990 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.3271 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6404 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.9310 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7518 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6983 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.8461 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9652 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 95.0773 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.1388 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3555 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5171 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 98.5952 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6390 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 163.2123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 650.9927 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6820 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 299.1209 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8996 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.1119 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2542 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 320.2390 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 95.1111 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6549 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6828 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5832 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7706 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8837 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2277 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6905 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.8257 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.4169 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 635.2374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6650 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0755 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0819 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6799 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7142 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 172.4359 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0029 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2004 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5015 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.9866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 374.2652 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 177.6897 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2966 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 612.9702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.2587 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6133 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7810 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 126.2614 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3429 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6366 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5950 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 291.4325 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4884 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 500.2860 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 232.3389 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5516 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.6432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4732 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6722 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1170 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 238.2037 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.6360 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7053 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 358.2623 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.0775 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5580 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7369 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2639 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0923 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6566 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6534 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 207.2694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7071 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6800 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 265.4708 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9498 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5868 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9337 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5792 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.7849 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 739.1060 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.3269 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 305.9714 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9479 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.0950 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9407 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4796 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7616 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9053 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8042 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6798 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9787 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.0022 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2443 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6676 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 222.7284 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.2332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5955 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9385 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.5954 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7182 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6255 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5079 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6895 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2150 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6594 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.8433 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 534.8525 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7505 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.4398 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4157 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2817 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5002 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6707 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7249 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 128.2646 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5981 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 125.0740 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.0402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9837 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5328 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6819 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7708 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.9227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7416 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6506 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 88.4166 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 369.8265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5811 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6484 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.3167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3376 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2843 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6643 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9789 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6049 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5871 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7353 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4073 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 119.5793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7219 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6422 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8773 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.6520 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 272.5599 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6851 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5208 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.7156 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9754 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7719 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5681 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.9211 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5097 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0575 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8770 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 288.2952 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6562 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5850 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5665 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 66.9125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5421 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5558 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.7990 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2289 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5271 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8651 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2936 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.2176 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7061 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2490 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5567 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6977 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 632.6739 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.5074 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.7552 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5263 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0099 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6988 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6639 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6907 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7064 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.2409 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6451 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1034 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5345 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0072 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9994 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 622.6200 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7349 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 404.7609 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2716 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 298.6513 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0181 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7380 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 376.8694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5402 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.8115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5209 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 343.5222 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0771 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3668 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 320.9557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.6202 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.4226 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7407 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.5977 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6892 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7061 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6081 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 354.2845 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0354 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5111 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5083 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.0285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.7152 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6562 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7169 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8171 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.2052 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.9323 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.0998 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4210 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2526 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1626 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5253 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5660 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.9022 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5851 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 732.5035 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8812 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7280 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 329.9258 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6283 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3033 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 157.7784 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9065 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 61.2000 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1327 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6130 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5678 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 693.2808 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1588 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 330.4710 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 391.4030 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7705 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7875 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 107.1784 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1412 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9955 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.4430 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8851 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 91.0112 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1654 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 285.2411 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.6584 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6271 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0819 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 232.1811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6714 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7316 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0135 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 915.8199 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1904 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.5821 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7576 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6989 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5045 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2361 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4652 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 631.3956 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.5273 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8259 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 69.6259 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.9869 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6836 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 449.5457 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 262.6373 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9164 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0787 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5313 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.8508 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.1970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3175 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.9747 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5902 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5190 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.0172 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6713 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0995 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8081 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2433 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4302 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7789 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6259 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.9621 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5533 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3296 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5968 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5172 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 413.9510 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 437.5862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8050 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8857 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5382 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7042 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7280 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1895 - accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7520 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9764 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7562 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 27.2017 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1136 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2873 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 500.6520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.7539 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 72.2325 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6708 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.5116 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.1768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7799 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 650.1465 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2111 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.3159 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4227 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7314 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.4023 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7288 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.3921 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5868 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6991 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 56.4636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.7007 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 459.1422 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7677 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4563 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6290 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0785 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3155 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6897 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6244 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.2009 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 116.1065 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 283.7362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 534.4053 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6866 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3554 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5806 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6352 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3952 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.1737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7158 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7508 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6967 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7102 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1471 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2061 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 233.5361 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7749 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5548 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4396 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 178.5318 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.3554 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7443 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3013 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.9052 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 305.8543 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5162 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7251 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3258 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.8484 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6811 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9134 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6733 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4385 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5171 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 214.2368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2687 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.5470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5635 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6547 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8533 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5630 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.9803 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5307 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2529 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 146.3903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 409.4544 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8160 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.5522 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.4735 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0314 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7289 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 177.3895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8439 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2716 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.6861 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7089 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5748 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6629 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.7957 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 187.3620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.2354 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5532 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5699 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7451 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 90.8480 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 193.1645 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.6372 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3766 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6312 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7387 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2776 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7380 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3363 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7577 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6024 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8397 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2653 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5807 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7382 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.1354 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.0793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.2315 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5553 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6785 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4656 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.8937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.6455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5128 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.0068 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7016 - accuracy: 0.2222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6770 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6845 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7138 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9156 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7116 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2575 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 288.7431 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.3644 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8267 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8014 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5849 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 550.6597 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9408 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 326.2065 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7840 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9017 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.4223 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.8669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9667 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 169.5600 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.6867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.4276 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2309 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 449.3864 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6220 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1505 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5494 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 277.8253 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6635 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9731 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2277 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6782 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.5772 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.4503 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.6789 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5397 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2436 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5494 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.1859 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 67.9968 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6889 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6871 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5886 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 142.3519 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5334 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1536 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4053 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4838 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6953 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9801 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.6969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6722 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3622 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7912 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6930 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.5240 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.4486 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9172 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6343 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5761 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.0576 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5861 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6365 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.5658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8181 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6282 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7394 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2497 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 186.4850 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 347.2325 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6530 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7364 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8003 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 214.0444 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5374 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6823 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0917 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1846 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5988 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7153 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 183.7212 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9512 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6138 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 212.0882 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.9456 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7585 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8637 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7800 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7558 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6980 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3879 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7042 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9251 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0726 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5500 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 324.3291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 222.8174 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 536.4208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6237 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9422 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.5046 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6342 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1003 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8310 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 132.4403 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8420 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 292.9778 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4302 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.0013 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5244 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6367 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 303.4536 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 406.4555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5853 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1266 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 228.5495 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 174.1876 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7063 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5452 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 119.0770 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6048 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 149.5060 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8273 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 149.1720 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9962 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.8011 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2376 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9371 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 285.6040 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.2396 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 139.6710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9823 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7516 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.0967 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5311 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7308 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4860 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1936 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7067 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7870 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5495 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6686 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 536.3434 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5561 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 216.8874 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.9227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6487 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4000 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2586 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2158 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.9193 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2535 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0752 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7449 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1917 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6942 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6740 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6290 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0179 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6929 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.7043 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 695.2267 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0421 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7274 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3372 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.1455 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5302 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 608.7093 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8057 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3712 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 405.7819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6393 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 243.2144 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2429 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9092 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.8224 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 474.2853 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6077 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7245 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2750 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.2779 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7328 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.9635 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 175.4264 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5304 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7817 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 416.3855 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6416 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7882 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7459 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8917 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1634 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6412 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0406 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0570 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9488 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6699 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0432 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9473 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7580 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 265.4999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.0922 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8431 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2506 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7069 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7006 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.4320 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5157 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7541 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6368 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.9857 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2568 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7709 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6562 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6078 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0765 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.3481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2116 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.8520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2119 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8338 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5517 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2871 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6907 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 426.5751 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1494 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6995 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.7255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 451.7877 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 411.8621 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0860 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6302 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3006 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.5629 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5846 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6385 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.6456 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7218 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3781 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.9896 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5773 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.8596 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9612 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0654 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6870 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7146 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 589.7748 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5765 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0631 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.9905 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9363 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5322 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 431.4645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 427.2064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6438 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.9549 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.1689 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0938 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0374 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 323.8364 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9647 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.4611 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6698 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5672 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 345.8759 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5855 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.8098 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 602.5072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0321 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.7537 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 132.1401 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0876 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9703 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7441 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.0357 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8571 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0964 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5975 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7109 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6250 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9785 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1414 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6787 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5497 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 338.0662 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0774 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1857 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4840 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 170.9267 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.9212 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0448 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4968 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9145 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7092 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5327 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2547 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7570 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0279 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.1066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9718 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.2016 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 174.8093 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8354 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.6946 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 513.5250 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7060 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 294.9747 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6321 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 122.6007 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7619 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3341 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5837 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7530 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0968 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6905 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 475.1464 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7080 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4849 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3053 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5318 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7401 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 126.6023 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8012 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7888 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6019 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.4532 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 384.5989 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.8742 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2275 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.4116 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6309 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.5802 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2675 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 334.8168 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9691 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5784 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9396 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3194 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3458 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.4588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6621 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.4854 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5840 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 158.2312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.8086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2410 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5448 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6068 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2910 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 310.2472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 276.1907 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9733 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 341.1696 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.3230 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6179 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8555 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6761 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8390 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.4631 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.0514 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.3668 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5214 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.1746 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 202.3581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.3608 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.5014 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 177.8800 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.1563 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7520 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.0674 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 166.0393 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7746 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9148 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3525 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5642 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 223.0130 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7353 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.4104 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.8471 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5736 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9762 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4749 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8759 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 72.9920 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 125.4631 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7922 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6376 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0095 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7091 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7209 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5824 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7247 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 321.6595 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2885 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 513.0436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.4629 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3628 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8220 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6585 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7311 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7266 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7149 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 658.0864 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.8547 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.2315 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.1093 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.9212 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 919.5223 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.2209 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.6437 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6377 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9950 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6521 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5794 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 476.9482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7107 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7426 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.4176 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2301 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5526 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6138 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 448.7285 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7004 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7906 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 64.3997 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 276.4033 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7094 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7689 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0287 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.4684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4845 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5948 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.5198 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 305.8274 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.5366 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7369 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9587 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 45.5384 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7406 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2670 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5518 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6344 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6955 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6708 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3749 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5668 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.0692 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.9836 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1757 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3658 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2412 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9836 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 70.4248 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 475.2817 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 535.2654 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2414 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4932 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 393.1339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7305 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6791 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 918.5177 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5799 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.5691 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.4123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6961 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.8015 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 179.4899 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 367.0105 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.8488 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6820 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8787 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6518 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.5711 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0472 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3578 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8289 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6119 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.9036 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6973 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7585 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.7170 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6007 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6555 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.6925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8522 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6051 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3842 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5792 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5199 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3496 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.2292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6900 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.7872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5927 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4861 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.7948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8697 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.0203 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9686 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9655 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.2264 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7279 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6941 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1676 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7718 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 239.0545 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 50.0393 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0814 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6803 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.1400 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6824 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8616 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 50.2771 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5879 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9166 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6607 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.0308 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6030 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 90.1280 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 24.3665 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7081 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7457 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1106 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7455 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7427 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3891 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.2376 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2837 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4330 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4718 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.7747 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.8122 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7641 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.9667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2229 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5071 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6081 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.1245 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4918 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.1584 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6738 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9525 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6694 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5343 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.2856 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9541 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.6802 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8954 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0135 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 116.3866 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.0952 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 305.7217 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 110.9202 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.1555 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 349.0944 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 71.5110 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 331.1659 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.5834 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6058 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.5902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5378 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 554.0226 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 611.3935 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7831 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7071 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7234 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5927 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5800 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3991 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 156.7838 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 145.5427 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7041 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7353 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8026 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 167.9391 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6558 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3230 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6529 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2759 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 129.6274 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6779 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 102.4192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.9577 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5704 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4422 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6228 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7821 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.5593 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6882 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6900 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 266.2076 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8582 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4569 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8329 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7771 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 86.0255 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.8543 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.6618 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 95.2421 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7841 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5659 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6838 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.0736 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2130 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 113.5483 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6407 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9549 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.8873 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7180 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8944 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6937 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5955 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 615.1028 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7628 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 733.2369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 183.5898 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.5137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6097 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3664 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0207 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 626.2202 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 295.0518 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6812 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0282 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7028 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5398 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5876 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0722 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6331 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.2852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5308 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5508 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.1416 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 323.9302 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5224 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6193 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.3570 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2584 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2139 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.9088 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.0208 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.5274 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 170.8796 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0178 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.8380 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8805 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7526 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 238.6060 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 295.3045 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4210 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8255 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9511 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.2879 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3344 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6790 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5594 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2383 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.2179 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.1919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8290 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3903 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6374 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.0050 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7044 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4937 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 270.0653 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9146 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8758 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8048 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0059 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6448 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 288.4806 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6711 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9852 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.6601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8352 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7524 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5823 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5357 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7292 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6637 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.7925 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.7008 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7918 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7384 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 117.5612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6339 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7675 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.4846 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6009 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3298 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5708 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7159 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6973 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2176 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0085 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8362 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7118 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8521 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7808 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.3033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 337.0999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 535.1680 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6809 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7397 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7110 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6845 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6895 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.1081 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4861 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2492 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 297.1595 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 295.5439 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6789 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.1025 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3056 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.2615 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 683.0745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9909 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4571 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8831 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7389 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9589 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6636 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2680 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.8755 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3195 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8386 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 549.0673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 189.4421 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6391 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9453 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 409.4234 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7403 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6419 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5886 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2718 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6915 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.1798 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9095 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3030 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.9215 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6276 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 458.4901 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8102 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5675 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3261 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 336.7783 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 73.8018 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6412 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9243 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6853 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6502 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.4410 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6829 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7528 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.3974 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6639 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.2299 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6902 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6318 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8151 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.1928 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 624.1481 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7185 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3495 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.2323 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8417 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8138 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.1315 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8494 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 243.2897 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 563.5264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5977 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7863 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7419 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7376 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9370 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1810 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4811 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4825 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6750 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4121 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.2883 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5579 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.0976 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2625 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5665 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 334.5536 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 159.7427 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.7597 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0555 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.9889 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 223.5944 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 356.4927 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5876 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6593 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 263.4525 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7293 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7242 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 140.9547 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 266.4712 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6899 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.7796 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7621 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9887 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7478 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7799 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8301 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.2662 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 380.5315 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2200 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5939 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5782 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6723 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 339.2218 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1587 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6507 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7878 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6829 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1662 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5979 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6363 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0770 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0122 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7563 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6141 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5634 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7896 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 155.1263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.2021 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3484 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 282.8298 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 442.4296 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4984 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7815 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 510.1831 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4500 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.2628 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 495.7935 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7129 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 195.1821 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.8679 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.2491 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 132.3205 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6756 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6094 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5464 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4529 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2140 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0152 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7307 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2371 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 389.7432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9826 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1893 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.4968 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.8282 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 541.1624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2022 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.6140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6562 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5677 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7586 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 361.4010 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7956 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.0928 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 368.9936 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8963 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.7605 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4162 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7072 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.9188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.0932 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1583 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 447.3780 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5728 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.8329 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5256 - accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": range(2, 6), \n",
    "                \"n_units\": range(50, 300, 50),\n",
    "                \"dropout\": np.arange(0, 0.6, 0.1),\n",
    "                \"kernel_regularizer\": [0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                \"optimizer\": [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "studySoftmax_Grid = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "studySoftmax_Grid.optimize(objectiveSoftmax_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64f63924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 2,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0.01,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 0.0001,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0.01,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0.01,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0.1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 250,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0.01,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 0.001,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0.0001,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0.01,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0.001,\n",
       "  'optimizer': 'RMSprop'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(studySoftmax_Grid.get_trials())\n",
    "models_same_acc_OptunaSearchCV(studySoftmax_Grid.get_trials(), top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e5e3b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 1.5075 - acc: 0.5882 - val_loss: 1.5001 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.5304 - acc: 0.4706 - val_loss: 1.4901 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.4589 - acc: 0.5882 - val_loss: 1.4768 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.4533 - acc: 0.6471 - val_loss: 1.4611 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4087 - acc: 0.7255 - val_loss: 1.4429 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4211 - acc: 0.6275 - val_loss: 1.4238 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3313 - acc: 0.8235 - val_loss: 1.4043 - val_acc: 0.6471\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.2838 - acc: 0.8235 - val_loss: 1.3802 - val_acc: 0.7059\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2530 - acc: 0.8039 - val_loss: 1.3500 - val_acc: 0.7647\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1600 - acc: 0.8824 - val_loss: 1.3148 - val_acc: 0.7059\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0294 - acc: 0.9412 - val_loss: 1.2800 - val_acc: 0.7647\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9853 - acc: 0.9608 - val_loss: 1.2541 - val_acc: 0.7647\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9037 - acc: 1.0000 - val_loss: 1.2496 - val_acc: 0.7647\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8796 - acc: 0.9804 - val_loss: 1.2711 - val_acc: 0.8235\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8407 - acc: 1.0000 - val_loss: 1.3055 - val_acc: 0.8235\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8134 - acc: 1.0000 - val_loss: 1.3115 - val_acc: 0.8235\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.7850 - acc: 1.0000 - val_loss: 1.3138 - val_acc: 0.8235\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7692 - acc: 1.0000 - val_loss: 1.3324 - val_acc: 0.7647\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7634 - acc: 1.0000 - val_loss: 1.3467 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6955 - acc: 0.6667\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Grid_softmax = models.Sequential()\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001), \n",
    "                                             input_shape=(410,)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_optuna_Grid_softmax.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_Grid_softmax.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Grid_softmax.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91d41c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveSoftmax_TPE(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación softmax\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c552f735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 357.7457 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.6211 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7350 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 81.4107 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 771.1399 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0561 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.7121 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 346.2152 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.7379 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 615.5834 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 584.3633 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0562 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7276 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.9502 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7640 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.2501 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 78.2007 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.2132 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 34.0476 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.7434 - accuracy: 0.2222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 308.5221 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 403.9059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8029 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.5336 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8591 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9166 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2834 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1531 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0511 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0539 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7152 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4388 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0338 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7152 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4898 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5648 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6877 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0754 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6879 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6077 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8838 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4159 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3784 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 95.8417 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5281 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 299.1025 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 44.6263 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0647 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4831 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3793 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1897 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 732.8246 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8516 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3371 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 79.5591 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6852 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0133 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8102 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 326.5013 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.1314 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7305 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3947 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 64.9597 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 622.5339 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.0318 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8608 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0719 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6220 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5926 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5693 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9413 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5848 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7893 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7434 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6951 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 66.4396 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 456.9581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2300 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6963 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1650 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6578 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0878 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6324 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7117 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9565 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7455 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.4761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7716 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7187 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8020 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9306 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7003 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 554.3813 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0894 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7798 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9086 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8767 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8772 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7749 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8657 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.4507 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7529 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6807 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4392 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.7784 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 636.2859 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8255 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5874 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9508 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.8082 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5615 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6372 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 369.3751 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8146 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1732 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8944 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6430 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9920 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8635 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2384 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0225 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8892 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1567 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 55.8142 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0754 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8249 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6248 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2248 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1031 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3184 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9519 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1518 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5131 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6241 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7792 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9894 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6147 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3148 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3195 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3380 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.9490 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6517 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5171 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7071 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0038 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9464 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1597 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.2109 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.1208 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 283.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5767 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9905 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9299 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3096 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7824 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1302 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7645 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.4968 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5023 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7530 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5577 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7926 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.7229 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9005 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6337 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0053 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7485 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7081 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7303 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8662 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2686 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3231 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7965 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6946 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 731.5424 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8159 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2774 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6900 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3549 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5825 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.0571 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4845 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8557 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7780 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9389 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7446 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1091 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8626 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2804 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6249 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9813 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.4942 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7242 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1898 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.1978 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9044 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9004 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7293 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7047 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4341 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6684 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7263 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.4443 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1126 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.0559 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4422 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.4956 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6224 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6715 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8321 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9863 - accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "studySoftmax_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "studySoftmax_TPE.optimize(objectiveSoftmax_TPE, n_trials=216)\n",
    "# n_trials = (4 x 5 x 6 x 6 x 3) * 0.1 = 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4cfd980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 5,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0.1,\n",
       "  'optimizer': 'SGD'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(studySoftmax_TPE.get_trials())\n",
    "models_same_acc_OptunaSearchCV(studySoftmax_TPE.get_trials(), top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cdf62f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=18, values=[0.8888888955116272], datetime_start=datetime.datetime(2022, 7, 3, 2, 1, 4, 673838), datetime_complete=datetime.datetime(2022, 7, 3, 2, 1, 5, 925074), params={'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'kernel_regularizer': 0.1, 'optimizer': 'SGD'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1), 'kernel_regularizer': CategoricalDistribution(choices=(0, 0.0001, 0.001, 0.01, 0.1, 1)), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=18, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studySoftmax_TPE.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19d7dcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 82.5780 - acc: 0.5686 - val_loss: 82.0513 - val_acc: 0.3529\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 81.9542 - acc: 0.3922 - val_loss: 81.4004 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 81.2773 - acc: 0.5490 - val_loss: 80.7557 - val_acc: 0.3529\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 80.6401 - acc: 0.5686 - val_loss: 80.1161 - val_acc: 0.3529\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 80.0036 - acc: 0.5490 - val_loss: 79.4815 - val_acc: 0.4706\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 79.3661 - acc: 0.5098 - val_loss: 78.8521 - val_acc: 0.5294\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 78.7274 - acc: 0.5882 - val_loss: 78.2288 - val_acc: 0.4706\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 78.1143 - acc: 0.5686 - val_loss: 77.6091 - val_acc: 0.5294\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 77.5020 - acc: 0.5686 - val_loss: 76.9952 - val_acc: 0.5294\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 76.8811 - acc: 0.4902 - val_loss: 76.3861 - val_acc: 0.5294\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 76.2602 - acc: 0.6667 - val_loss: 75.7822 - val_acc: 0.5294\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 75.7797 - acc: 0.5000\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE_softmax = models.Sequential()\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1),\n",
    "                                            input_shape=(410,)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_optuna_TPE_softmax.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE_softmax.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE_softmax.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa31a6",
   "metadata": {},
   "source": [
    "Obtenemos un mayor accuracy utilizando la activación softmax. Sin embargo, parece que la red tiene un problema de sobreajuste. Vamos a tratar de reducir esta diferencia probando distintos tipos de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddc9d896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 0.6826 - acc: 0.5686 - val_loss: 0.6321 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5491 - acc: 0.7255 - val_loss: 0.5449 - val_acc: 0.8235\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2874 - acc: 0.9608 - val_loss: 0.4808 - val_acc: 0.8235\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2832 - acc: 0.8824 - val_loss: 1.4154 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4606 - acc: 0.8431 - val_loss: 0.4541 - val_acc: 0.7059\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.4503 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.4612 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4476 - acc: 0.8889\n",
      "Accuracy : 88.89% ----- Regularización: None \n",
      "\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 235ms/step - loss: 0.6908 - acc: 0.5490 - val_loss: 0.6602 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5952 - acc: 0.6471 - val_loss: 0.6676 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4646 - acc: 0.8039 - val_loss: 0.7404 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3168 - acc: 0.8824 - val_loss: 0.6688 - val_acc: 0.7647\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1293 - acc: 1.0000 - val_loss: 0.9230 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0666 - acc: 1.0000 - val_loss: 0.8326 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.5416 - val_acc: 0.7059\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.9422 - val_acc: 0.7647\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.8858 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6068 - acc: 0.8333\n",
      "Accuracy : 83.33% ----- Regularización: l1 \n",
      "\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 0.6851 - acc: 0.5686 - val_loss: 0.6678 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5931 - acc: 0.6667 - val_loss: 0.7296 - val_acc: 0.6471\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4681 - acc: 0.7647 - val_loss: 0.8234 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3093 - acc: 0.9412 - val_loss: 0.8019 - val_acc: 0.7647\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1507 - acc: 0.9804 - val_loss: 1.1311 - val_acc: 0.6471\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0768 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.5294\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.6976 - val_acc: 0.5882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8220 - val_acc: 0.7059\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.8327 - val_acc: 0.6471\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8160 - acc: 0.7222\n",
      "Accuracy : 72.22% ----- Regularización: l2 \n",
      "\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 0.6893 - acc: 0.4510 - val_loss: 0.6878 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5906 - acc: 0.6471 - val_loss: 0.8122 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5085 - acc: 0.7255 - val_loss: 0.6951 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2444 - acc: 1.0000 - val_loss: 0.7203 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0699 - acc: 1.0000 - val_loss: 1.0157 - val_acc: 0.7059\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 1.0366 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9169 - val_acc: 0.6471\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.1239 - val_acc: 0.6471\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.0979 - val_acc: 0.6471\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.1169 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1226 - acc: 0.7222\n",
      "Accuracy : 72.22% ----- Regularización: l1_l2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "regularizers = [None, \"l1\", \"l2\", \"l1_l2\"]\n",
    "\n",
    "for regularizer in regularizers:\n",
    "    modelFC_optuna_Grid_softmax = models.Sequential()\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\"))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\"))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\"))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\"))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    modelFC_optuna_Grid_softmax.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "    es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna_Grid_softmax.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy = modelFC_optuna_Grid_softmax.evaluate(X_test, y_test_softmax)\n",
    "    print(\"Accuracy : {:0.2f}% ----- Regularización: {} \\n\".format(accuracy * 100, regularizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eebafe",
   "metadata": {},
   "source": [
    "### Función de pérdida personalizada\n",
    "\n",
    "Otra posibilidad es tratar de tener en cuenta los datos con peores resultados en el backpropagation, es decir, asignar un mayor peso a esos datos. Esta es la idea del método \"AdaBoost\" que sin embargo no está actualmente implementado en keras. Una alternativa es definir propiamente otra función de loss personalizada.\n",
    "\n",
    "Fuente: https://stackoverflow.com/questions/48720197/weight-samples-if-incorrect-guessed-in-binary-cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad055d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, tp_weight=0.5, tn_weight=0.5, fp_weight=1, fn_weight=1):\n",
    "    '''\n",
    "    Función de pérdida personalizada para el optimizador de una red neuronal.\n",
    "    El método recibe las predicciones y el valor real de la clasificación, así como los pesos que se desea asignar a los\n",
    "    clasificaciones tanto erróneas como acertadas.\n",
    "    '''\n",
    "#     print(\"NEW ITER ------\")\n",
    "#     print(\"Y_TRUE:\", tf.print(y_true))\n",
    "#     print(\"Y_PRED:\", tf.print(y_pred))\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_classes = tf.keras.backend.greater_equal(y_pred, 0.5)\n",
    "    y_pred_classes_float = tf.keras.backend.cast(y_pred_classes, tf.keras.backend.floatx())\n",
    "    y_true_float = tf.keras.backend.cast(y_true, tf.keras.backend.floatx())\n",
    "    \n",
    "#     print(\"\\n\")\n",
    "#     print(\"1:\", tf.print(y_pred_classes_float))\n",
    "#     print(\"2:\", tf.print(y_true_float))\n",
    "\n",
    "    # Get misclassified examples\n",
    "    wrongly_classified = tf.keras.backend.not_equal(y_true_float, y_pred_classes_float)\n",
    "    wrongly_classified_float = tf.keras.backend.cast(wrongly_classified, tf.keras.backend.floatx())\n",
    "    wrongly_classified_float2 = tf.gather(wrongly_classified_float, [0], axis=1)\n",
    "    \n",
    "#     print(\"3:\", tf.print(wrongly_classified_float2))\n",
    "    \n",
    "    # Get correctly classified examples\n",
    "    correctly_classified = tf.keras.backend.equal(y_true_float, y_pred_classes_float)\n",
    "    correctly_classified_float = tf.keras.backend.cast(correctly_classified, tf.keras.backend.floatx())\n",
    "    correctly_classified_float2 = tf.gather(correctly_classified_float, [0], axis=1)\n",
    "    \n",
    "#     print(\"4:\", tf.print(correctly_classified_float2))\n",
    "\n",
    "    # Get tp, fp, tn, fn\n",
    "    tp = correctly_classified_float * y_true_float\n",
    "    tn = correctly_classified_float * (1 - y_true_float)\n",
    "    fp = wrongly_classified_float * y_true_float\n",
    "    fn = wrongly_classified_float * (1 - y_true_float)\n",
    "\n",
    "    # Get weights\n",
    "    weight = tp_weight * tp + fp_weight * fp + tn_weight * tn + fn_weight * fn\n",
    "    weight2 = tf.gather(weight, [0], axis=1)\n",
    "    weight3 = tf.math.reduce_sum(weight2, axis=1)\n",
    "#     print(\"TN_W\", tn)\n",
    "#     tf.print(tp)\n",
    "#     tf.print(tp2)\n",
    "#     tf.print(weight3)\n",
    "    \n",
    "    loss = tf.keras.metrics.binary_crossentropy(y_true, y_pred)\n",
    "#     tf.print(loss)\n",
    "    weighted_loss = loss * weight3\n",
    "#     tf.print(weighted_loss)\n",
    "    \n",
    "#     weighted_loss2 = tf.gather(weighted_loss, [0], axis=1)\n",
    "    \n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73f781",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que los anteriores ``tp``, ``fn``, ... son tensores (vectores de ``tensorflow``) y por tanto, el resultado guardado en ``weight`` es igualmente otro tensor, no un único valor numérico.\n",
    "\n",
    "_NOTA: se entienden los positivos como aquellas muestras correspondientes con una etiqueta \"1\" (enfermos) y por tanto como negativos los registros con etiqueta \"0\" (grupo de control)._\n",
    "\n",
    "Vamos a probar cómo funciona la función personalizada sobre los modelos de redes neuronales que peores resultados han obtenido para comprobar si de este modo podemos mejorar sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9bb9f5a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.5306 - acc: 0.5098 - val_loss: 0.4859 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4283 - acc: 0.7059 - val_loss: 0.4530 - val_acc: 0.6471\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3334 - acc: 0.8235 - val_loss: 0.4740 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2332 - acc: 0.9020 - val_loss: 0.4568 - val_acc: 0.7059\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1204 - acc: 0.9804 - val_loss: 0.4746 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0468 - acc: 1.0000 - val_loss: 0.3448 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.2940 - val_acc: 0.8235\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4290 - val_acc: 0.8235\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4033 - val_acc: 0.7647\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.4145 - val_acc: 0.7647\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.4270 - val_acc: 0.7647\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5148 - acc: 0.8889\n",
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_CL = models.Sequential()\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_CL.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_CL.compile(loss=custom_loss, optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_CL.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_CL.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd16fe8",
   "metadata": {},
   "source": [
    "### Sample-weight\n",
    "\n",
    "Una alternativa a lo anterior, sería usar un vector de pesos propio y pasarlo a la función ``fit`` del modelo, a través del parámetro ``sample_weight``, en lugar de definir una función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "065bb881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 170ms/step - loss: 0.3418 - acc: 0.5882 - val_loss: 0.3174 - val_acc: 0.5882\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2318 - acc: 0.7255 - val_loss: 0.2629 - val_acc: 0.7059\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.1168 - acc: 0.9020 - val_loss: 0.2408 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.2301 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1631 - val_acc: 0.6471\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1534 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0171 - acc: 0.9804 - val_loss: 0.0695 - val_acc: 0.5294\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.0540 - val_acc: 0.6471\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.7059\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 6.9570e-04 - acc: 1.0000 - val_loss: 0.1776 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.9242e-04 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.1914e-04 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 2.6941e-04 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.3213e-04 - acc: 1.0000 - val_loss: 0.1616 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2.0263e-04 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.7837e-04 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.5763e-04 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.3951e-04 - acc: 1.0000 - val_loss: 0.1678 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2198e-04 - acc: 1.0000 - val_loss: 0.1702 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0704e-04 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9.4490e-05 - acc: 1.0000 - val_loss: 0.1751 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 8.3502e-05 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 7.4014e-05 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 6.5577e-05 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.8259e-05 - acc: 1.0000 - val_loss: 0.1845 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 5.1701e-05 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 4.5930e-05 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.0814e-05 - acc: 1.0000 - val_loss: 0.1920 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.6248e-05 - acc: 1.0000 - val_loss: 0.1945 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.2222e-05 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.8600e-05 - acc: 1.0000 - val_loss: 0.1996 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.5364e-05 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.2497e-05 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.9926e-05 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.7646e-05 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.5631e-05 - acc: 1.0000 - val_loss: 0.2115 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.3827e-05 - acc: 1.0000 - val_loss: 0.2139 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.2214e-05 - acc: 1.0000 - val_loss: 0.2166 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.0797e-05 - acc: 1.0000 - val_loss: 0.2190 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.5555e-06 - acc: 1.0000 - val_loss: 0.2216 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 8.4535e-06 - acc: 1.0000 - val_loss: 0.2242 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 7.4818e-06 - acc: 1.0000 - val_loss: 0.2269 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6.6251e-06 - acc: 1.0000 - val_loss: 0.2294 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.8649e-06 - acc: 1.0000 - val_loss: 0.2319 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 5.1860e-06 - acc: 1.0000 - val_loss: 0.2346 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.5859e-06 - acc: 1.0000 - val_loss: 0.2371 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.0577e-06 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.5893e-06 - acc: 1.0000 - val_loss: 0.2425 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.1776e-06 - acc: 1.0000 - val_loss: 0.2453 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.8149e-06 - acc: 1.0000 - val_loss: 0.2482 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.4956e-06 - acc: 1.0000 - val_loss: 0.2508 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 2.2142e-06 - acc: 1.0000 - val_loss: 0.2536 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.9652e-06 - acc: 1.0000 - val_loss: 0.2564 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.7452e-06 - acc: 1.0000 - val_loss: 0.2593 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.5513e-06 - acc: 1.0000 - val_loss: 0.2620 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.3805e-06 - acc: 1.0000 - val_loss: 0.2648 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.2288e-06 - acc: 1.0000 - val_loss: 0.2677 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0948e-06 - acc: 1.0000 - val_loss: 0.2705 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 9.7596e-07 - acc: 1.0000 - val_loss: 0.2734 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.7077e-07 - acc: 1.0000 - val_loss: 0.2763 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 7.7780e-07 - acc: 1.0000 - val_loss: 0.2792 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.9515e-07 - acc: 1.0000 - val_loss: 0.2822 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6.2163e-07 - acc: 1.0000 - val_loss: 0.2851 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 5.5604e-07 - acc: 1.0000 - val_loss: 0.2881 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.9785e-07 - acc: 1.0000 - val_loss: 0.2909 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.4638e-07 - acc: 1.0000 - val_loss: 0.2938 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.0049e-07 - acc: 1.0000 - val_loss: 0.2967 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.5970e-07 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.2349e-07 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 2.9107e-07 - acc: 1.0000 - val_loss: 0.3050 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.6225e-07 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.3647e-07 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.1347e-07 - acc: 1.0000 - val_loss: 0.3131 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.9299e-07 - acc: 1.0000 - val_loss: 0.3158 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.7461e-07 - acc: 1.0000 - val_loss: 0.3184 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.5822e-07 - acc: 1.0000 - val_loss: 0.3210 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.4349e-07 - acc: 1.0000 - val_loss: 0.3235 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.3034e-07 - acc: 1.0000 - val_loss: 0.3261 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1843e-07 - acc: 1.0000 - val_loss: 0.3285 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0785e-07 - acc: 1.0000 - val_loss: 0.3311 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9.8266e-08 - acc: 1.0000 - val_loss: 0.3335 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 8.9734e-08 - acc: 1.0000 - val_loss: 0.3359 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 8.1984e-08 - acc: 1.0000 - val_loss: 0.3383 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 7.5081e-08 - acc: 1.0000 - val_loss: 0.3406 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 6.8810e-08 - acc: 1.0000 - val_loss: 0.3429 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.3179e-08 - acc: 1.0000 - val_loss: 0.3452 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.8093e-08 - acc: 1.0000 - val_loss: 0.3473 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 5.3460e-08 - acc: 1.0000 - val_loss: 0.3495 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 4.9298e-08 - acc: 1.0000 - val_loss: 0.3516 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.5485e-08 - acc: 1.0000 - val_loss: 0.3536 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 4.2053e-08 - acc: 1.0000 - val_loss: 0.3555 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.8970e-08 - acc: 1.0000 - val_loss: 0.3574 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.6137e-08 - acc: 1.0000 - val_loss: 0.3592 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.3568e-08 - acc: 1.0000 - val_loss: 0.3610 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.1245e-08 - acc: 1.0000 - val_loss: 0.3628 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.9094e-08 - acc: 1.0000 - val_loss: 0.3645 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.7173e-08 - acc: 1.0000 - val_loss: 0.3662 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.5407e-08 - acc: 1.0000 - val_loss: 0.3678 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 2.3780e-08 - acc: 1.0000 - val_loss: 0.3694 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.2272e-08 - acc: 1.0000 - val_loss: 0.3709 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5757 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_SW = models.Sequential()\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_SW.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_SW.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "\n",
    "args = y_train_softmax.astype(bool)\n",
    "y_pred = modelFC_SW.predict(X_train)\n",
    "samples = 1 - y_pred[args]\n",
    "for epoch in range(100):\n",
    "    modelFC_SW.fit(X_train, y_train_softmax, epochs=1, validation_split=0.25, sample_weight=samples)\n",
    "    y_pred = modelFC_SW.predict(X_train)\n",
    "    samples = 1 - y_pred[args]\n",
    "    \n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_SW.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570984a",
   "metadata": {},
   "source": [
    "### Pseudo-labeling\n",
    "\n",
    "Fuente: https://towardsdatascience.com/pseudo-labeling-to-deal-with-small-datasets-what-why-how-fd6f903213af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04feba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_epoch(epoch, val, start, stop):\n",
    "    if epoch < start:\n",
    "        alpha = 0\n",
    "    elif epoch < stop:\n",
    "        alpha = ((epoch-start) / (stop-start)) * val\n",
    "    else:\n",
    "        alpha = val\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7172a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "start = 15\n",
    "stop = 90\n",
    "alpha_values = [0.25, 0.5, 0.75, 1]\n",
    "iters = 100\n",
    "\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "\n",
    "test_reduc = test_kaggle.iloc[:10000, :]\n",
    "X_tot = np.concatenate((X_train, test_reduc))\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for i in range(iters):\n",
    "        pseudolabels = modelFC.predict(test_reduc).squeeze()\n",
    "        alpha_t = alpha_epoch(i+1, alpha, start, stop)\n",
    "        samples = np.concatenate((np.ones(len(y_train)), alpha_t*np.ones(len(pseudolabels))))\n",
    "        modelFC.fit(X_train, y_train_softmax, sample_weight=samples, epochs=1, validation_split=0.25, verbose = 0)\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy_pl = modelFC.evaluate(X_test, y_test_softmax)\n",
    "    print(\"Accuracy: {:0.2f}% ------- alpha = {:0.2f}\".format(accuracy_pl * 100, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3114c",
   "metadata": {},
   "source": [
    "Vamos a pintar la evolución del valor del peso $\\alpha$ (función $\\alpha(t)$) elegido a lo largo de 100 iteraciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4838bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start = 15\n",
    "stop = 90\n",
    "alpha_values = 1\n",
    "iters = 100\n",
    "\n",
    "alpha_per_epoch = []\n",
    "for i in range(iters):\n",
    "    alpha_per_epoch.append(alpha_epoch(i+1, alpha, start, stop))\n",
    "    \n",
    "# Pintamos el vector\n",
    "plt.plot(alpha_per_epoch)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(r\"$\\alpha(t)$\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
