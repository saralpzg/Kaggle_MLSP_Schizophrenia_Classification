{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d66f63",
   "metadata": {},
   "source": [
    "# Comparación de técnicas de preprocesamiento de los datos\n",
    "\n",
    "En este notebook se van a probar distintos métodos de preprocesado de los datos para entrenar todas las alternativas con un mismo modelo (_XGBoost_) y comparar los resultados mediante el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2591ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, mutual_info_classif, RFE, SelectFromModel\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Cargar los datos\n",
    "from Modelos.data_and_submissions import *\n",
    "\n",
    "# Métodos para los entrenamientos con CV\n",
    "from Modelos.train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374022c8",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488be98e",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990eb214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, _ = load_data(True)\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28999cd",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8717295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "# Modelo e hiperparámetros sobre los que se realizan las pruebas\n",
    "model_XGB = XGBClassifier(eval_metric=\"logloss\", random_state=0, use_label_encoder=False)\n",
    "param_grid_XGB = {\n",
    "    \"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "    \"learning_rate\": [0.001, 0.05, 0.1, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96418c",
   "metadata": {},
   "source": [
    "# Sin preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fade9e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'booster': 'gblinear', 'learning_rate': 0.001},\n",
       " {'booster': 'gblinear', 'learning_rate': 0.05},\n",
       " {'booster': 'gblinear', 'learning_rate': 0.1}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_preprocessing = train_GridSearchCV(model_XGB, param_grid_XGB, X_train, X_test, y_train, y_test)\n",
    "top_acc = top_acc_GridSearchCV(no_preprocessing[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(no_preprocessing, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d167f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "no_preprocessing_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.001, \n",
    "                                     random_state=0, use_label_encoder=False)  \n",
    "no_preprocessing_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_no_preprocessing = no_preprocessing_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy_no_preprocessing = accuracy_score(y_test, y_pred_no_preprocessing)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy_no_preprocessing * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac42ef6",
   "metadata": {},
   "source": [
    "# Normalize\n",
    "\n",
    "Datos con norma unitaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "215b1083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Norma: L1\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 66.18% \n",
      "\n",
      "----- Norma: L2\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 64.71% \n",
      "\n",
      "----- Norma: MAX\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 63.24% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "norm_types = [\"l1\", \"l2\", \"max\"]\n",
    "acc = 0\n",
    "\n",
    "for norm in norm_types:\n",
    "    print(f\"----- Norma: {norm.upper()}\")\n",
    "    X_train_processed = normalize(X_train, norm)\n",
    "    X_test_processed = normalize(X_test, norm)\n",
    "    \n",
    "    normalized = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(normalized[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(normalized, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78538ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.78%\n",
      "Resultado obtenido usando la norma L1.\n"
     ]
    }
   ],
   "source": [
    "X_train_processed = normalize(X_train, \"l1\")\n",
    "X_test_processed = normalize(X_test, \"l1\")\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "normalized_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.1, \n",
    "                               random_state=0, use_label_encoder=False)  \n",
    "normalized_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_normalized = normalized_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_normalized = accuracy_score(y_test, y_pred_normalized)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_normalized * 100))\n",
    "print(\"Resultado obtenido usando la norma L1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f7bca",
   "metadata": {},
   "source": [
    "# Escalado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f181bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'booster': 'gblinear', 'learning_rate': 0.5}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = StandardScaler()\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test)\n",
    "\n",
    "scaled = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "top_acc = top_acc_GridSearchCV(scaled[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(scaled, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752d3b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.22%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "scaled_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.5, \n",
    "                           random_state=0, use_label_encoder=False)  \n",
    "scaled_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_scaled = scaled_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_scaled * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf473af",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a89a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 2 PCs\n",
      "[{'booster': 'gbtree', 'learning_rate': 0.1}, {'booster': 'dart', 'learning_rate': 0.1}]\n",
      "Accuracy: 64.71% \n",
      "\n",
      "----- 4 PCs\n",
      "[{'booster': 'gbtree', 'learning_rate': 0.05}, {'booster': 'dart', 'learning_rate': 0.05}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- 6 PCs\n",
      "[{'booster': 'gbtree', 'learning_rate': 0.5}, {'booster': 'dart', 'learning_rate': 0.5}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 8 PCs\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- 10 PCs\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 12 PCs\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 66.18% \n",
      "\n",
      "----- 14 PCs\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 64.71% \n",
      "\n",
      "----- 16 PCs\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 63.24% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTA: la dimensionalidad del espacio reducido del método PCA (paquete sklearn) en python tiene como tamaño máximo el mínimo\n",
    "# entre el número de variables y el número de muestras. Como en este caso nuestro conjunto de datos es pequeño, el número \n",
    "# máximo de componentes será precisamente el número de muestras en el conjunto de test.\n",
    "\n",
    "n_components_range = list(range(2, X_test.shape[0], 2))\n",
    "acc = 0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "for n_components in n_components_range:\n",
    "    print(f\"----- {n_components} PCs\")\n",
    "    pca = PCA(n_components=n_components)\n",
    "    preprocess = Pipeline([(\"scaling\", scaler), (\"pca\", pca)])\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test)\n",
    "\n",
    "    pca_cv = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(pca_cv[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(pca_cv, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8124477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 33.33%\n",
      "Resultado obtenido usando 6 PCs.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=6)\n",
    "preprocess = Pipeline([(\"scaling\", scaler), (\"pca\", pca)])\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "pca_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gbtree\", learning_rate=0.5, \n",
    "                        random_state=0, use_label_encoder=False)  \n",
    "pca_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_pca = pca_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_pca * 100))\n",
    "print(\"Resultado obtenido usando 6 PCs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5074e9a",
   "metadata": {},
   "source": [
    "# SelectKBest\n",
    "\n",
    "Documentación scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)\n",
    "\n",
    "Este método selecciona las k mejores variables en base a la puntuación que estas reciben de acuerdo a una función que toma como parámetro (test estadísticos). \n",
    "\n",
    "La función que utiliza por defecto y con la que probaremos inicialmente en el siguiente código el método es ``f_classif``. Esta función calcula el ANOVA F-valor entre etiquetas y características para problemas de clasificación.\n",
    "\n",
    "_NOTA: ANalysis Of VAriance: método estadístico que permite descubrir si los resultados de una prueba son significativos._\n",
    "\n",
    "_NOTA: distribución F o de Fisher-Snedecor es una distribución de probabilidad continua, especialmente aplicada en el análisis de la varianza._\n",
    "\n",
    "Como hay que indicar un parámetro ``k`` que será el número de variables seleccionadas, probaremos varios valores para ver con cual se obtiene mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b5255a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 10 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 76.47% \n",
      "\n",
      "----- 50 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 77.94% \n",
      "\n",
      "----- 90 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 77.94% \n",
      "\n",
      "----- 130 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 76.47% \n",
      "\n",
      "----- 170 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 77.94% \n",
      "\n",
      "----- 210 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 79.41% \n",
      "\n",
      "----- 250 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 290 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- 330 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- 370 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 64.71% \n",
      "\n",
      "----- 410 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 63.24% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(10, 450, 40))\n",
    "acc = 0\n",
    "\n",
    "for k in k_range:\n",
    "    print(f\"----- {k} best features\")\n",
    "    \n",
    "    preprocess = SelectKBest(k=k)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "    select_k = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(select_k[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(select_k, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693058c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n",
      "Resultado obtenido usando las 210 'mejores variables'.\n"
     ]
    }
   ],
   "source": [
    "preprocess = SelectKBest(k=210)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "select_k_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.05, \n",
    "                             random_state=0, use_label_encoder=False)  \n",
    "select_k_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_select_k = select_k_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_select_k = accuracy_score(y_test, y_pred_select_k)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_select_k * 100))\n",
    "print(\"Resultado obtenido usando las 210 'mejores variables'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05a367",
   "metadata": {},
   "source": [
    "A continuación, probamos los resultados del código anterior, utilizando una función de score distinta y apropiada para clasificación.\n",
    "\n",
    "### mutual_info_classif: \n",
    "\n",
    "Mutual Information (MI) es un criterio de estimación de mide la dependencia entre dos variables (en este caso para una variable objetivo discreta). Su valor es no negativo y vale cero las dos variables son totalmente independientes, por tanto, cuanto más alto es su valor, mayor es la dependencia.\n",
    "\n",
    "Su implementación en sklearn se apoya en métodos no-paramétricos, basados en la estimación de la entropía de las distancias de los k-vecinos más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8f5d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 10 best features\n",
      "[{'booster': 'gbtree', 'learning_rate': 0.5}, {'booster': 'dart', 'learning_rate': 0.5}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 50 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 90 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 130 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- 170 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 210 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 70.59% \n",
      "\n",
      "----- 250 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- 290 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 66.18% \n",
      "\n",
      "----- 330 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 370 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 64.71% \n",
      "\n",
      "----- 410 best features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 64.71% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for k in k_range:\n",
    "    print(f\"----- {k} best features\")\n",
    "    \n",
    "    preprocess = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "    select_k2 = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(select_k2[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(select_k2, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349a7fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.89%\n",
      "Resultado obtenido usando las 90 'mejores variables'.\n"
     ]
    }
   ],
   "source": [
    "preprocess = SelectKBest(score_func=mutual_info_classif, k=90)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "select_k_opt2 = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.5, \n",
    "                              random_state=0, use_label_encoder=False)  \n",
    "select_k_opt2.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_select_k2 = select_k_opt2.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_select_k2 = accuracy_score(y_test, y_pred_select_k2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_select_k2 * 100))\n",
    "print(\"Resultado obtenido usando las 90 'mejores variables'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db083d",
   "metadata": {},
   "source": [
    "El resto de funciones implementadas en sklearn son para regresión o no válidas en nuestro conjunto de datos (chi2 no admite valores negativos).\n",
    "\n",
    "# SelectPercentile\n",
    "\n",
    "Documentación scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html?highlight=select%20percentile#sklearn.feature_selection.SelectPercentile)\n",
    "\n",
    "Método muy similar al anterior ``SelectKBest`` pero que hace la selección de las variables esta vez de acuerdo a un percentil de las puntuaciones más altas. También utiliza las mismas funciones de score y seguiremos el mismo procedimiento.\n",
    "\n",
    "### f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d4b4868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Percentil 10\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 73.53% \n",
      "\n",
      "----- Percentil 20\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 77.94% \n",
      "\n",
      "----- Percentil 30\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 79.41% \n",
      "\n",
      "----- Percentil 40\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 76.47% \n",
      "\n",
      "----- Percentil 50\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 79.41% \n",
      "\n",
      "----- Percentil 60\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 76.47% \n",
      "\n",
      "----- Percentil 70\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- Percentil 80\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- Percentil 90\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 64.71% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "percentile_range = list(range(10, 100, 10))\n",
    "acc = 0\n",
    "\n",
    "for percent in percentile_range:\n",
    "    print(f\"----- Percentil {percent}\")\n",
    "    \n",
    "    preprocess = SelectPercentile(percentile=percent)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    select_percent = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(select_percent[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(select_percent, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c780c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n",
      "Resultado obtenido usando el percentil 50 de las 'mejores variables'.\n"
     ]
    }
   ],
   "source": [
    "preprocess = SelectPercentile(percentile=50)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "select_percent_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.001, \n",
    "                                   random_state=0, use_label_encoder=False)  \n",
    "select_percent_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_select_percent = select_percent_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_select_percent = accuracy_score(y_test, y_pred_select_percent)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_select_percent * 100))\n",
    "print(\"Resultado obtenido usando el percentil 50 de las 'mejores variables'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f445a4bb",
   "metadata": {},
   "source": [
    "### mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a5b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Percentil 10\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- Percentil 20\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 73.53% \n",
      "\n",
      "----- Percentil 30\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- Percentil 40\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- Percentil 50\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 70.59% \n",
      "\n",
      "----- Percentil 60\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- Percentil 70\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- Percentil 80\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- Percentil 90\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 67.65% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for percent in percentile_range:\n",
    "    print(f\"----- Percentil {percent}\")\n",
    "    \n",
    "    preprocess = SelectPercentile(score_func=mutual_info_classif, percentile=percent)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    select_percent2 = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(select_percent2[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(select_percent2, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d0d8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.11%\n",
      "Resultado obtenido usando el percentil 20 de las 'mejores variables'.\n"
     ]
    }
   ],
   "source": [
    "preprocess = SelectPercentile(score_func=mutual_info_classif, percentile=20)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "select_percent_opt2 = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.1, \n",
    "                                    random_state=0, use_label_encoder=False)  \n",
    "select_percent_opt2.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_select_percent2 = select_percent_opt2.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_select_percent2 = accuracy_score(y_test, y_pred_select_percent2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_select_percent2 * 100))\n",
    "print(\"Resultado obtenido usando el percentil 20 de las 'mejores variables'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be6c94",
   "metadata": {},
   "source": [
    "# RFE\n",
    "\n",
    "Documentación scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html?highlight=rfe#sklearn.feature_selection.RFE)\n",
    "\n",
    "RFE = Recursive Feature Elimination.\n",
    "\n",
    "Dado un estimador que asigna pesos a las variables (por ejemplos los coeficientes de un modelo lineal), el método elimina de manera recursiva  variables, considerando cada vez conjuntos más pequeños de acuerdo a estos pesos. Inicialmente se entrena el estimador sobre el conjunto original de variables y se obtiene la importancia de cada variable. Acto seguido se podan las variables menos importantes del conjunto. Este proceso se repite de manera recursiva sobre los conjuntos podados que se van generando hasta que se alcanza el número de variables deseado.\n",
    "\n",
    "### Estimador SVC (Support Vector Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30030230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 10 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 95.59% \n",
      "\n",
      "----- 50 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 90 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 92.65% \n",
      "\n",
      "----- 130 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 88.24% \n",
      "\n",
      "----- 170 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 210 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 89.71% \n",
      "\n",
      "----- 250 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 85.29% \n",
      "\n",
      "----- 290 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 79.41% \n",
      "\n",
      "----- 330 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 70.59% \n",
      "\n",
      "----- 370 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 410 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 66.18% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_features_range = list(range(10, 450, 40))\n",
    "acc = 0\n",
    "\n",
    "estimator = SVC(kernel=\"linear\", random_state=0) # kernel soportado\n",
    "for num_features in num_features_range:\n",
    "    print(f\"----- {num_features} features\")\n",
    "    \n",
    "    preprocess = RFE(estimator, n_features_to_select=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "    rfe_svc = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(rfe_svc[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(rfe_svc, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fdedbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.22%\n",
      "Resultado obtenido usando las 10 'mejores variables'. Estimador SVC.\n"
     ]
    }
   ],
   "source": [
    "estimator = SVC(kernel=\"linear\", random_state=0)\n",
    "preprocess = RFE(estimator, n_features_to_select=10)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "rfe_svc_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.5, \n",
    "                            random_state=0, use_label_encoder=False)  \n",
    "rfe_svc_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_rfe_svc = rfe_svc_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_rfe_svc = accuracy_score(y_test, y_pred_rfe_svc)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_rfe_svc * 100))\n",
    "print(\"Resultado obtenido usando las 10 'mejores variables'. Estimador SVC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76349e",
   "metadata": {},
   "source": [
    "### Estimador LinearSVC\n",
    "\n",
    "Este estimador es muy similar al anterior SVC, utilizando exclusivamente sobre un kernel lineal, pero que por motivos de su implementación permite frente a este anterior una mayor flexibilidad en la elección de funciones de loss, términos de penalización, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a46d6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 10 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 88.24% \n",
      "\n",
      "----- 50 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 95.59% \n",
      "\n",
      "----- 90 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 130 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 170 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 210 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 92.65% \n",
      "\n",
      "----- 250 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 83.82% \n",
      "\n",
      "----- 290 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 77.94% \n",
      "\n",
      "----- 330 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 370 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 66.18% \n",
      "\n",
      "----- 410 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 63.24% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "estimator = LinearSVC(random_state=0)\n",
    "for num_features in num_features_range:\n",
    "    print(f\"----- {num_features} features\")\n",
    "    \n",
    "    preprocess = RFE(estimator, n_features_to_select=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    rfe_linearsvc = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(rfe_linearsvc[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(rfe_linearsvc, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c8d8925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.22%\n",
      "Resultado obtenido usando las 50 'mejores variables'. Estimador LinearSVC.\n"
     ]
    }
   ],
   "source": [
    "estimator = LinearSVC(random_state=0)\n",
    "preprocess = RFE(estimator, n_features_to_select=50)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "rfe_linearsvc_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.5, \n",
    "                                  random_state=0, use_label_encoder=False)  \n",
    "rfe_linearsvc_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_rfe_linearsvc = rfe_linearsvc_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_rfe_linearsvc = accuracy_score(y_test, y_pred_rfe_linearsvc)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_rfe_linearsvc * 100))\n",
    "print(\"Resultado obtenido usando las 50 'mejores variables'. Estimador LinearSVC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce9081",
   "metadata": {},
   "source": [
    "### Estimador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdb8ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 10 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- 50 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 73.53% \n",
      "\n",
      "----- 90 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 130 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 77.94% \n",
      "\n",
      "----- 170 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 210 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 250 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 75.00% \n",
      "\n",
      "----- 290 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- 330 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 66.18% \n",
      "\n",
      "----- 370 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 66.18% \n",
      "\n",
      "----- 410 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 66.18% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "estimator = RandomForestClassifier(random_state=0)\n",
    "for num_features in num_features_range:\n",
    "    print(f\"----- {num_features} features\")\n",
    "    \n",
    "    preprocess = RFE(estimator, n_features_to_select=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    rfe_rf = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(rfe_rf[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(rfe_rf, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f15f05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.89%\n",
      "Resultado obtenido usando las 130 'mejores variables'. Estimador Random Forest Classifier.\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(random_state=0)\n",
    "preprocess = RFE(estimator, n_features_to_select=130)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "rfe_rf_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.001, \n",
    "                           random_state=0, use_label_encoder=False)  \n",
    "rfe_rf_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_rfe_rf = rfe_rf_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_rfe_rf = accuracy_score(y_test, y_pred_rfe_rf)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_rfe_rf * 100))\n",
    "print(\"Resultado obtenido usando las 130 'mejores variables'. Estimador Random Forest Classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6803bc1",
   "metadata": {},
   "source": [
    "# SelectFromModel\n",
    "\n",
    "Documentación scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
    "\n",
    "Método muy similar al anterior, se apoya en el uso de otros estimadores para asignar pesos a las variables del conjunto para eliminar aquellas que considera menos significativas.\n",
    "\n",
    "### Estimador SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67ec0ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 10 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}]\n",
      "Accuracy: 86.76% \n",
      "\n",
      "----- 50 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 95.59% \n",
      "\n",
      "----- 90 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 130 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 92.65% \n",
      "\n",
      "----- 170 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 210 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 250 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 85.29% \n",
      "\n",
      "----- 290 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 77.94% \n",
      "\n",
      "----- 330 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 73.53% \n",
      "\n",
      "----- 370 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 70.59% \n",
      "\n",
      "----- 410 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 63.24% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "estimator = SVC(kernel=\"linear\", random_state=0)\n",
    "for num_features in num_features_range:\n",
    "    print(f\"----- {num_features} features\")\n",
    "    \n",
    "    preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    rfe_sfm_svc = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(rfe_sfm_svc[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(rfe_sfm_svc, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "846c3663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.56%\n",
      "Resultado obtenido usando las 50 'mejores variables'. Estimador SVC.\n"
     ]
    }
   ],
   "source": [
    "estimator = SVC(kernel=\"linear\", random_state=0)\n",
    "preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=50)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "rfe_sfm_svc_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.05, \n",
    "                                random_state=0, use_label_encoder=False)  \n",
    "rfe_sfm_svc_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_sfm_svc = rfe_sfm_svc_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_sfm_svc = accuracy_score(y_test, y_pred_sfm_svc)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_sfm_svc * 100))\n",
    "print(\"Resultado obtenido usando las 50 'mejores variables'. Estimador SVC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d75f84",
   "metadata": {},
   "source": [
    "### Estimador LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ac15096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 10 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 88.24% \n",
      "\n",
      "----- 50 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 98.53% \n",
      "\n",
      "----- 90 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 130 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 89.71% \n",
      "\n",
      "----- 170 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 92.65% \n",
      "\n",
      "----- 210 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 94.12% \n",
      "\n",
      "----- 250 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 85.29% \n",
      "\n",
      "----- 290 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 79.41% \n",
      "\n",
      "----- 330 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 70.59% \n",
      "\n",
      "----- 370 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 66.18% \n",
      "\n",
      "----- 410 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "estimator = LinearSVC(random_state=0)\n",
    "for num_features in num_features_range:\n",
    "    print(f\"----- {num_features} features\")\n",
    "    \n",
    "    preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    rfe_sfm_linearsvc = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(rfe_sfm_linearsvc[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(rfe_sfm_linearsvc, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcf79425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n",
      "Resultado obtenido usando las 50 'mejores variables'. Estimador LinearSVC.\n"
     ]
    }
   ],
   "source": [
    "estimator = LinearSVC(random_state=0)\n",
    "preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=50)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "rfe_sfm_linearsvc_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.5, \n",
    "                                      random_state=0, use_label_encoder=False)  \n",
    "rfe_sfm_linearsvc_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_sfm_linearsvc = rfe_sfm_linearsvc_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_sfm_linearsvc = accuracy_score(y_test, y_pred_sfm_linearsvc)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_sfm_linearsvc * 100))\n",
    "print(\"Resultado obtenido usando las 50 'mejores variables'. Estimador LinearSVC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7dd9c",
   "metadata": {},
   "source": [
    "### Estimador RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d6eb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 10 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 76.47% \n",
      "\n",
      "----- 50 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.05}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- 90 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.001}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 130 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.05}, {'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 73.53% \n",
      "\n",
      "----- 170 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}, {'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 72.06% \n",
      "\n",
      "----- 210 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 70.59% \n",
      "\n",
      "----- 250 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 69.12% \n",
      "\n",
      "----- 290 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 330 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 370 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.1}]\n",
      "Accuracy: 67.65% \n",
      "\n",
      "----- 410 features\n",
      "[{'booster': 'gblinear', 'learning_rate': 0.5}]\n",
      "Accuracy: 66.18% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "estimator = RandomForestClassifier(random_state=0)\n",
    "for num_features in num_features_range:\n",
    "    print(f\"----- {num_features} features\")\n",
    "    \n",
    "    preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    rfe_sfm_rf = train_GridSearchCV(model_XGB, param_grid_XGB, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    top_acc = top_acc_GridSearchCV(rfe_sfm_rf[\"mean_test_score\"])\n",
    "    print(models_same_acc_GridSearchCV(rfe_sfm_rf, top_acc))\n",
    "    print(\"Accuracy: {:0.2f}% \\n\".format(top_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa0e8ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.56%\n",
      "Resultado obtenido usando las 10 'mejores variables'. Estimador Random Forest.\n"
     ]
    }
   ],
   "source": [
    "estimator = RandomForestClassifier(random_state=0)\n",
    "preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=10)\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "rfe_sfm_rf_opt = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.1, \n",
    "                               random_state=0, use_label_encoder=False)  \n",
    "rfe_sfm_rf_opt.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_sfm_rf = rfe_sfm_rf_opt.predict(X_test_processed)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_sfm_rf = accuracy_score(y_test, y_pred_sfm_rf)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_sfm_rf * 100))\n",
    "print(\"Resultado obtenido usando las 10 'mejores variables'. Estimador Random Forest.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17720e01",
   "metadata": {},
   "source": [
    "# Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0c67f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = [accuracy_no_preprocessing,acc_normalized, acc_scaled, acc_pca, acc_select_k, acc_select_k2, acc_select_percent, \n",
    "           acc_select_percent2, acc_rfe_svc, acc_rfe_linearsvc, acc_rfe_rf, acc_sfm_svc, acc_sfm_linearsvc, acc_sfm_rf]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "xaxis = [\"Sin\\n preprocesar\", \"Normalizado\", \"Escalado\", \"PCA\", \"KBest \\n (ANOVA)\", \"KBest \\n (MI)\", \"Percent. \\n (ANOVA)\", \n",
    "         \"Percent \\n (MI)\", \"RFE \\n SVC\", \"RFE \\n LinearSVC\", \"RFE \\n RF\", \"SFM \\n SVC\", \"SFM \\n LinearSVC\", \"SFM \\n RF\"]\n",
    "barlist = plt.bar(xaxis, results, width=0.5)\n",
    "barlist[0].set_color(\"r\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
