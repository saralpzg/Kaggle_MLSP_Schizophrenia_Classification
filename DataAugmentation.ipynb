{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70addaeb",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Uno de los principales obstáculos que se encuentran al intentar hallar la major solución al problema de clasificación, es la escasez de datos para el entrenamiento de los modelos.\n",
    "\n",
    "Este notebook tiene como objetivo implementar y comparar los resultados obtenidos implementando técnicas de Data Augmentation para crear datos sintéticos y poder operar sobre un mayor volumen de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989e8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Cargar los datos\n",
    "from Modelos.data_and_submissions import *\n",
    "# Métodos para los entrenamientos con CV\n",
    "from Modelos.train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72411cba",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3c3352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data(True)\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d83db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_partition(data_augmented):\n",
    "    X = data_augmented.iloc[:, 1:]\n",
    "    Y = data_augmented.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bba535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119834, 410)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.concat((y_train, y_test), axis=0)\n",
    "features = pd.concat((X_train, X_test), axis=0)\n",
    "features_tot = pd.concat((features, test_kaggle), axis=0)\n",
    "print(features_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90d87f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>0.435160</td>\n",
       "      <td>0.225050</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>-0.353480</td>\n",
       "      <td>0.447420</td>\n",
       "      <td>0.183180</td>\n",
       "      <td>0.122420</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.404830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314668</td>\n",
       "      <td>-0.114078</td>\n",
       "      <td>-0.476524</td>\n",
       "      <td>-0.556896</td>\n",
       "      <td>0.505738</td>\n",
       "      <td>0.873278</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.211690</td>\n",
       "      <td>0.536933</td>\n",
       "      <td>-0.424864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0.468280</td>\n",
       "      <td>0.108890</td>\n",
       "      <td>0.072178</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.266450</td>\n",
       "      <td>0.350770</td>\n",
       "      <td>-0.210100</td>\n",
       "      <td>-0.089635</td>\n",
       "      <td>-0.140530</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200450</td>\n",
       "      <td>1.817908</td>\n",
       "      <td>-0.299583</td>\n",
       "      <td>0.740836</td>\n",
       "      <td>1.491966</td>\n",
       "      <td>0.993555</td>\n",
       "      <td>-0.043188</td>\n",
       "      <td>0.564047</td>\n",
       "      <td>-0.916360</td>\n",
       "      <td>2.771659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137060</td>\n",
       "      <td>-0.188670</td>\n",
       "      <td>-0.160220</td>\n",
       "      <td>-0.152680</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.142780</td>\n",
       "      <td>0.349660</td>\n",
       "      <td>-0.046245</td>\n",
       "      <td>-0.133690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922012</td>\n",
       "      <td>-0.197890</td>\n",
       "      <td>1.585873</td>\n",
       "      <td>-0.056353</td>\n",
       "      <td>0.806093</td>\n",
       "      <td>-1.517281</td>\n",
       "      <td>1.672678</td>\n",
       "      <td>-0.376343</td>\n",
       "      <td>-0.061299</td>\n",
       "      <td>-0.945018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.366770</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>-0.085309</td>\n",
       "      <td>-0.295600</td>\n",
       "      <td>0.311750</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200334</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>1.149330</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.729352</td>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.210830</td>\n",
       "      <td>0.423430</td>\n",
       "      <td>0.263870</td>\n",
       "      <td>0.298310</td>\n",
       "      <td>-0.088201</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266496</td>\n",
       "      <td>-1.527078</td>\n",
       "      <td>-1.028776</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>-0.938700</td>\n",
       "      <td>0.215549</td>\n",
       "      <td>-0.575946</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.619411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>-0.313110</td>\n",
       "      <td>-0.702080</td>\n",
       "      <td>-0.626550</td>\n",
       "      <td>-0.490060</td>\n",
       "      <td>-0.432500</td>\n",
       "      <td>-0.538550</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>0.198530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969872</td>\n",
       "      <td>0.470231</td>\n",
       "      <td>-0.319118</td>\n",
       "      <td>-0.160328</td>\n",
       "      <td>0.632695</td>\n",
       "      <td>-1.015545</td>\n",
       "      <td>-0.633930</td>\n",
       "      <td>0.683149</td>\n",
       "      <td>0.720507</td>\n",
       "      <td>1.369418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.189330</td>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.312910</td>\n",
       "      <td>0.245270</td>\n",
       "      <td>-0.226630</td>\n",
       "      <td>-0.130830</td>\n",
       "      <td>0.077108</td>\n",
       "      <td>-0.046652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.774058</td>\n",
       "      <td>1.739382</td>\n",
       "      <td>-1.845892</td>\n",
       "      <td>-1.522856</td>\n",
       "      <td>-1.344479</td>\n",
       "      <td>0.008769</td>\n",
       "      <td>0.898490</td>\n",
       "      <td>-0.164422</td>\n",
       "      <td>-0.050235</td>\n",
       "      <td>1.367143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>0.314770</td>\n",
       "      <td>0.295030</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.274070</td>\n",
       "      <td>0.396880</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.127860</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.126330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626300</td>\n",
       "      <td>-0.241099</td>\n",
       "      <td>-0.354035</td>\n",
       "      <td>-0.405403</td>\n",
       "      <td>-0.544734</td>\n",
       "      <td>-0.164949</td>\n",
       "      <td>0.659083</td>\n",
       "      <td>-0.868930</td>\n",
       "      <td>-0.530455</td>\n",
       "      <td>-0.722450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.128630</td>\n",
       "      <td>-0.290760</td>\n",
       "      <td>-0.505190</td>\n",
       "      <td>-0.554770</td>\n",
       "      <td>-0.275930</td>\n",
       "      <td>-0.026265</td>\n",
       "      <td>-0.418280</td>\n",
       "      <td>-0.527620</td>\n",
       "      <td>-0.381970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623423</td>\n",
       "      <td>0.509388</td>\n",
       "      <td>0.728753</td>\n",
       "      <td>-0.151419</td>\n",
       "      <td>1.698903</td>\n",
       "      <td>0.460504</td>\n",
       "      <td>-0.599519</td>\n",
       "      <td>1.229305</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.043127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "83      1  0.435160  0.225050  0.057172 -0.353480  0.447420  0.183180   \n",
       "40      0  0.468280  0.108890  0.072178  0.002432  0.266450  0.350770   \n",
       "60      0  0.137060 -0.188670 -0.160220 -0.152680  0.143570  0.142780   \n",
       "45      1 -0.174850 -0.119840 -0.366770 -0.354050  0.065508 -0.085309   \n",
       "73      1 -0.020630  0.250100  0.210830  0.423430  0.263870  0.298310   \n",
       "34      0  0.037074 -0.313110 -0.702080 -0.626550 -0.490060 -0.432500   \n",
       "20      0  0.328300  0.189330  0.027821  0.312910  0.245270 -0.226630   \n",
       "10      1  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "70      0  0.314770  0.295030  0.002139  0.274070  0.396880  0.078688   \n",
       "12      1 -0.128630 -0.290760 -0.505190 -0.554770 -0.275930 -0.026265   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "83  0.122420  0.024561  0.404830  ...   0.314668  -0.114078  -0.476524   \n",
       "40 -0.210100 -0.089635 -0.140530  ...   1.200450   1.817908  -0.299583   \n",
       "60  0.349660 -0.046245 -0.133690  ...  -0.922012  -0.197890   1.585873   \n",
       "45 -0.295600  0.311750 -0.013669  ...   1.200334   0.313340   0.287729   \n",
       "73 -0.088201  0.081132 -0.025001  ...  -0.266496  -1.527078  -1.028776   \n",
       "34 -0.538550  0.023721  0.198530  ...   0.969872   0.470231  -0.319118   \n",
       "20 -0.130830  0.077108 -0.046652  ...  -0.774058   1.739382  -1.845892   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "70  0.127860  0.011281  0.126330  ...  -0.626300  -0.241099  -0.354035   \n",
       "12 -0.418280 -0.527620 -0.381970  ...   0.623423   0.509388   0.728753   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "83  -0.556896   0.505738   0.873278   0.040048   0.211690   0.536933   \n",
       "40   0.740836   1.491966   0.993555  -0.043188   0.564047  -0.916360   \n",
       "60  -0.056353   0.806093  -1.517281   1.672678  -0.376343  -0.061299   \n",
       "45  -0.370420   0.224179   1.149330   1.842975   1.458239   0.729352   \n",
       "73   0.437655  -0.938700   0.215549  -0.575946   0.804762   1.351451   \n",
       "34  -0.160328   0.632695  -1.015545  -0.633930   0.683149   0.720507   \n",
       "20  -1.522856  -1.344479   0.008769   0.898490  -0.164422  -0.050235   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "70  -0.405403  -0.544734  -0.164949   0.659083  -0.868930  -0.530455   \n",
       "12  -0.151419   1.698903   0.460504  -0.599519   1.229305   0.998584   \n",
       "\n",
       "    SBM_map75  \n",
       "83  -0.424864  \n",
       "40   2.771659  \n",
       "60  -0.945018  \n",
       "45   0.522059  \n",
       "73   0.619411  \n",
       "34   1.369418  \n",
       "20   1.367143  \n",
       "10   1.003364  \n",
       "70  -0.722450  \n",
       "12   0.043127  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((labels, features), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea0b5c",
   "metadata": {},
   "source": [
    "# Random noise\n",
    "\n",
    "**Precisión de un modelo de Random Forest sobre el conjunto original de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447b1eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 750}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "no_data_aug = train_GridSearchCV(model_RF, param_grid_RF, X_train, X_test, y_train, y_test)\n",
    "top_acc = top_acc_GridSearchCV(no_data_aug[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(no_data_aug, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2139dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "no_data_aug_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=750, random_state=0)  \n",
    "no_data_aug_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_no_data_aug = no_data_aug_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_no_data_aug = accuracy_score(y_test, y_pred_no_data_aug)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_no_data_aug * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f03cbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_no_data_aug = no_data_aug_opt.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_no_data_aug, \"RF_no_DataAugmentation\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010d2b1",
   "metadata": {},
   "source": [
    "### Ruido gaussiano\n",
    "\n",
    "Una primera prueba de introducción de ruido artificial se basará en añadir a los datos originales, valores (ruido) que se tomarán de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de valores para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c268e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del intervalo)\n",
    "max_per_var = features_tot.max(axis=0)\n",
    "min_per_var = features_tot.min(axis=0)\n",
    "std_per_var = (max_per_var - min_per_var) * 0.1\n",
    "std_per_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304cc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232200</td>\n",
       "      <td>-0.042566</td>\n",
       "      <td>-0.791727</td>\n",
       "      <td>-0.772790</td>\n",
       "      <td>-0.346480</td>\n",
       "      <td>-0.117090</td>\n",
       "      <td>-0.509645</td>\n",
       "      <td>-0.336619</td>\n",
       "      <td>0.797302</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.222112</td>\n",
       "      <td>-1.402231</td>\n",
       "      <td>1.920834</td>\n",
       "      <td>1.026937</td>\n",
       "      <td>-1.144009</td>\n",
       "      <td>-2.123258</td>\n",
       "      <td>-1.525115</td>\n",
       "      <td>-1.448959</td>\n",
       "      <td>-2.371252</td>\n",
       "      <td>-0.894455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>-0.303637</td>\n",
       "      <td>-0.227025</td>\n",
       "      <td>-0.235851</td>\n",
       "      <td>0.187904</td>\n",
       "      <td>-0.334999</td>\n",
       "      <td>0.293302</td>\n",
       "      <td>0.586997</td>\n",
       "      <td>0.407761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001576</td>\n",
       "      <td>0.855035</td>\n",
       "      <td>0.711041</td>\n",
       "      <td>-0.935583</td>\n",
       "      <td>0.473294</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>-0.780473</td>\n",
       "      <td>-0.661480</td>\n",
       "      <td>2.054732</td>\n",
       "      <td>0.556554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.603918</td>\n",
       "      <td>-0.138133</td>\n",
       "      <td>-0.615962</td>\n",
       "      <td>-0.481932</td>\n",
       "      <td>-0.475437</td>\n",
       "      <td>-0.487702</td>\n",
       "      <td>-0.444205</td>\n",
       "      <td>-0.522006</td>\n",
       "      <td>-0.332678</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.920996</td>\n",
       "      <td>-1.332419</td>\n",
       "      <td>0.839660</td>\n",
       "      <td>0.103529</td>\n",
       "      <td>1.004458</td>\n",
       "      <td>-3.103754</td>\n",
       "      <td>1.742597</td>\n",
       "      <td>-1.272035</td>\n",
       "      <td>-0.018540</td>\n",
       "      <td>1.237611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119350</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.300453</td>\n",
       "      <td>0.223938</td>\n",
       "      <td>-0.018287</td>\n",
       "      <td>0.282171</td>\n",
       "      <td>0.039545</td>\n",
       "      <td>-0.361698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991947</td>\n",
       "      <td>-2.944841</td>\n",
       "      <td>1.107726</td>\n",
       "      <td>2.932836</td>\n",
       "      <td>1.460491</td>\n",
       "      <td>0.621709</td>\n",
       "      <td>-2.899831</td>\n",
       "      <td>-0.278128</td>\n",
       "      <td>-1.450732</td>\n",
       "      <td>-2.987256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318331</td>\n",
       "      <td>0.094148</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>-0.388997</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>-0.188975</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.799038</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370051</td>\n",
       "      <td>-1.407210</td>\n",
       "      <td>0.437209</td>\n",
       "      <td>0.150966</td>\n",
       "      <td>0.458162</td>\n",
       "      <td>0.662532</td>\n",
       "      <td>-1.468774</td>\n",
       "      <td>-0.648076</td>\n",
       "      <td>-1.144024</td>\n",
       "      <td>-0.057911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.050827</td>\n",
       "      <td>-0.481793</td>\n",
       "      <td>-0.077876</td>\n",
       "      <td>-0.149324</td>\n",
       "      <td>-0.301414</td>\n",
       "      <td>-0.158155</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>-0.092545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.305155</td>\n",
       "      <td>0.150132</td>\n",
       "      <td>0.607371</td>\n",
       "      <td>-0.224237</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>1.897722</td>\n",
       "      <td>0.304188</td>\n",
       "      <td>-0.171216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.232200 -0.042566 -0.791727 -0.772790 -0.346480 -0.117090   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.262460 -0.303637 -0.227025 -0.235851  0.187904 -0.334999   \n",
       "14    0.0 -0.603918 -0.138133 -0.615962 -0.481932 -0.475437 -0.487702   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.119350  0.115388  0.071737  0.300453  0.223938 -0.018287   \n",
       "18    0.0  0.318331  0.094148  0.007068 -0.388997  0.378600 -0.188975   \n",
       "3     1.0 -0.013986 -0.050827 -0.481793 -0.077876 -0.149324 -0.301414   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.509645 -0.336619  0.797302  ...  -3.222112  -1.402231   1.920834   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39  0.293302  0.586997  0.407761  ...   1.001576   0.855035   0.711041   \n",
       "14 -0.444205 -0.522006 -0.332678  ...  -1.920996  -1.332419   0.839660   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.282171  0.039545 -0.361698  ...   0.991947  -2.944841   1.107726   \n",
       "18  0.168999  0.799038  0.101366  ...   1.370051  -1.407210   0.437209   \n",
       "3  -0.158155  0.343952 -0.092545  ...   1.305155   0.150132   0.607371   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60   1.026937  -1.144009  -2.123258  -1.525115  -1.448959  -2.371252   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39  -0.935583   0.473294   0.998934  -0.780473  -0.661480   2.054732   \n",
       "14   0.103529   1.004458  -3.103754   1.742597  -1.272035  -0.018540   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   2.932836   1.460491   0.621709  -2.899831  -0.278128  -1.450732   \n",
       "18   0.150966   0.458162   0.662532  -1.468774  -0.648076  -1.144024   \n",
       "3   -0.224237   0.018921   0.976853   1.183815   1.897722   0.304188   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -0.894455  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.556554  \n",
       "14   1.237611  \n",
       "10   1.003364  \n",
       "69  -2.987256  \n",
       "18  -0.057911  \n",
       "3   -0.171216  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% del rango de la variable\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_gaussian[i, :] = generate_noisy_sample_gaussian(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian = np.c_[labels, noisy_features_gaussian]\n",
    "\n",
    "noisy_data_gaussian = pd.concat([data, pd.DataFrame(noisy_features_gaussian, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian = noisy_data_gaussian.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian.shape))\n",
    "noisy_data_gaussian.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9dee9",
   "metadata": {},
   "source": [
    "Precisión del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726e40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_gaussian, X_test_gaussian, y_train_gaussian, y_test_gaussian) = data_partition(noisy_data_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901beed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 250}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_gaussian = train_GridSearchCV(model_RF, param_grid_RF, X_train_gaussian, X_test_gaussian, \n",
    "                                       y_train_gaussian, y_test_gaussian)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_gaussian[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_gaussian, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430961ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_gaussian_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=5, n_estimators=250, random_state=0)  \n",
    "data_aug_gaussian_opt.fit(X_train_gaussian, y_train_gaussian)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_gaussian = data_aug_gaussian_opt.predict(X_test_gaussian)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_gaussian = accuracy_score(y_test_gaussian, y_pred_data_aug_gaussian)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_gaussian * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a4d8c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_data_aug_gaussian = data_aug_gaussian_opt.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_data_aug_gaussian, \"RF_DataAugmentation_GaussianI\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e989c1",
   "metadata": {},
   "source": [
    "Vamos a modificar ahora el método, de modo que los valores generados de ruido se tomen de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de la diferencia entre la media de las variables para pacientes con esquizofrenia y la media de las variables de los individuos de control.\n",
    "\n",
    "La motivación para introducir esta modificación es que podría ser que las distribuciones que definen cada variable sean diferentes cuando se considera a un individuo sano (etiqueta 0) y a un individuo enfermo (etiqueta 1). Si estas distribuciones están lo suficientemente cercanas, introducir un ruido aparentemente pequeño podría modificar una muestra originalmente correspondiente a una clase y generar otra de manera artificial con la misma etiqueta pero que se solapa con la distribución de la etiqueta opuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = data[data[\"Class\"] == 0]\n",
    "sick = data[data[\"Class\"] == 0]\n",
    "\n",
    "labels_control = control_group.iloc[:, 0]\n",
    "features_control = np.array(control_group.iloc[:, 1:])\n",
    "labels_sick = sick.iloc[:, 0]\n",
    "features_sick = np.array(sick.iloc[:, 1:])\n",
    "\n",
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del rango de la diferencia)\n",
    "avg_per_var_control = features_control.mean(axis=0)\n",
    "avg_per_var_sick = features_sick.mean(axis=0)\n",
    "std_per_var = abs((avg_per_var_control - avg_per_var_sick)) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330f58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.343140</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>-0.547010</td>\n",
       "      <td>-0.652910</td>\n",
       "      <td>-0.226870</td>\n",
       "      <td>-0.354650</td>\n",
       "      <td>-0.630850</td>\n",
       "      <td>-0.189460</td>\n",
       "      <td>0.704020</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.424498</td>\n",
       "      <td>-1.512935</td>\n",
       "      <td>1.480432</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-1.151279</td>\n",
       "      <td>-2.123389</td>\n",
       "      <td>-0.962200</td>\n",
       "      <td>-0.524886</td>\n",
       "      <td>-2.310918</td>\n",
       "      <td>-1.740839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>-0.196510</td>\n",
       "      <td>-0.245280</td>\n",
       "      <td>-0.083840</td>\n",
       "      <td>0.304210</td>\n",
       "      <td>-0.180270</td>\n",
       "      <td>-0.008647</td>\n",
       "      <td>0.384610</td>\n",
       "      <td>0.300520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>1.135537</td>\n",
       "      <td>-0.256829</td>\n",
       "      <td>0.222902</td>\n",
       "      <td>0.528734</td>\n",
       "      <td>1.098908</td>\n",
       "      <td>-1.239779</td>\n",
       "      <td>-0.421480</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>0.325227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.391350</td>\n",
       "      <td>-0.284360</td>\n",
       "      <td>-0.655090</td>\n",
       "      <td>-0.645960</td>\n",
       "      <td>-0.241020</td>\n",
       "      <td>-0.352420</td>\n",
       "      <td>-0.480940</td>\n",
       "      <td>-0.393730</td>\n",
       "      <td>-0.277160</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.180108</td>\n",
       "      <td>-0.404150</td>\n",
       "      <td>0.358206</td>\n",
       "      <td>0.285097</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>-3.015051</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>-1.158544</td>\n",
       "      <td>-0.694036</td>\n",
       "      <td>-0.540947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.319650</td>\n",
       "      <td>0.099134</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.120010</td>\n",
       "      <td>0.088958</td>\n",
       "      <td>0.171350</td>\n",
       "      <td>-0.117730</td>\n",
       "      <td>-0.263870</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240290</td>\n",
       "      <td>-2.316457</td>\n",
       "      <td>0.115988</td>\n",
       "      <td>1.992077</td>\n",
       "      <td>1.094181</td>\n",
       "      <td>0.362267</td>\n",
       "      <td>-1.395818</td>\n",
       "      <td>-0.647623</td>\n",
       "      <td>-0.699748</td>\n",
       "      <td>-2.677100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263490</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>-0.367170</td>\n",
       "      <td>0.300860</td>\n",
       "      <td>-0.016165</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.370830</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781677</td>\n",
       "      <td>-0.535058</td>\n",
       "      <td>0.034981</td>\n",
       "      <td>-0.853332</td>\n",
       "      <td>0.965745</td>\n",
       "      <td>1.067908</td>\n",
       "      <td>-0.563230</td>\n",
       "      <td>-1.104692</td>\n",
       "      <td>-1.118982</td>\n",
       "      <td>-0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.366770</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>-0.085309</td>\n",
       "      <td>-0.295600</td>\n",
       "      <td>0.311750</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200334</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>1.149330</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.729352</td>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.343140  0.020893 -0.547010 -0.652910 -0.226870 -0.354650   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.026362 -0.196510 -0.245280 -0.083840  0.304210 -0.180270   \n",
       "14    0.0 -0.391350 -0.284360 -0.655090 -0.645960 -0.241020 -0.352420   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.319650  0.099134  0.010361  0.004176  0.120010  0.088958   \n",
       "18    0.0  0.263490  0.022323  0.043017 -0.367170  0.300860 -0.016165   \n",
       "3     1.0 -0.174850 -0.119840 -0.366770 -0.354050  0.065508 -0.085309   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.630850 -0.189460  0.704020  ...  -3.424498  -1.512935   1.480432   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39 -0.008647  0.384610  0.300520  ...   0.464108   1.135537  -0.256829   \n",
       "14 -0.480940 -0.393730 -0.277160  ...  -2.180108  -0.404150   0.358206   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.171350 -0.117730 -0.263870  ...   1.240290  -2.316457   0.115988   \n",
       "18  0.100220  0.370830  0.123080  ...   0.781677  -0.535058   0.034981   \n",
       "3  -0.295600  0.311750 -0.013669  ...   1.200334   0.313340   0.287729   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60  -0.012000  -1.151279  -2.123389  -0.962200  -0.524886  -2.310918   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39   0.222902   0.528734   1.098908  -1.239779  -0.421480   1.130700   \n",
       "14   0.285097   0.955665  -3.015051   0.024974  -1.158544  -0.694036   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   1.992077   1.094181   0.362267  -1.395818  -0.647623  -0.699748   \n",
       "18  -0.853332   0.965745   1.067908  -0.563230  -1.104692  -1.118982   \n",
       "3   -0.370420   0.224179   1.149330   1.842975   1.458239   0.729352   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -1.740839  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.325227  \n",
       "14  -0.540947  \n",
       "10   1.003364  \n",
       "69  -2.677100  \n",
       "18  -0.037143  \n",
       "3    0.522059  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian2(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% de la diferencia entre la media de la variable para cada clase\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian_2 = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_gaussian_2[i, :] = generate_noisy_sample_gaussian2(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian_2 = np.c_[labels, noisy_features_gaussian_2]\n",
    "\n",
    "noisy_data_gaussian_2 = pd.concat([data, pd.DataFrame(noisy_features_gaussian_2, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian_2 = noisy_data_gaussian_2.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian_2.shape))\n",
    "noisy_data_gaussian_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f12f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_gaussian2, X_test_gaussian2, y_train_gaussian2, y_test_gaussian2) = data_partition(noisy_data_gaussian_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f11370e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 500}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_gaussian2 = train_GridSearchCV(model_RF, param_grid_RF, X_train_gaussian2, X_test_gaussian2, \n",
    "                                        y_train_gaussian2, y_test_gaussian2)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_gaussian2[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_gaussian2, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755ba791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.57%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_gaussian_opt2 = RandomForestClassifier(criterion=\"gini\", max_depth=20, n_estimators=500, random_state=0)  \n",
    "data_aug_gaussian_opt2.fit(X_train_gaussian2, y_train_gaussian2)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_gaussian2 = data_aug_gaussian_opt2.predict(X_test_gaussian2)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_gaussian2 = accuracy_score(y_test_gaussian2, y_pred_data_aug_gaussian2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_gaussian2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fee9d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_data_aug_gaussian2 = data_aug_gaussian_opt2.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_data_aug_gaussian2, \"RF_DataAugmentation_GaussianII\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8603",
   "metadata": {},
   "source": [
    "### Ruido uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "724ab306",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_var = features_tot.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a75640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0.143325</td>\n",
       "      <td>-0.607460</td>\n",
       "      <td>-0.668581</td>\n",
       "      <td>-0.043226</td>\n",
       "      <td>-0.299202</td>\n",
       "      <td>-0.731040</td>\n",
       "      <td>-0.240142</td>\n",
       "      <td>0.768622</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.499343</td>\n",
       "      <td>-1.440684</td>\n",
       "      <td>1.418062</td>\n",
       "      <td>-0.112408</td>\n",
       "      <td>-1.172020</td>\n",
       "      <td>-1.980269</td>\n",
       "      <td>-0.910399</td>\n",
       "      <td>-0.415231</td>\n",
       "      <td>-2.311371</td>\n",
       "      <td>-1.608504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249280</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>-0.305730</td>\n",
       "      <td>-0.099511</td>\n",
       "      <td>0.487854</td>\n",
       "      <td>-0.124822</td>\n",
       "      <td>-0.108838</td>\n",
       "      <td>0.333928</td>\n",
       "      <td>0.365122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389263</td>\n",
       "      <td>1.207788</td>\n",
       "      <td>-0.319200</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.507993</td>\n",
       "      <td>1.242028</td>\n",
       "      <td>-1.187978</td>\n",
       "      <td>-0.311825</td>\n",
       "      <td>1.130247</td>\n",
       "      <td>0.457562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168432</td>\n",
       "      <td>-0.161928</td>\n",
       "      <td>-0.715540</td>\n",
       "      <td>-0.661631</td>\n",
       "      <td>-0.057376</td>\n",
       "      <td>-0.296972</td>\n",
       "      <td>-0.581130</td>\n",
       "      <td>-0.444412</td>\n",
       "      <td>-0.212558</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.254953</td>\n",
       "      <td>-0.331899</td>\n",
       "      <td>0.295836</td>\n",
       "      <td>0.184689</td>\n",
       "      <td>0.934924</td>\n",
       "      <td>-2.871931</td>\n",
       "      <td>0.076776</td>\n",
       "      <td>-1.048889</td>\n",
       "      <td>-0.694488</td>\n",
       "      <td>-0.408612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542568</td>\n",
       "      <td>0.221566</td>\n",
       "      <td>-0.050089</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.303654</td>\n",
       "      <td>0.144406</td>\n",
       "      <td>0.071160</td>\n",
       "      <td>-0.168412</td>\n",
       "      <td>-0.199268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165445</td>\n",
       "      <td>-2.244207</td>\n",
       "      <td>0.053618</td>\n",
       "      <td>1.891669</td>\n",
       "      <td>1.073441</td>\n",
       "      <td>0.505387</td>\n",
       "      <td>-1.344017</td>\n",
       "      <td>-0.537968</td>\n",
       "      <td>-0.700200</td>\n",
       "      <td>-2.544765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486408</td>\n",
       "      <td>0.144755</td>\n",
       "      <td>-0.017433</td>\n",
       "      <td>-0.382841</td>\n",
       "      <td>0.484504</td>\n",
       "      <td>0.039283</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.320148</td>\n",
       "      <td>0.187682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706832</td>\n",
       "      <td>-0.462807</td>\n",
       "      <td>-0.027389</td>\n",
       "      <td>-0.953739</td>\n",
       "      <td>0.945004</td>\n",
       "      <td>1.211029</td>\n",
       "      <td>-0.511429</td>\n",
       "      <td>-0.995037</td>\n",
       "      <td>-1.119434</td>\n",
       "      <td>0.095193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048068</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>-0.427220</td>\n",
       "      <td>-0.369721</td>\n",
       "      <td>0.249152</td>\n",
       "      <td>-0.029861</td>\n",
       "      <td>-0.395790</td>\n",
       "      <td>0.261068</td>\n",
       "      <td>0.050933</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125489</td>\n",
       "      <td>0.385591</td>\n",
       "      <td>0.225359</td>\n",
       "      <td>-0.470828</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>1.292451</td>\n",
       "      <td>1.894776</td>\n",
       "      <td>1.567895</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.654394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.120222  0.143325 -0.607460 -0.668581 -0.043226 -0.299202   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.249280 -0.074078 -0.305730 -0.099511  0.487854 -0.124822   \n",
       "14    0.0 -0.168432 -0.161928 -0.715540 -0.661631 -0.057376 -0.296972   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.542568  0.221566 -0.050089 -0.011495  0.303654  0.144406   \n",
       "18    0.0  0.486408  0.144755 -0.017433 -0.382841  0.484504  0.039283   \n",
       "3     1.0  0.048068  0.002592 -0.427220 -0.369721  0.249152 -0.029861   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.731040 -0.240142  0.768622  ...  -3.499343  -1.440684   1.418062   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39 -0.108838  0.333928  0.365122  ...   0.389263   1.207788  -0.319200   \n",
       "14 -0.581130 -0.444412 -0.212558  ...  -2.254953  -0.331899   0.295836   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.071160 -0.168412 -0.199268  ...   1.165445  -2.244207   0.053618   \n",
       "18  0.000030  0.320148  0.187682  ...   0.706832  -0.462807  -0.027389   \n",
       "3  -0.395790  0.261068  0.050933  ...   1.125489   0.385591   0.225359   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60  -0.112408  -1.172020  -1.980269  -0.910399  -0.415231  -2.311371   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39   0.122495   0.507993   1.242028  -1.187978  -0.311825   1.130247   \n",
       "14   0.184689   0.934924  -2.871931   0.076776  -1.048889  -0.694488   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   1.891669   1.073441   0.505387  -1.344017  -0.537968  -0.700200   \n",
       "18  -0.953739   0.945004   1.211029  -0.511429  -0.995037  -1.119434   \n",
       "3   -0.470828   0.203439   1.292451   1.894776   1.567895   0.728900   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -1.608504  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.457562  \n",
       "14  -0.408612  \n",
       "10   1.003364  \n",
       "69  -2.544765  \n",
       "18   0.095193  \n",
       "3    0.654394  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_uniform(original_sample, data=data, std_per_var=std_per_var, avg_per_var=avg_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución uniforme\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.uniform(avg_per_var[j]-std_per_var[j], avg_per_var[j]+std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_uniform = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_uniform[i, :] = generate_noisy_sample_uniform(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_uniform = np.c_[labels, noisy_features_uniform]\n",
    "\n",
    "noisy_data_uniform = pd.concat([data, pd.DataFrame(noisy_features_uniform, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_uniform = noisy_data_uniform.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_uniform.shape))\n",
    "noisy_data_uniform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31db9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_uniform, X_test_uniform, y_train_uniform, y_test_uniform) = data_partition(noisy_data_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7512601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 1000}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_uniform = train_GridSearchCV(model_RF, param_grid_RF, X_train_uniform, X_test_uniform, y_train_uniform, y_test_uniform)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_uniform[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_uniform, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46bb5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_uniform_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=1000, random_state=0)  \n",
    "data_aug_uniform_opt.fit(X_train_uniform, y_train_uniform)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_uniform = data_aug_uniform_opt.predict(X_test_uniform)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_uniform = accuracy_score(y_test_uniform, y_pred_data_aug_uniform)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_uniform * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3fea997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_data_aug_uniform = data_aug_uniform_opt.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_data_aug_uniform, \"RF_DataAugmentation_Uniform\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe059ea4",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Otra posibilidad para hacer Data Augmentation es, dado que se dispone de un gran volumen de datos no etiquetados, obtener una estimación lo más acertada posible de las etiquetas a las que estarían asociados estos datos. En este caso, podríamos plantearnos repetir algún entrenamiento, esta vez sobre un conjunto de datos mucho mayor.\n",
    "\n",
    "El modelo en base al cual vamos a generar estas predicciones va a ser el encoder ya visto anteriormente. Ya que como se ha explicado, se genera a partir de una red autoencoder que ha entrenado sobre el conjunto de datos completo que queremos etiquetar aquí y posteriormente ha adaptado sus pesos en la parte encoder al problema de clasificación que nos interesa aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8409ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e38bb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.load_model(\"Modelos/encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f094f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 410)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "args = np.random.choice(a=np.arange(0, test_kaggle.shape[0]), size=10000, replace=False)\n",
    "test_kaggle_reduc = test_kaggle.iloc[args, :]\n",
    "\n",
    "test_kaggle_reduc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "922cfa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_kaggle_reduc = encoder.predict(test_kaggle_reduc)\n",
    "\n",
    "labels_tot = np.concatenate((np.reshape(y_train.to_numpy(), (68, 1)), y_test_kaggle_reduc), axis=0)\n",
    "labels_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a5e4f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 410)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tot = np.concatenate((X_train, test_kaggle_reduc))\n",
    "features_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2052d",
   "metadata": {},
   "source": [
    "Vamos a repetir el entrenamiento con una de las configuraciones de Random Forest que ha alcanzado los mejores resultados.\n",
    "\n",
    "Accuracy en ``y_test`` sin aumentar el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c221fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "no_data_aug_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "no_data_aug_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_no_data_aug = no_data_aug_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_no_data_aug2 = accuracy_score(y_test, y_pred_no_data_aug)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_no_data_aug2 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fc4ca",
   "metadata": {},
   "source": [
    "Accuracy en ``y_test`` aumentando el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "277f1abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "rf_encoder1 = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "rf_encoder1.fit(features_tot, np.around(labels_tot, decimals=0).ravel())\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_encoder1 = rf_encoder1.predict(X_test.to_numpy())\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_encoder1 = accuracy_score(y_test, y_pred_encoder1)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_encoder1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd2943",
   "metadata": {},
   "source": [
    "**Prueba con el segundo autoencoder entrenado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebef0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder3 = models.load_model(\"Modelos/encoder3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1fe3141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_kaggle_reduc = encoder3.predict(test_kaggle_reduc)\n",
    "\n",
    "labels_tot = np.concatenate((np.reshape(y_train.to_numpy(), (68, 1)), y_test_kaggle_reduc), axis=0)\n",
    "labels_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cf63b",
   "metadata": {},
   "source": [
    "Accuracy en ``y_test`` aumentando el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82e4e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "rf_encoder3 = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "rf_encoder3.fit(features_tot, np.around(labels_tot, decimals=0).ravel())\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_encoder3 = rf_encoder3.predict(X_test.to_numpy())\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_encoder3 = accuracy_score(y_test, y_pred_encoder3)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_encoder3 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea7227",
   "metadata": {},
   "source": [
    "# Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "198c17e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_acc = [acc_no_data_aug, acc_data_aug_gaussian, acc_data_aug_gaussian2, acc_data_aug_uniform]\n",
    "xaxis = [\"Sin Data Augmentation\", \"Ruido gaussiano I\", \"Ruido gaussiano II\", \"Ruido uniforme\"]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "barlist = plt.bar(xaxis, results_acc, width=0.2)\n",
    "barlist[0].set_color(\"r\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.ylim(bottom=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "154d03d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEvCAYAAAB2Xan3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkjklEQVR4nO3deXxU5b3H8e+PEGQHEVwQbbAXypKNmAQEZBcBF2SxgBGKCogVvdULBduK1Fu8bi2IXSgq4sIqCCKLIAUEBTRhB1FEAVmsBVRkC5jw3D9mGELIMoHAQ8Ln/Xr5cuac55zzm5mHfOecM+c85pwTAADwp4TvAgAAuNgRxgAAeEYYAwDgGWEMAIBnhDEAAJ4RxgAAeFbS14arVq3qoqKifG0eAIDzbuXKlXudc9WyT/cWxlFRUUpLS/O1eQAAzjsz257TdA5TAwDgGWEMAIBnhDEAAJ4RxgAAeEYYAwDgGWEMAIBnhDEAAJ4RxgAAeEYYAwDgGWEMAIBnhDEAAJ55uzc1cDGKGjLbdwna9vQtvksAkA17xgAAeEYYAwDgGWEMAIBnhDEAAJ4RxgAAeEYYAwDgGWEMAIBnxeY64wvh+k2JazgBFG0Xwt/Si/HvKHvGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOBZsbm06YIxrJLvCgKG7fddAS5U9FFc6C7CPsqeMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnoUVxmbWzsw+N7MtZjYkh/mVzOxdM1trZhvN7J7CLxUAgOIp3zA2swhJf5PUXlI9ST3MrF62Zg9K+tQ5FyephaQ/m1mpQq4VAIBiKZw942RJW5xzXznnjkmaJKljtjZOUgUzM0nlJX0nKaNQKwUAoJgKJ4yvlrQjy/OdwWlZ/VVSXUm7Ja2X9N/OueOFUiEAAMVcOGFsOUxz2Z7fLGmNpOqS4iX91cwqnrYis35mlmZmaXv27ClgqQAAFE/hhPFOSddkeV5DgT3grO6R9LYL2CJpq6Q62VfknBvjnEt0ziVWq1btTGsGAKBYCSeMUyXVMrOawR9ldZc0M1ubryW1liQzu0LSLyR9VZiFAgBQXOU7UIRzLsPMBkiaJylC0ljn3EYz6x+cP1rS/0oaZ2brFTisPdg5t/cc1g0AQLER1qhNzrk5kuZkmzY6y+PdktoWbmkAAFwcuAMXAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHhGGAMA4BlhDACAZ4QxAACeEcYAAHgWVhibWTsz+9zMtpjZkFzatDCzNWa20cw+KNwyAQAovkrm18DMIiT9TdJNknZKSjWzmc65T7O0qSzp75LaOee+NrPLz1G9AAAUO+HsGSdL2uKc+8o5d0zSJEkds7W5S9LbzrmvJck595/CLRMAgOIrnDC+WtKOLM93BqdlVVvSpWa22MxWmlmvnFZkZv3MLM3M0vbs2XNmFQMAUMyEE8aWwzSX7XlJSddLukXSzZIeN7Papy3k3BjnXKJzLrFatWoFLhYAgOIo33PGCuwJX5PleQ1Ju3Nos9c5d0jSITNbIilO0uZCqRIAgGIsnD3jVEm1zKymmZWS1F3SzGxt3pF0o5mVNLOykhpK2lS4pQIAUDzlu2fsnMswswGS5kmKkDTWObfRzPoH5492zm0ys/ckrZN0XNLLzrkN57JwAACKi3AOU8s5N0fSnGzTRmd7/pyk5wqvNAAALg7cgQsAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM8IYwAAPCOMAQDwjDAGAMAzwhgAAM/CCmMza2dmn5vZFjMbkke7JDPLNLOuhVciAADFW75hbGYRkv4mqb2kepJ6mFm9XNo9I2leYRcJAEBxFs6ecbKkLc65r5xzxyRNktQxh3YPSZom6T+FWB8AAMVeOGF8taQdWZ7vDE4LMbOrJXWSNLrwSgMA4OIQThhbDtNctucjJQ12zmXmuSKzfmaWZmZpe/bsCbNEAACKt5JhtNkp6Zosz2tI2p2tTaKkSWYmSVUldTCzDOfcjKyNnHNjJI2RpMTExOyBDgDARSmcME6VVMvMakraJam7pLuyNnDO1Tzx2MzGSZqVPYgBAEDO8g1j51yGmQ1Q4FfSEZLGOuc2mln/4HzOEwMAcBbC2TOWc26OpDnZpuUYws653mdfFgAAFw/uwAUAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnhHGAAB4RhgDAOAZYQwAgGeEMQAAnoUVxmbWzsw+N7MtZjYkh/kpZrYu+N8yM4sr/FIBACie8g1jM4uQ9DdJ7SXVk9TDzOpla7ZVUnPnXKyk/5U0prALBQCguApnzzhZ0hbn3FfOuWOSJknqmLWBc26Zc+774NMVkmoUbpkAABRf4YTx1ZJ2ZHm+MzgtN/dJmpvTDDPrZ2ZpZpa2Z8+e8KsEAKAYCyeMLYdpLseGZi0VCOPBOc13zo1xziU65xKrVasWfpUAABRjJcNos1PSNVme15C0O3sjM4uV9LKk9s65fYVTHgAAxV84e8apkmqZWU0zKyWpu6SZWRuY2bWS3pbU0zm3ufDLBACg+Mp3z9g5l2FmAyTNkxQhaaxzbqOZ9Q/OHy1pqKTLJP3dzCQpwzmXeO7KBgCg+AjnMLWcc3Mkzck2bXSWx30k9Snc0gAAuDhwBy4AADwjjAEA8IwwBgDAM8IYAADPCGMAADwjjAEA8IwwBgDAM8IYAADPCGMAADwjjAEA8IwwBgDAM8IYAADPCGMAADwjjAEA8IwwBgDAs7DGMwZwcfupVGXtTBis9ErXSbLCWemmTYWzHhSql26/yncJ2mRTfJcQcBZ9tHTp0qpRo4YiIyPDak8YA8jXzoTBqnBdoqLKlZRZIYVx9bqFsx4Uqp92/uC7BNUtUUh97GydYR91zmnfvn3auXOnatasGdYyHKYGkK/0StfpssIMYqAYMzNddtllSk9PD3sZwhhAGIwgBgqgoP9eCGMARcb06dNlZvrss898l1Jg27Zt04QJE87Junv37q2aNWsqLi5OtWvXVq9evbRr1658lxs5cqQOHz5c4O1lZGSoeezP9cLTfzyTcs+Lp0a9ckbtGt/e+xxUkz/OGQMosKhRuwthLSfXse3pW8JaYuLEiWratKkmTZqkYcOGFUINOcvMzFREREShrvNEGN91112nzcvIyFDJkmf35/i5555T165d5ZzTyJEj1bJlS23YsEGlSpXKdZmRI0fq7rvvVtmyZQu0reVLFirq5/+l+e/O0MODh16QR02eenGsfvfwfQVut2zmuHNYVe7YMwZQJBw8eFAfffSRXnnlFU2aNCk0PTMzUwMHDlRMTIxiY2P14osvSpJSU1PVuHFjxcXFKTk5WQcOHNC4ceM0YMCA0LK33nqrFi9eLEkqX768hg4dqoYNG2r58uV68sknlZSUpOjoaPXr10/OOUnSli1b1KZNG8XFxSkhIUFffvmlevbsqXfeeSe03pSUFM2cOfOU+ocMGaKlS5cqPj5eI0aM0Lhx43TnnXfqtttuU9u2bXXw4EG1bt1aCQkJiomJCa3v0KFDuuWWWxQXF6fo6GhNnjw5z/fJzPTII4/oyiuv1Ny5cyVJDzzwgBITE1W/fn098cQTkqRRo0Zp9+7datmypVq2bBlq16NDS3VqfYP+/uf/y3Ubc9+Zprvu7a8rr66hdatSQ9Pb3xCr77/bJ0nauHa17rvzVknSd/v26v67Oqlb++Z6cshv1K5RjL7/bp927fhaHVska9igh9W59Q167KG+WrF0sZp0vEe1mnTUJ6s3BN6Dw0d076PDlNThbjVo20PvzAt8ZuMmz1TnPv+jdikPqlaTjvrtn0YG3uunRulI+lHF39RdKQN+L0m6495HdX27u1S/ZVeNeXNaru3K12oiKfAjrEGDBik6OloxMTGh933x4sVq0aKFunbtqjp16iglJSXUN84Ge8YAioQZM2aoXbt2ql27tqpUqaJVq1YpISFBY8aM0datW7V69WqVLFlS3333nY4dO6Zu3bpp8uTJSkpK0o8//qgyZcrkuf5Dhw4pOjpaTz75pCSpXr16Gjp0qCSpZ8+emjVrlm677TalpKRoyJAh6tSpk9LT03X8+HH16dNHI0aMUMeOHbV//34tW7ZMr7322inrf/rpp/X8889r1qxZkqRx48Zp+fLlWrdunapUqaKMjAxNnz5dFStW1N69e9WoUSPdfvvteu+991S9enXNnj1bkrR///6w3q+EhAR99tln6tixo4YPH64qVaooMzNTrVu31rp16/Twww/rL3/5ixYtWqSqVatKkoYPH66dh0soMzNT/bp31OZNG1S7bvQp600/ckSffLhEjz89Qgd+3K+570xT3PXJedYyesQzSm58o+4b8Kg+WrRA08affG92bPtKz//jVQ19ZqTuurWV5syYqg9njNXM+R/oqRfHasbYv2j4Cy+rVZMkjf3LMP2w/4CSb+mpNjc2lCSt2bhZq+dN0CWlSukXzTrpoXu66+nfPay/vjpZa94/+aVt7J+fUJVLK+nIkXQl3dJTXTq0zrHdCW/PWag1a9Zo7dq12rt3r5KSktSsWTNJ0urVq7Vx40ZVr15dTZo00UcffaSmTZuG9bnkhj1jAEXCxIkT1b17d0lS9+7dNXHiREnSggUL1L9//9Bh3ipVqujzzz/XVVddpaSkJElSxYoV8z0MHBERoS5duoSeL1q0SA0bNlRMTIwWLlyojRs36sCBA9q1a5c6deokKXAtadmyZdW8eXNt2bJF//nPfzRx4kR16dIlrMPON910k6pUqSIpsCf2u9/9TrGxsWrTpo127dqlb7/9VjExMVqwYIEGDx6spUuXqlKlSmG9X1n31qZMmaKEhAQ1aNBAGzdu1KeffprjMlOmTFG39s3VrV0zfbn5M325+fPT2iz51zwlNW6qMmXKqk2H27XwvVnKzMzMs5Y1qSt08+2B97ZJyzaqWKlyaN7V1/xMterWV4kSJfTz2nXUsGkzmZli6vyXtu0InMqYv2SFnv7bOMXf1F0tuvZV+tFj+nrXN5Kk1k2TValiBZUufYnq1b5O24PTsxs1dqLi2nRTo9t+pR27v9UXW7/Os+YPP1mtHj16KCIiQldccYWaN2+u1NTAUYDk5GTVqFFDJUqUUHx8vLZt25bnusLBnjGAC96+ffu0cOFCbdiwQWamzMxMmZmeffZZOedOO2eZ0zRJKlmypI4fPx56nvXSk9KlS4fOE6enp+vXv/610tLSdM0112jYsGFKT0/P83Bkz549NX78eE2aNEljx44N63WVK1cu9Hj8+PHas2ePVq5cqcjISEVFRSk9PV21a9fWypUrNWfOHD322GNq27ZtaI89L6tXr1br1q21detWPf/880pNTdWll16q3r1753jJzYl242YsUMXKlfX4I7/WsaNHT2s3951pWpP2sdrfECtJ2v/990pdtlSNbmyhiIiT7+/Roye3kdf7FpnlnHYJK6FSpS4JPC5RQhnBkHfOadqY5/SL/4o6ZdmPV23QJaVO3lQjokQJZWSc/sVg8bI0LVj6iZa/O05ly5QJBXpe8qr5kksuObnNiAhlZGTkua5wsGcM4II3depU9erVS9u3b9e2bdu0Y8cO1axZUx9++KHatm2r0aNHh/4gfvfdd6pTp452794d2pM5cOCAMjIyFBUVpTVr1uj48ePasWOHPvnkkxy3dyKsqlatqoMHD2rq1KmSAnvYNWrU0IwZMyRJR48eDf0auXfv3ho5cqQkqX79+qets0KFCjpw4ECur3H//v26/PLLFRkZqUWLFmn79u2SpN27d6ts2bK6++67NXDgQK1atSrP98o5p1GjRumbb75Ru3bt9OOPP6pcuXKqVKmSvv3229B55Ow1nWhXvmJF7dvzH324eMFp6z544EetTl2heSvWa+7ydZq7fJ0e+9NzmvtO4Bxs9Wuu1ab1ayRJ/5rzbmi5BkmNNH/WdEnSsg8W6sf9P+T5GrK7ufkNevHVSaGAXL0h/1/TR0aW1E8//SRJ2n/goC6tVEFly5TRZ1u2asWq9Tm2y6pZowRNnjxZmZmZ2rNnj5YsWaLk5LwPx58NwhjABW/ixImhQ8MndOnSRRMmTFCfPn107bXXKjY2VnFxcZowYYJKlSqlyZMn66GHHlJcXJxuuukmpaenq0mTJqpZs6ZiYmI0cOBAJSQk5Li9ypUrq2/fvoqJidEdd9wROtwtSW+88YZGjRql2NhYNW7cWP/+978lSVdccYXq1q2re+65J8d1xsbGqmTJkoqLi9OIESNOm5+SkqK0tDQlJiZq/PjxqlOnjiRp/fr1Sk5OVnx8vIYPH64//OEPOa5/0KBBoUubUlNTtWjRIpUqVUpxcXFq0KCB6tevr3vvvVdNmjQJLdOvXz+1b99eLVu2DLXr3PoGPTFwgOITG562jX/NnaXkxjeqVJY9w5ZtO+iD9+fq2NGj6v+b3+qZJx5T787tVSLLr9Hvf2Swli9ZpG7tm+ujRQtU7fIrVa5c+RxfR04e/01f/fRThmLbdFN0qzv1+LN/z3eZfimdFdumm1IG/F7tWjRWRmamYtv8Uo8/+w81SojJsV1Wndq3CvWpVq1a6dlnn9WVV14Zds0FZYXxK7AzkZiY6NLS0gptfVFDZhfaus7GttKnX7bgxbDwfuSB8+tC6Kdn0kc33TxFdX92eeEWUr1B4a7Ps8OHDysmJkarVq0K+7zuhWjdObgd5rGjR1UiIkIlS5bU2pWfaPjv/kdT5i3NtX1sia2FXsMZOcs+umnTJtWte+otNc1spXMuMXtbzhkDwFlasGCB7r33Xj366KNFOojPlW9279SgB+6RO35ckZGlNPSZF3yXdMEhjAHgLLVp00Zff533r3MvZj+r+XNNeW+J7zIuaJwzBgDAM8IYAADPCGMAADwjjAEA8IwwBlBkFOUhFHPToUMH/fDDD2G3HzZsmK6++mrFx8erVq1a6ty5c663t8xq3Lhx2r37zEbburNtUw1+MP8RkHwZ+dJ4HT5ypMDtOvR8SD/sz/1GLOcTv6YGUHBjWhTu+sK8Lr4oD6GYmzlz5hR4mUceeUQDBw6UJE2ePFmtWrXS+vXrVa1atVyXGTdunKKjo1W9evUCbeurLz7X8ePHtfLj5Tp8+JDKli2X/0Ln2ciXJ+juLh1UNp/BQLK3m/PGi+ejvLCwZwygSCjqQyh+8803atasmeLj4xUdHa2lSwM3vYiKitLevXu1bds21a1bV3379lX9+vXVtm1bHQljb69bt25q27atJkyYIEk51j116lSlpaUpJSVF8fHxOnLkSK6vL7s5M6bq1i7ddEOzlvpg/slbad53563auHa1JOn77/aF7lV95MhhDXrgHnW9qYkGPXCvUm5rE2rX6Bc1NOKpJ9S9Qwv163GH1q9eqfvuvFUdmsRr8fw5oc9z0P+OUFKHuxXb5pf65xuBW5EuXpamFl37qmvfQarTrLNSBvw+cOvPVyZq97d71PLO+9Wyaz9J0gNDnlJi+xTVb9lVTzz/D0nKsV1Uw1u097vvJUl/+eebim51p6Jb3amRL42XpDP+TM4EYQygSMhpCEVJpwyhuG7dOqWkpISGUHzhhRe0du1aLViwIOwhFD/++GM1bdpUAwYMUGpqqjZs2KAjR46Ehj5MSUnRgw8+qLVr12rZsmW66qqr1KdPH7366quSFBpCsUOHDqesf8KECbr55ptDw/LFx8efVsMXX3yhBx98UBs3blTlypU1bdq0sN6bE8MlSsqx7q5du4Zus7lmzRqVKVMm19eX3bx3p+vm2zqpfccuoXtQ52XKa6+oQqVKmvr+R+r33wND96qWpCOHDynphqaaNGexypYrr78+N1yjJ0zXiJfeCI2fPH3SG6pUoYJS57yp1Nlv6qUJ07X1612SpNUbPtfIPw7Up4un6qvtO/VR6ho9fF8PVb+imha99U8tmjpGkjR88INKmzte6xZM1gcrVmndp5tzbHfCynWf6tUpM/XxrNe14t3X9NKE6aH7X5/pZ1JQhDGAIqGoD6GYlJSkV199VcOGDdP69etVoUKF02qoWbNmKKSvv/76sIfmy7pXm1PdOQmn3YY1q1TlsstUvca1ati0uTZtWKcf8zm/vTp1hdoFh0usVaeeatU9OWhGZKlSatKiTWheYqPGioyMVK069bV7Z+CmKcuXLNLrU2cp/qbuanhrL+37fn9ouMPk+PqqUf2KwNCF9X8RGmIxuynvvq+Em+9Sg5t7aOPnX+rTL/K+veaHn6xRp3YtVa5sGZUvV1ad27fS0o8De/Nn+pkUFOeMAVzwisMQis2aNdOSJUs0e/Zs9ezZU4MGDVKvXr1OaZN9aL5wD4muXr1aiYmJudadXbjt5r4zTVu3fBE6BH3o4AEtmDtTnXv0UkSW9/JYmMMlliwZGfpcSpTINlxixsnhEl/80291c4vGpyy7eFnaqcMlRuQ8XOLWr3fp+X++rtTZb+rSyhXV+zdPKD399KEgsyrIcIkcpgZw0SoOQyhu375dl19+ufr27av77rsv36EQwzVt2jTNnz9fPXr0yLVu6dThEvNqd8Lx48f1/uwZemv+h6HhEke+Mv7kcIk1Tg6X+P7sk+fHGyQ30vx3A8Mlfrn5M235LP9femfVuHkr/eP1qaFhDTd/uV2HDucdgBXKl9OBg4HP4ccDh1SuTBlVqlhe3+7Zp7mLPsqxXVbNGiVoxrxFOnzkiA4dPqLp7y3SjQ3P70Am7BkDuOBNnDhRQ4YMOWXaiSEUX3zxRW3evFmxsbGKjIxU3759NWDAgNAQikeOHFGZMmW0YMGCU4ZQjI6ODmsIxaioqNOGULz//vs1dOhQRUZG6q233tJ1110XGkLxjjvuyHGdixcv1nPPPafIyEiVL19er7/++hm/HyNGjNCbb74ZOs+9cOHC0C+pc6u7d+/e6t+/v8qUKaPly5fn2u6ElR8v0+VXVtcVV5389fX1DRvrsS8+155v/61f3T9Agx64R7Penqzkxs1CbX7Z6z49/siv1fWmJqoTHatadeurfMWKYb+2zj16KWPnOiW0S5FzTtWqXKoZY/+c5zL9Ujqr/d0P6arLq2rR1DFqEF1H9Vt21XXX1lCTpLhc252QEFNXve+8Xcm3BI5U9OlxhxpE19G2Y2GXfdYYQrGQMYQi8nIh9FOGUDw3GEIxIDMzUxk//aRLSpfWjm1b1a9HR838IE2RpUqFvQ6GUAQAFBhDKJ6UfuSw+vzydmVk/CTnnH7/1J8LFMQXK8IYAM4SQyieVK58BU2cs8h3GUUOP+ACAMAzwhhAGFyel38AOFVB/70QxgDyVXr/V9p3KINABsLgnNO+fftUunTpsJfhnDGAfNVY9Yx2arD2VLpO0uk30zgj+zcVznpQqL79/tzc1KIgNtke3yUEnEUfLV26tGrUqBF2+7DC2MzaSXpBUoSkl51zT2ebb8H5HSQdltTbOVc4V7QD8C7y2A+queKxwl0pl99dkNoX0cvvzonz2EfzPUxtZhGS/iapvaR6knqYWb1szdpLqhX8r5+kfxRynQAAFFvhnDNOlrTFOfeVc+6YpEmSOmZr01HS6y5ghaTKZnZVIdcKAECxFE4YXy1pR5bnO4PTCtoGAADkIJxzxjn9WiP7TyrDaSMz66fAYWxJOmhmn4ex/SLFpKqS9vquQ38spB/ZoNihj+JCV8z76M9ymhhOGO+UdE2W5zUkZR9EMpw2cs6NkTQm+/TixMzScrrvKHChoI/iQncx9tFwDlOnSqplZjXNrJSk7pJmZmszU1IvC2gkab9z7ptCrhUAgGIp3z1j51yGmQ2QNE+BS5vGOuc2mln/4PzRkuYocFnTFgUubbrn3JUMAEDx4m0IxeLKzPoFD8cDFyT6KC50F2MfJYwBAPCMe1MDAOBZkQhjM8s0szVmtsHM3jWzyvm0TzSzUbnM22ZmVc9JoYXEzPqbWa9zvI2D53L9FxP65znZxsHg/6PMbMO53NbFrij1XzOrbmZTszyfaGbrzOyRc7XN86VIHKY2s4POufLBx69J2uycG36G69omKdE55/8aNo+yvqc4O/TPwnfiPTWzKEmznHPRvmsqropq/zWzKyV97JzL8brdXJYp6ZzLOIdlnbEisWeczXIF7+5lZovNLDH4uGqwI8jMWpjZrODjy8xsvpmtNrN/KssNSszs0eC3wQ1m9pucNmZm95nZ5uC2XjKzvwan32ZmHwfXu8DMrghOH2ZmA7MsvyH47b6cmc02s7XBad2C8582s0+D3+6ez74OM+trZqnB5aaZWdng9HFmNsrMlpnZV2bWNTjdzOy54DbWn9gOzhv6p+ifRdj57r8Hszzuambjgo9z6z9Zj5TMl3S5BfbqbzSzeDNbEeyr083s0iyv4ykz+0DSfwefjzCzJWa2ycySzOxtM/vCzP6UpZ67zeyT4Pr/aYFxGs6ZIhXGwTejtU6/zjkvT0j60DnXILjctcF1Xa/AJVgNJTWS1NfMGmTbXnVJjwfn3ySpTpbZH0pqFFzvJEm/zaeOdpJ2O+figt/y3zOzKpI6SarvnIuV9KcclnvbOZfknIuTtEnSfVnmXSWpqaRbJZ0YSauzpHhJcZLaSHrOuE/4eUH/pH8WZee7/4Yhp/6T1e2SvnTOxTvnlkp6XdLgYF9dH6zthMrOuebOuT8Hnx9zzjWTNFrSO5IelBQtqXfwC0ZdSd0kNXHOxUvKlJRSwPoLpKiEcRkzWyNpn6Qqkt4vwLLNJL0pSc652ZK+D05vKmm6c+6Qc+6gpLcl3Zht2WRJHzjnvnPO/STprSzzakiaZ2brJQ2SVD+fOtZLamNmz5jZjc65/ZJ+lJQu6WUz66zANdrZRZvZ0uB2UrJtZ4Zz7rhz7lNJV2R5XROdc5nOuW8lfSApKZ/acHbon/TPosxX/81PTv0nR2ZWSYHA/SA46bVgbSdMzrbIiS8c6yVtdM5945w7KukrBe4m2VrS9ZJSg+9Na0nXFbD+AikqYXwk+O3kZ5JKKfAtRpIydPI1lM5j+ZxOjIdz09G82rwo6a/OuRhJ92fZftaaQnU55zYr8OGul/R/ZjY0eO4iWdI0SXdIei+H7YyTNCC4nT/q1Nd5NIdaueHv+Uf/pH8WZb76b/Zls28jp/5zpg7lsu7j2bZzXIGbYZmk14J73fHOuV8454adZQ15KiphLEkKflt/WNJAM4uUtE2BPyCS1DWXxZYoeHjBzNpLujTL9DvMrKyZlVPgcNzSbMt+Iqm5mV1qZiUldckyr5KkXcHHv8oyfZukhOD2EiTVDD6uLumwc+5NSc9LSjCz8pIqOefmSPqNAofvsqsg6Zvg6w3nMMkSSd3MLMLMqinw7fCTMJbDWaJ/0j+LMg/9V5K+NbO6ZlYi2OZsav/ezE7sffdU4KjLmfqXpK5mdrkkmVkVMwv7h2JnIpyBIi4ozrnVZrZWgXtkPy9pipn1lLQwl0X+KGmima1S4MP5OrieVcEfC5z4Q/Cyc251tm3tMrOnJH2swMAXn0raH5w9TNJbZrZL0goF/6gpsBfRK3hoI1XS5uD0GAXOjx2X9JOkBxT4Q/aOmZVW4JtYTj/Pfzy4/e0K7LVUyOv9kTRd0g2S1irwrfO3zrl/57MMCgn9k/5ZlJ3P/hs0RNIsBYbg3SDpbK7w+JWk0Rb4EeFXOovbMjvnPjWzP0iaH/yi8JMCRwy2n0V9eSoSlzb5ZGblnXMHg3se0xW4N/d033UBEv0TKC6K1GFqT4YF9yI2SNoqaYbXaoBT0T+BYoA9YwAAPGPPGAAAzwhjAAA8I4wBAPCMMAYAwDPCGAAAzwhjAAA8+38JmsFK7LTVUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_acc = [acc_data_aug_gaussian, acc_data_aug_gaussian2, acc_data_aug_uniform]\n",
    "original_acc = [acc_no_data_aug]*3\n",
    "xaxis = [\"Ruido gaussiano I\", \"Ruido gaussiano II\", \"Ruido uniforme\"]\n",
    "x = np.arange(len(xaxis))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(x-0.1, results_acc, width=0.2, label=\"Accuracy tras Data Augmentation\")\n",
    "plt.bar(x+0.1, original_acc, width=0.2,  label=\"Accuracy sin Data Augmentation\")\n",
    "plt.xticks(range(0, len(xaxis)), xaxis, rotation=0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
