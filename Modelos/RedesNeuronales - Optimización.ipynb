{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99f259b",
   "metadata": {},
   "source": [
    "# Optimización de un modelo de red neuronal (fully-connected)\n",
    "\n",
    "Este notebook recoge los resultados de la búsqueda del mejor modelo de clasificación mediante una red neuronal densa o fully-connected, ya que el uso de redes convolucionales no parece adecuado para un problema de datos tabulares.\n",
    "\n",
    "Para buscar el mejor modelo posible, se tratará de buscar los mejores hiperparámetros para el número de capas ocultas de la red, su anchura (número de neuronas), posible introducción de términos de regularización, optimizadores, ...\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40286d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías de optimización de hiperparámetros\n",
    "import optuna\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar los datos\n",
    "from data_and_submissions import *\n",
    "\n",
    "# Métodos para los entrenamientos con CV\n",
    "from train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea4b44",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3014e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data()\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1493353",
   "metadata": {},
   "source": [
    "# Prueba: efectividad preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3cf423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d73d9",
   "metadata": {},
   "source": [
    "### Sin aplicar preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229ebc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_no_preprocess(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    Se va a utilizar para estudiar si las redes tienen un mejor funcionamiento si se escalan sus datos\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7d1592",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:44,475]\u001b[0m A new study created in memory with name: no-name-81588589-8ab2-4318-8613-5e76a6c6d570\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:50,490]\u001b[0m Trial 0 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:52,110]\u001b[0m Trial 1 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:53,899]\u001b[0m Trial 2 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:55,292]\u001b[0m Trial 3 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 50, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:56,756]\u001b[0m Trial 4 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:01:59,197]\u001b[0m Trial 5 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:01,585]\u001b[0m Trial 6 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:03,246]\u001b[0m Trial 7 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:05,566]\u001b[0m Trial 8 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:07,384]\u001b[0m Trial 9 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:10,681]\u001b[0m Trial 10 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:12,839]\u001b[0m Trial 11 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:15,169]\u001b[0m Trial 12 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:17,460]\u001b[0m Trial 13 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:19,079]\u001b[0m Trial 14 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_no_preprocess = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_no_preprocess.optimize(objective_no_preprocess, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b989dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.4444444477558136], datetime_start=datetime.datetime(2022, 7, 3, 13, 1, 44, 477414), datetime_complete=datetime.datetime(2022, 7, 3, 13, 1, 50, 490850), params={'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_no_preprocess.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a955780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.6823 - acc: 0.5686 - val_loss: 0.6734 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4921 - acc: 0.8431 - val_loss: 0.9328 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4662 - acc: 0.7255 - val_loss: 0.6614 - val_acc: 0.7059\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1876 - acc: 1.0000 - val_loss: 0.6741 - val_acc: 0.6471\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0767 - acc: 1.0000 - val_loss: 0.8513 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.7580 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.7779 - val_acc: 0.5882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.8797 - val_acc: 0.7647\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.8762 - val_acc: 0.7059\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.9029 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6104 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_no_preprocess = models.Sequential()\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_no_preprocess.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_no_preprocess.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_no_preprocess.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_no_preprocess.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e833425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "pred_kaggle_no_preprocess = modelFC_optuna_no_preprocess.predict(test_kaggle)\n",
    "pred_kaggle_no_preprocess = np.around(pred_kaggle_no_preprocess, decimals=0).ravel()\n",
    "\n",
    "create_submission(pred_kaggle_no_preprocess, \"NN-no-preprocess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483038e5",
   "metadata": {},
   "source": [
    "### Escalando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18948b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "preprocess = StandardScaler()\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test)\n",
    "test_kaggle_processed = preprocess.fit_transform(test_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a3405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_preprocess(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    Se va a utilizar para estudiar si las redes tienen un mejor funcionamiento si se escalan sus datos\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train_processed, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test_processed, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7712f7d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:50,414]\u001b[0m A new study created in memory with name: no-name-ff3ad585-c237-465a-8fb9-9935c75b19d1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:51,978]\u001b[0m Trial 0 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:53,211]\u001b[0m Trial 1 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:55,057]\u001b[0m Trial 2 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:56,179]\u001b[0m Trial 3 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 50, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:57,315]\u001b[0m Trial 4 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:58,889]\u001b[0m Trial 5 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:02:59,978]\u001b[0m Trial 6 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:01,203]\u001b[0m Trial 7 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:02,811]\u001b[0m Trial 8 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:04,726]\u001b[0m Trial 9 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:06,515]\u001b[0m Trial 10 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:08,401]\u001b[0m Trial 11 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:09,645]\u001b[0m Trial 12 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:11,405]\u001b[0m Trial 13 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-03 13:03:12,714]\u001b[0m Trial 14 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_preprocess = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_preprocess.optimize(objective_preprocess, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f51d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.4444444477558136], datetime_start=datetime.datetime(2022, 7, 3, 13, 2, 50, 414191), datetime_complete=datetime.datetime(2022, 7, 3, 13, 2, 51, 977516), params={'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_preprocess.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8624554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 814ms/step - loss: 0.6690 - acc: 0.5686 - val_loss: 0.8292 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3761 - acc: 0.8627 - val_loss: 0.7716 - val_acc: 0.7059\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1697 - acc: 0.9412 - val_loss: 0.6257 - val_acc: 0.8235\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0484 - acc: 1.0000 - val_loss: 0.6701 - val_acc: 0.7647\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.6927 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7372 - val_acc: 0.8235\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6386 - acc: 0.6111\n",
      "Accuracy: 61.11%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_preprocess = models.Sequential()\n",
    "modelFC_optuna_preprocess.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_preprocess.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_preprocess.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_preprocess.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_preprocess.fit(X_train_processed, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_preprocess.evaluate(X_test_processed, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7d8744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "pred_kaggle_preprocess = modelFC_optuna_preprocess.predict(test_kaggle)\n",
    "pred_kaggle_preprocess = np.around(pred_kaggle_preprocess, decimals=0).ravel()\n",
    "\n",
    "create_submission(pred_kaggle_preprocess, \"NN-preprocess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229a45eb",
   "metadata": {},
   "source": [
    "Lo anterior muestra que el uso de los datos escalados puede hacer que, aún habiéndose escogido la misma infraestructura de red en el proceso de optimización, la misma red entrenada sobre los datos escalados pierde en accuracy más de un 20% frente a la entrenada con los datos sin aplicar ningún tipo de preprocesado.\n",
    "\n",
    "Para la elección final se han subido las predicciones del modelo al portal de Kaggle, que secunda las conclusiones de estas pruebas locales. Por tanto, en el resto del notebook, el conjunto de datos utilizado en todas las pruebas será el conjunto original, sin preprocesado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb208b",
   "metadata": {},
   "source": [
    "# Pruebas de optimización\n",
    "\n",
    "Para redes neuronales, compararemos los resultados obtenidos construyendo redes a partir de librerías distintas.\n",
    "\n",
    "## ``MLPClassifier`` de ``sklearn`` y búsqueda de hiperparámetros con ``GridSearchCV``:\n",
    "\n",
    "Documentación: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "El método ``MLPClassifier`` debe recibir arquitecturas de red pre-definidas, por lo que probaremos topologías variadas en cuanto a profundidad, ancho y número de capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d163caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_MLPC = MLPClassifier(max_iter=1000, random_state=0)\n",
    "param_grid_MLPC = {\n",
    "    \"hidden_layer_sizes\": [(100, 200, 100, 1), (100, 100, 100, 100, 1), (200, 200, 100, 50, 1), (100, 250, 250, 100, 1)],\n",
    "    \"activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"], # solver \"lbfgs\" no permite hacer los plots más abajo\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"] # únicamente válido junto con el solver \"sgd\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993a0ee",
   "metadata": {},
   "source": [
    "_NOTA: el parámetro ``learning_rate`` sólo se aplica cuando el solver que se esté utilizando sea el \"sgd\", el cual toma el valor constamte por defecto. Podría resultar de especial utilidad cuando toma el valor \"adaptive\", en ese caso mantiene el valor del learning_rate constante mientras la curva de pérdida siga decreciendo, en el momento en que haya dos épocas consecutivas en las que no decrece un mínimo el valor de loss, el learning_rate se divide entre 5._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2733f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv_results_MLPC = train_GridSearchCV(model_MLPC, param_grid_MLPC, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d305580c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96fdd2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt = MLPClassifier(activation=\"relu\", hidden_layer_sizes=(100, 250, 250, 100, 1), solver=\"adam\",\n",
    "                               max_iter=1000, random_state=0)\n",
    "model_MLPC_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC = model_MLPC_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b89f6b",
   "metadata": {},
   "source": [
    "_COMPROBACIÓN: la función de activación elegida sólo afecta a las capas ocultas y no a la capa de clasificación en la salida._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8455bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logistic'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLPC_opt.out_activation_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6075466",
   "metadata": {},
   "source": [
    "Las anteriores celdas de código muestran un \"warning\" indicando que el método de computación alcanza el número máximo de iteraciones (épocas de entrenamiento) sin haber llegado a converger.\n",
    "\n",
    "El criterio para considerar que ha habido convergencia está definido en la documentación como: la reducción del valor de la función de loss es inferior a 1e-4 por un número de etapas determinado. \n",
    "\n",
    "La anterior condición por tanto no se está cumpliendo en nuestro entrenamiento, así que vamos a pintar la evolución de la función de pérdida para determinar si estamos cortando el entrenamiento demasiado pronto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a417d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.plot(model_MLPC_opt.loss_curve_)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3d32f",
   "metadata": {},
   "source": [
    "La anterior curva de loss parece tener una tendencia aún claramente descendiente cuando es cortada en la época número 1000. Se va a repetir el entrenamiento incrementando este valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c41d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_MLPC2 = MLPClassifier(max_iter=1500, random_state=0)\n",
    "cv_results_MLPC2 = train_GridSearchCV(model_MLPC2, param_grid_MLPC, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef1316b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'sgd'},\n",
       " {'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'sgd'},\n",
       " {'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC2[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC2, top_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac2844",
   "metadata": {},
   "source": [
    "Ahora hay varias configuraciones óptimas. Vamos a comparar todas ellas en accuracy y en número de iteraciones (complejidad computacional) para decantarnos por una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67055f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt2 = MLPClassifier(activation=\"tanh\", hidden_layer_sizes=(200, 200, 100, 50, 1), solver=\"sgd\",\n",
    "                                learning_rate=\"constant\", max_iter=1500, random_state=0)\n",
    "model_MLPC_opt2.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC2 = model_MLPC_opt2.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1039b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt3 = MLPClassifier(activation=\"tanh\", hidden_layer_sizes=(200, 200, 100, 50, 1), solver=\"adam\",\n",
    "                                max_iter=1500, random_state=0)\n",
    "model_MLPC_opt3.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC3 = model_MLPC_opt3.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC3)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b98648be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt4 = MLPClassifier(activation=\"tanh\", hidden_layer_sizes=(200, 200, 100, 50, 1), solver=\"sgd\",\n",
    "                                learning_rate=\"adaptive\", max_iter=1500, random_state=0)\n",
    "model_MLPC_opt4.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC4 = model_MLPC_opt4.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC4)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5241269e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt5 = MLPClassifier(activation=\"tanh\", hidden_layer_sizes=(100, 250, 250, 100, 1), solver=\"adam\",\n",
    "                                max_iter=1500, random_state=0)\n",
    "model_MLPC_opt5.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC5 = model_MLPC_opt5.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC5)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22a1e654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt6 = MLPClassifier(activation=\"relu\", hidden_layer_sizes=(100, 250, 250, 100, 1), solver=\"adam\",\n",
    "                                max_iter=1500, random_state=0)\n",
    "model_MLPC_opt6.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC6 = model_MLPC_opt6.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC6)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a12850b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLPC_opt5.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d07dda4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23490360105732586"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLPC_opt5.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c9b4ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_MLPC_opt5.loss_curve_)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c71c1fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16344069030819114"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLPC_opt6.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8264908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_MLPC_opt6.loss_curve_)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af707e",
   "metadata": {},
   "source": [
    "De los dos modelos que logran mayor accuracy en test, se observa que el primero logra completar su proceso iterativo (ha requerido en total de 1090 épocas), mientras que el otro aún no ha podido converger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14ede2",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "La librería ``sklearn`` permite implementar un tercer optimizador, lbfgs, que no se ha incluído en las pruebas anteriores ya que no permite dibujar la curva de loss para hacer las anteriores comprobaciones. Por tanto, vamos ahora a probar y comparar los resultados manualmente incluyendo este optimizador.\n",
    "\n",
    "El solver ``sgd`` no se ha elegido en ninguna de las anteriores pruebas. Como en esta ocasión queremos comprobar si el solver ``lbfgs`` incrementa el accuracy frente a los resultados anteriores, prescindiremos del solver ``sgd`` y la optimización del tipo de learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f906f2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_MLPC3 = MLPClassifier(max_iter=1000, random_state=0)\n",
    "param_grid_MLPC3 = {\n",
    "    \"hidden_layer_sizes\": [(100, 200, 100, 1), (100, 100, 100, 100, 1), (200, 200, 100, 50, 1), (100, 250, 250, 100, 1)],\n",
    "    \"activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"adam\", \"lbfgs\"]\n",
    "}\n",
    "cv_results_MLPC3 = train_GridSearchCV(model_MLPC3, param_grid_MLPC3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8e26327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC3[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC3, top_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f027b",
   "metadata": {},
   "source": [
    "Si volvemos a utilizar el máximo de 1000 iteraciones, el óptimo es el mismo obtenido en el primer caso. Vamos a repetir el intento ahora con 1500 épocas de máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83e7f5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_MLPC4 = MLPClassifier(max_iter=1500, random_state=0)\n",
    "cv_results_MLPC4 = train_GridSearchCV(model_MLPC4, param_grid_MLPC3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce5d8de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'tanh',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'solver': 'lbfgs'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC4[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC4, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "381d797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt7 = MLPClassifier(activation=\"tanh\", hidden_layer_sizes=(200, 200, 100, 50, 1), solver=\"lbfgs\",\n",
    "                                max_iter=1500, random_state=0)\n",
    "model_MLPC_opt7.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC7 = model_MLPC_opt7.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC7)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32497b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLPC_opt7.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c5e8c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11734237449432437"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLPC_opt7.loss_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514a78c",
   "metadata": {},
   "source": [
    "Al aumentar el número de épocas, los resultados varían y el modelo que se retorna ahora como óptimo necesita solamente 18 épocas para converger.\n",
    "\n",
    "Sin embargo, sorprende que este último modelo que ha resultado generar predicciones con un mejor accuracy y que no sobrepasan el primer tope de 1000 iteraciones no haya sido el elegido en la primera búsqueda. Vamos a comparar las precisiones que han alcanzado cada uno de los modelos en el entrenamiento en cada una de las repeticiones de cross-validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffc8d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = {'activation': 'relu',\n",
    "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
    "  'solver': 'adam'}\n",
    "\n",
    "result2 = {'activation': 'tanh',\n",
    "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
    "  'solver': 'lbfgs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c83f816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(cv_results_MLPC3[\"params\"]):\n",
    "    if item == result1:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "for i, item in enumerate(cv_results_MLPC3[\"params\"]):\n",
    "    if item == result2:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a3f7649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO OPT (1000 iter) - Accuracy en primer entrenamiento: 0.7058823529411765\n",
      "MODELO OPT (1500 iter) - Accuracy en primer entrenamiento: 0.7058823529411764\n"
     ]
    }
   ],
   "source": [
    "print(\"MODELO OPT (1000 iter) - Accuracy en primer entrenamiento:\", cv_results_MLPC3[\"mean_test_score\"][22])\n",
    "print(\"MODELO OPT (1500 iter) - Accuracy en primer entrenamiento:\", cv_results_MLPC3[\"mean_test_score\"][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8531c536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(cv_results_MLPC4[\"params\"]):\n",
    "    if item == result1:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "for i, item in enumerate(cv_results_MLPC4[\"params\"]):\n",
    "    if item == result2:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "002df573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO OPT (1000 iter) - Accuracy en segundo entrenamiento: 0.6911764705882353\n",
      "MODELO OPT (1500 iter) - Accuracy en segundo entrenamiento: 0.7058823529411764\n"
     ]
    }
   ],
   "source": [
    "print(\"MODELO OPT (1000 iter) - Accuracy en segundo entrenamiento:\", cv_results_MLPC4[\"mean_test_score\"][22])\n",
    "print(\"MODELO OPT (1500 iter) - Accuracy en segundo entrenamiento:\", cv_results_MLPC4[\"mean_test_score\"][13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2317ac",
   "metadata": {},
   "source": [
    "Se observa que en la primera prueba de ``GridSearchCV`` ambos modelos tienen una accuracy prácticamente idéntica durante el entrenamiento, aunque al no terminar de converger el primero (visto con las 1000 iteraciones), finalmente su accuracy tiene un decimal diferente y por ser en definitiva mayor, es el único modelo escogido. Sin embargo, al aumentar el margen de iteraciones, mientras que el segundo modelo (1500 iteraciones) no cambia su accuracy, el primero sigue entrenando y el valor final de precisión del entrenamiento en este segundo caso decrece.\n",
    "\n",
    "Por tanto, el óptimo hasta este momento y de acuerdo a las pruebas anteriores es el modelo obtenido en la segunda prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cde6acba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_GridSearchCV = model_MLPC_opt7.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_GridSearchCV, \"NN_GridSearchCV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b5a47",
   "metadata": {},
   "source": [
    "## Redes de ``keras`` y búsqueda de hiperparámetros con ``optuna``\n",
    "\n",
    "Ahora utilizaremos la librería de ``keras``, por su mayor flexibilidad para intentar mejorar los resultados de la red neuronal.\n",
    "\n",
    "Comenzaremos repitiendo la búsqueda de hiperparámetros, ya que la propia librería de ``keras`` dispone de integración con otras que nos permitirán hacer una búsqueda algo más exhaustiva por ejemplo en cuanto al número de capas y neuronas en estas. Concretamente, vamos a utilizar ``optuna``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be2b93",
   "metadata": {},
   "source": [
    "Documentación:\n",
    "* https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html\n",
    "* https://optuna.org/\n",
    "\n",
    "Búsqueda mediante la librería ``optuna`` probando 2 métodos de búsqueda de hiperparámetros:\n",
    "\n",
    "* **GridSampler:** equivalente a la anterior búsqueda de grid de sklearn. Lo usaremos para que los resultados sean comparables.\n",
    "* **TPE:** algoritmo para hacer una \"búsqueda inteligente\" de hiperparámetros. Debería ahorrar intentos de combinaciones haciendo una selección inteligente de las pruebas. En nuestro caso le permitiremos probar un 10% del número de combinaciones posibles. \n",
    "\n",
    "Ante la flexibilidad de configuraciones de ``keras`` y la necesidad de regularizar de alguna forma las redes neuronales se ha decidido comprobar paralelamente dos formas de optimización:\n",
    "\n",
    "* Optimizar únicamente la arquitectura de la red y el algoritmo optimizador. En este caso la tendencia de la optimización tenderá a favorecer modelos más pequeños y por tanto la red se regulariza en el sentido de que se limita su complejidad. \n",
    "* Optimizar tanto arquitectura de red como parámetros de regularización. En este otro caso por tanto, lo que se espera es tener modelos más complejos.\n",
    "\n",
    "### Optimización únicamente de la arquitectura\n",
    "\n",
    "**Optuna + GridSampler (activación sigmoide)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6a5df88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_Grid_Arq(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 1, 250)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a672f174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": range(2, 6), \n",
    "                \"n_units\": range(50, 300, 50),\n",
    "                \"optimizer\": [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study_Grid_Arq = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_Grid_Arq.optimize(objectiveNN_Grid_Arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b50dc130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444477558136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_Grid_Arq.get_trials())\n",
    "print(top_acc)\n",
    "models_Grid_Arq = models_same_acc_OptunaSearchCV(study_Grid_Arq.get_trials(), top_acc)\n",
    "len(models_Grid_Arq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859804a",
   "metadata": {},
   "source": [
    "Los 60 modelos probados tienen la misma accuracy (44.44%) en el entrenamiento. Quizás la red se satura, vamos a fijar un valor para el número de capas, por ejemplo en 3, y al optimizador RMSProp y vamos a repetir la optimización en un grid en el que además se va a reducir la dimensión de las unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bf4182e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": [3], \n",
    "                \"n_units\": range(1, 20, 2),\n",
    "                \"optimizer\": [\"RMSprop\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study_Grid_Arq = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_Grid_Arq.optimize(objectiveNN_Grid_Arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8beec13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_Grid_Arq.get_trials())\n",
    "print(top_acc)\n",
    "models_Grid_Arq = models_same_acc_OptunaSearchCV(study_Grid_Arq.get_trials(), top_acc)\n",
    "len(models_Grid_Arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d2760a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=4, values=[0.5], datetime_start=datetime.datetime(2022, 7, 4, 20, 18, 31, 346146), datetime_complete=datetime.datetime(2022, 7, 4, 20, 18, 32, 294421), params={'n_layers': 3, 'n_units': 7, 'optimizer': 'RMSprop'}, distributions={'n_layers': IntUniformDistribution(high=5, low=1, step=1), 'n_units': IntUniformDistribution(high=250, low=1, step=1), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={'search_space': OrderedDict([('n_layers', [3]), ('n_units', [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]), ('optimizer', ['RMSprop'])]), 'grid_id': 3}, intermediate_values={}, trial_id=4, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_Grid_Arq.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3a5460d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.6787 - acc: 0.5882 - val_loss: 0.6685 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6386 - acc: 0.7059 - val_loss: 0.6494 - val_acc: 0.6471\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6073 - acc: 0.7647 - val_loss: 0.6290 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5751 - acc: 0.7843 - val_loss: 0.6225 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5496 - acc: 0.8431 - val_loss: 0.6105 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5235 - acc: 0.8627 - val_loss: 0.6111 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5082 - acc: 0.8627 - val_loss: 0.6099 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5465 - acc: 0.7778\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Grid_Arq = models.Sequential()\n",
    "modelFC_optuna_Grid_Arq.add(layers.Dense(7, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_Grid_Arq.add(layers.Dense(7, activation=\"relu\"))\n",
    "modelFC_optuna_Grid_Arq.add(layers.Dense(7, activation=\"relu\"))\n",
    "modelFC_optuna_Grid_Arq.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_Grid_Arq.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_Grid_Arq.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Grid_Arq.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c57c3",
   "metadata": {},
   "source": [
    "**Optuna + TPE (activación sigmoide)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "89da8d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_TPE_Arq(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b6d2da6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_TPE.optimize(objectiveNN_TPE_Arq, n_trials=6)\n",
    "# n_trials = (4 x 5 x 3) * 0.1 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab42229",
   "metadata": {},
   "source": [
    "Lógicamente, las 6 pruebas tienen el mismo valor de accuracy en el entrenamiento. Se va a repetir la optimización en un grid que fija en 3 el número de capas y el optimizador esta vez como \"Adam\" y se centra en la optimización de las unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9700f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_TPE_Arq2(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = 3\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 1, 10, 1)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a49c6f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 19:15:59,491]\u001b[0m A new study created in memory with name: no-name-366e5511-3610-4aea-9509-0a284298460f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 19:16:08,275]\u001b[0m Trial 0 finished with value: 0.4444444477558136 and parameters: {'n_units': 6}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 19:16:09,383]\u001b[0m Trial 1 finished with value: 0.4444444477558136 and parameters: {'n_units': 8}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 19:16:10,142]\u001b[0m Trial 2 finished with value: 0.7222222089767456 and parameters: {'n_units': 7}. Best is trial 2 with value: 0.7222222089767456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 19:16:11,048]\u001b[0m Trial 3 finished with value: 0.4444444477558136 and parameters: {'n_units': 6}. Best is trial 2 with value: 0.7222222089767456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 19:16:12,013]\u001b[0m Trial 4 finished with value: 0.4444444477558136 and parameters: {'n_units': 5}. Best is trial 2 with value: 0.7222222089767456.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_TPE_Arq = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_TPE_Arq.optimize(objectiveNN_TPE_Arq2, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e5d0e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=2, values=[0.7222222089767456], datetime_start=datetime.datetime(2022, 7, 5, 19, 16, 9, 385897), datetime_complete=datetime.datetime(2022, 7, 5, 19, 16, 10, 142761), params={'n_units': 7}, distributions={'n_units': IntUniformDistribution(high=10, low=1, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_TPE_Arq.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c124d4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 175ms/step - loss: 0.6786 - acc: 0.6078 - val_loss: 0.6870 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6596 - acc: 0.6471 - val_loss: 0.6774 - val_acc: 0.7059\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6440 - acc: 0.6863 - val_loss: 0.6672 - val_acc: 0.7059\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6305 - acc: 0.7059 - val_loss: 0.6577 - val_acc: 0.6471\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6170 - acc: 0.6863 - val_loss: 0.6484 - val_acc: 0.6471\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6045 - acc: 0.7451 - val_loss: 0.6379 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5905 - acc: 0.8235 - val_loss: 0.6282 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5809 - acc: 0.7778\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE_Arq = models.Sequential()\n",
    "modelFC_optuna_TPE_Arq.add(layers.Dense(7, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_TPE_Arq.add(layers.Dense(7, activation=\"relu\"))\n",
    "modelFC_optuna_TPE_Arq.add(layers.Dense(7, activation=\"relu\"))\n",
    "modelFC_optuna_TPE_Arq.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE_Arq.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE_Arq.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE_Arq.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40547ed5",
   "metadata": {},
   "source": [
    "Estamos en la misma configuración que la red anterior.\n",
    "\n",
    "En las pruebas realizadas se ha ido variando constantemente el número de unidades hasta encontrar combinaciones que permitían diferenciarse en accuracy del resto. Estas son las que han quedado reflejadas en el notebook y como se puede ver ha sido necesario reducir el número de unidades a 7, un valor que podría parecer excesivamente pequeño dada la magnitud del problema. Para comprobar que la red generada no es adecuada para el problema, se ha utilizado para crear una predicción que enviar a Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a1486bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_optuna_Grid_Arq = modelFC_optuna_Grid_Arq.predict(test_kaggle)\n",
    "y_pred_optuna_Grid_Arq = np.around(y_pred_optuna_Grid_Arq, decimals=0).ravel()\n",
    "\n",
    "create_submission(y_pred_optuna_Grid_Arq, \"NN_GridSampler_OnlyOptArchitecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808381c",
   "metadata": {},
   "source": [
    "En el leaderboard público la precisión de la red es únicamente del 50%, parece actuar como un clasificador aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1231ee89",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Veamos si podemos obtener mejores resultados cambiando la última capa con activación sigmoide por una activación softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516cc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# En primer lugar, hay que adaptar los datos\n",
    "NUM_CLASSES = 2\n",
    "y_train_softmax = np_utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_softmax = np_utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762780d",
   "metadata": {},
   "source": [
    "**Optuna + GridSampler (activación softmax)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b43e209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveSoftmax_Grid_Arq(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación softmax\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "42032e7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5524 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5372 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6886 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5707 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8198 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6846 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5852 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6214 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6700 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5763 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5569 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6681 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5678 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5183 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6869 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6349 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6782 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3457 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5296 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6913 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5660 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5105 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9945 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6915 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6017 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6423 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7024 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7138 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5222 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5370 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5306 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6780 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5815 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5886 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7027 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5378 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5577 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6562 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5014 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5193 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6618 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6504 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8172 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4593 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4317 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6329 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5115 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5471 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7427 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6980 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5849 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5671 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6796 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6064 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6595 - accuracy: 0.6111\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": range(2, 6), \n",
    "                \"n_units\": range(50, 300, 50),\n",
    "                \"optimizer\": [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "studySoftmax_Grid_Arq = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "studySoftmax_Grid_Arq.optimize(objectiveSoftmax_Grid_Arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8417fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888955116272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(studySoftmax_Grid_Arq.get_trials())\n",
    "print(top_acc)\n",
    "modelsSoftmax_Grid_Arq = models_same_acc_OptunaSearchCV(studySoftmax_Grid_Arq.get_trials(), top_acc)\n",
    "len(modelsSoftmax_Grid_Arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "09512e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=22, values=[0.8888888955116272], datetime_start=datetime.datetime(2022, 7, 4, 22, 40, 4, 388535), datetime_complete=datetime.datetime(2022, 7, 4, 22, 40, 5, 428087), params={'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}, distributions={'n_layers': IntUniformDistribution(high=5, low=1, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=1), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={'search_space': OrderedDict([('n_layers', [2, 3, 4, 5]), ('n_units', [50, 100, 150, 200, 250]), ('optimizer', ['Adam', 'RMSprop', 'SGD'])]), 'grid_id': 40}, intermediate_values={}, trial_id=22, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studySoftmax_Grid_Arq.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e4bd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.6864 - acc: 0.5686 - val_loss: 0.6845 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5365 - acc: 0.7451 - val_loss: 0.7852 - val_acc: 0.6471\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4486 - acc: 0.7647 - val_loss: 0.7125 - val_acc: 0.7059\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2293 - acc: 0.9804 - val_loss: 0.7357 - val_acc: 0.6471\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0894 - acc: 1.0000 - val_loss: 0.9013 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.8433 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.7682 - val_acc: 0.6471\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9585 - val_acc: 0.7059\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.9094 - val_acc: 0.6471\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.9247 - val_acc: 0.6471\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5813 - acc: 0.8889\n",
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optunaSoftmax_Grid_Arq = models.Sequential()\n",
    "modelFC_optunaSoftmax_Grid_Arq.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optunaSoftmax_Grid_Arq.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optunaSoftmax_Grid_Arq.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optunaSoftmax_Grid_Arq.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optunaSoftmax_Grid_Arq.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_optunaSoftmax_Grid_Arq.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optunaSoftmax_Grid_Arq.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optunaSoftmax_Grid_Arq.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652d844",
   "metadata": {},
   "source": [
    "**Optuna + TPE (activación softmax)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b818caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveSoftmax_TPE_Arq(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación softmax\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "    modelFC_optuna.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "02fdaadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5105 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6595 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6886 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5183 - accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "studySoftmax_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "studySoftmax_TPE.optimize(objectiveSoftmax_TPE_Arq, n_trials=6)\n",
    "# n_trials = (4 x 5 x 3) * 0.1 = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f0c91a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.8888888955116272], datetime_start=datetime.datetime(2022, 7, 4, 22, 42, 31, 994438), datetime_complete=datetime.datetime(2022, 7, 4, 22, 42, 33, 69115), params={'n_layers': 4, 'n_units': 200, 'optimizer': 'RMSprop'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studySoftmax_TPE.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5efc8",
   "metadata": {},
   "source": [
    "TPE retorna el mismo modelo óptimo que en el caso anterior.\n",
    "\n",
    "Vamos a estimar las predicciones para estos modelos óptimos y contrastar en Kaggle los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9859b4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_optunaSoftmax_Grid_Arq = modelFC_optunaSoftmax_Grid_Arq.predict(test_kaggle)\n",
    "y_pred_optunaSoftmax_Grid_Arq = np.around(y_pred_optunaSoftmax_Grid_Arq, decimals=0).ravel()\n",
    "\n",
    "create_submission(y_pred_optunaSoftmax_Grid_Arq, \"NN_Softmax_GridSampler_OnlyOptArchitecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1e3e0",
   "metadata": {},
   "source": [
    "Para las redes de optimización únicamente de la arquitectura no se va a tratar de aplicar sobre un óptimo elegido ningún tipo de técnica de regularización por lo explicado al inicio de la sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401a234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_Arq = modelFC_optunaSoftmax_Grid_Arq.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_Arq, \"NN_Opt_Arq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57d3ff",
   "metadata": {},
   "source": [
    "### Optimización completa (arquitectura + regularización)\n",
    "\n",
    "**Optuna + GridSampler (activación sigmoide)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b1709fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_Grid_Comp(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 5, 250)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ea2fd41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5113 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5198 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5216 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6570 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6822 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4531 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6567 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8505 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8930 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1143 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2808 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2774 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5468 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8008 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8245 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8201 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0406 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0973 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2756 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3814 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3108 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3120 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2782 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4306 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3718 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6126 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4102 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6988 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2736 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6798 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1104 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1971 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5971 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.7948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8935 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1600 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.5840 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.7206 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.7136 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.1899 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0028 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2204 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5478 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0690 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3940 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.1801 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5898 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0829 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1450 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6749 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.8100 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1542 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.5236 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.2623 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.5616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0468 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9842 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5751 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5882 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.5153 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0750 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.6385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.6231 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.6878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6356 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.0945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.0121 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.4169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9071 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.0197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.1800 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.6782 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4229 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.6345 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0563 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0358 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0664 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0677 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0804 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0829 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0458 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0457 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0663 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0883 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1052 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1103 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0281 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0551 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0821 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1057 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1090 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1297 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1382 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1376 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3660 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4623 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5544 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1882 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1904 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3492 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5100 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5112 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5217 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6536 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7900 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2349 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4524 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4503 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4611 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6550 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6705 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8476 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0349 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2771 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2889 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5420 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5604 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7994 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8065 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0401 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2734 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3407 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3111 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3183 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3874 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6127 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4222 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3533 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6990 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2764 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2081 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6798 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1078 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5973 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8067 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8940 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2722 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7627 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6674 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0352 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0229 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6661 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2453 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2758 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2217 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3939 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2640 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1770 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5906 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8881 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0303 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6445 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.6209 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.1000 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5638 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6349 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8703 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5759 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4950 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1677 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.6752 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.9672 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.6411 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.8050 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.4812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0543 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.7361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.1833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.9087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.5625 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.9732 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.0210 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.3534 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.6799 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.7820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.9530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.1760 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.8096 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.7368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.6035 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.8071 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.2260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.1355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.6154 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.8780 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.9512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.8336 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.3482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.5507 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.9142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.8389 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 58.5949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.3617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.2272 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.4368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9250 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.6611 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.2437 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9625 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.9536 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.7052 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.9353 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.9761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 58.5613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.1890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.5372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.8309 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.1645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.1444 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.9000 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.9007 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.7125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.9464 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.0144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.3836 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.7477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.2174 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 79.9354 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.3030 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.9041 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 95.5714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.7535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 125.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 90.3978 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.6449 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.3266 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 195.7697 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 163.2347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.6579 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 254.6477 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 220.3741 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 228.8710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 293.8626 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 246.7350 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 386.7768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 306.2636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.3243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.3377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 131.4987 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 108.1543 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 197.7804 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 189.4828 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.7499 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 327.6304 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 299.2802 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.4073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 478.3709 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.6694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 412.4254 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 494.9219 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 448.0971 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 460.8500 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.2889 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 170.5219 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.0724 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 355.8227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 302.8649 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 283.9945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 498.6226 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.3931 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.9908 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 624.8450 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 508.3864 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 493.6109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 739.8118 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.3979 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 653.4929 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 199.3640 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.7036 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.4767 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 417.8384 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 373.0646 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 345.2167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 511.7526 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 505.2254 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 771.9780 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 629.7072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.2482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 917.0353 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 733.0951 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 807.5220 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0570 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0544 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0882 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0698 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0868 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0934 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0860 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1301 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1438 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3796 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5921 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1899 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5121 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5319 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5215 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6952 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7950 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4525 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4609 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6539 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6803 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8479 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9102 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1352 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2779 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2891 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8358 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8200 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0310 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1095 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3891 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3105 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3887 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3841 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6988 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2600 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6797 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2680 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5968 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7708 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7441 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8936 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1564 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5834 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6413 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7380 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1892 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9157 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6654 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2297 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.1355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1796 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.9522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1356 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.6735 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6249 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1981 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6408 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.2848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.2358 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5250 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4408 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8719 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9217 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5747 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5277 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.1642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 9.2252 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.9952 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 10.6367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 11.2198 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.5173 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 13.0489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 10.8979 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0229 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.2750 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.8342 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.0193 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.9945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.7415 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4222 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.4707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.4159 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.1745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.3777 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.4695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.5995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.4432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.8657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0037 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.5532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.1312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 32.8643 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.2246 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.7394 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.3378 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.7986 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.6634 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.8322 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 57.5771 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.6953 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.8839 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 18.2966 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.9484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.9123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.6763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.4669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.9098 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.4071 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 58.8213 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.1552 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.4618 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.2061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.1275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.2385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.0539 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.9153 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.7972 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.8467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.0032 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.8872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.4818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.1852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 77.9167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.3270 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.8636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 92.7703 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 91.3190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.9644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.9233 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.5514 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 67.5845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 195.6840 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 163.1234 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.6473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 254.5425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 220.2501 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 228.8582 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 293.7533 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.1201 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 246.7294 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 386.6588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 306.1237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.2999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.2450 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 131.3997 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 108.1378 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 197.6668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 189.3737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.7093 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 345.6078 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 317.7417 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.3588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 478.2313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.5169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 412.3928 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 527.9292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 447.9075 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 460.8124 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 194.1769 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 170.4098 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 148.0596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 355.7119 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 302.7699 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 283.9134 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 498.3920 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 414.1580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 412.8716 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 589.6949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 508.1641 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 493.4741 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 739.5311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 590.1404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 653.3164 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 199.2149 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 193.5647 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 139.7798 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 417.6951 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 372.9417 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 318.3871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.4191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 511.5420 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 505.1005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 771.7181 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 629.4756 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.0847 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 916.7148 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 732.8456 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 807.3174 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0268 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0474 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0494 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0706 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1158 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0284 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0567 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0855 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1304 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1429 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1387 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2627 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3680 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3771 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1897 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5216 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6568 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6901 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7962 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4609 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6790 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6703 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8500 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9042 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2797 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2777 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5459 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8200 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1085 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3106 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3056 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2778 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3887 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4004 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3836 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6988 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2712 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3042 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6797 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7828 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7529 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.8934 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2025 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1660 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5836 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1894 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.9449 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1935 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6655 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.1500 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6009 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2453 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2046 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1792 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1907 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5892 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0349 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1713 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6742 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.7184 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.2035 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6414 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 9.4016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 10.2896 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5604 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5602 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4776 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.9729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5747 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.2807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.3688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 10.6374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.4109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.6489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0497 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5468 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.0425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.0145 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.3541 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.8686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 25.0193 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 28.0832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 24.7179 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.4223 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.5403 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.2899 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.1749 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.5034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.2907 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.6009 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.5065 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 13.8935 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0025 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.5796 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.1919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.8657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.3708 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.6790 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.3405 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.9001 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 43.2555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 63.8330 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.7595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.5054 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7162 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.9379 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.2445 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.9227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.0640 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.7679 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9491 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 50.9272 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.4615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 63.9164 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.6348 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 58.3688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.1605 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.8064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 74.1340 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.1333 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.3054 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.3318 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.9110 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9271 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.0130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.0039 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.1052 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 56.2324 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 78.1911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.1276 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 72.4431 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.8699 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 93.1260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 91.5781 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.9717 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 90.3131 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.8963 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 62.3554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 195.7026 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 163.1470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 161.6471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 254.5654 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 220.2812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 228.8577 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 293.7768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.1455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 246.7309 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 386.6808 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 306.1413 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.3087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 151.2571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 125.7982 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 108.1313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 197.6850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 189.3896 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 148.7129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 345.6346 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 299.1398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.3721 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 478.2518 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 387.5419 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 412.3961 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 494.7491 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 447.9422 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 460.8214 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.1956 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 170.4367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.0581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 355.7256 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 302.7810 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 283.9232 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 498.4208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.1851 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 412.9034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 589.7244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 508.1936 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 493.4955 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 739.5658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.1674 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 653.3436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 199.2265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.5752 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 139.7647 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 417.7085 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 372.9521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.3890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.4456 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 511.5678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 505.1244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 771.7455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 629.5047 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.1103 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 916.7458 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 732.8643 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 807.3486 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4777 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5579 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5803 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.1214 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.1760 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.6253 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 36.0243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 53.6016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.6303 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.9963 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.0029 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.7667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.2897 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 32.8695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.5880 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.7257 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.3451 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 49.1781 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.1083 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.8353 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 58.1131 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.0514 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.7191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.0765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 18.3512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9257 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.3050 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.0049 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.9546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.2402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.3219 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.9225 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.1325 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 58.6354 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.1709 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.4103 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.5920 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.1442 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.7816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.5326 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.9070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.1497 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.2788 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.0070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.5804 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.4838 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.1994 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 78.7106 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 72.2470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 101.8806 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 94.0070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.0053 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 124.9851 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.5028 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 75.9255 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 62.3444 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 195.7232 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 163.1705 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.6500 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 254.5920 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 220.3156 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 228.8615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 293.8078 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.1828 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 246.7361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 386.7217 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 306.1896 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.3129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.2852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 131.4414 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 108.1325 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 197.7166 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 189.4209 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.7232 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 327.5327 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 317.8099 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.3947 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 478.2938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.5887 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 412.4070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 494.8087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 447.9942 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 460.8351 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.2255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 170.4687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 148.0744 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 355.7612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 302.8137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 283.9525 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 498.4720 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.2375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 412.9321 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 589.7929 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 508.2568 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 493.5376 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 739.6496 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 590.2526 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 653.3949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 199.2601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 186.6356 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 139.7488 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 417.7416 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 372.9864 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.3993 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.4926 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 511.6066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 505.1589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 771.8108 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 629.5701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 658.1520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 916.8234 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 732.9176 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 807.4045 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0271 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0389 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0501 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0548 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0718 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0814 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0887 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0476 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0936 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1055 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1161 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0814 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1055 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1423 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1386 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1393 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3799 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4887 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5966 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1904 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5111 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5330 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5215 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6559 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6975 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7923 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2354 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4507 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4628 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4609 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6518 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9095 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1215 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0605 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2891 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5531 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7883 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8325 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8199 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0682 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2414 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3105 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3096 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3888 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4106 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3822 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3728 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3754 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6987 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2453 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6796 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2909 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7366 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8935 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.6069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1889 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8798 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1980 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6653 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0236 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6111 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1780 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0956 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5888 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8965 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.1085 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6732 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5527 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1495 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.6403 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.1561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4983 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4565 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8724 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8236 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8660 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5746 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.0660 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4415 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1638 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.0724 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7959 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.6363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.0180 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 12.1751 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.4700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0152 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.1911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8253 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.0191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.9077 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.7323 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.4211 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 34.4038 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.5515 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.1735 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.3270 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.7685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.6001 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.4021 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.8564 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0031 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 24.3467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 23.0841 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.8635 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 39.1489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.9449 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 49.3354 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.7569 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.0837 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.8318 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 57.4680 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 53.2003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7135 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.8450 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.3283 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 22.9238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.8657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 31.9122 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.9454 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 50.5540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.4981 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.9069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.2938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.1452 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 82.1507 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.3292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.5443 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.1242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.1996 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.0642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.9195 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.7359 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.8142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.0023 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 61.7622 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 56.6363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 78.1815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 77.7591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.4169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.8601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 92.6218 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 91.4320 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 124.9596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 90.2795 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.5317 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 62.3556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 195.6707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 163.1147 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 161.6464 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 254.5221 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 220.2339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 228.8506 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 275.9547 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 249.0948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 246.7243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 386.6445 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 306.1158 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.3042 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 151.2330 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 125.7702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 108.1349 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 197.6573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 189.3637 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.7068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 345.5895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 299.0902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 296.3477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 478.2170 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 387.4937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.3921 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 527.9105 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 447.8927 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 460.8092 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.1688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 170.4161 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.0616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 355.7031 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 302.7606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 283.9037 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 498.3772 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 414.1404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 412.8576 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 589.6782 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 508.1472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 493.4547 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 739.5139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.1378 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 653.2997 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 199.2066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.5561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.5618 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 417.6885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 372.9357 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 318.3839 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 613.4092 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 511.5349 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 505.0836 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 771.7047 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 629.4666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.0701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 916.6977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 732.8333 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 807.2972 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0459 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0464 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0682 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0286 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0283 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0840 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1120 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1303 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1383 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1383 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2604 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3730 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3715 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4649 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0269 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8935 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1014 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1187 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5643 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.6841 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1887 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.8440 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1785 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6653 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9659 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5653 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1942 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1539 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0430 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0966 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.8259 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.0016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6730 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4570 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.9987 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.0095 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.8182 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4767 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4342 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7735 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8002 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5746 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.9616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2378 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1635 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.9498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 9.4760 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.8346 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.6550 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.0481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.8181 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.0058 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.0151 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.1568 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.8457 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.0185 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.8556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.7761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4202 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.3628 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.7012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.1738 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 40.2691 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.9307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.5999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.3803 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 13.8804 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.0027 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.2765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.1142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.6033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.0949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.0699 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.3340 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.7191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 44.4678 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 63.8318 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 57.3764 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.7132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.8173 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.3467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 35.7984 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.8828 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.9424 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.4730 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 46.5103 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 63.9053 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.2247 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.4489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.1493 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.1996 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.1116 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.1212 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.1722 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.0805 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.9237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.7103 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.9509 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 53.0024 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.7253 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.7672 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.1793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.7066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 73.0551 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.8594 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 92.5556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 90.7042 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.9572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 90.2681 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.5222 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 67.5885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 195.6595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 163.1034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 161.6424 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 254.5048 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 220.2123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 228.8454 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 275.9463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 246.7259 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 386.6334 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 306.1075 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 346.3034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 151.2265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 125.7612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 108.1330 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 197.6501 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 189.3577 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.7070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 345.5726 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 317.6980 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.3409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 478.2113 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.4867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.3920 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 527.8992 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 447.8856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 460.8084 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.1657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 170.4166 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.0623 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 355.6949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 302.7511 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 283.8880 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 498.3681 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.1333 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.8492 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 589.6688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 508.1361 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 493.4486 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 739.5056 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.1355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 653.2837 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 206.1574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 193.5532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.5764 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 417.6856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 372.9329 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.3846 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.4037 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 511.5317 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 505.0736 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 771.6991 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 629.4642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.0672 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 916.6900 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 732.8289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 807.2861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0380 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0487 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0567 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0359 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0359 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0696 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0934 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1048 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1150 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0282 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0283 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0553 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0806 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0851 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1047 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1124 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1276 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1387 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4904 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5604 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5988 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1904 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3514 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5090 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5330 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5215 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7880 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8109 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4608 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6459 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6748 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9002 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0120 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1024 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0605 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2892 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5342 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5478 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7773 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8156 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8199 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0682 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2196 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3105 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2631 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3887 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3981 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6124 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6986 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2380 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6796 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0504 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3080 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7493 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0503 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0550 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0720 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0887 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0459 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0664 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": range(2, 6), \n",
    "                \"n_units\": range(50, 300, 50),\n",
    "                \"dropout\": np.arange(0, 0.6, 0.1),\n",
    "                \"kernel_regularizer\": [0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                \"optimizer\": [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study_Grid_Comp = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_Grid_Comp.optimize(objectiveNN_Grid_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5691260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555820465088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_Grid_Comp.get_trials())\n",
    "print(top_acc)\n",
    "models_Grid_Comp = models_same_acc_OptunaSearchCV(study_Grid_Comp.get_trials(), top_acc)\n",
    "len(models_Grid_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "05efef75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'Adam'}]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_Grid_Comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d211270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 137.1864 - acc: 0.4706 - val_loss: 125.2094 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 123.4114 - acc: 0.5490 - val_loss: 116.0127 - val_acc: 0.6471\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 114.6676 - acc: 0.4902 - val_loss: 108.8446 - val_acc: 0.7059\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 107.7290 - acc: 0.5490 - val_loss: 102.7721 - val_acc: 0.7059\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 101.7949 - acc: 0.4902 - val_loss: 97.4108 - val_acc: 0.6471\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 96.5183 - acc: 0.6078 - val_loss: 92.5569 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 91.7478 - acc: 0.5098 - val_loss: 88.0941 - val_acc: 0.7059\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 87.3246 - acc: 0.6275 - val_loss: 83.9395 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 83.9824 - acc: 0.5000\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Grid_Comp = models.Sequential()\n",
    "modelFC_optuna_Grid_Comp.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.L2(1), input_shape=(410,)))\n",
    "modelFC_optuna_Grid_Comp.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_Grid_Comp.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_Grid_Comp.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_Grid_Comp.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_Grid_Comp.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_Grid_Comp.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Grid_Comp.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda679e",
   "metadata": {},
   "source": [
    "Los 6 modelos tienen todos asociados un valor óptimo de la unidad para la tasa de regularización, lo que podría parecer demasiado elevado.\n",
    "\n",
    "Vamos a simular de nuevo la prueba anterior, es decir, se van a fijar 2 capas ocultas para la red (valor óptimo según la prueba anterior) y el optimizador \"RMSProp\" y se va a probar a optimizar el número de neuronas y la regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "befe1d6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5071 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.5347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.3822 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.1288 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.0425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 10.9927 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 11.4442 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.8055 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 49.4791 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2632 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.0661 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.9026 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 84.0767 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.8963 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.9620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 107.0542 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0100 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0127 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0165 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0730 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0854 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0993 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1119 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1248 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1383 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1531 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1623 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6904 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7950 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0278 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2782 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4254 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4990 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5507 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.2983 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.1435 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.0510 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.4365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.8211 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.5145 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2630 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.0853 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 69.0157 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0154 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0163 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0843 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0981 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1246 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1376 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5605 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6888 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7882 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9145 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0420 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4868 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6029 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3662 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1177 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.2137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.1833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.1289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.4731 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.8606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.5329 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2843 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.7415 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.0763 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 84.1427 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.6449 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.0177 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 107.1425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.4807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.7818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.2813 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2334 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 56.0446 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.8600 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 84.0474 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.5317 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.9403 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 107.0121 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0734 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0859 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0998 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1268 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1541 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1637 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5618 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6892 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9205 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1646 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5273 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4426 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2905 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3116 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.1056 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.0229 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9874 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.4606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.7871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.4694 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.2431 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.0515 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 65.8680 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 84.0612 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.5514 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.9468 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 107.0345 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0141 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0156 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0731 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0854 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1127 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1387 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0113 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1633 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5577 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6915 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7921 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0487 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2778 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4158 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 84.0945 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.8462 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 84.0393 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.5222 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.9314 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 107.0070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.9255 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0116 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.9816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0157 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0734 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 107.0784 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1002 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1135 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1272 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1393 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6874 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7915 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1634 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5043 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5395 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9766 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1646 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5590 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6821 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7914 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9155 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0451 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1577 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2631 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4035 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5022 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5298 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4058 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.3019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.1064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.0058 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9754 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.5064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.7795 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.4273 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.3111 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.1122 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2095 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 67.1929 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0157 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0168 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0734 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0860 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1004 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1136 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1270 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2841 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3594 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": [2], \n",
    "                \"n_units\": range(20, 65, 5),\n",
    "                \"dropout\": np.arange(0, 0.6, 0.1),\n",
    "                \"kernel_regularizer\": [0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                \"optimizer\": [\"RMSprop\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study_Grid_Comp = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_Grid_Comp.optimize(objectiveNN_Grid_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "64a2f682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555820465088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_Grid_Comp.get_trials())\n",
    "print(top_acc)\n",
    "models_Grid_Comp = models_same_acc_OptunaSearchCV(study_Grid_Comp.get_trials(), top_acc)\n",
    "len(models_Grid_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "90208b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 2,\n",
       "  'n_units': 30,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 40,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 30,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 30,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 40,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.5,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 40,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 50,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 40,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 2,\n",
       "  'n_units': 40,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'RMSprop'}]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_Grid_Comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac18e1",
   "metadata": {},
   "source": [
    "No se ha conseguido mejorar la accuracy del entrenamiento ni reducir la tasa de regularización ``kernel_regularizer``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87291bde",
   "metadata": {},
   "source": [
    "**Optuna + TPE (activación sigmoide)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5bb2cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_TPE_Comp(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6846d5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 493.4955 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 590.1355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.0303 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.3554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 771.8108 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.9257 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 346.2999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.1815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 447.8856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.1378 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6952 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.0543 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6952 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1677 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0468 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.9546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.2482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4222 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 417.6951 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 412.9034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.9257 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.7012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.2003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 629.7072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 807.5220 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2764 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.9257 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.9307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.9307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.7012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 387.4867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 732.8333 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.0948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 629.7072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.9230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0037 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7135 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 76.7132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.1116 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.7685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.9307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.9307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.2624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.7685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.7012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.0948 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 629.7072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.4926 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.1275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.1275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.1212 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.1275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.7132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.7685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.7685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.7685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.9307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.7012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.7012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.7012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.1019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2081 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.2391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4222 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.4926 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0817 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_TPE_Comp = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_TPE_Comp.optimize(objectiveNN_TPE_Comp, n_trials=216)\n",
    "# n_trials = (4 x 5 x 6 x 6 x 3) * 0.1 = 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "91d9f8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444477558136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_TPE_Comp.get_trials())\n",
    "print(top_acc)\n",
    "models_TPE_Comp = models_same_acc_OptunaSearchCV(study_TPE_Comp.get_trials(), top_acc)\n",
    "len(models_TPE_Comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb23357",
   "metadata": {},
   "source": [
    "Las 216 pruebas tienen la misma accuracy en entrenamiento. Se repite la búsqueda, fijando como en el caso de anterior el número de capas y el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6317d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_TPE_Comp2(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = 3\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 1, 10, 1)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "52d2e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 19.3449 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3943 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0023 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.8213e-04 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.6820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0168 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3310 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6659 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.9322 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3926 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3205 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.8114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3528 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.3168 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0022 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3220 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.3011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0017 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3205 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.3011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0017 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.9322 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3494 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6422 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.3345e-04 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.8632 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3345e-04 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_TPE_Comp = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study_TPE_Comp.optimize(objectiveNN_TPE_Comp2, n_trials=36)\n",
    "# n_trials = (10 x 6 x 6) * 0.1 = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5c3ef2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333134651184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_TPE_Comp.get_trials())\n",
    "print(top_acc)\n",
    "models_TPE_Comp = models_same_acc_OptunaSearchCV(study_TPE_Comp.get_trials(), top_acc)\n",
    "len(models_TPE_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "91b7050e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_units': 7, 'dropout': 0.5, 'kernel_regularizer': 1},\n",
       " {'n_units': 7, 'dropout': 0.5, 'kernel_regularizer': 1}]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_TPE_Comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d14b938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 147ms/step - loss: 29.5321 - acc: 0.5294 - val_loss: 27.6555 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 27.3046 - acc: 0.6275 - val_loss: 25.5467 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 25.1859 - acc: 0.5490 - val_loss: 23.6124 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 23.2644 - acc: 0.5294 - val_loss: 21.8329 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 21.5387 - acc: 0.5686 - val_loss: 20.1859 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 19.9080 - acc: 0.4706 - val_loss: 18.6663 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.6337 - acc: 0.5556\n",
      "Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE_Comp = models.Sequential()\n",
    "modelFC_optuna_TPE_Comp.add(layers.Dense(7, activation=\"relu\", kernel_regularizer=regularizers.L2(1), input_shape=(410,)))\n",
    "modelFC_optuna_TPE_Comp.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE_Comp.add(layers.Dense(7, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE_Comp.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE_Comp.add(layers.Dense(7, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE_Comp.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE_Comp.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE_Comp.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE_Comp.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE_Comp.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8da59",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Veamos si podemos obtener mejores resultados cambiando la última capa con activación sigmoide por una activación softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93117638",
   "metadata": {},
   "source": [
    "**Optuna + GridSampler (activación softmax)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4b767209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveSoftmax_Grid_Comp(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación softmax\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2b70e2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8968 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9923 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9053 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0281 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1765 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0156 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1971 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1925 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2795 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3389 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3292 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3621 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4798 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9212 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9176 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9272 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0807 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0610 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1369 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3156 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0998 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3550 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4786 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2851 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5745 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6935 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6138 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.7713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9728 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9604 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9856 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2405 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2128 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2609 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5004 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6803 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6374 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7607 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9597 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9030 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0045 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9752 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9065 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1663 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7860 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6759 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2893 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8161 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4836 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3191 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7840 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6697 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4183 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1780 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2073 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2752 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2903 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5995 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8257 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8382 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2517 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2176 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8334 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9002 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0203 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3329 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2761 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.7756 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7098 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8118 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7823 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0730 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9754 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1677 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2628 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.5505 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3999 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3389 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5460 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6201 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.3436 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.6080 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1359 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3530 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2098 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5755 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3419 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9186 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2604 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.8369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.2290 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7942 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3177 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.6601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.4075 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.6868 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.2162 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.2460 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0948 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.5628 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.2427 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.7108 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.6244 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.2382 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.1993 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.5653 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6691 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5786 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7040 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7003 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7057 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7024 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6910 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7035 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7065 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6933 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6930 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6939 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6820 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6959 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7110 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7192 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7780 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6815 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6430 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7254 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5772 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6735 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5933 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5476 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7824 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6149 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5708 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7329 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7285 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7290 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7000 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6666 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7022 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7047 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5884 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7306 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6299 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6309 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7354 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6615 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6161 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7528 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7166 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7216 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7132 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7145 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7079 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7207 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7016 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7366 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7467 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7539 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6601 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7964 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7742 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6894 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7278 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7305 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7313 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7558 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7595 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7717 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7752 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7966 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7855 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8007 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8440 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8314 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8270 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8357 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8316 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9037 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8701 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8705 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9614 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9027 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8580 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0075 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9992 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9383 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2057 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1035 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0444 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2385 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8984 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8859 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9000 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0182 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9887 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0272 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1624 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0494 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1994 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2148 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1640 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3376 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3650 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3026 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4820 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9254 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9239 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9291 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1066 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1108 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1352 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3358 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2686 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3489 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5093 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3838 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5776 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6981 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5766 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7640 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9840 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9807 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9914 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2444 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2630 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5084 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5127 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9839 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9342 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0054 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9900 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9403 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1547 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9604 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7701 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3100 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7850 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5619 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3246 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4160 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8151 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4190 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3007 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9194 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3598 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3146 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6024 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9152 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6791 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2388 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2636 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8005 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8390 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2563 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8596 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3313 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3768 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8707 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7110 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8663 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0781 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6665 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1957 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2606 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6027 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2824 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3052 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0585 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0911 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.3529 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.6581 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1113 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2504 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4115 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5801 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.6387 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2344 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5353 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8466 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.6993 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.0539 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3172 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.1340 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.0487 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6968 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.8098 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.1553 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0816 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.8260 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.4959 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.7019 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.4856 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4749 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.2027 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.8101 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.4836 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.5895 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.6889 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.2559 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.2425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.1376 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.9546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.8342 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.8131 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.7059 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.7335 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.5206 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.1816 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.6697 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.8618 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.8835 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.4776 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.2527 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.1219 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.9381 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.5944 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.1591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.5683 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.0519 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.7905 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.5933 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.5849 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 41.1865 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.5779 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.1058 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.0027 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.4854 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 71.9641 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 57.3546 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 97.0357 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.9966 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.3662 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.2624 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.0186 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.1621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.3898 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.4996 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.3432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.2165 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 71.4986 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 65.2891 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.7015 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 89.5240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.3496 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 121.6650 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 83.2919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.6204 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 86.8089 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 186.7343 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 163.8080 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 162.2432 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 227.7943 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.6065 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 153.3827 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 332.8395 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.7930 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 290.5360 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.3312 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 306.7042 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.7659 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 152.0088 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 95.0359 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.8260 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 240.2536 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 221.7121 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 161.8655 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 310.9045 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 299.8549 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 183.0959 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 478.9964 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 339.8435 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.9484 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 330.4072 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 269.6129 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 334.1259 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.9160 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 171.1441 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.5398 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 356.4959 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 303.5515 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 223.3576 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 499.2218 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 294.4246 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 299.3787 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 439.0742 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 392.8666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 535.5422 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 651.9608 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.9525 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 603.1076 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 237.2332 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 209.6206 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 178.8063 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 367.2809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 355.9305 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 231.0990 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 584.2345 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 512.3879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 466.4419 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 650.6104 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.7531 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 658.6070 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 862.0325 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 682.9852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 584.8606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6680 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5675 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5814 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7834 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5907 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5535 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7395 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6774 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6757 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7248 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5586 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5442 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6975 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5794 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6069 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7255 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5800 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6335 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7366 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6167 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6065 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7481 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6715 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6034 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7108 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5862 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5832 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7228 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5851 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5735 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7594 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5727 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5983 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7908 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7186 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9214 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8161 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6762 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5643 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7266 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7309 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6884 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7561 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7191 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6950 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7716 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6115 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6750 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8735 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8554 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8211 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8201 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7459 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8714 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8500 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8017 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9363 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8518 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8266 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0021 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9676 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9595 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2068 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0651 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0363 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2450 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8413 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8429 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8959 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8696 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8288 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0228 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0194 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0410 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1945 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1553 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1547 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3389 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3173 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2888 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4775 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8828 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8229 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9269 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9800 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9523 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1374 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1479 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1256 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3624 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3158 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3038 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5721 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6067 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7113 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7702 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9169 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7941 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9868 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2106 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0911 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2600 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3016 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3327 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5090 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4755 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9017 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8394 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9999 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8990 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7841 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1061 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7648 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6544 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2649 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6713 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3073 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3197 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9557 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1766 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4204 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9696 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5621 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2769 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1736 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1778 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5992 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0730 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0932 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2470 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0178 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1661 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8482 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8760 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9268 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3332 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0962 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3326 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7080 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8079 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5229 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0770 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9096 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8012 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2638 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2934 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0281 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3630 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8926 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0027 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3416 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5961 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1099 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0200 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8973 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5772 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8564 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2557 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2022 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2496 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8251 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7021 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.1911 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3157 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.4631 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3509 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.7040 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.1015 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.8118 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.6394 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.0828 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.7235 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.7591 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.3757 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9588 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 35.2023 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.2576 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.6122 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.5938 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.9873 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.5330 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.2524 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.3988 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.3275 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.8388 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 27.2121 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0177 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.7850 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.4566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.2932 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 48.8236 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.0682 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.8141 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.4847 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.8934 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.8850 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.9483 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.6444 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.5664 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 23.5774 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.3930 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.1111 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.6066 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.8965 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.3394 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.5749 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.5002 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.1975 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.8307 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.9579 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.9921 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.7998 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.4294 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.6843 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.2741 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.8061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.0877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.8384 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.2019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.9915 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.3873 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 69.7391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.8290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.7188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.0537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.1676 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.6254 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 103.9218 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.7465 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.3329 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 104.9485 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.1349 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 149.7187 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 241.0687 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.5041 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 180.1857 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 276.5539 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.6784 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 290.5551 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.2338 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 306.5923 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.7923 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.9219 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 94.9326 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 117.8651 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 198.3304 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 190.0327 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.8947 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 328.0807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 299.7082 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 233.1783 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 333.5511 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 362.9194 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.9777 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 433.9835 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 448.4923 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 362.2332 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.8340 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 152.0526 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.5868 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 356.3758 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 303.4283 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 284.5066 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 384.4299 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 391.2274 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 276.2425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 438.8611 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 392.7027 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 494.0623 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 694.8500 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 590.7758 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 653.8428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 237.1009 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 209.4705 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 178.8716 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 383.5905 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 355.8226 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 231.1191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 584.0127 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 512.2115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 396.9729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 650.3768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 590.5720 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 607.6014 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 861.6647 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 682.6977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 497.7391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6445 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5698 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5583 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6881 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5206 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4597 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6293 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5214 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5723 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7346 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4910 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6805 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6910 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6192 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7062 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5234 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4928 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6631 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6263 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5402 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6736 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5428 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5959 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6702 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5309 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7234 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6672 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6630 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6179 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6864 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5742 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5249 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6750 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4653 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4980 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6908 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5406 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5054 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7051 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6379 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6795 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7108 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6806 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6177 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7002 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6675 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5428 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7005 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6454 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4979 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6893 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5578 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5467 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5603 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4692 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6895 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7037 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6764 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5963 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5869 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7143 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5576 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4982 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6664 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5742 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6198 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7817 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5638 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5493 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7090 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6356 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7252 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5567 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5654 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6992 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6764 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6036 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7258 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6210 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6592 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7372 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6093 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6255 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7483 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6868 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6290 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7104 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6212 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5540 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7211 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5258 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8347 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7578 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6286 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5733 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7920 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7337 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7293 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7098 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6335 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7291 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7295 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7715 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7566 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7301 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5330 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6655 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6765 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7986 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6599 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5993 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8206 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8257 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8017 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9134 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8218 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8124 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9502 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8824 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8204 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0006 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9646 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9928 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2050 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0399 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0276 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2423 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8776 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7961 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8964 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8690 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8330 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0244 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1317 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0465 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1946 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1800 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2013 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3394 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3132 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2784 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4777 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8942 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8427 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9264 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0763 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9458 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1356 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1370 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1153 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3607 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3387 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2825 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5732 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6342 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5737 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9593 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9348 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9894 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2042 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1406 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2605 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4418 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1708 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5454 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5046 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7515 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.6921 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9995 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9108 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8359 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1646 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7046 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6591 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2908 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7473 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3927 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3180 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8469 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3375 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4185 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5977 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6660 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2741 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3516 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0557 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5994 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2164 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2238 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2427 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1454 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0961 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8317 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7110 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0135 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3336 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2896 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5379 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7080 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7907 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5585 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0765 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6504 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8719 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2509 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9886 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3075 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3611 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1889 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4602 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.3425 - accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 9.2906 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2831 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2664 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0752 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8866 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5794 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1253 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1801 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2602 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2608 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8247 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5835 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5903 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.3171 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8956 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4112 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.7241 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.4061 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5110 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.0934 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.1800 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.8140 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.9060 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.4878 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0881 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.1996 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.7724 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.7684 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.5911 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.4533 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.8969 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.2486 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.0799 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.5497 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.8364 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.1398 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.1450 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2579 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.6155 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4688 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.3043 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.5758 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.1439 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.4836 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.1360 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.1162 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.9467 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.9900 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.2906 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.5765 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.5083 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.2404 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.5604 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.9257 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.5293 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.5710 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.7056 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.7550 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.8295 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.1845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.2087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.7991 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.5102 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.7770 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.2740 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.8997 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.3860 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.6130 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.3662 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.1459 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.3864 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 69.9242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.9734 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.7182 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.8713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.3755 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 118.8074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 103.9399 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.5379 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 86.8288 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.4879 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 130.8472 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.6328 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 227.7222 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.5276 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 180.1797 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 276.5770 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.7004 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 290.5480 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.2518 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 306.6169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.7830 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.9367 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 132.0647 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.8515 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 240.1455 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 180.6827 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 149.3720 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 328.1052 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 282.4780 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 233.1736 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 478.8822 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 278.9796 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.9700 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 434.0133 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 290.1352 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 362.2289 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.8449 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 121.5029 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.5858 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 356.3901 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 303.4434 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 284.4968 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 499.0722 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 329.6883 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 276.2326 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 438.8850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 392.7208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 259.1581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 694.8767 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.8030 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 653.8375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 237.1141 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 209.4865 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 178.8627 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 383.5994 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 355.8285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 231.1206 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 584.0290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 512.2261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 396.9744 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.4335 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 554.0201 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 607.5961 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 861.6919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 682.7190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 539.5618 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7061 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6993 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7755 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6248 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5908 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6889 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5450 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4723 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6306 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5074 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5048 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7345 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5092 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4883 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6989 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6863 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7067 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6392 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5634 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6667 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6665 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5496 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6762 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5525 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5263 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6696 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5505 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5866 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6693 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6832 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6842 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6873 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6417 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6190 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6762 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6583 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6017 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6853 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6352 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4685 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7065 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6706 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6096 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7112 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6884 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6857 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6965 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7075 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6848 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7009 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7026 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6864 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9456 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2050 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0453 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0166 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8849 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.4534 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.5898 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.3876 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.9154 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.2484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.1479 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9856 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.8340 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.0707 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.1960 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.7843 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.9016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.2994 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.0263 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4451 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.4819 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.2662 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.5047 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.5443 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.2174 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0821 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.2086 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.6646 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.9407 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.6009 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.2345 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.5227 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.0425 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.1415 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.3661 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.8285 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.5999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 56.4848 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.7980 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.6500 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.9723 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.2682 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.8020 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.5877 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.2175 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.7176 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.4690 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.2274 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.8265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 56.6595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.7139 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.9403 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.9097 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 120.7109 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 108.6407 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.7366 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 86.8277 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.5121 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 93.7276 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.6243 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 227.7498 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.5583 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 180.1733 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 243.7081 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.7387 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 290.5407 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.2917 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 306.6544 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.7754 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 151.9633 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 132.0931 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.8367 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 240.1813 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 180.7191 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 149.3675 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 328.1530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 299.7780 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 233.1590 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 478.9206 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.1627 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.9644 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 434.0693 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 360.7291 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 362.2196 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.8631 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 141.0251 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 137.0867 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 356.4125 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 303.4668 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 262.4488 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 499.1168 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 329.7300 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 276.2220 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 438.9382 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 392.7651 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 494.0470 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 740.2629 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.8494 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 653.8321 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 237.1407 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 209.5204 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 178.8499 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 351.3854 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 339.2212 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 231.1090 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 555.2080 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 512.2631 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 466.4833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 578.2987 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 590.6201 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 405.8517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 861.7657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 682.7769 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 687.3761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6979 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7033 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7641 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6199 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6137 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6992 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5397 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5009 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6363 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5159 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5024 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7353 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5585 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5161 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6767 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7104 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7085 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7099 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6615 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6360 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6660 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6522 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5949 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6784 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6060 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5448 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6684 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5814 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5331 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6717 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6907 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6892 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6560 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6658 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6747 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6829 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6733 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6797 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6693 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6210 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7096 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5540 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6773 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8035 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5772 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6908 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4837 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5179 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6965 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9230 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6861 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7090 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5939 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5405 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6986 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7350 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6999 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5665 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5513 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6880 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6087 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6145 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6894 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9453 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8732 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6879 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7080 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6213 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7602 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6038 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7023 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4783 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4539 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6688 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5707 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6241 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7869 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5900 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6100 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7442 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6190 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5955 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7232 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5851 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6329 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6934 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5547 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5353 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7236 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6353 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7311 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7367 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6159 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6435 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7482 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6524 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5480 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7111 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6025 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5883 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7234 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8453 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6588 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7579 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5697 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5943 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7833 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0431 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8006 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8151 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6234 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5643 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7275 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7487 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7559 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6371 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7741 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7144 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7118 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7963 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0113 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5074 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8190 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8274 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7571 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8858 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8444 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8351 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9382 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7953 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7691 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0030 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9691 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9798 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2102 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0732 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0761 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7858 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7695 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8943 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9072 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9069 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0187 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9940 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9817 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1927 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2058 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2434 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3390 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3070 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2841 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4776 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8610 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7309 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9271 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9948 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9727 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1380 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2285 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1682 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3608 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3101 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3034 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5642 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8877 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5826 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8701 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9878 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2104 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1994 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2599 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2756 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2612 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5918 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5839 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7574 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1509 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8079 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9977 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9256 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8150 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1282 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7307 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6162 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2688 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0939 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0170 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3206 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9977 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3950 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4239 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8870 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4464 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9668 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0748 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5977 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1883 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8505 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2376 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1956 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1034 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8464 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7778 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1852 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3334 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9268 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6595 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7082 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7660 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2828 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0773 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8186 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3710 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2645 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3058 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2044 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3616 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4554 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1825 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.2931 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.8184 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4260 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9895 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7034 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5781 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1355 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6730 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2227 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4003 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6707 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4594 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8963 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3153 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3701 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5004 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6918 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8783 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.5682 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.3419 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.0195 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.6632 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.9465 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.7472 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.8832 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 35.2040 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.1686 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.5107 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 45.5981 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.8777 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.4383 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.2572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.7833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.3806 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.8380 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.1357 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9290 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2586 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.3613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.0826 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.8223 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.9494 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.8651 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.4852 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 50.4329 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.5906 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.5474 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.8618 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.5052 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.5775 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.3402 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.0583 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.6077 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.7834 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.2332 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.5750 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.3509 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.4452 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.9733 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.8260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 59.8865 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.7994 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.3960 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.6508 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.2756 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.7560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.0437 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.4562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.1184 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.9245 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.3883 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 69.6443 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 59.7533 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.7197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 86.9328 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.0850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 121.6831 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.8814 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.6213 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.8306 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 104.9401 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 99.1255 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.4590 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 241.0538 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 220.7269 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 166.2566 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 276.5398 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.6618 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 290.5629 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.2252 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 306.5819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.7960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 151.9158 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 107.1350 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.8672 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 188.9621 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 190.0185 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 149.3885 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 328.0660 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 299.6948 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 215.1311 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 333.5363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 362.9058 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.9788 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 528.5319 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 448.4765 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 392.6626 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.8284 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 130.8502 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.5848 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 356.3696 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 303.4212 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 284.5094 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 427.2709 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 391.2123 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 235.1290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 466.1913 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 392.6881 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.8499 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 740.1735 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 549.5029 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 653.8445 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 237.0967 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 209.4659 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 178.8745 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 400.6601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 373.6310 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 231.1203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 584.0027 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 512.2048 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 396.9781 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 650.3663 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.5609 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 607.6058 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 861.6545 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 682.6944 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 459.1548 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6785 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6401 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7319 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5934 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5519 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6742 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4882 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4657 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6309 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5191 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5192 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7364 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5333 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5044 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6565 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6541 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7058 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5944 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4938 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6613 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5226 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5623 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6733 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5107 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5527 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6696 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7113 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6827 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6401 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7223 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7336 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6812 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7523 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7239 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5564 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7933 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7772 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8830 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8173 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7175 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7161 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7254 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7595 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7357 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7569 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7758 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7739 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7647 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7353 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7997 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8282 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8956 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8444 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7943 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9152 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8791 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8339 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9510 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9084 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8286 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0019 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9464 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5338 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5280 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6670 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6469 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5803 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6868 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5354 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5712 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6767 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5165 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5012 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6924 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4845 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5198 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7040 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6049 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7944 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6478 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5834 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6977 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6749 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6602 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7000 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6408 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6123 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6896 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5126 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7302 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6900 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7131 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6666 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6900 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6920 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6217 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7459 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6192 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5814 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7005 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5254 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5106 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5964 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2658 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1401 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2367 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8312 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8169 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6343 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4369 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3336 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.7830 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4440 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7095 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5328 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2428 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0771 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7148 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6484 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2655 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7332 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1230 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3622 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0022 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5414 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.2756 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9728 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.9188 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0122 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5992 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5777 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0317 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2098 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5866 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5193 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8232 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9289 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5642 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3147 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.2490 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5211 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.6784 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1294 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.6645 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.9804 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.9657 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.4047 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.3257 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.6842 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.8141 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.2060 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.1073 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.4578 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.6017 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.5687 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.3709 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.8221 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.2130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.8736 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.8376 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.0773 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9459 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2593 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.2747 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.5785 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.9305 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.3200 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.0927 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.4863 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 50.3234 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.6289 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.5509 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3825 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.3154 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.5777 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.3021 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.0207 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.6097 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 45.7179 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.1779 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.5763 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.4356 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.0350 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.3498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.7505 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.8378 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.7997 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 24.3753 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.6279 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.2764 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.7266 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.0242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.4576 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.0699 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.8862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.3892 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.6528 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.6789 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.7207 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 92.4316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 74.0423 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 120.7181 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.6319 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.4881 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 58.2029 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 160.0379 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.1163 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 92.4624 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 241.0417 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 220.7155 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 166.2611 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 276.5273 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.6489 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 290.5701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.2178 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 306.5721 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 319.9312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 151.9112 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 91.1742 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.8714 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 188.9527 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 190.0086 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 149.3918 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 328.0542 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 299.6851 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 168.9746 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 377.1738 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 388.0807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 412.9836 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 353.8989 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 448.4672 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 392.6717 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.8261 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 126.0751 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.5850 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 356.3675 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 303.4174 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 284.5150 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 427.2626 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.7758 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 235.1349 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 466.1801 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 392.6802 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.8526 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 740.1671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 549.4998 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 653.8469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 237.0942 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 209.4619 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 178.8793 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 400.6571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 373.6310 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 231.1226 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 583.9960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 512.2003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 396.9818 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 650.3611 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 630.1324 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 517.0391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 808.6595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 733.4990 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 584.9363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6943 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6113 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7462 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5895 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5747 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6761 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4392 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4196 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6317 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5260 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5843 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7398 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5341 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5450 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5525 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6728 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6377 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6929 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6989 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6574 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6950 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7205 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7143 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7895 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6513 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6020 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7151 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5837 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5059 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6678 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5524 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5564 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7816 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5630 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5494 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7380 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7176 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7095 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7257 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6767 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6088 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7029 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7193 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6109 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7283 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6105 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7304 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7366 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6400 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6595 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7504 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7078 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7094 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7584 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6476 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5615 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7790 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1064 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8004 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8146 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6338 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6752 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7269 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7090 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8799 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7997 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5879 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6609 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6349 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7955 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6784 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8887 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8157 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8005 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7578 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9045 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8372 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8171 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9417 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8120 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7838 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0042 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9499 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9722 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2131 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0738 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0116 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7726 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7562 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8929 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9942 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9359 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0176 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9885 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9696 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1829 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2105 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1845 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3392 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3333 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2780 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4786 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7984 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7375 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9269 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0675 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0225 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1389 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7460 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2092 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3613 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3701 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2716 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5598 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9616 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5607 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8657 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9053 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9872 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4082 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2161 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3854 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1662 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5067 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5148 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4531 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7566 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7001 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7979 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9943 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8871 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8196 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1547 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7625 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5160 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2765 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1129 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5697 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6679 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6698 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5364 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5549 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6670 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6286 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5111 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6871 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7281 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3219 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8873 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5771 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4268 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9778 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6796 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2674 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0005 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9820 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8172 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7024 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7138 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5222 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5524 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5372 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6886 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5707 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8198 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6846 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6746 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6408 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7787 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6103 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5917 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7058 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4966 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4727 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6701 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5583 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5975 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7897 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5928 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5867 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7342 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6060 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5983 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7218 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6985 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5960 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6923 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5552 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5982 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7139 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6524 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6892 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7369 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6564 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6486 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7492 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5905 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5233 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7109 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6841 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6009 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5814 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7042 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5409 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5944 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6573 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5025 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4836 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6715 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5852 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6214 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6700 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5763 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5569 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6681 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5678 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5183 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6869 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6349 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6782 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3457 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5296 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6913 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5660 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5105 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9945 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6915 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6017 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6423 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6020 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6980 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6504 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6880 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5370 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5306 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6780 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5815 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5886 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7027 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5378 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5577 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6562 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5014 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5193 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6618 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6924 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7243 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4593 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3854 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4317 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6329 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5115 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5471 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7427 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5849 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5671 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6796 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6064 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6595 - accuracy: 0.6111\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": range(2, 6), \n",
    "                \"n_units\": range(50, 300, 50),\n",
    "                \"dropout\": np.arange(0, 0.6, 0.1),\n",
    "                \"kernel_regularizer\": [0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                \"optimizer\": [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "studySoftmax_Grid_Comp = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "studySoftmax_Grid_Comp.optimize(objectiveSoftmax_Grid_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "64f63924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888955116272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(studySoftmax_Grid_Comp.get_trials())\n",
    "print(top_acc)\n",
    "modelsSoftmax_Grid_Comp = models_same_acc_OptunaSearchCV(studySoftmax_Grid_Comp.get_trials(), top_acc)\n",
    "len(modelsSoftmax_Grid_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "01cc2fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layers': 5, 'n_units': 150, 'dropout': 0.2, 'kernel_regularizer': 0.0001, 'optimizer': 'RMSprop'}\n",
      "{'n_layers': 5, 'n_units': 150, 'dropout': 0.2, 'kernel_regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "{'n_layers': 5, 'n_units': 150, 'dropout': 0.2, 'kernel_regularizer': 0.01, 'optimizer': 'Adam'}\n",
      "{'n_layers': 5, 'n_units': 150, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0.0001, 'optimizer': 'RMSprop'}\n",
      "{'n_layers': 5, 'n_units': 150, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "{'n_layers': 5, 'n_units': 250, 'dropout': 0.30000000000000004, 'kernel_regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "{'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'kernel_regularizer': 0, 'optimizer': 'RMSprop'}\n",
      "{'n_layers': 5, 'n_units': 200, 'dropout': 0.1, 'kernel_regularizer': 0.001, 'optimizer': 'RMSprop'}\n",
      "{'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'kernel_regularizer': 0.01, 'optimizer': 'RMSprop'}\n",
      "{'n_layers': 5, 'n_units': 150, 'dropout': 0.2, 'kernel_regularizer': 0, 'optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "for model in modelsSoftmax_Grid_Comp:\n",
    "    if model[\"n_layers\"] == 5:\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eda7c2",
   "metadata": {},
   "source": [
    "Vamos a escoger la configuración más compleja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e3b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 203ms/step - loss: 2.0014 - acc: 0.5294 - val_loss: 1.9291 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.9372 - acc: 0.5686 - val_loss: 1.8969 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.8706 - acc: 0.7255 - val_loss: 1.8507 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7871 - acc: 0.7255 - val_loss: 1.8025 - val_acc: 0.7059\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.6763 - acc: 0.8235 - val_loss: 2.0822 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.6281 - acc: 0.8039 - val_loss: 1.8865 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.4396 - acc: 0.9020 - val_loss: 1.9826 - val_acc: 0.5882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4212 - acc: 0.9020 - val_loss: 1.9354 - val_acc: 0.7647\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2337 - acc: 0.9804 - val_loss: 1.9156 - val_acc: 0.5882\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1842 - acc: 0.9804 - val_loss: 2.0367 - val_acc: 0.5882\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2073 - acc: 0.9804 - val_loss: 2.0733 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6031 - acc: 0.8889\n",
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optunaSoftmax_Grid_Comp = models.Sequential()\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001), \n",
    "                                             input_shape=(410,)))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dropout(0.3))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dropout(0.3))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dropout(0.3))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dropout(0.3))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dropout(0.3))\n",
    "modelFC_optunaSoftmax_Grid_Comp.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_optunaSoftmax_Grid_Comp.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optunaSoftmax_Grid_Comp.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optunaSoftmax_Grid_Comp.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed97c75",
   "metadata": {},
   "source": [
    "**Optuna + TPE (activación softmax)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "91d41c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveSoftmax_TPE_Comp(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación softmax\n",
    "    '''\n",
    "    tf.keras.utils.set_random_seed(0)\n",
    "    \n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c552f735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 259.1581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 549.4998 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5115 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.0911 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6992 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 86.8288 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 578.2987 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9458 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 23.2086 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 346.7923 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1994 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1994 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1994 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0410 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2612 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8288 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.9723 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6371 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5794 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8312 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.7332 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8312 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0022 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.3710 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.8312 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7281 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6286 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7144 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8288 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.6544 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2756 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7332 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5471 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6564 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 101.7197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5771 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2824 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8169 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8500 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5547 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 466.1913 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7332 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5852 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6700 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3710 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7281 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.8719 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 303.4283 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 37.2747 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7823 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7953 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8500 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6681 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8312 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1230 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9069 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1317 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1230 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1230 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9727 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7941 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1994 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8505 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8312 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.2747 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 241.0687 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6484 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7281 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5585 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8351 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7332 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9727 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9727 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5852 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5763 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5160 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3219 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.6843 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1230 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7332 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7332 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6343 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1714 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6343 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5014 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5296 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6588 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.7758 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7332 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5852 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5852 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8055 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9878 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4317 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5772 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7305 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5933 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5933 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7192 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5837 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5059 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5059 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5059 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6735 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4749 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.6065 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6735 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4749 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.6065 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5392 - accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "studySoftmax_TPE_Comp = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "studySoftmax_TPE_Comp.optimize(objectiveSoftmax_TPE_Comp, n_trials=216)\n",
    "# n_trials = (4 x 5 x 6 x 6 x 3) * 0.1 = 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b4cfd980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888955116272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(studySoftmax_TPE_Comp.get_trials())\n",
    "print(top_acc)\n",
    "modelsSoftmax_TPE_Comp = models_same_acc_OptunaSearchCV(studySoftmax_TPE_Comp.get_trials(), top_acc)\n",
    "len(modelsSoftmax_TPE_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f8e16cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layers': 4, 'n_units': 100, 'dropout': 0.0, 'kernel_regularizer': 0.01, 'optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "for model in modelsSoftmax_TPE_Comp:\n",
    "    if model[\"n_layers\"] == 4:\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d2afe5",
   "metadata": {},
   "source": [
    "Mantenemos el modelo más complejo optimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "19d7dcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 224ms/step - loss: 5.1905 - acc: 0.6078 - val_loss: 4.8339 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 4.7449 - acc: 0.6078 - val_loss: 4.5484 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 4.4449 - acc: 0.6275 - val_loss: 4.3273 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.1885 - acc: 0.7843 - val_loss: 4.1577 - val_acc: 0.6471\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.9640 - acc: 0.8431 - val_loss: 4.0304 - val_acc: 0.6471\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.7559 - acc: 0.8824 - val_loss: 3.8955 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.5942 - acc: 0.9020 - val_loss: 3.7875 - val_acc: 0.5882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.4498 - acc: 0.9804 - val_loss: 3.7151 - val_acc: 0.7647\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.2470 - acc: 0.9804 - val_loss: 3.5810 - val_acc: 0.6471\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.0981 - acc: 0.9804 - val_loss: 3.5240 - val_acc: 0.6471\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.9558 - acc: 1.0000 - val_loss: 3.4642 - val_acc: 0.6471\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.2617 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optunaSoftmax_TPE_Comp = models.Sequential()\n",
    "modelFC_optunaSoftmax_TPE_Comp.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01),\n",
    "                                            input_shape=(410,)))\n",
    "modelFC_optunaSoftmax_TPE_Comp.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01)))\n",
    "modelFC_optunaSoftmax_TPE_Comp.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01)))\n",
    "modelFC_optunaSoftmax_TPE_Comp.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01)))\n",
    "modelFC_optunaSoftmax_TPE_Comp.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_optunaSoftmax_TPE_Comp.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optunaSoftmax_TPE_Comp.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optunaSoftmax_TPE_Comp.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a90ed7",
   "metadata": {},
   "source": [
    "Predicciones de Kaggle para estas últimas pruebas de optimización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab97dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_Comp = modelFC_optunaSoftmax_Grid_Comp.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_Comp, \"NN_Opt_Comp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
