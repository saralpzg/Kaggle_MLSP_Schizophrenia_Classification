{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70addaeb",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Uno de los principales obstáculos que se encuentran al intentar hallar la major solución al problema de clasificación, es la escasez de datos para el entrenamiento de los modelos.\n",
    "\n",
    "Este notebook tiene como objetivo implementar y comparar los resultados obtenidos implementando técnicas de Data Augmentation para crear datos sintéticos y poder operar sobre un mayor volumen de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989e8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72411cba",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f7bd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>0.216620</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.353800</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.133020</td>\n",
       "      <td>-0.035222</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257114</td>\n",
       "      <td>0.597229</td>\n",
       "      <td>1.220756</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>-0.435494</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>1.090910</td>\n",
       "      <td>-0.448562</td>\n",
       "      <td>-0.508497</td>\n",
       "      <td>0.350434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.410730</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.242260</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>0.599790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050862</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>0.609465</td>\n",
       "      <td>1.181878</td>\n",
       "      <td>-2.279469</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>-0.012693</td>\n",
       "      <td>-1.244346</td>\n",
       "      <td>-1.080442</td>\n",
       "      <td>-0.788502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.318170</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.539922</td>\n",
       "      <td>-1.495822</td>\n",
       "      <td>1.643866</td>\n",
       "      <td>1.687780</td>\n",
       "      <td>1.521086</td>\n",
       "      <td>-1.988432</td>\n",
       "      <td>-0.267471</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>1.104566</td>\n",
       "      <td>-1.067206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.112830</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0.202750</td>\n",
       "      <td>0.191420</td>\n",
       "      <td>-0.056662</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.593326</td>\n",
       "      <td>1.063052</td>\n",
       "      <td>0.434726</td>\n",
       "      <td>1.604964</td>\n",
       "      <td>-0.359736</td>\n",
       "      <td>0.210107</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>-0.323557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "2       0  0.245850  0.216620 -0.124680 -0.353800  0.161500 -0.002032   \n",
       "13      1  0.410730 -0.031925  0.210700  0.242260  0.320100 -0.419290   \n",
       "53      1  0.070919  0.034179 -0.011755  0.019158  0.024645 -0.032022   \n",
       "41      0  0.087377 -0.052462 -0.007835 -0.112830  0.389380  0.216080   \n",
       "74      0  0.202750  0.191420 -0.056662 -0.157780  0.244040  0.039780   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "2  -0.133020 -0.035222  0.259040  ...  -0.257114   0.597229   1.220756   \n",
       "13 -0.187140  0.168450  0.599790  ...  -0.050862   0.870602   0.609465   \n",
       "53  0.004620  0.318170  0.212550  ...  -1.539922  -1.495822   1.643866   \n",
       "41  0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "74 -0.001503  0.001056 -0.048222  ...   0.044457   0.593326   1.063052   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "2   -0.059213  -0.435494  -0.092971   1.090910  -0.448562  -0.508497   \n",
       "13   1.181878  -2.279469  -0.013484  -0.012693  -1.244346  -1.080442   \n",
       "53   1.687780   1.521086  -1.988432  -0.267471   0.510576   1.104566   \n",
       "41  -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "74   0.434726   1.604964  -0.359736   0.210107   0.355922   0.730287   \n",
       "\n",
       "    SBM_map75  \n",
       "2    0.350434  \n",
       "13  -0.788502  \n",
       "53  -1.067206  \n",
       "41  -0.260920  \n",
       "74  -0.323557  \n",
       "\n",
       "[5 rows x 411 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de entrenamiento\n",
    "trainFNC = pd.read_csv(\"data/train_FNC.csv\")\n",
    "trainSBM = pd.read_csv(\"data/train_SBM.csv\")\n",
    "train_labels = pd.read_csv(\"data/train_labels.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "train = pd.merge(left=trainFNC, right=trainSBM, left_on=\"Id\", right_on=\"Id\")\n",
    "data = pd.merge(left=train_labels, right=train, left_on=\"Id\", right_on=\"Id\")\n",
    "data.drop(\"Id\", inplace=True, axis=1)\n",
    "\n",
    "# Shuffle de los datos de train\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d83db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_partition(data_augmented):\n",
    "    X = data_augmented.iloc[:, 1:]\n",
    "    Y = data_augmented.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1986728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61cfdadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>FNC10</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476127</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>-0.608133</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>-0.637038</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>-0.192434</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.060474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451994</td>\n",
       "      <td>1.123770</td>\n",
       "      <td>2.083006</td>\n",
       "      <td>1.145440</td>\n",
       "      <td>-0.067608</td>\n",
       "      <td>1.202529</td>\n",
       "      <td>0.851587</td>\n",
       "      <td>0.451583</td>\n",
       "      <td>-0.159739</td>\n",
       "      <td>0.192076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.267183</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>-0.261327</td>\n",
       "      <td>0.191869</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>0.088761</td>\n",
       "      <td>0.177048</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696987</td>\n",
       "      <td>1.397832</td>\n",
       "      <td>1.046136</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>-2.192023</td>\n",
       "      <td>-0.369276</td>\n",
       "      <td>0.822225</td>\n",
       "      <td>-0.109342</td>\n",
       "      <td>-0.580476</td>\n",
       "      <td>0.174160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.435452</td>\n",
       "      <td>0.046780</td>\n",
       "      <td>0.243742</td>\n",
       "      <td>0.397030</td>\n",
       "      <td>-0.147821</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>-0.461963</td>\n",
       "      <td>-0.610736</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.400985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>1.906989</td>\n",
       "      <td>-2.661633</td>\n",
       "      <td>-0.193911</td>\n",
       "      <td>0.440873</td>\n",
       "      <td>0.641739</td>\n",
       "      <td>0.918397</td>\n",
       "      <td>-0.758046</td>\n",
       "      <td>0.154701</td>\n",
       "      <td>-0.476647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.204510</td>\n",
       "      <td>-0.036735</td>\n",
       "      <td>-0.760705</td>\n",
       "      <td>-0.740495</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>0.349926</td>\n",
       "      <td>-0.273826</td>\n",
       "      <td>-0.174384</td>\n",
       "      <td>-0.120248</td>\n",
       "      <td>0.175618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974828</td>\n",
       "      <td>-1.997087</td>\n",
       "      <td>-2.083782</td>\n",
       "      <td>1.154107</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>2.332424</td>\n",
       "      <td>0.659124</td>\n",
       "      <td>-0.809445</td>\n",
       "      <td>0.558960</td>\n",
       "      <td>2.790871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599435</td>\n",
       "      <td>-0.166441</td>\n",
       "      <td>0.122431</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.346906</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.274734</td>\n",
       "      <td>0.211510</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-0.033434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.789153</td>\n",
       "      <td>1.578984</td>\n",
       "      <td>1.402592</td>\n",
       "      <td>-1.230440</td>\n",
       "      <td>0.296686</td>\n",
       "      <td>2.806314</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>-0.240682</td>\n",
       "      <td>-0.196948</td>\n",
       "      <td>-1.544345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FNC1      FNC2      FNC3      FNC4      FNC5      FNC6      FNC7  \\\n",
       "0  0.476127  0.064466  0.053238 -0.608133  0.073988 -0.637038  0.113556   \n",
       "1  0.013833  0.267183  0.232178 -0.167151 -0.261327  0.191869  0.406493   \n",
       "2 -0.435452  0.046780  0.243742  0.397030 -0.147821  0.173620 -0.461963   \n",
       "3 -0.204510 -0.036735 -0.760705 -0.740495  0.064668  0.349926 -0.273826   \n",
       "4  0.599435 -0.166441  0.122431  0.011539  0.346906 -0.017430 -0.274734   \n",
       "\n",
       "       FNC8      FNC9     FNC10  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "0 -0.192434 -0.004025 -0.060474  ...  -0.451994   1.123770   2.083006   \n",
       "1  0.088761  0.177048  0.036718  ...   0.696987   1.397832   1.046136   \n",
       "2 -0.610736  0.419753  0.400985  ...   0.160145   1.906989  -2.661633   \n",
       "3 -0.174384 -0.120248  0.175618  ...   0.974828  -1.997087  -2.083782   \n",
       "4  0.211510  0.151012 -0.033434  ...  -0.789153   1.578984   1.402592   \n",
       "\n",
       "   SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  SBM_map75  \n",
       "0   1.145440  -0.067608   1.202529   0.851587   0.451583  -0.159739   0.192076  \n",
       "1  -0.191733  -2.192023  -0.369276   0.822225  -0.109342  -0.580476   0.174160  \n",
       "2  -0.193911   0.440873   0.641739   0.918397  -0.758046   0.154701  -0.476647  \n",
       "3   1.154107  -0.643947   2.332424   0.659124  -0.809445   0.558960   2.790871  \n",
       "4  -1.230440   0.296686   2.806314   0.427184  -0.240682  -0.196948  -1.544345  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de test\n",
    "testFNC = pd.read_csv(\"data/test_FNC.csv\")\n",
    "testSBM = pd.read_csv(\"data/test_SBM.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "test_kaggle = pd.merge(left=testFNC, right=testSBM, left_on=\"Id\", right_on=\"Id\")\n",
    "test_kaggle.drop(\"Id\", inplace=True, axis=1)\n",
    "test_kaggle.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13bba535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119834, 410)\n"
     ]
    }
   ],
   "source": [
    "labels = data.iloc[:, 0]\n",
    "features = np.array(data.iloc[:, 1:])\n",
    "features_tot = np.concatenate((features, test_kaggle))\n",
    "print(features_tot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea0b5c",
   "metadata": {},
   "source": [
    "# Random noise\n",
    "\n",
    "**Precisión de un modelo de Random Forest sobre el conjunto original de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447b1eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Data Augmentation: 83.33%\n"
     ]
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [10, 50, 100, 200, 400]\n",
    "}\n",
    "grid_search_RF = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF.fit(X_train, y_train)\n",
    "model_RF_opt = grid_search_RF.best_estimator_\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF = model_RF_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy without Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010d2b1",
   "metadata": {},
   "source": [
    "### Ruigo gaussiano\n",
    "\n",
    "Una primera prueba de introducción de ruido artificial se basará en añadir a los datos originales, valores (ruido) que se tomarán de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de valores para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c268e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del intervalo)\n",
    "max_per_var = features_tot.max(axis=0)\n",
    "min_per_var = features_tot.min(axis=0)\n",
    "std_per_var = (max_per_var - min_per_var) * 0.1\n",
    "std_per_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304cc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090310</td>\n",
       "      <td>0.186641</td>\n",
       "      <td>-0.033887</td>\n",
       "      <td>0.303550</td>\n",
       "      <td>0.144260</td>\n",
       "      <td>0.535870</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>-0.066027</td>\n",
       "      <td>0.068281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064109</td>\n",
       "      <td>-1.416375</td>\n",
       "      <td>-0.588373</td>\n",
       "      <td>1.476591</td>\n",
       "      <td>-0.931430</td>\n",
       "      <td>0.215681</td>\n",
       "      <td>-1.138860</td>\n",
       "      <td>-0.119312</td>\n",
       "      <td>1.291117</td>\n",
       "      <td>1.465796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.138510</td>\n",
       "      <td>0.258360</td>\n",
       "      <td>-0.510770</td>\n",
       "      <td>-0.457780</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>-0.344340</td>\n",
       "      <td>-0.283480</td>\n",
       "      <td>-0.380750</td>\n",
       "      <td>-0.339130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>-0.896406</td>\n",
       "      <td>-1.232269</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>-0.817785</td>\n",
       "      <td>-0.419049</td>\n",
       "      <td>-1.509745</td>\n",
       "      <td>-0.946138</td>\n",
       "      <td>0.259551</td>\n",
       "      <td>-1.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>-0.303650</td>\n",
       "      <td>0.592750</td>\n",
       "      <td>-0.170640</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>-0.471900</td>\n",
       "      <td>-0.180450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527436</td>\n",
       "      <td>-0.014958</td>\n",
       "      <td>-0.682168</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>1.148412</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>1.696830</td>\n",
       "      <td>-0.434430</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.119103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>-0.575757</td>\n",
       "      <td>-0.510545</td>\n",
       "      <td>-0.655821</td>\n",
       "      <td>-0.626826</td>\n",
       "      <td>-0.183842</td>\n",
       "      <td>0.286757</td>\n",
       "      <td>0.562557</td>\n",
       "      <td>0.113185</td>\n",
       "      <td>...</td>\n",
       "      <td>1.879741</td>\n",
       "      <td>-1.258914</td>\n",
       "      <td>1.126362</td>\n",
       "      <td>-0.268733</td>\n",
       "      <td>0.739928</td>\n",
       "      <td>0.638815</td>\n",
       "      <td>0.934721</td>\n",
       "      <td>2.100384</td>\n",
       "      <td>3.440071</td>\n",
       "      <td>-0.320113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.149488</td>\n",
       "      <td>-0.035793</td>\n",
       "      <td>-0.072892</td>\n",
       "      <td>-0.134532</td>\n",
       "      <td>-0.078967</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.334085</td>\n",
       "      <td>-0.236176</td>\n",
       "      <td>0.241712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438323</td>\n",
       "      <td>-1.170183</td>\n",
       "      <td>0.237547</td>\n",
       "      <td>1.105830</td>\n",
       "      <td>-0.988333</td>\n",
       "      <td>0.614596</td>\n",
       "      <td>2.344493</td>\n",
       "      <td>0.214602</td>\n",
       "      <td>0.175995</td>\n",
       "      <td>2.294870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386970</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>-0.221020</td>\n",
       "      <td>-0.216810</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.333490</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>0.306680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012167</td>\n",
       "      <td>1.308194</td>\n",
       "      <td>-1.412457</td>\n",
       "      <td>1.490609</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>0.565845</td>\n",
       "      <td>-0.988205</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0.279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173938</td>\n",
       "      <td>-0.180256</td>\n",
       "      <td>-0.183904</td>\n",
       "      <td>0.212437</td>\n",
       "      <td>0.408138</td>\n",
       "      <td>-0.287515</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0.202692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.507154</td>\n",
       "      <td>0.734908</td>\n",
       "      <td>1.163661</td>\n",
       "      <td>0.895043</td>\n",
       "      <td>1.358350</td>\n",
       "      <td>-2.743792</td>\n",
       "      <td>-0.051985</td>\n",
       "      <td>0.379716</td>\n",
       "      <td>0.015072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.385621</td>\n",
       "      <td>0.195405</td>\n",
       "      <td>0.183701</td>\n",
       "      <td>0.274933</td>\n",
       "      <td>0.491690</td>\n",
       "      <td>-0.019830</td>\n",
       "      <td>0.095519</td>\n",
       "      <td>-0.024712</td>\n",
       "      <td>-0.187834</td>\n",
       "      <td>...</td>\n",
       "      <td>1.321553</td>\n",
       "      <td>-1.595880</td>\n",
       "      <td>-0.219030</td>\n",
       "      <td>0.159802</td>\n",
       "      <td>0.080166</td>\n",
       "      <td>1.098231</td>\n",
       "      <td>-0.252857</td>\n",
       "      <td>1.797618</td>\n",
       "      <td>-0.175905</td>\n",
       "      <td>-0.074648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248241</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>-0.122858</td>\n",
       "      <td>0.163344</td>\n",
       "      <td>0.174548</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.201017</td>\n",
       "      <td>-0.219028</td>\n",
       "      <td>-0.159444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>-0.622670</td>\n",
       "      <td>0.115314</td>\n",
       "      <td>-0.473325</td>\n",
       "      <td>-1.615781</td>\n",
       "      <td>-0.477100</td>\n",
       "      <td>-2.181088</td>\n",
       "      <td>1.033173</td>\n",
       "      <td>-0.351526</td>\n",
       "      <td>-0.954194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "60    1.0  0.090310  0.186641 -0.033887  0.303550  0.144260  0.535870   \n",
       "19    1.0 -0.138510  0.258360 -0.510770 -0.457780 -0.440400 -0.344340   \n",
       "31    0.0  0.216780  0.270110  0.087964 -0.303650  0.592750 -0.170640   \n",
       "39    1.0  0.089888 -0.575757 -0.510545 -0.655821 -0.626826 -0.183842   \n",
       "14    1.0 -0.149488 -0.035793 -0.072892 -0.134532 -0.078967  0.029238   \n",
       "43    0.0  0.386970  0.139220 -0.221020 -0.216810 -0.017924  0.139650   \n",
       "69    0.0 -0.173938 -0.180256 -0.183904  0.212437  0.408138 -0.287515   \n",
       "18    1.0  0.385621  0.195405  0.183701  0.274933  0.491690 -0.019830   \n",
       "3     0.0  0.248241  0.016551 -0.122858  0.163344  0.174548 -0.000025   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "60  0.033004 -0.066027  0.068281  ...  -0.064109  -1.416375  -0.588373   \n",
       "19 -0.283480 -0.380750 -0.339130  ...  -0.038365  -0.896406  -1.232269   \n",
       "31 -0.143090 -0.471900 -0.180450  ...  -1.527436  -0.014958  -0.682168   \n",
       "39  0.286757  0.562557  0.113185  ...   1.879741  -1.258914   1.126362   \n",
       "14  0.334085 -0.236176  0.241712  ...   0.438323  -1.170183   0.237547   \n",
       "43  0.333490  0.412210  0.306680  ...   1.012167   1.308194  -1.412457   \n",
       "69  0.102173  0.541885  0.202692  ...   0.215764   0.507154   0.734908   \n",
       "18  0.095519 -0.024712 -0.187834  ...   1.321553  -1.595880  -0.219030   \n",
       "3   0.201017 -0.219028 -0.159444  ...   0.027468  -0.622670   0.115314   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "60   1.476591  -0.931430   0.215681  -1.138860  -0.119312   1.291117   \n",
       "19   0.785572  -0.817785  -0.419049  -1.509745  -0.946138   0.259551   \n",
       "31   0.114895   1.148412   0.434126   1.696830  -0.434430   0.094033   \n",
       "39  -0.268733   0.739928   0.638815   0.934721   2.100384   3.440071   \n",
       "14   1.105830  -0.988333   0.614596   2.344493   0.214602   0.175995   \n",
       "43   1.490609   0.081146   0.564483   0.565845  -0.988205   0.014638   \n",
       "69   1.163661   0.895043   1.358350  -2.743792  -0.051985   0.379716   \n",
       "18   0.159802   0.080166   1.098231  -0.252857   1.797618  -0.175905   \n",
       "3   -0.473325  -1.615781  -0.477100  -2.181088   1.033173  -0.351526   \n",
       "\n",
       "    SBM_map75  \n",
       "10   1.003364  \n",
       "60   1.465796  \n",
       "19  -1.026065  \n",
       "31  -0.119103  \n",
       "39  -0.320113  \n",
       "14   2.294870  \n",
       "43   0.279144  \n",
       "69   0.015072  \n",
       "18  -0.074648  \n",
       "3   -0.954194  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% del rango de la variable\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian = np.empty(features.shape)\n",
    "for i, sample in enumerate(features):\n",
    "    noisy_features_gaussian[i, :] = generate_noisy_sample_gaussian(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian = np.c_[labels, noisy_features_gaussian]\n",
    "\n",
    "noisy_data_gaussian = pd.concat([data, pd.DataFrame(noisy_features_gaussian, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian = noisy_data_gaussian.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian.shape))\n",
    "noisy_data_gaussian.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9dee9",
   "metadata": {},
   "source": [
    "Precisión del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6449defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 91.43%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_gaussian)\n",
    "\n",
    "grid_search_RF_gaussian = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF_gaussian.fit(X_train, y_train)\n",
    "model_RF_opt_gaussian = grid_search_RF_gaussian.best_estimator_\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF_gaussian = model_RF_opt_gaussian.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_gaussian)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e989c1",
   "metadata": {},
   "source": [
    "Vamos a modificar ahora el método, de modo que los valores generados de ruido se tomen de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de la diferencia entre la media de las variables para pacientes con esquizofrenia y la media de las variables de los individuos de control.\n",
    "\n",
    "La motivación para introducir esta modificación es que podría ser que las distribuciones que definen cada variable sean diferentes cuando se considera a un individuo sano (etiqueta 0) y a un individuo enfermo (etiqueta 1). Si estas distribuciones están lo suficientemente cercanas, introducir un ruido aparentemente pequeño podría modificar una muestra originalmente correspondiente a una clase y generar otra de manera artificial con la misma etiqueta pero que se solapa con la distribución de la etiqueta opuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = data[data[\"Class\"] == 0]\n",
    "sick = data[data[\"Class\"] == 0]\n",
    "\n",
    "labels_control = control_group.iloc[:, 0]\n",
    "features_control = np.array(control_group.iloc[:, 1:])\n",
    "labels_sick = sick.iloc[:, 0]\n",
    "features_sick = np.array(sick.iloc[:, 1:])\n",
    "\n",
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del rango de la diferencia)\n",
    "avg_per_var_control = features_control.mean(axis=0)\n",
    "avg_per_var_sick = features_sick.mean(axis=0)\n",
    "std_per_var = abs((avg_per_var_control - avg_per_var_sick)) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "330f58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.14185</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.210830</td>\n",
       "      <td>0.42343</td>\n",
       "      <td>0.263870</td>\n",
       "      <td>0.298310</td>\n",
       "      <td>-0.088201</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266496</td>\n",
       "      <td>-1.527078</td>\n",
       "      <td>-1.028776</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>-0.938700</td>\n",
       "      <td>0.215549</td>\n",
       "      <td>-0.575946</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.619411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.138510</td>\n",
       "      <td>0.258360</td>\n",
       "      <td>-0.510770</td>\n",
       "      <td>-0.45778</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>-0.344340</td>\n",
       "      <td>-0.283480</td>\n",
       "      <td>-0.380750</td>\n",
       "      <td>-0.339130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>-0.896406</td>\n",
       "      <td>-1.232269</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>-0.817785</td>\n",
       "      <td>-0.419049</td>\n",
       "      <td>-1.509745</td>\n",
       "      <td>-0.946138</td>\n",
       "      <td>0.259551</td>\n",
       "      <td>-1.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>-0.30365</td>\n",
       "      <td>0.592750</td>\n",
       "      <td>-0.170640</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>-0.471900</td>\n",
       "      <td>-0.180450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527436</td>\n",
       "      <td>-0.014958</td>\n",
       "      <td>-0.682168</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>1.148412</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>1.696830</td>\n",
       "      <td>-0.434430</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.119103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.50381</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>-0.182020</td>\n",
       "      <td>-0.112020</td>\n",
       "      <td>-0.29856</td>\n",
       "      <td>0.155450</td>\n",
       "      <td>0.164520</td>\n",
       "      <td>0.297350</td>\n",
       "      <td>-0.107900</td>\n",
       "      <td>0.297230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179212</td>\n",
       "      <td>-0.241914</td>\n",
       "      <td>-0.243907</td>\n",
       "      <td>1.287397</td>\n",
       "      <td>-1.037125</td>\n",
       "      <td>0.703299</td>\n",
       "      <td>0.626871</td>\n",
       "      <td>0.328094</td>\n",
       "      <td>-0.499501</td>\n",
       "      <td>0.516312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386970</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>-0.221020</td>\n",
       "      <td>-0.21681</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.333490</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>0.306680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012167</td>\n",
       "      <td>1.308194</td>\n",
       "      <td>-1.412457</td>\n",
       "      <td>1.490609</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>0.565845</td>\n",
       "      <td>-0.988205</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0.279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>-0.196510</td>\n",
       "      <td>-0.245280</td>\n",
       "      <td>-0.08384</td>\n",
       "      <td>0.304210</td>\n",
       "      <td>-0.180270</td>\n",
       "      <td>-0.008647</td>\n",
       "      <td>0.384610</td>\n",
       "      <td>0.300520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>1.135537</td>\n",
       "      <td>-0.256829</td>\n",
       "      <td>0.222902</td>\n",
       "      <td>0.528734</td>\n",
       "      <td>1.098908</td>\n",
       "      <td>-1.239779</td>\n",
       "      <td>-0.421480</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>0.325227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.330780</td>\n",
       "      <td>0.123580</td>\n",
       "      <td>0.219650</td>\n",
       "      <td>0.29676</td>\n",
       "      <td>0.413950</td>\n",
       "      <td>0.152980</td>\n",
       "      <td>0.026740</td>\n",
       "      <td>-0.452920</td>\n",
       "      <td>-0.166120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733179</td>\n",
       "      <td>-0.723728</td>\n",
       "      <td>-0.621257</td>\n",
       "      <td>-0.844496</td>\n",
       "      <td>0.587749</td>\n",
       "      <td>1.503607</td>\n",
       "      <td>0.652687</td>\n",
       "      <td>1.341002</td>\n",
       "      <td>-0.150862</td>\n",
       "      <td>-0.053879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.11283</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3     FNC4      FNC5      FNC6  \\\n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.14185 -0.148490 -0.085769   \n",
       "60    1.0 -0.020630  0.250100  0.210830  0.42343  0.263870  0.298310   \n",
       "19    1.0 -0.138510  0.258360 -0.510770 -0.45778 -0.440400 -0.344340   \n",
       "31    0.0  0.216780  0.270110  0.087964 -0.30365  0.592750 -0.170640   \n",
       "39    1.0 -0.146210 -0.468630 -0.528800 -0.50381 -0.510520 -0.029113   \n",
       "14    1.0  0.063080 -0.182020 -0.112020 -0.29856  0.155450  0.164520   \n",
       "43    0.0  0.386970  0.139220 -0.221020 -0.21681 -0.017924  0.139650   \n",
       "69    0.0  0.026362 -0.196510 -0.245280 -0.08384  0.304210 -0.180270   \n",
       "18    1.0  0.330780  0.123580  0.219650  0.29676  0.413950  0.152980   \n",
       "3     0.0  0.087377 -0.052462 -0.007835 -0.11283  0.389380  0.216080   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "60 -0.088201  0.081132 -0.025001  ...  -0.266496  -1.527078  -1.028776   \n",
       "19 -0.283480 -0.380750 -0.339130  ...  -0.038365  -0.896406  -1.232269   \n",
       "31 -0.143090 -0.471900 -0.180450  ...  -1.527436  -0.014958  -0.682168   \n",
       "39 -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "14  0.297350 -0.107900  0.297230  ...   0.179212  -0.241914  -0.243907   \n",
       "43  0.333490  0.412210  0.306680  ...   1.012167   1.308194  -1.412457   \n",
       "69 -0.008647  0.384610  0.300520  ...   0.464108   1.135537  -0.256829   \n",
       "18  0.026740 -0.452920 -0.166120  ...   0.733179  -0.723728  -0.621257   \n",
       "3   0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "60   0.437655  -0.938700   0.215549  -0.575946   0.804762   1.351451   \n",
       "19   0.785572  -0.817785  -0.419049  -1.509745  -0.946138   0.259551   \n",
       "31   0.114895   1.148412   0.434126   1.696830  -0.434430   0.094033   \n",
       "39   0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "14   1.287397  -1.037125   0.703299   0.626871   0.328094  -0.499501   \n",
       "43   1.490609   0.081146   0.564483   0.565845  -0.988205   0.014638   \n",
       "69   0.222902   0.528734   1.098908  -1.239779  -0.421480   1.130700   \n",
       "18  -0.844496   0.587749   1.503607   0.652687   1.341002  -0.150862   \n",
       "3   -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "\n",
       "    SBM_map75  \n",
       "10   1.003364  \n",
       "60   0.619411  \n",
       "19  -1.026065  \n",
       "31  -0.119103  \n",
       "39  -0.551440  \n",
       "14   0.516312  \n",
       "43   0.279144  \n",
       "69   0.325227  \n",
       "18  -0.053879  \n",
       "3   -0.260920  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian2(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% de la diferencia entre la media de la variable para cada clase\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian_2 = np.empty(features.shape)\n",
    "for i, sample in enumerate(features):\n",
    "    noisy_features_gaussian_2[i, :] = generate_noisy_sample_gaussian2(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian_2 = np.c_[labels, noisy_features_gaussian_2]\n",
    "\n",
    "noisy_data_gaussian_2 = pd.concat([data, pd.DataFrame(noisy_features_gaussian_2, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian_2 = noisy_data_gaussian_2.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian_2.shape))\n",
    "noisy_data_gaussian_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca27980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 100.00%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_gaussian_2)\n",
    "\n",
    "grid_search_RF_gaussian2 = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF_gaussian2.fit(X_train, y_train)\n",
    "model_RF_opt_gaussian2 = grid_search_RF_gaussian2.best_estimator_\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF_gaussian2 = model_RF_opt_gaussian2.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_gaussian2)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8603",
   "metadata": {},
   "source": [
    "### Ruido uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "724ab306",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_var = features_tot.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10a75640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.202288</td>\n",
       "      <td>0.372532</td>\n",
       "      <td>0.150380</td>\n",
       "      <td>0.407759</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.353758</td>\n",
       "      <td>-0.188391</td>\n",
       "      <td>0.030450</td>\n",
       "      <td>0.039601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341341</td>\n",
       "      <td>-1.454827</td>\n",
       "      <td>-1.091146</td>\n",
       "      <td>0.337247</td>\n",
       "      <td>-0.959441</td>\n",
       "      <td>0.358669</td>\n",
       "      <td>-0.524144</td>\n",
       "      <td>0.914417</td>\n",
       "      <td>1.350999</td>\n",
       "      <td>0.751747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.138510</td>\n",
       "      <td>0.258360</td>\n",
       "      <td>-0.510770</td>\n",
       "      <td>-0.457780</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>-0.344340</td>\n",
       "      <td>-0.283480</td>\n",
       "      <td>-0.380750</td>\n",
       "      <td>-0.339130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>-0.896406</td>\n",
       "      <td>-1.232269</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>-0.817785</td>\n",
       "      <td>-0.419049</td>\n",
       "      <td>-1.509745</td>\n",
       "      <td>-0.946138</td>\n",
       "      <td>0.259551</td>\n",
       "      <td>-1.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>-0.303650</td>\n",
       "      <td>0.592750</td>\n",
       "      <td>-0.170640</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>-0.471900</td>\n",
       "      <td>-0.180450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527436</td>\n",
       "      <td>-0.014958</td>\n",
       "      <td>-0.682168</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>1.148412</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>1.696830</td>\n",
       "      <td>-0.434430</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.119103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076708</td>\n",
       "      <td>-0.346198</td>\n",
       "      <td>-0.589250</td>\n",
       "      <td>-0.519481</td>\n",
       "      <td>-0.326876</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>-0.115382</td>\n",
       "      <td>0.309488</td>\n",
       "      <td>0.070546</td>\n",
       "      <td>...</td>\n",
       "      <td>1.267428</td>\n",
       "      <td>-0.906161</td>\n",
       "      <td>0.096122</td>\n",
       "      <td>0.789345</td>\n",
       "      <td>0.774628</td>\n",
       "      <td>0.881908</td>\n",
       "      <td>0.527217</td>\n",
       "      <td>2.450039</td>\n",
       "      <td>2.515586</td>\n",
       "      <td>-0.419105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285998</td>\n",
       "      <td>-0.059588</td>\n",
       "      <td>-0.172470</td>\n",
       "      <td>-0.314231</td>\n",
       "      <td>0.339094</td>\n",
       "      <td>0.219968</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>-0.158582</td>\n",
       "      <td>0.361832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104367</td>\n",
       "      <td>-0.169663</td>\n",
       "      <td>-0.306278</td>\n",
       "      <td>1.186990</td>\n",
       "      <td>-1.057866</td>\n",
       "      <td>0.846419</td>\n",
       "      <td>0.678672</td>\n",
       "      <td>0.437749</td>\n",
       "      <td>-0.499953</td>\n",
       "      <td>0.648647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386970</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>-0.221020</td>\n",
       "      <td>-0.216810</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.333490</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>0.306680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012167</td>\n",
       "      <td>1.308194</td>\n",
       "      <td>-1.412457</td>\n",
       "      <td>1.490609</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>0.565845</td>\n",
       "      <td>-0.988205</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0.279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249280</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>-0.305730</td>\n",
       "      <td>-0.099511</td>\n",
       "      <td>0.487854</td>\n",
       "      <td>-0.124822</td>\n",
       "      <td>-0.108838</td>\n",
       "      <td>0.333928</td>\n",
       "      <td>0.365122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389263</td>\n",
       "      <td>1.207788</td>\n",
       "      <td>-0.319200</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.507993</td>\n",
       "      <td>1.242028</td>\n",
       "      <td>-1.187978</td>\n",
       "      <td>-0.311825</td>\n",
       "      <td>1.130247</td>\n",
       "      <td>0.457562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.553698</td>\n",
       "      <td>0.246012</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.597594</td>\n",
       "      <td>0.208428</td>\n",
       "      <td>-0.073450</td>\n",
       "      <td>-0.503602</td>\n",
       "      <td>-0.101518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658334</td>\n",
       "      <td>-0.651477</td>\n",
       "      <td>-0.683628</td>\n",
       "      <td>-0.944904</td>\n",
       "      <td>0.567008</td>\n",
       "      <td>1.646727</td>\n",
       "      <td>0.704488</td>\n",
       "      <td>1.450657</td>\n",
       "      <td>-0.151315</td>\n",
       "      <td>0.078456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310295</td>\n",
       "      <td>0.069970</td>\n",
       "      <td>-0.068285</td>\n",
       "      <td>-0.128501</td>\n",
       "      <td>0.573024</td>\n",
       "      <td>0.271528</td>\n",
       "      <td>-0.036618</td>\n",
       "      <td>-0.301912</td>\n",
       "      <td>-0.015966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152198</td>\n",
       "      <td>-0.387212</td>\n",
       "      <td>-0.266698</td>\n",
       "      <td>-0.719916</td>\n",
       "      <td>-1.431263</td>\n",
       "      <td>-0.161502</td>\n",
       "      <td>-1.470127</td>\n",
       "      <td>0.703346</td>\n",
       "      <td>0.073186</td>\n",
       "      <td>-0.128584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "60    1.0  0.202288  0.372532  0.150380  0.407759  0.447514  0.353758   \n",
       "19    1.0 -0.138510  0.258360 -0.510770 -0.457780 -0.440400 -0.344340   \n",
       "31    0.0  0.216780  0.270110  0.087964 -0.303650  0.592750 -0.170640   \n",
       "39    1.0  0.076708 -0.346198 -0.589250 -0.519481 -0.326876  0.026335   \n",
       "14    1.0  0.285998 -0.059588 -0.172470 -0.314231  0.339094  0.219968   \n",
       "43    0.0  0.386970  0.139220 -0.221020 -0.216810 -0.017924  0.139650   \n",
       "69    0.0  0.249280 -0.074078 -0.305730 -0.099511  0.487854 -0.124822   \n",
       "18    1.0  0.553698  0.246012  0.159200  0.281089  0.597594  0.208428   \n",
       "3     0.0  0.310295  0.069970 -0.068285 -0.128501  0.573024  0.271528   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "60 -0.188391  0.030450  0.039601  ...  -0.341341  -1.454827  -1.091146   \n",
       "19 -0.283480 -0.380750 -0.339130  ...  -0.038365  -0.896406  -1.232269   \n",
       "31 -0.143090 -0.471900 -0.180450  ...  -1.527436  -0.014958  -0.682168   \n",
       "39 -0.115382  0.309488  0.070546  ...   1.267428  -0.906161   0.096122   \n",
       "14  0.197160 -0.158582  0.361832  ...   0.104367  -0.169663  -0.306278   \n",
       "43  0.333490  0.412210  0.306680  ...   1.012167   1.308194  -1.412457   \n",
       "69 -0.108838  0.333928  0.365122  ...   0.389263   1.207788  -0.319200   \n",
       "18 -0.073450 -0.503602 -0.101518  ...   0.658334  -0.651477  -0.683628   \n",
       "3  -0.036618 -0.301912 -0.015966  ...  -0.152198  -0.387212  -0.266698   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "60   0.337247  -0.959441   0.358669  -0.524144   0.914417   1.350999   \n",
       "19   0.785572  -0.817785  -0.419049  -1.509745  -0.946138   0.259551   \n",
       "31   0.114895   1.148412   0.434126   1.696830  -0.434430   0.094033   \n",
       "39   0.789345   0.774628   0.881908   0.527217   2.450039   2.515586   \n",
       "14   1.186990  -1.057866   0.846419   0.678672   0.437749  -0.499953   \n",
       "43   1.490609   0.081146   0.564483   0.565845  -0.988205   0.014638   \n",
       "69   0.122495   0.507993   1.242028  -1.187978  -0.311825   1.130247   \n",
       "18  -0.944904   0.567008   1.646727   0.704488   1.450657  -0.151315   \n",
       "3   -0.719916  -1.431263  -0.161502  -1.470127   0.703346   0.073186   \n",
       "\n",
       "    SBM_map75  \n",
       "10   1.003364  \n",
       "60   0.751747  \n",
       "19  -1.026065  \n",
       "31  -0.119103  \n",
       "39  -0.419105  \n",
       "14   0.648647  \n",
       "43   0.279144  \n",
       "69   0.457562  \n",
       "18   0.078456  \n",
       "3   -0.128584  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_uniform(original_sample, data=data, std_per_var=std_per_var, avg_per_var=avg_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución uniforme\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.uniform(avg_per_var[j]-std_per_var[j], avg_per_var[j]+std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_uniform = np.empty(features.shape)\n",
    "for i, sample in enumerate(features):\n",
    "    noisy_features_uniform[i, :] = generate_noisy_sample_uniform(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_uniform = np.c_[labels, noisy_features_uniform]\n",
    "\n",
    "noisy_data_uniform = pd.concat([data, pd.DataFrame(noisy_features_uniform, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_uniform = noisy_data_uniform.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_uniform.shape))\n",
    "noisy_data_uniform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6615e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 91.43%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_uniform)\n",
    "\n",
    "grid_search_RF_uniform = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF_uniform.fit(X_train, y_train)\n",
    "model_RF_opt_uniform = grid_search_RF_uniform.best_estimator_\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF_uniform = model_RF_opt_uniform.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_uniform)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851437dd",
   "metadata": {},
   "source": [
    "# Pseudo-labeling\n",
    "\n",
    "Fuente: https://towardsdatascience.com/pseudo-labeling-to-deal-with-small-datasets-what-why-how-fd6f903213af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac493413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21aaf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# Para utilizar redes con activación softmax, en primer lugar hay que adaptar los datos\n",
    "NUM_CLASSES = 2\n",
    "y_train_softmax = np_utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_softmax = np_utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c498e7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 4s 34ms/step - loss: 0.7230 - acc: 0.3382\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6228 - acc: 0.7059\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4894 - acc: 0.9118\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4211 - acc: 0.8382\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1909 - acc: 0.9706\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.6427e-04 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.7815e-04 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.3458e-04 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.3485e-04 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4830e-04 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9464e-04 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.5447e-04 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2184e-04 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.9697e-05 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.1990e-05 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6803e-05 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.3597e-05 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1420e-05 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 3.1339e-05 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6028e-05 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1105e-05 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6887e-05 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4374e-05 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1987e-05 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 9.7802e-06 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.2517e-06 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7760e-06 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 5.6048e-06 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2139e-06 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.5224e-06 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.9483e-06 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3138e-06 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9738e-06 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6799e-06 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4330e-06 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2384e-06 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0714e-06 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.0642e-07 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.1936e-07 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.2483e-07 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.2670e-07 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.0966e-07 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4581e-07 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.0837e-07 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5605e-07 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1785e-07 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.8588e-07 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5219e-07 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3291e-07 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.1571e-07 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0218e-07 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.0109e-08 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.6913e-08 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6717e-08 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.8036e-08 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.9677e-08 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2954e-08 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.6544e-08 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 3.2437e-08 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.7274e-08 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.3440e-08 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.1435e-08 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.9890e-08 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.8056e-08 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6214e-08 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.4398e-08 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.3538e-08 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2716e-08 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1909e-08 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0795e-08 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0232e-08 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 9.6519e-09 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 9.2514e-09 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.7472e-09 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.2455e-09 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.9228e-09 - acc: 1.0000\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 7.5310e-09 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.2499e-09 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.9530e-09 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.7633e-09 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.5182e-09 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.3589e-09 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2440e-09 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.0816e-09 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9585e-09 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.8384e-09 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.7147e-09 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.6008e-09 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 5.4838e-09 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5.3449e-09 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.2512e-09 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.5297 - acc: 0.8889\n",
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "modelFC.fit(X_train, y_train_softmax, epochs=100)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e57be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_epoch(epoch, val, start, stop):\n",
    "    if epoch < start:\n",
    "        alpha = 0\n",
    "    elif epoch < stop:\n",
    "        alpha = ((epoch-start) / (stop-start)) * val\n",
    "    else:\n",
    "        alpha = val\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9189c",
   "metadata": {},
   "source": [
    "Vamos a pintar la evolución del valor del peso $\\alpha$ a lo largo de 100 iteraciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f26592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start = 25\n",
    "stop = 190\n",
    "alpha = 1\n",
    "iters = 200\n",
    "\n",
    "alpha_per_epoch = []\n",
    "for i in range(iters):\n",
    "    alpha_per_epoch.append(alpha_epoch(i+1, alpha, start, stop))\n",
    "    \n",
    "# Pintamos el vector\n",
    "plt.plot(alpha_per_epoch)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(r\"$\\alpha(t)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be1e3b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step - loss: 1.3676 - acc: 0.7778\n",
      "Accuracy: 77.78% ------- alpha = 0.50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4581 - acc: 0.8333\n",
      "Accuracy: 83.33% ------- alpha = 1.00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5980 - acc: 0.7778\n",
      "Accuracy: 77.78% ------- alpha = 1.50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6692 - acc: 0.8333\n",
      "Accuracy: 83.33% ------- alpha = 2.00\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "start = 15\n",
    "stop = 90\n",
    "alpha_values = [0.5, 1, 1.5, 2]\n",
    "iters = 100\n",
    "\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "test_reduc = test_kaggle.iloc[:2000, :]\n",
    "X_tot = np.concatenate((X_train, test_reduc))\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    old_pseudolabels = np.ones((2000))\n",
    "    for i in range(iters):\n",
    "        new_pseudolabels = modelFC.predict(test_reduc).squeeze()\n",
    "        alpha_t = alpha_epoch(i+1, alpha, start, stop)\n",
    "        loss_pl = np.abs(new_pseudolabels - old_pseudolabels)\n",
    "        old_pseudolabels = new_pseudolabels\n",
    "        samples = np.concatenate((np.ones(len(y_train)), alpha_t*loss_pl))\n",
    "        modelFC.fit(X_train, y_train, sample_weight=samples, epochs=1, validation_split=0.25, verbose = 0)\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy = modelFC.evaluate(X_test, y_test)\n",
    "    print(\"Accuracy: {:0.2f}% ------- alpha = {:0.2f}\".format(accuracy * 100, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc03928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 118ms/step - loss: 1.4723 - acc: 0.8889\n",
      "Accuracy: 88.89% ------- alpha = 0.50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6284 - acc: 0.8889\n",
      "Accuracy: 88.89% ------- alpha = 1.00\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6685 - acc: 0.8889\n",
      "Accuracy: 88.89% ------- alpha = 1.50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6924 - acc: 0.8889\n",
      "Accuracy: 88.89% ------- alpha = 2.00\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "start = 15\n",
    "stop = 90\n",
    "alpha_values = [0.5, 1, 1.5, 2]\n",
    "iters = 100\n",
    "\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "\n",
    "test_reduc = test.iloc[:1000, :]\n",
    "X_tot = np.concatenate((X_train, test_reduc))\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    old_pseudolabels = np.ones((1000, 2))\n",
    "    for i in range(iters):\n",
    "        new_pseudolabels = modelFC.predict(test_reduc)\n",
    "        alpha_t = alpha_epoch(i+1, alpha, start, stop)\n",
    "        loss_pl = np.abs(new_pseudolabels - old_pseudolabels)\n",
    "        old_pseudolabels = new_pseudolabels\n",
    "        samples = np.concatenate((np.ones(len(y_train)), alpha_t*(loss_pl[:, 0] + loss_pl[:, 1])))\n",
    "        # ESTÁ BIEN HACER LA SUMA? COMO HAGO MERGE DE LAS DOS DIMENSIONES??\n",
    "        modelFC.fit(X_train, y_train_softmax, sample_weight=samples, epochs=1, validation_split=0.25, verbose = 0)\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy = modelFC.evaluate(X_test, y_test_softmax)\n",
    "    print(\"Accuracy: {:0.2f}% ------- alpha = {:0.2f}\".format(accuracy * 100, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b90ae",
   "metadata": {},
   "source": [
    "# Create submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021cfa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "def create_submission(pred, test_id=testFNC[\"Id\"]):\n",
    "    '''\n",
    "    Función para generar un csv con las predicciones de un modelo para participar en la competición de Kaggle\n",
    "    '''\n",
    "    submissionDF = pd.DataFrame(list(zip(test_id, pred)), columns=[\"Id\", \"Probability\"])\n",
    "    print(submissionDF.shape) # Comprobación del tamaño, debe ser: (119748, 2)\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y_%Hh%Mmin\")\n",
    "    current_path = pathlib.Path().resolve()\n",
    "    submissionDF.to_csv(f\"{current_path}\\submissions\\MLSP_submission_DataAug_{current_time}.csv\", header=True, index=False)\n",
    "    \n",
    "create_submission(pred=model_RF_opt.predict(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
