{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70addaeb",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Uno de los principales obstáculos que se encuentran al intentar hallar la major solución al problema de clasificación, es la escasez de datos para el entrenamiento de los modelos.\n",
    "\n",
    "Este notebook tiene como objetivo implementar y comparar los resultados obtenidos implementando técnicas de Data Augmentation para crear datos sintéticos y poder operar sobre un mayor volumen de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989e8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Cargar los datos\n",
    "from Modelos.data_and_submissions import *\n",
    "# Métodos para los entrenamientos con CV\n",
    "from Modelos.train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72411cba",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3c3352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data(True)\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d83db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_partition(data_augmented):\n",
    "    X = data_augmented.iloc[:, 1:]\n",
    "    Y = data_augmented.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bba535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119834, 410)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.concat((y_train, y_test), axis=0)\n",
    "features = pd.concat((X_train, X_test), axis=0)\n",
    "features_tot = pd.concat((features, test_kaggle), axis=0)\n",
    "print(features_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90d87f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>0.435160</td>\n",
       "      <td>0.225050</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>-0.353480</td>\n",
       "      <td>0.447420</td>\n",
       "      <td>0.183180</td>\n",
       "      <td>0.122420</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.404830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314668</td>\n",
       "      <td>-0.114078</td>\n",
       "      <td>-0.476524</td>\n",
       "      <td>-0.556896</td>\n",
       "      <td>0.505738</td>\n",
       "      <td>0.873278</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.211690</td>\n",
       "      <td>0.536933</td>\n",
       "      <td>-0.424864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0.468280</td>\n",
       "      <td>0.108890</td>\n",
       "      <td>0.072178</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.266450</td>\n",
       "      <td>0.350770</td>\n",
       "      <td>-0.210100</td>\n",
       "      <td>-0.089635</td>\n",
       "      <td>-0.140530</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200450</td>\n",
       "      <td>1.817908</td>\n",
       "      <td>-0.299583</td>\n",
       "      <td>0.740836</td>\n",
       "      <td>1.491966</td>\n",
       "      <td>0.993555</td>\n",
       "      <td>-0.043188</td>\n",
       "      <td>0.564047</td>\n",
       "      <td>-0.916360</td>\n",
       "      <td>2.771659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137060</td>\n",
       "      <td>-0.188670</td>\n",
       "      <td>-0.160220</td>\n",
       "      <td>-0.152680</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.142780</td>\n",
       "      <td>0.349660</td>\n",
       "      <td>-0.046245</td>\n",
       "      <td>-0.133690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922012</td>\n",
       "      <td>-0.197890</td>\n",
       "      <td>1.585873</td>\n",
       "      <td>-0.056353</td>\n",
       "      <td>0.806093</td>\n",
       "      <td>-1.517281</td>\n",
       "      <td>1.672678</td>\n",
       "      <td>-0.376343</td>\n",
       "      <td>-0.061299</td>\n",
       "      <td>-0.945018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.366770</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>-0.085309</td>\n",
       "      <td>-0.295600</td>\n",
       "      <td>0.311750</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200334</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>1.149330</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.729352</td>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.210830</td>\n",
       "      <td>0.423430</td>\n",
       "      <td>0.263870</td>\n",
       "      <td>0.298310</td>\n",
       "      <td>-0.088201</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266496</td>\n",
       "      <td>-1.527078</td>\n",
       "      <td>-1.028776</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>-0.938700</td>\n",
       "      <td>0.215549</td>\n",
       "      <td>-0.575946</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.619411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>-0.313110</td>\n",
       "      <td>-0.702080</td>\n",
       "      <td>-0.626550</td>\n",
       "      <td>-0.490060</td>\n",
       "      <td>-0.432500</td>\n",
       "      <td>-0.538550</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>0.198530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969872</td>\n",
       "      <td>0.470231</td>\n",
       "      <td>-0.319118</td>\n",
       "      <td>-0.160328</td>\n",
       "      <td>0.632695</td>\n",
       "      <td>-1.015545</td>\n",
       "      <td>-0.633930</td>\n",
       "      <td>0.683149</td>\n",
       "      <td>0.720507</td>\n",
       "      <td>1.369418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.189330</td>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.312910</td>\n",
       "      <td>0.245270</td>\n",
       "      <td>-0.226630</td>\n",
       "      <td>-0.130830</td>\n",
       "      <td>0.077108</td>\n",
       "      <td>-0.046652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.774058</td>\n",
       "      <td>1.739382</td>\n",
       "      <td>-1.845892</td>\n",
       "      <td>-1.522856</td>\n",
       "      <td>-1.344479</td>\n",
       "      <td>0.008769</td>\n",
       "      <td>0.898490</td>\n",
       "      <td>-0.164422</td>\n",
       "      <td>-0.050235</td>\n",
       "      <td>1.367143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>0.314770</td>\n",
       "      <td>0.295030</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.274070</td>\n",
       "      <td>0.396880</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.127860</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.126330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626300</td>\n",
       "      <td>-0.241099</td>\n",
       "      <td>-0.354035</td>\n",
       "      <td>-0.405403</td>\n",
       "      <td>-0.544734</td>\n",
       "      <td>-0.164949</td>\n",
       "      <td>0.659083</td>\n",
       "      <td>-0.868930</td>\n",
       "      <td>-0.530455</td>\n",
       "      <td>-0.722450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.128630</td>\n",
       "      <td>-0.290760</td>\n",
       "      <td>-0.505190</td>\n",
       "      <td>-0.554770</td>\n",
       "      <td>-0.275930</td>\n",
       "      <td>-0.026265</td>\n",
       "      <td>-0.418280</td>\n",
       "      <td>-0.527620</td>\n",
       "      <td>-0.381970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623423</td>\n",
       "      <td>0.509388</td>\n",
       "      <td>0.728753</td>\n",
       "      <td>-0.151419</td>\n",
       "      <td>1.698903</td>\n",
       "      <td>0.460504</td>\n",
       "      <td>-0.599519</td>\n",
       "      <td>1.229305</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.043127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "83      1  0.435160  0.225050  0.057172 -0.353480  0.447420  0.183180   \n",
       "40      0  0.468280  0.108890  0.072178  0.002432  0.266450  0.350770   \n",
       "60      0  0.137060 -0.188670 -0.160220 -0.152680  0.143570  0.142780   \n",
       "45      1 -0.174850 -0.119840 -0.366770 -0.354050  0.065508 -0.085309   \n",
       "73      1 -0.020630  0.250100  0.210830  0.423430  0.263870  0.298310   \n",
       "34      0  0.037074 -0.313110 -0.702080 -0.626550 -0.490060 -0.432500   \n",
       "20      0  0.328300  0.189330  0.027821  0.312910  0.245270 -0.226630   \n",
       "10      1  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "70      0  0.314770  0.295030  0.002139  0.274070  0.396880  0.078688   \n",
       "12      1 -0.128630 -0.290760 -0.505190 -0.554770 -0.275930 -0.026265   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "83  0.122420  0.024561  0.404830  ...   0.314668  -0.114078  -0.476524   \n",
       "40 -0.210100 -0.089635 -0.140530  ...   1.200450   1.817908  -0.299583   \n",
       "60  0.349660 -0.046245 -0.133690  ...  -0.922012  -0.197890   1.585873   \n",
       "45 -0.295600  0.311750 -0.013669  ...   1.200334   0.313340   0.287729   \n",
       "73 -0.088201  0.081132 -0.025001  ...  -0.266496  -1.527078  -1.028776   \n",
       "34 -0.538550  0.023721  0.198530  ...   0.969872   0.470231  -0.319118   \n",
       "20 -0.130830  0.077108 -0.046652  ...  -0.774058   1.739382  -1.845892   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "70  0.127860  0.011281  0.126330  ...  -0.626300  -0.241099  -0.354035   \n",
       "12 -0.418280 -0.527620 -0.381970  ...   0.623423   0.509388   0.728753   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "83  -0.556896   0.505738   0.873278   0.040048   0.211690   0.536933   \n",
       "40   0.740836   1.491966   0.993555  -0.043188   0.564047  -0.916360   \n",
       "60  -0.056353   0.806093  -1.517281   1.672678  -0.376343  -0.061299   \n",
       "45  -0.370420   0.224179   1.149330   1.842975   1.458239   0.729352   \n",
       "73   0.437655  -0.938700   0.215549  -0.575946   0.804762   1.351451   \n",
       "34  -0.160328   0.632695  -1.015545  -0.633930   0.683149   0.720507   \n",
       "20  -1.522856  -1.344479   0.008769   0.898490  -0.164422  -0.050235   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "70  -0.405403  -0.544734  -0.164949   0.659083  -0.868930  -0.530455   \n",
       "12  -0.151419   1.698903   0.460504  -0.599519   1.229305   0.998584   \n",
       "\n",
       "    SBM_map75  \n",
       "83  -0.424864  \n",
       "40   2.771659  \n",
       "60  -0.945018  \n",
       "45   0.522059  \n",
       "73   0.619411  \n",
       "34   1.369418  \n",
       "20   1.367143  \n",
       "10   1.003364  \n",
       "70  -0.722450  \n",
       "12   0.043127  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((labels, features), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea0b5c",
   "metadata": {},
   "source": [
    "# Random noise\n",
    "\n",
    "**Precisión de un modelo de Random Forest sobre el conjunto original de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447b1eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 750}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "no_data_aug = train_GridSearchCV(model_RF, param_grid_RF, X_train, X_test, y_train, y_test)\n",
    "top_acc = top_acc_GridSearchCV(no_data_aug[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(no_data_aug, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2139dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "no_data_aug_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=750, random_state=0)  \n",
    "no_data_aug_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_no_data_aug = no_data_aug_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_no_data_aug = accuracy_score(y_test, y_pred_no_data_aug)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_no_data_aug * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010d2b1",
   "metadata": {},
   "source": [
    "### Ruido gaussiano\n",
    "\n",
    "Una primera prueba de introducción de ruido artificial se basará en añadir a los datos originales, valores (ruido) que se tomarán de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de valores para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c268e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del intervalo)\n",
    "max_per_var = features_tot.max(axis=0)\n",
    "min_per_var = features_tot.min(axis=0)\n",
    "std_per_var = (max_per_var - min_per_var) * 0.1\n",
    "std_per_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304cc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232200</td>\n",
       "      <td>-0.042566</td>\n",
       "      <td>-0.791727</td>\n",
       "      <td>-0.772790</td>\n",
       "      <td>-0.346480</td>\n",
       "      <td>-0.117090</td>\n",
       "      <td>-0.509645</td>\n",
       "      <td>-0.336619</td>\n",
       "      <td>0.797302</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.222112</td>\n",
       "      <td>-1.402231</td>\n",
       "      <td>1.920834</td>\n",
       "      <td>1.026937</td>\n",
       "      <td>-1.144009</td>\n",
       "      <td>-2.123258</td>\n",
       "      <td>-1.525115</td>\n",
       "      <td>-1.448959</td>\n",
       "      <td>-2.371252</td>\n",
       "      <td>-0.894455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>-0.303637</td>\n",
       "      <td>-0.227025</td>\n",
       "      <td>-0.235851</td>\n",
       "      <td>0.187904</td>\n",
       "      <td>-0.334999</td>\n",
       "      <td>0.293302</td>\n",
       "      <td>0.586997</td>\n",
       "      <td>0.407761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001576</td>\n",
       "      <td>0.855035</td>\n",
       "      <td>0.711041</td>\n",
       "      <td>-0.935583</td>\n",
       "      <td>0.473294</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>-0.780473</td>\n",
       "      <td>-0.661480</td>\n",
       "      <td>2.054732</td>\n",
       "      <td>0.556554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.603918</td>\n",
       "      <td>-0.138133</td>\n",
       "      <td>-0.615962</td>\n",
       "      <td>-0.481932</td>\n",
       "      <td>-0.475437</td>\n",
       "      <td>-0.487702</td>\n",
       "      <td>-0.444205</td>\n",
       "      <td>-0.522006</td>\n",
       "      <td>-0.332678</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.920996</td>\n",
       "      <td>-1.332419</td>\n",
       "      <td>0.839660</td>\n",
       "      <td>0.103529</td>\n",
       "      <td>1.004458</td>\n",
       "      <td>-3.103754</td>\n",
       "      <td>1.742597</td>\n",
       "      <td>-1.272035</td>\n",
       "      <td>-0.018540</td>\n",
       "      <td>1.237611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119350</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.300453</td>\n",
       "      <td>0.223938</td>\n",
       "      <td>-0.018287</td>\n",
       "      <td>0.282171</td>\n",
       "      <td>0.039545</td>\n",
       "      <td>-0.361698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991947</td>\n",
       "      <td>-2.944841</td>\n",
       "      <td>1.107726</td>\n",
       "      <td>2.932836</td>\n",
       "      <td>1.460491</td>\n",
       "      <td>0.621709</td>\n",
       "      <td>-2.899831</td>\n",
       "      <td>-0.278128</td>\n",
       "      <td>-1.450732</td>\n",
       "      <td>-2.987256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318331</td>\n",
       "      <td>0.094148</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>-0.388997</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>-0.188975</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.799038</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370051</td>\n",
       "      <td>-1.407210</td>\n",
       "      <td>0.437209</td>\n",
       "      <td>0.150966</td>\n",
       "      <td>0.458162</td>\n",
       "      <td>0.662532</td>\n",
       "      <td>-1.468774</td>\n",
       "      <td>-0.648076</td>\n",
       "      <td>-1.144024</td>\n",
       "      <td>-0.057911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.050827</td>\n",
       "      <td>-0.481793</td>\n",
       "      <td>-0.077876</td>\n",
       "      <td>-0.149324</td>\n",
       "      <td>-0.301414</td>\n",
       "      <td>-0.158155</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>-0.092545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.305155</td>\n",
       "      <td>0.150132</td>\n",
       "      <td>0.607371</td>\n",
       "      <td>-0.224237</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>1.897722</td>\n",
       "      <td>0.304188</td>\n",
       "      <td>-0.171216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.232200 -0.042566 -0.791727 -0.772790 -0.346480 -0.117090   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.262460 -0.303637 -0.227025 -0.235851  0.187904 -0.334999   \n",
       "14    0.0 -0.603918 -0.138133 -0.615962 -0.481932 -0.475437 -0.487702   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.119350  0.115388  0.071737  0.300453  0.223938 -0.018287   \n",
       "18    0.0  0.318331  0.094148  0.007068 -0.388997  0.378600 -0.188975   \n",
       "3     1.0 -0.013986 -0.050827 -0.481793 -0.077876 -0.149324 -0.301414   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.509645 -0.336619  0.797302  ...  -3.222112  -1.402231   1.920834   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39  0.293302  0.586997  0.407761  ...   1.001576   0.855035   0.711041   \n",
       "14 -0.444205 -0.522006 -0.332678  ...  -1.920996  -1.332419   0.839660   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.282171  0.039545 -0.361698  ...   0.991947  -2.944841   1.107726   \n",
       "18  0.168999  0.799038  0.101366  ...   1.370051  -1.407210   0.437209   \n",
       "3  -0.158155  0.343952 -0.092545  ...   1.305155   0.150132   0.607371   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60   1.026937  -1.144009  -2.123258  -1.525115  -1.448959  -2.371252   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39  -0.935583   0.473294   0.998934  -0.780473  -0.661480   2.054732   \n",
       "14   0.103529   1.004458  -3.103754   1.742597  -1.272035  -0.018540   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   2.932836   1.460491   0.621709  -2.899831  -0.278128  -1.450732   \n",
       "18   0.150966   0.458162   0.662532  -1.468774  -0.648076  -1.144024   \n",
       "3   -0.224237   0.018921   0.976853   1.183815   1.897722   0.304188   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -0.894455  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.556554  \n",
       "14   1.237611  \n",
       "10   1.003364  \n",
       "69  -2.987256  \n",
       "18  -0.057911  \n",
       "3   -0.171216  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% del rango de la variable\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_gaussian[i, :] = generate_noisy_sample_gaussian(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian = np.c_[labels, noisy_features_gaussian]\n",
    "\n",
    "noisy_data_gaussian = pd.concat([data, pd.DataFrame(noisy_features_gaussian, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian = noisy_data_gaussian.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian.shape))\n",
    "noisy_data_gaussian.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9dee9",
   "metadata": {},
   "source": [
    "Precisión del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726e40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_gaussian, X_test_gaussian, y_train_gaussian, y_test_gaussian) = data_partition(noisy_data_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901beed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 250}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_gaussian = train_GridSearchCV(model_RF, param_grid_RF, X_train_gaussian, X_test_gaussian, \n",
    "                                       y_train_gaussian, y_test_gaussian)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_gaussian[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_gaussian, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430961ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_gaussian_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=5, n_estimators=250, random_state=0)  \n",
    "data_aug_gaussian_opt.fit(X_train_gaussian, y_train_gaussian)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_gaussian = data_aug_gaussian_opt.predict(X_test_gaussian)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_gaussian = accuracy_score(y_test_gaussian, y_pred_data_aug_gaussian)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_gaussian * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e989c1",
   "metadata": {},
   "source": [
    "Vamos a modificar ahora el método, de modo que los valores generados de ruido se tomen de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de la diferencia entre la media de las variables para pacientes con esquizofrenia y la media de las variables de los individuos de control.\n",
    "\n",
    "La motivación para introducir esta modificación es que podría ser que las distribuciones que definen cada variable sean diferentes cuando se considera a un individuo sano (etiqueta 0) y a un individuo enfermo (etiqueta 1). Si estas distribuciones están lo suficientemente cercanas, introducir un ruido aparentemente pequeño podría modificar una muestra originalmente correspondiente a una clase y generar otra de manera artificial con la misma etiqueta pero que se solapa con la distribución de la etiqueta opuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = data[data[\"Class\"] == 0]\n",
    "sick = data[data[\"Class\"] == 0]\n",
    "\n",
    "labels_control = control_group.iloc[:, 0]\n",
    "features_control = np.array(control_group.iloc[:, 1:])\n",
    "labels_sick = sick.iloc[:, 0]\n",
    "features_sick = np.array(sick.iloc[:, 1:])\n",
    "\n",
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del rango de la diferencia)\n",
    "avg_per_var_control = features_control.mean(axis=0)\n",
    "avg_per_var_sick = features_sick.mean(axis=0)\n",
    "std_per_var = abs((avg_per_var_control - avg_per_var_sick)) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330f58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.343140</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>-0.547010</td>\n",
       "      <td>-0.652910</td>\n",
       "      <td>-0.226870</td>\n",
       "      <td>-0.354650</td>\n",
       "      <td>-0.630850</td>\n",
       "      <td>-0.189460</td>\n",
       "      <td>0.704020</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.424498</td>\n",
       "      <td>-1.512935</td>\n",
       "      <td>1.480432</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-1.151279</td>\n",
       "      <td>-2.123389</td>\n",
       "      <td>-0.962200</td>\n",
       "      <td>-0.524886</td>\n",
       "      <td>-2.310918</td>\n",
       "      <td>-1.740839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>-0.196510</td>\n",
       "      <td>-0.245280</td>\n",
       "      <td>-0.083840</td>\n",
       "      <td>0.304210</td>\n",
       "      <td>-0.180270</td>\n",
       "      <td>-0.008647</td>\n",
       "      <td>0.384610</td>\n",
       "      <td>0.300520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>1.135537</td>\n",
       "      <td>-0.256829</td>\n",
       "      <td>0.222902</td>\n",
       "      <td>0.528734</td>\n",
       "      <td>1.098908</td>\n",
       "      <td>-1.239779</td>\n",
       "      <td>-0.421480</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>0.325227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.391350</td>\n",
       "      <td>-0.284360</td>\n",
       "      <td>-0.655090</td>\n",
       "      <td>-0.645960</td>\n",
       "      <td>-0.241020</td>\n",
       "      <td>-0.352420</td>\n",
       "      <td>-0.480940</td>\n",
       "      <td>-0.393730</td>\n",
       "      <td>-0.277160</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.180108</td>\n",
       "      <td>-0.404150</td>\n",
       "      <td>0.358206</td>\n",
       "      <td>0.285097</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>-3.015051</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>-1.158544</td>\n",
       "      <td>-0.694036</td>\n",
       "      <td>-0.540947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.319650</td>\n",
       "      <td>0.099134</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.120010</td>\n",
       "      <td>0.088958</td>\n",
       "      <td>0.171350</td>\n",
       "      <td>-0.117730</td>\n",
       "      <td>-0.263870</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240290</td>\n",
       "      <td>-2.316457</td>\n",
       "      <td>0.115988</td>\n",
       "      <td>1.992077</td>\n",
       "      <td>1.094181</td>\n",
       "      <td>0.362267</td>\n",
       "      <td>-1.395818</td>\n",
       "      <td>-0.647623</td>\n",
       "      <td>-0.699748</td>\n",
       "      <td>-2.677100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263490</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>-0.367170</td>\n",
       "      <td>0.300860</td>\n",
       "      <td>-0.016165</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.370830</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781677</td>\n",
       "      <td>-0.535058</td>\n",
       "      <td>0.034981</td>\n",
       "      <td>-0.853332</td>\n",
       "      <td>0.965745</td>\n",
       "      <td>1.067908</td>\n",
       "      <td>-0.563230</td>\n",
       "      <td>-1.104692</td>\n",
       "      <td>-1.118982</td>\n",
       "      <td>-0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.366770</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>-0.085309</td>\n",
       "      <td>-0.295600</td>\n",
       "      <td>0.311750</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200334</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>1.149330</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.729352</td>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.343140  0.020893 -0.547010 -0.652910 -0.226870 -0.354650   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.026362 -0.196510 -0.245280 -0.083840  0.304210 -0.180270   \n",
       "14    0.0 -0.391350 -0.284360 -0.655090 -0.645960 -0.241020 -0.352420   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.319650  0.099134  0.010361  0.004176  0.120010  0.088958   \n",
       "18    0.0  0.263490  0.022323  0.043017 -0.367170  0.300860 -0.016165   \n",
       "3     1.0 -0.174850 -0.119840 -0.366770 -0.354050  0.065508 -0.085309   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.630850 -0.189460  0.704020  ...  -3.424498  -1.512935   1.480432   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39 -0.008647  0.384610  0.300520  ...   0.464108   1.135537  -0.256829   \n",
       "14 -0.480940 -0.393730 -0.277160  ...  -2.180108  -0.404150   0.358206   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.171350 -0.117730 -0.263870  ...   1.240290  -2.316457   0.115988   \n",
       "18  0.100220  0.370830  0.123080  ...   0.781677  -0.535058   0.034981   \n",
       "3  -0.295600  0.311750 -0.013669  ...   1.200334   0.313340   0.287729   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60  -0.012000  -1.151279  -2.123389  -0.962200  -0.524886  -2.310918   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39   0.222902   0.528734   1.098908  -1.239779  -0.421480   1.130700   \n",
       "14   0.285097   0.955665  -3.015051   0.024974  -1.158544  -0.694036   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   1.992077   1.094181   0.362267  -1.395818  -0.647623  -0.699748   \n",
       "18  -0.853332   0.965745   1.067908  -0.563230  -1.104692  -1.118982   \n",
       "3   -0.370420   0.224179   1.149330   1.842975   1.458239   0.729352   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -1.740839  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.325227  \n",
       "14  -0.540947  \n",
       "10   1.003364  \n",
       "69  -2.677100  \n",
       "18  -0.037143  \n",
       "3    0.522059  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian2(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% de la diferencia entre la media de la variable para cada clase\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian_2 = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_gaussian_2[i, :] = generate_noisy_sample_gaussian2(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian_2 = np.c_[labels, noisy_features_gaussian_2]\n",
    "\n",
    "noisy_data_gaussian_2 = pd.concat([data, pd.DataFrame(noisy_features_gaussian_2, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian_2 = noisy_data_gaussian_2.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian_2.shape))\n",
    "noisy_data_gaussian_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f12f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_gaussian2, X_test_gaussian2, y_train_gaussian2, y_test_gaussian2) = data_partition(noisy_data_gaussian_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f11370e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 500}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_gaussian2 = train_GridSearchCV(model_RF, param_grid_RF, X_train_gaussian2, X_test_gaussian2, \n",
    "                                        y_train_gaussian2, y_test_gaussian2)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_gaussian2[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_gaussian2, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755ba791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.57%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_gaussian_opt2 = RandomForestClassifier(criterion=\"gini\", max_depth=20, n_estimators=500, random_state=0)  \n",
    "data_aug_gaussian_opt2.fit(X_train_gaussian2, y_train_gaussian2)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_gaussian2 = data_aug_gaussian_opt2.predict(X_test_gaussian2)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_gaussian2 = accuracy_score(y_test_gaussian2, y_pred_data_aug_gaussian2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_gaussian2 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8603",
   "metadata": {},
   "source": [
    "### Ruido uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "724ab306",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_var = features_tot.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a75640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0.143325</td>\n",
       "      <td>-0.607460</td>\n",
       "      <td>-0.668581</td>\n",
       "      <td>-0.043226</td>\n",
       "      <td>-0.299202</td>\n",
       "      <td>-0.731040</td>\n",
       "      <td>-0.240142</td>\n",
       "      <td>0.768622</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.499343</td>\n",
       "      <td>-1.440684</td>\n",
       "      <td>1.418062</td>\n",
       "      <td>-0.112408</td>\n",
       "      <td>-1.172020</td>\n",
       "      <td>-1.980269</td>\n",
       "      <td>-0.910399</td>\n",
       "      <td>-0.415231</td>\n",
       "      <td>-2.311371</td>\n",
       "      <td>-1.608504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249280</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>-0.305730</td>\n",
       "      <td>-0.099511</td>\n",
       "      <td>0.487854</td>\n",
       "      <td>-0.124822</td>\n",
       "      <td>-0.108838</td>\n",
       "      <td>0.333928</td>\n",
       "      <td>0.365122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389263</td>\n",
       "      <td>1.207788</td>\n",
       "      <td>-0.319200</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.507993</td>\n",
       "      <td>1.242028</td>\n",
       "      <td>-1.187978</td>\n",
       "      <td>-0.311825</td>\n",
       "      <td>1.130247</td>\n",
       "      <td>0.457562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168432</td>\n",
       "      <td>-0.161928</td>\n",
       "      <td>-0.715540</td>\n",
       "      <td>-0.661631</td>\n",
       "      <td>-0.057376</td>\n",
       "      <td>-0.296972</td>\n",
       "      <td>-0.581130</td>\n",
       "      <td>-0.444412</td>\n",
       "      <td>-0.212558</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.254953</td>\n",
       "      <td>-0.331899</td>\n",
       "      <td>0.295836</td>\n",
       "      <td>0.184689</td>\n",
       "      <td>0.934924</td>\n",
       "      <td>-2.871931</td>\n",
       "      <td>0.076776</td>\n",
       "      <td>-1.048889</td>\n",
       "      <td>-0.694488</td>\n",
       "      <td>-0.408612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542568</td>\n",
       "      <td>0.221566</td>\n",
       "      <td>-0.050089</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.303654</td>\n",
       "      <td>0.144406</td>\n",
       "      <td>0.071160</td>\n",
       "      <td>-0.168412</td>\n",
       "      <td>-0.199268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165445</td>\n",
       "      <td>-2.244207</td>\n",
       "      <td>0.053618</td>\n",
       "      <td>1.891669</td>\n",
       "      <td>1.073441</td>\n",
       "      <td>0.505387</td>\n",
       "      <td>-1.344017</td>\n",
       "      <td>-0.537968</td>\n",
       "      <td>-0.700200</td>\n",
       "      <td>-2.544765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486408</td>\n",
       "      <td>0.144755</td>\n",
       "      <td>-0.017433</td>\n",
       "      <td>-0.382841</td>\n",
       "      <td>0.484504</td>\n",
       "      <td>0.039283</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.320148</td>\n",
       "      <td>0.187682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706832</td>\n",
       "      <td>-0.462807</td>\n",
       "      <td>-0.027389</td>\n",
       "      <td>-0.953739</td>\n",
       "      <td>0.945004</td>\n",
       "      <td>1.211029</td>\n",
       "      <td>-0.511429</td>\n",
       "      <td>-0.995037</td>\n",
       "      <td>-1.119434</td>\n",
       "      <td>0.095193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048068</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>-0.427220</td>\n",
       "      <td>-0.369721</td>\n",
       "      <td>0.249152</td>\n",
       "      <td>-0.029861</td>\n",
       "      <td>-0.395790</td>\n",
       "      <td>0.261068</td>\n",
       "      <td>0.050933</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125489</td>\n",
       "      <td>0.385591</td>\n",
       "      <td>0.225359</td>\n",
       "      <td>-0.470828</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>1.292451</td>\n",
       "      <td>1.894776</td>\n",
       "      <td>1.567895</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.654394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.120222  0.143325 -0.607460 -0.668581 -0.043226 -0.299202   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.249280 -0.074078 -0.305730 -0.099511  0.487854 -0.124822   \n",
       "14    0.0 -0.168432 -0.161928 -0.715540 -0.661631 -0.057376 -0.296972   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.542568  0.221566 -0.050089 -0.011495  0.303654  0.144406   \n",
       "18    0.0  0.486408  0.144755 -0.017433 -0.382841  0.484504  0.039283   \n",
       "3     1.0  0.048068  0.002592 -0.427220 -0.369721  0.249152 -0.029861   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.731040 -0.240142  0.768622  ...  -3.499343  -1.440684   1.418062   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39 -0.108838  0.333928  0.365122  ...   0.389263   1.207788  -0.319200   \n",
       "14 -0.581130 -0.444412 -0.212558  ...  -2.254953  -0.331899   0.295836   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.071160 -0.168412 -0.199268  ...   1.165445  -2.244207   0.053618   \n",
       "18  0.000030  0.320148  0.187682  ...   0.706832  -0.462807  -0.027389   \n",
       "3  -0.395790  0.261068  0.050933  ...   1.125489   0.385591   0.225359   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60  -0.112408  -1.172020  -1.980269  -0.910399  -0.415231  -2.311371   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39   0.122495   0.507993   1.242028  -1.187978  -0.311825   1.130247   \n",
       "14   0.184689   0.934924  -2.871931   0.076776  -1.048889  -0.694488   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   1.891669   1.073441   0.505387  -1.344017  -0.537968  -0.700200   \n",
       "18  -0.953739   0.945004   1.211029  -0.511429  -0.995037  -1.119434   \n",
       "3   -0.470828   0.203439   1.292451   1.894776   1.567895   0.728900   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -1.608504  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.457562  \n",
       "14  -0.408612  \n",
       "10   1.003364  \n",
       "69  -2.544765  \n",
       "18   0.095193  \n",
       "3    0.654394  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_uniform(original_sample, data=data, std_per_var=std_per_var, avg_per_var=avg_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución uniforme\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.uniform(avg_per_var[j]-std_per_var[j], avg_per_var[j]+std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_uniform = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_uniform[i, :] = generate_noisy_sample_uniform(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_uniform = np.c_[labels, noisy_features_uniform]\n",
    "\n",
    "noisy_data_uniform = pd.concat([data, pd.DataFrame(noisy_features_uniform, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_uniform = noisy_data_uniform.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_uniform.shape))\n",
    "noisy_data_uniform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31db9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_uniform, X_test_uniform, y_train_uniform, y_test_uniform) = data_partition(noisy_data_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7512601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 1000}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_uniform = train_GridSearchCV(model_RF, param_grid_RF, X_train_uniform, X_test_uniform, y_train_uniform, y_test_uniform)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_uniform[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_uniform, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46bb5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_uniform_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=1000, random_state=0)  \n",
    "data_aug_uniform_opt.fit(X_train_uniform, y_train_uniform)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_uniform = data_aug_uniform_opt.predict(X_test_uniform)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_uniform = accuracy_score(y_test_uniform, y_pred_data_aug_uniform)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_uniform * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe059ea4",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Otra posibilidad para hacer Data Augmentation es, dado que se dispone de un gran volumen de datos no etiquetados, obtener una estimación lo más acertada posible de las etiquetas a las que estarían asociados estos datos. En este caso, podríamos plantearnos repetir algún entrenamiento, esta vez sobre un conjunto de datos mucho mayor.\n",
    "\n",
    "El modelo en base al cual vamos a generar estas predicciones va a ser el encoder ya visto anteriormente. Ya que como se ha explicado, se genera a partir de una red autoencoder que ha entrenado sobre el conjunto de datos completo que queremos etiquetar aquí y posteriormente ha adaptado sus pesos en la parte encoder al problema de clasificación que nos interesa aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8409ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e38bb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.load_model(\"Modelos/encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f094f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 410)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "args = np.random.choice(a=np.arange(0, test_kaggle.shape[0]), size=10000, replace=False)\n",
    "test_kaggle_reduc = test_kaggle.iloc[args, :]\n",
    "\n",
    "test_kaggle_reduc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "922cfa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_kaggle_reduc = encoder.predict(test_kaggle_reduc)\n",
    "\n",
    "labels_tot = np.concatenate((np.reshape(y_train.to_numpy(), (68, 1)), y_test_kaggle_reduc), axis=0)\n",
    "labels_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a5e4f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 410)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tot = np.concatenate((X_train, test_kaggle_reduc))\n",
    "features_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2052d",
   "metadata": {},
   "source": [
    "Vamos a repetir el entrenamiento con una de las configuraciones de Random Forest que ha alcanzado los mejores resultados.\n",
    "\n",
    "Accuracy en ``y_test`` sin aumentar el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c221fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "no_data_aug_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "no_data_aug_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_no_data_aug = no_data_aug_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_no_data_aug2 = accuracy_score(y_test, y_pred_no_data_aug)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_no_data_aug2 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fc4ca",
   "metadata": {},
   "source": [
    "Accuracy en ``y_test`` aumentando el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "277f1abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "rf_encoder1 = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "rf_encoder1.fit(features_tot, np.around(labels_tot, decimals=0).ravel())\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_encoder1 = rf_encoder1.predict(X_test.to_numpy())\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_encoder1 = accuracy_score(y_test, y_pred_encoder1)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_encoder1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd2943",
   "metadata": {},
   "source": [
    "**Prueba con el segundo autoencoder entrenado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebef0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder3 = models.load_model(\"Modelos/encoder3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1fe3141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_kaggle_reduc = encoder3.predict(test_kaggle_reduc)\n",
    "\n",
    "labels_tot = np.concatenate((np.reshape(y_train.to_numpy(), (68, 1)), y_test_kaggle_reduc), axis=0)\n",
    "labels_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cf63b",
   "metadata": {},
   "source": [
    "Accuracy en ``y_test`` aumentando el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82e4e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "rf_encoder3 = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "rf_encoder3.fit(features_tot, np.around(labels_tot, decimals=0).ravel())\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_encoder3 = rf_encoder3.predict(X_test.to_numpy())\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_encoder3 = accuracy_score(y_test, y_pred_encoder3)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_encoder3 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea7227",
   "metadata": {},
   "source": [
    "# Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "198c17e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_acc = [acc_no_data_aug, acc_data_aug_gaussian, acc_data_aug_gaussian2, acc_data_aug_uniform]\n",
    "xaxis = [\"Random Forest en \\n conjunto original\", \"Random Forest en \\n conjunto aumentado con ruido gaussiano \\n Forma I\", \n",
    "         \"Random Forest en \\n conjunto aumentado con ruido gaussiano \\n Forma II\", \n",
    "         \"Random Forest en \\n conjunto aumentado con ruido uniforme\"]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "barlist = plt.bar(xaxis, results_acc, width=0.2)\n",
    "barlist[0].set_color(\"r\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(bottom=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "154d03d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_acc = [acc_data_aug_gaussian, acc_data_aug_gaussian2, acc_data_aug_uniform]\n",
    "original_acc = [acc_no_data_aug]*3\n",
    "xaxis = [\"Ruido gaussiano I\", \"Ruido gaussiano II\", \"Ruido uniforme\"]\n",
    "x = np.arange(len(xaxis))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(x-0.1, results_acc, width=0.2, label=\"Accuracy tras Data Augmentation\")\n",
    "plt.bar(x+0.1, original_acc, width=0.2,  label=\"Accuracy sin Data Augmentation\")\n",
    "plt.xticks(range(0, len(xaxis)), xaxis, rotation=0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
