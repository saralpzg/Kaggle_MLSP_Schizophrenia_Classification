{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70addaeb",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Uno de los principales obstáculos que se encuentran al intentar hallar la major solución al problema de clasificación, es la escasez de datos para el entrenamiento de los modelos.\n",
    "\n",
    "Este notebook tiene como objetivo implementar y comparar los resultados obtenidos implementando técnicas de Data Augmentation para crear datos sintéticos y poder operar sobre un mayor volumen de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989e8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Cargar los datos\n",
    "from Modelos.data_and_submissions import *\n",
    "# Métodos para los entrenamientos con CV\n",
    "from Modelos.train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72411cba",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3c3352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data(True)\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d83db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_partition(data_augmented):\n",
    "    X = data_augmented.iloc[:, 1:]\n",
    "    Y = data_augmented.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bba535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119834, 410)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.concat((y_train, y_test), axis=0)\n",
    "features = pd.concat((X_train, X_test), axis=0)\n",
    "features_tot = pd.concat((features, test_kaggle), axis=0)\n",
    "print(features_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90d87f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>0.435160</td>\n",
       "      <td>0.225050</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>-0.353480</td>\n",
       "      <td>0.447420</td>\n",
       "      <td>0.183180</td>\n",
       "      <td>0.122420</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.404830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314668</td>\n",
       "      <td>-0.114078</td>\n",
       "      <td>-0.476524</td>\n",
       "      <td>-0.556896</td>\n",
       "      <td>0.505738</td>\n",
       "      <td>0.873278</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.211690</td>\n",
       "      <td>0.536933</td>\n",
       "      <td>-0.424864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0.468280</td>\n",
       "      <td>0.108890</td>\n",
       "      <td>0.072178</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.266450</td>\n",
       "      <td>0.350770</td>\n",
       "      <td>-0.210100</td>\n",
       "      <td>-0.089635</td>\n",
       "      <td>-0.140530</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200450</td>\n",
       "      <td>1.817908</td>\n",
       "      <td>-0.299583</td>\n",
       "      <td>0.740836</td>\n",
       "      <td>1.491966</td>\n",
       "      <td>0.993555</td>\n",
       "      <td>-0.043188</td>\n",
       "      <td>0.564047</td>\n",
       "      <td>-0.916360</td>\n",
       "      <td>2.771659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137060</td>\n",
       "      <td>-0.188670</td>\n",
       "      <td>-0.160220</td>\n",
       "      <td>-0.152680</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.142780</td>\n",
       "      <td>0.349660</td>\n",
       "      <td>-0.046245</td>\n",
       "      <td>-0.133690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922012</td>\n",
       "      <td>-0.197890</td>\n",
       "      <td>1.585873</td>\n",
       "      <td>-0.056353</td>\n",
       "      <td>0.806093</td>\n",
       "      <td>-1.517281</td>\n",
       "      <td>1.672678</td>\n",
       "      <td>-0.376343</td>\n",
       "      <td>-0.061299</td>\n",
       "      <td>-0.945018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.366770</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>-0.085309</td>\n",
       "      <td>-0.295600</td>\n",
       "      <td>0.311750</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200334</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>1.149330</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.729352</td>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.210830</td>\n",
       "      <td>0.423430</td>\n",
       "      <td>0.263870</td>\n",
       "      <td>0.298310</td>\n",
       "      <td>-0.088201</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266496</td>\n",
       "      <td>-1.527078</td>\n",
       "      <td>-1.028776</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>-0.938700</td>\n",
       "      <td>0.215549</td>\n",
       "      <td>-0.575946</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.619411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>-0.313110</td>\n",
       "      <td>-0.702080</td>\n",
       "      <td>-0.626550</td>\n",
       "      <td>-0.490060</td>\n",
       "      <td>-0.432500</td>\n",
       "      <td>-0.538550</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>0.198530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969872</td>\n",
       "      <td>0.470231</td>\n",
       "      <td>-0.319118</td>\n",
       "      <td>-0.160328</td>\n",
       "      <td>0.632695</td>\n",
       "      <td>-1.015545</td>\n",
       "      <td>-0.633930</td>\n",
       "      <td>0.683149</td>\n",
       "      <td>0.720507</td>\n",
       "      <td>1.369418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.189330</td>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.312910</td>\n",
       "      <td>0.245270</td>\n",
       "      <td>-0.226630</td>\n",
       "      <td>-0.130830</td>\n",
       "      <td>0.077108</td>\n",
       "      <td>-0.046652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.774058</td>\n",
       "      <td>1.739382</td>\n",
       "      <td>-1.845892</td>\n",
       "      <td>-1.522856</td>\n",
       "      <td>-1.344479</td>\n",
       "      <td>0.008769</td>\n",
       "      <td>0.898490</td>\n",
       "      <td>-0.164422</td>\n",
       "      <td>-0.050235</td>\n",
       "      <td>1.367143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>0.314770</td>\n",
       "      <td>0.295030</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.274070</td>\n",
       "      <td>0.396880</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.127860</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.126330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626300</td>\n",
       "      <td>-0.241099</td>\n",
       "      <td>-0.354035</td>\n",
       "      <td>-0.405403</td>\n",
       "      <td>-0.544734</td>\n",
       "      <td>-0.164949</td>\n",
       "      <td>0.659083</td>\n",
       "      <td>-0.868930</td>\n",
       "      <td>-0.530455</td>\n",
       "      <td>-0.722450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.128630</td>\n",
       "      <td>-0.290760</td>\n",
       "      <td>-0.505190</td>\n",
       "      <td>-0.554770</td>\n",
       "      <td>-0.275930</td>\n",
       "      <td>-0.026265</td>\n",
       "      <td>-0.418280</td>\n",
       "      <td>-0.527620</td>\n",
       "      <td>-0.381970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623423</td>\n",
       "      <td>0.509388</td>\n",
       "      <td>0.728753</td>\n",
       "      <td>-0.151419</td>\n",
       "      <td>1.698903</td>\n",
       "      <td>0.460504</td>\n",
       "      <td>-0.599519</td>\n",
       "      <td>1.229305</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.043127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "83      1  0.435160  0.225050  0.057172 -0.353480  0.447420  0.183180   \n",
       "40      0  0.468280  0.108890  0.072178  0.002432  0.266450  0.350770   \n",
       "60      0  0.137060 -0.188670 -0.160220 -0.152680  0.143570  0.142780   \n",
       "45      1 -0.174850 -0.119840 -0.366770 -0.354050  0.065508 -0.085309   \n",
       "73      1 -0.020630  0.250100  0.210830  0.423430  0.263870  0.298310   \n",
       "34      0  0.037074 -0.313110 -0.702080 -0.626550 -0.490060 -0.432500   \n",
       "20      0  0.328300  0.189330  0.027821  0.312910  0.245270 -0.226630   \n",
       "10      1  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "70      0  0.314770  0.295030  0.002139  0.274070  0.396880  0.078688   \n",
       "12      1 -0.128630 -0.290760 -0.505190 -0.554770 -0.275930 -0.026265   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "83  0.122420  0.024561  0.404830  ...   0.314668  -0.114078  -0.476524   \n",
       "40 -0.210100 -0.089635 -0.140530  ...   1.200450   1.817908  -0.299583   \n",
       "60  0.349660 -0.046245 -0.133690  ...  -0.922012  -0.197890   1.585873   \n",
       "45 -0.295600  0.311750 -0.013669  ...   1.200334   0.313340   0.287729   \n",
       "73 -0.088201  0.081132 -0.025001  ...  -0.266496  -1.527078  -1.028776   \n",
       "34 -0.538550  0.023721  0.198530  ...   0.969872   0.470231  -0.319118   \n",
       "20 -0.130830  0.077108 -0.046652  ...  -0.774058   1.739382  -1.845892   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "70  0.127860  0.011281  0.126330  ...  -0.626300  -0.241099  -0.354035   \n",
       "12 -0.418280 -0.527620 -0.381970  ...   0.623423   0.509388   0.728753   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "83  -0.556896   0.505738   0.873278   0.040048   0.211690   0.536933   \n",
       "40   0.740836   1.491966   0.993555  -0.043188   0.564047  -0.916360   \n",
       "60  -0.056353   0.806093  -1.517281   1.672678  -0.376343  -0.061299   \n",
       "45  -0.370420   0.224179   1.149330   1.842975   1.458239   0.729352   \n",
       "73   0.437655  -0.938700   0.215549  -0.575946   0.804762   1.351451   \n",
       "34  -0.160328   0.632695  -1.015545  -0.633930   0.683149   0.720507   \n",
       "20  -1.522856  -1.344479   0.008769   0.898490  -0.164422  -0.050235   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "70  -0.405403  -0.544734  -0.164949   0.659083  -0.868930  -0.530455   \n",
       "12  -0.151419   1.698903   0.460504  -0.599519   1.229305   0.998584   \n",
       "\n",
       "    SBM_map75  \n",
       "83  -0.424864  \n",
       "40   2.771659  \n",
       "60  -0.945018  \n",
       "45   0.522059  \n",
       "73   0.619411  \n",
       "34   1.369418  \n",
       "20   1.367143  \n",
       "10   1.003364  \n",
       "70  -0.722450  \n",
       "12   0.043127  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((labels, features), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea0b5c",
   "metadata": {},
   "source": [
    "# Random noise\n",
    "\n",
    "**Precisión de un modelo de Random Forest sobre el conjunto original de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447b1eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 750}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "no_data_aug = train_GridSearchCV(model_RF, param_grid_RF, X_train, X_test, y_train, y_test)\n",
    "top_acc = top_acc_GridSearchCV(no_data_aug[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(no_data_aug, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2139dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "no_data_aug_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=750, random_state=0)  \n",
    "no_data_aug_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_no_data_aug = no_data_aug_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_no_data_aug = accuracy_score(y_test, y_pred_no_data_aug)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_no_data_aug * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f03cbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_no_data_aug = no_data_aug_opt.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_no_data_aug, \"RF_no_DataAugmentation\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010d2b1",
   "metadata": {},
   "source": [
    "### Ruido gaussiano\n",
    "\n",
    "Una primera prueba de introducción de ruido artificial se basará en añadir a los datos originales, valores (ruido) que se tomarán de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de valores para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c268e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del intervalo)\n",
    "max_per_var = features_tot.max(axis=0)\n",
    "min_per_var = features_tot.min(axis=0)\n",
    "std_per_var = (max_per_var - min_per_var) * 0.1\n",
    "std_per_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304cc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232200</td>\n",
       "      <td>-0.042566</td>\n",
       "      <td>-0.791727</td>\n",
       "      <td>-0.772790</td>\n",
       "      <td>-0.346480</td>\n",
       "      <td>-0.117090</td>\n",
       "      <td>-0.509645</td>\n",
       "      <td>-0.336619</td>\n",
       "      <td>0.797302</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.222112</td>\n",
       "      <td>-1.402231</td>\n",
       "      <td>1.920834</td>\n",
       "      <td>1.026937</td>\n",
       "      <td>-1.144009</td>\n",
       "      <td>-2.123258</td>\n",
       "      <td>-1.525115</td>\n",
       "      <td>-1.448959</td>\n",
       "      <td>-2.371252</td>\n",
       "      <td>-0.894455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>-0.303637</td>\n",
       "      <td>-0.227025</td>\n",
       "      <td>-0.235851</td>\n",
       "      <td>0.187904</td>\n",
       "      <td>-0.334999</td>\n",
       "      <td>0.293302</td>\n",
       "      <td>0.586997</td>\n",
       "      <td>0.407761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001576</td>\n",
       "      <td>0.855035</td>\n",
       "      <td>0.711041</td>\n",
       "      <td>-0.935583</td>\n",
       "      <td>0.473294</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>-0.780473</td>\n",
       "      <td>-0.661480</td>\n",
       "      <td>2.054732</td>\n",
       "      <td>0.556554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.603918</td>\n",
       "      <td>-0.138133</td>\n",
       "      <td>-0.615962</td>\n",
       "      <td>-0.481932</td>\n",
       "      <td>-0.475437</td>\n",
       "      <td>-0.487702</td>\n",
       "      <td>-0.444205</td>\n",
       "      <td>-0.522006</td>\n",
       "      <td>-0.332678</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.920996</td>\n",
       "      <td>-1.332419</td>\n",
       "      <td>0.839660</td>\n",
       "      <td>0.103529</td>\n",
       "      <td>1.004458</td>\n",
       "      <td>-3.103754</td>\n",
       "      <td>1.742597</td>\n",
       "      <td>-1.272035</td>\n",
       "      <td>-0.018540</td>\n",
       "      <td>1.237611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119350</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.300453</td>\n",
       "      <td>0.223938</td>\n",
       "      <td>-0.018287</td>\n",
       "      <td>0.282171</td>\n",
       "      <td>0.039545</td>\n",
       "      <td>-0.361698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991947</td>\n",
       "      <td>-2.944841</td>\n",
       "      <td>1.107726</td>\n",
       "      <td>2.932836</td>\n",
       "      <td>1.460491</td>\n",
       "      <td>0.621709</td>\n",
       "      <td>-2.899831</td>\n",
       "      <td>-0.278128</td>\n",
       "      <td>-1.450732</td>\n",
       "      <td>-2.987256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318331</td>\n",
       "      <td>0.094148</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>-0.388997</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>-0.188975</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.799038</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370051</td>\n",
       "      <td>-1.407210</td>\n",
       "      <td>0.437209</td>\n",
       "      <td>0.150966</td>\n",
       "      <td>0.458162</td>\n",
       "      <td>0.662532</td>\n",
       "      <td>-1.468774</td>\n",
       "      <td>-0.648076</td>\n",
       "      <td>-1.144024</td>\n",
       "      <td>-0.057911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.050827</td>\n",
       "      <td>-0.481793</td>\n",
       "      <td>-0.077876</td>\n",
       "      <td>-0.149324</td>\n",
       "      <td>-0.301414</td>\n",
       "      <td>-0.158155</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>-0.092545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.305155</td>\n",
       "      <td>0.150132</td>\n",
       "      <td>0.607371</td>\n",
       "      <td>-0.224237</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>1.897722</td>\n",
       "      <td>0.304188</td>\n",
       "      <td>-0.171216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.232200 -0.042566 -0.791727 -0.772790 -0.346480 -0.117090   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.262460 -0.303637 -0.227025 -0.235851  0.187904 -0.334999   \n",
       "14    0.0 -0.603918 -0.138133 -0.615962 -0.481932 -0.475437 -0.487702   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.119350  0.115388  0.071737  0.300453  0.223938 -0.018287   \n",
       "18    0.0  0.318331  0.094148  0.007068 -0.388997  0.378600 -0.188975   \n",
       "3     1.0 -0.013986 -0.050827 -0.481793 -0.077876 -0.149324 -0.301414   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.509645 -0.336619  0.797302  ...  -3.222112  -1.402231   1.920834   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39  0.293302  0.586997  0.407761  ...   1.001576   0.855035   0.711041   \n",
       "14 -0.444205 -0.522006 -0.332678  ...  -1.920996  -1.332419   0.839660   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.282171  0.039545 -0.361698  ...   0.991947  -2.944841   1.107726   \n",
       "18  0.168999  0.799038  0.101366  ...   1.370051  -1.407210   0.437209   \n",
       "3  -0.158155  0.343952 -0.092545  ...   1.305155   0.150132   0.607371   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60   1.026937  -1.144009  -2.123258  -1.525115  -1.448959  -2.371252   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39  -0.935583   0.473294   0.998934  -0.780473  -0.661480   2.054732   \n",
       "14   0.103529   1.004458  -3.103754   1.742597  -1.272035  -0.018540   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   2.932836   1.460491   0.621709  -2.899831  -0.278128  -1.450732   \n",
       "18   0.150966   0.458162   0.662532  -1.468774  -0.648076  -1.144024   \n",
       "3   -0.224237   0.018921   0.976853   1.183815   1.897722   0.304188   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -0.894455  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.556554  \n",
       "14   1.237611  \n",
       "10   1.003364  \n",
       "69  -2.987256  \n",
       "18  -0.057911  \n",
       "3   -0.171216  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% del rango de la variable\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_gaussian[i, :] = generate_noisy_sample_gaussian(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian = np.c_[labels, noisy_features_gaussian]\n",
    "\n",
    "noisy_data_gaussian = pd.concat([data, pd.DataFrame(noisy_features_gaussian, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian = noisy_data_gaussian.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian.shape))\n",
    "noisy_data_gaussian.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9dee9",
   "metadata": {},
   "source": [
    "Precisión del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726e40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_gaussian, X_test_gaussian, y_train_gaussian, y_test_gaussian) = data_partition(noisy_data_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901beed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 250}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_gaussian = train_GridSearchCV(model_RF, param_grid_RF, X_train_gaussian, X_test_gaussian, \n",
    "                                       y_train_gaussian, y_test_gaussian)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_gaussian[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_gaussian, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430961ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_gaussian_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=5, n_estimators=250, random_state=0)  \n",
    "data_aug_gaussian_opt.fit(X_train_gaussian, y_train_gaussian)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_gaussian = data_aug_gaussian_opt.predict(X_test_gaussian)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_gaussian = accuracy_score(y_test_gaussian, y_pred_data_aug_gaussian)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_gaussian * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a4d8c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_data_aug_gaussian = data_aug_gaussian_opt.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_data_aug_gaussian, \"RF_DataAugmentation_GaussianI\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e989c1",
   "metadata": {},
   "source": [
    "Vamos a modificar ahora el método, de modo que los valores generados de ruido se tomen de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de la diferencia entre la media de las variables para pacientes con esquizofrenia y la media de las variables de los individuos de control.\n",
    "\n",
    "La motivación para introducir esta modificación es que podría ser que las distribuciones que definen cada variable sean diferentes cuando se considera a un individuo sano (etiqueta 0) y a un individuo enfermo (etiqueta 1). Si estas distribuciones están lo suficientemente cercanas, introducir un ruido aparentemente pequeño podría modificar una muestra originalmente correspondiente a una clase y generar otra de manera artificial con la misma etiqueta pero que se solapa con la distribución de la etiqueta opuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = data[data[\"Class\"] == 0]\n",
    "sick = data[data[\"Class\"] == 0]\n",
    "\n",
    "labels_control = control_group.iloc[:, 0]\n",
    "features_control = np.array(control_group.iloc[:, 1:])\n",
    "labels_sick = sick.iloc[:, 0]\n",
    "features_sick = np.array(sick.iloc[:, 1:])\n",
    "\n",
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del rango de la diferencia)\n",
    "avg_per_var_control = features_control.mean(axis=0)\n",
    "avg_per_var_sick = features_sick.mean(axis=0)\n",
    "std_per_var = abs((avg_per_var_control - avg_per_var_sick)) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330f58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.343140</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>-0.547010</td>\n",
       "      <td>-0.652910</td>\n",
       "      <td>-0.226870</td>\n",
       "      <td>-0.354650</td>\n",
       "      <td>-0.630850</td>\n",
       "      <td>-0.189460</td>\n",
       "      <td>0.704020</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.424498</td>\n",
       "      <td>-1.512935</td>\n",
       "      <td>1.480432</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-1.151279</td>\n",
       "      <td>-2.123389</td>\n",
       "      <td>-0.962200</td>\n",
       "      <td>-0.524886</td>\n",
       "      <td>-2.310918</td>\n",
       "      <td>-1.740839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>-0.196510</td>\n",
       "      <td>-0.245280</td>\n",
       "      <td>-0.083840</td>\n",
       "      <td>0.304210</td>\n",
       "      <td>-0.180270</td>\n",
       "      <td>-0.008647</td>\n",
       "      <td>0.384610</td>\n",
       "      <td>0.300520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>1.135537</td>\n",
       "      <td>-0.256829</td>\n",
       "      <td>0.222902</td>\n",
       "      <td>0.528734</td>\n",
       "      <td>1.098908</td>\n",
       "      <td>-1.239779</td>\n",
       "      <td>-0.421480</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>0.325227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.391350</td>\n",
       "      <td>-0.284360</td>\n",
       "      <td>-0.655090</td>\n",
       "      <td>-0.645960</td>\n",
       "      <td>-0.241020</td>\n",
       "      <td>-0.352420</td>\n",
       "      <td>-0.480940</td>\n",
       "      <td>-0.393730</td>\n",
       "      <td>-0.277160</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.180108</td>\n",
       "      <td>-0.404150</td>\n",
       "      <td>0.358206</td>\n",
       "      <td>0.285097</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>-3.015051</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>-1.158544</td>\n",
       "      <td>-0.694036</td>\n",
       "      <td>-0.540947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.319650</td>\n",
       "      <td>0.099134</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.120010</td>\n",
       "      <td>0.088958</td>\n",
       "      <td>0.171350</td>\n",
       "      <td>-0.117730</td>\n",
       "      <td>-0.263870</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240290</td>\n",
       "      <td>-2.316457</td>\n",
       "      <td>0.115988</td>\n",
       "      <td>1.992077</td>\n",
       "      <td>1.094181</td>\n",
       "      <td>0.362267</td>\n",
       "      <td>-1.395818</td>\n",
       "      <td>-0.647623</td>\n",
       "      <td>-0.699748</td>\n",
       "      <td>-2.677100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263490</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>-0.367170</td>\n",
       "      <td>0.300860</td>\n",
       "      <td>-0.016165</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.370830</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781677</td>\n",
       "      <td>-0.535058</td>\n",
       "      <td>0.034981</td>\n",
       "      <td>-0.853332</td>\n",
       "      <td>0.965745</td>\n",
       "      <td>1.067908</td>\n",
       "      <td>-0.563230</td>\n",
       "      <td>-1.104692</td>\n",
       "      <td>-1.118982</td>\n",
       "      <td>-0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.366770</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>-0.085309</td>\n",
       "      <td>-0.295600</td>\n",
       "      <td>0.311750</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200334</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>1.149330</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.729352</td>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.343140  0.020893 -0.547010 -0.652910 -0.226870 -0.354650   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.026362 -0.196510 -0.245280 -0.083840  0.304210 -0.180270   \n",
       "14    0.0 -0.391350 -0.284360 -0.655090 -0.645960 -0.241020 -0.352420   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.319650  0.099134  0.010361  0.004176  0.120010  0.088958   \n",
       "18    0.0  0.263490  0.022323  0.043017 -0.367170  0.300860 -0.016165   \n",
       "3     1.0 -0.174850 -0.119840 -0.366770 -0.354050  0.065508 -0.085309   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.630850 -0.189460  0.704020  ...  -3.424498  -1.512935   1.480432   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39 -0.008647  0.384610  0.300520  ...   0.464108   1.135537  -0.256829   \n",
       "14 -0.480940 -0.393730 -0.277160  ...  -2.180108  -0.404150   0.358206   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.171350 -0.117730 -0.263870  ...   1.240290  -2.316457   0.115988   \n",
       "18  0.100220  0.370830  0.123080  ...   0.781677  -0.535058   0.034981   \n",
       "3  -0.295600  0.311750 -0.013669  ...   1.200334   0.313340   0.287729   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60  -0.012000  -1.151279  -2.123389  -0.962200  -0.524886  -2.310918   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39   0.222902   0.528734   1.098908  -1.239779  -0.421480   1.130700   \n",
       "14   0.285097   0.955665  -3.015051   0.024974  -1.158544  -0.694036   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   1.992077   1.094181   0.362267  -1.395818  -0.647623  -0.699748   \n",
       "18  -0.853332   0.965745   1.067908  -0.563230  -1.104692  -1.118982   \n",
       "3   -0.370420   0.224179   1.149330   1.842975   1.458239   0.729352   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -1.740839  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.325227  \n",
       "14  -0.540947  \n",
       "10   1.003364  \n",
       "69  -2.677100  \n",
       "18  -0.037143  \n",
       "3    0.522059  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian2(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% de la diferencia entre la media de la variable para cada clase\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian_2 = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_gaussian_2[i, :] = generate_noisy_sample_gaussian2(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian_2 = np.c_[labels, noisy_features_gaussian_2]\n",
    "\n",
    "noisy_data_gaussian_2 = pd.concat([data, pd.DataFrame(noisy_features_gaussian_2, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian_2 = noisy_data_gaussian_2.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian_2.shape))\n",
    "noisy_data_gaussian_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f12f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_gaussian2, X_test_gaussian2, y_train_gaussian2, y_test_gaussian2) = data_partition(noisy_data_gaussian_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f11370e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 15, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 20, 'n_estimators': 500}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_gaussian2 = train_GridSearchCV(model_RF, param_grid_RF, X_train_gaussian2, X_test_gaussian2, \n",
    "                                        y_train_gaussian2, y_test_gaussian2)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_gaussian2[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_gaussian2, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755ba791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.57%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_gaussian_opt2 = RandomForestClassifier(criterion=\"gini\", max_depth=20, n_estimators=500, random_state=0)  \n",
    "data_aug_gaussian_opt2.fit(X_train_gaussian2, y_train_gaussian2)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_gaussian2 = data_aug_gaussian_opt2.predict(X_test_gaussian2)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_gaussian2 = accuracy_score(y_test_gaussian2, y_pred_data_aug_gaussian2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_gaussian2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fee9d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_data_aug_gaussian2 = data_aug_gaussian_opt2.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_data_aug_gaussian2, \"RF_DataAugmentation_GaussianII\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8603",
   "metadata": {},
   "source": [
    "### Ruido uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "724ab306",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_var = features_tot.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a75640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0.143325</td>\n",
       "      <td>-0.607460</td>\n",
       "      <td>-0.668581</td>\n",
       "      <td>-0.043226</td>\n",
       "      <td>-0.299202</td>\n",
       "      <td>-0.731040</td>\n",
       "      <td>-0.240142</td>\n",
       "      <td>0.768622</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.499343</td>\n",
       "      <td>-1.440684</td>\n",
       "      <td>1.418062</td>\n",
       "      <td>-0.112408</td>\n",
       "      <td>-1.172020</td>\n",
       "      <td>-1.980269</td>\n",
       "      <td>-0.910399</td>\n",
       "      <td>-0.415231</td>\n",
       "      <td>-2.311371</td>\n",
       "      <td>-1.608504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249280</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>-0.305730</td>\n",
       "      <td>-0.099511</td>\n",
       "      <td>0.487854</td>\n",
       "      <td>-0.124822</td>\n",
       "      <td>-0.108838</td>\n",
       "      <td>0.333928</td>\n",
       "      <td>0.365122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389263</td>\n",
       "      <td>1.207788</td>\n",
       "      <td>-0.319200</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.507993</td>\n",
       "      <td>1.242028</td>\n",
       "      <td>-1.187978</td>\n",
       "      <td>-0.311825</td>\n",
       "      <td>1.130247</td>\n",
       "      <td>0.457562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168432</td>\n",
       "      <td>-0.161928</td>\n",
       "      <td>-0.715540</td>\n",
       "      <td>-0.661631</td>\n",
       "      <td>-0.057376</td>\n",
       "      <td>-0.296972</td>\n",
       "      <td>-0.581130</td>\n",
       "      <td>-0.444412</td>\n",
       "      <td>-0.212558</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.254953</td>\n",
       "      <td>-0.331899</td>\n",
       "      <td>0.295836</td>\n",
       "      <td>0.184689</td>\n",
       "      <td>0.934924</td>\n",
       "      <td>-2.871931</td>\n",
       "      <td>0.076776</td>\n",
       "      <td>-1.048889</td>\n",
       "      <td>-0.694488</td>\n",
       "      <td>-0.408612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542568</td>\n",
       "      <td>0.221566</td>\n",
       "      <td>-0.050089</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.303654</td>\n",
       "      <td>0.144406</td>\n",
       "      <td>0.071160</td>\n",
       "      <td>-0.168412</td>\n",
       "      <td>-0.199268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165445</td>\n",
       "      <td>-2.244207</td>\n",
       "      <td>0.053618</td>\n",
       "      <td>1.891669</td>\n",
       "      <td>1.073441</td>\n",
       "      <td>0.505387</td>\n",
       "      <td>-1.344017</td>\n",
       "      <td>-0.537968</td>\n",
       "      <td>-0.700200</td>\n",
       "      <td>-2.544765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486408</td>\n",
       "      <td>0.144755</td>\n",
       "      <td>-0.017433</td>\n",
       "      <td>-0.382841</td>\n",
       "      <td>0.484504</td>\n",
       "      <td>0.039283</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.320148</td>\n",
       "      <td>0.187682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706832</td>\n",
       "      <td>-0.462807</td>\n",
       "      <td>-0.027389</td>\n",
       "      <td>-0.953739</td>\n",
       "      <td>0.945004</td>\n",
       "      <td>1.211029</td>\n",
       "      <td>-0.511429</td>\n",
       "      <td>-0.995037</td>\n",
       "      <td>-1.119434</td>\n",
       "      <td>0.095193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048068</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>-0.427220</td>\n",
       "      <td>-0.369721</td>\n",
       "      <td>0.249152</td>\n",
       "      <td>-0.029861</td>\n",
       "      <td>-0.395790</td>\n",
       "      <td>0.261068</td>\n",
       "      <td>0.050933</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125489</td>\n",
       "      <td>0.385591</td>\n",
       "      <td>0.225359</td>\n",
       "      <td>-0.470828</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>1.292451</td>\n",
       "      <td>1.894776</td>\n",
       "      <td>1.567895</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.654394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.120222  0.143325 -0.607460 -0.668581 -0.043226 -0.299202   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.249280 -0.074078 -0.305730 -0.099511  0.487854 -0.124822   \n",
       "14    0.0 -0.168432 -0.161928 -0.715540 -0.661631 -0.057376 -0.296972   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.542568  0.221566 -0.050089 -0.011495  0.303654  0.144406   \n",
       "18    0.0  0.486408  0.144755 -0.017433 -0.382841  0.484504  0.039283   \n",
       "3     1.0  0.048068  0.002592 -0.427220 -0.369721  0.249152 -0.029861   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.731040 -0.240142  0.768622  ...  -3.499343  -1.440684   1.418062   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39 -0.108838  0.333928  0.365122  ...   0.389263   1.207788  -0.319200   \n",
       "14 -0.581130 -0.444412 -0.212558  ...  -2.254953  -0.331899   0.295836   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.071160 -0.168412 -0.199268  ...   1.165445  -2.244207   0.053618   \n",
       "18  0.000030  0.320148  0.187682  ...   0.706832  -0.462807  -0.027389   \n",
       "3  -0.395790  0.261068  0.050933  ...   1.125489   0.385591   0.225359   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60  -0.112408  -1.172020  -1.980269  -0.910399  -0.415231  -2.311371   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39   0.122495   0.507993   1.242028  -1.187978  -0.311825   1.130247   \n",
       "14   0.184689   0.934924  -2.871931   0.076776  -1.048889  -0.694488   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   1.891669   1.073441   0.505387  -1.344017  -0.537968  -0.700200   \n",
       "18  -0.953739   0.945004   1.211029  -0.511429  -0.995037  -1.119434   \n",
       "3   -0.470828   0.203439   1.292451   1.894776   1.567895   0.728900   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -1.608504  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.457562  \n",
       "14  -0.408612  \n",
       "10   1.003364  \n",
       "69  -2.544765  \n",
       "18   0.095193  \n",
       "3    0.654394  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_uniform(original_sample, data=data, std_per_var=std_per_var, avg_per_var=avg_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución uniforme\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.uniform(avg_per_var[j]-std_per_var[j], avg_per_var[j]+std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_uniform = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_uniform[i, :] = generate_noisy_sample_uniform(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_uniform = np.c_[labels, noisy_features_uniform]\n",
    "\n",
    "noisy_data_uniform = pd.concat([data, pd.DataFrame(noisy_features_uniform, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_uniform = noisy_data_uniform.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_uniform.shape))\n",
    "noisy_data_uniform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31db9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_uniform, X_test_uniform, y_train_uniform, y_test_uniform) = data_partition(noisy_data_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7512601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 1000}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_uniform = train_GridSearchCV(model_RF, param_grid_RF, X_train_uniform, X_test_uniform, y_train_uniform, y_test_uniform)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_uniform[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_uniform, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46bb5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_uniform_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=1000, random_state=0)  \n",
    "data_aug_uniform_opt.fit(X_train_uniform, y_train_uniform)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_uniform = data_aug_uniform_opt.predict(X_test_uniform)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_uniform = accuracy_score(y_test_uniform, y_pred_data_aug_uniform)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_uniform * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3fea997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred_data_aug_uniform = data_aug_uniform_opt.predict(test_kaggle)\n",
    "\n",
    "create_submission(y_pred_data_aug_uniform, \"RF_DataAugmentation_Uniform\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe059ea4",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Otra posibilidad para hacer Data Augmentation es, dado que se dispone de un gran volumen de datos no etiquetados, obtener una estimación lo más acertada posible de las etiquetas a las que estarían asociados estos datos. En este caso, podríamos plantearnos repetir algún entrenamiento, esta vez sobre un conjunto de datos mucho mayor.\n",
    "\n",
    "El modelo en base al cual vamos a generar estas predicciones va a ser el encoder ya visto anteriormente. Ya que como se ha explicado, se genera a partir de una red autoencoder que ha entrenado sobre el conjunto de datos completo que queremos etiquetar aquí y posteriormente ha adaptado sus pesos en la parte encoder al problema de clasificación que nos interesa aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8409ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e38bb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.load_model(\"Modelos/encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f094f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 410)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "args = np.random.choice(a=np.arange(0, test_kaggle.shape[0]), size=10000, replace=False)\n",
    "test_kaggle_reduc = test_kaggle.iloc[args, :]\n",
    "\n",
    "test_kaggle_reduc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "922cfa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_kaggle_reduc = encoder.predict(test_kaggle_reduc)\n",
    "\n",
    "labels_tot = np.concatenate((np.reshape(y_train.to_numpy(), (68, 1)), y_test_kaggle_reduc), axis=0)\n",
    "labels_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a5e4f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 410)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tot = np.concatenate((X_train, test_kaggle_reduc))\n",
    "features_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2052d",
   "metadata": {},
   "source": [
    "Vamos a repetir el entrenamiento con una de las configuraciones de Random Forest que ha alcanzado los mejores resultados.\n",
    "\n",
    "Accuracy en ``y_test`` sin aumentar el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c221fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "no_data_aug_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "no_data_aug_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_no_data_aug = no_data_aug_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_no_data_aug2 = accuracy_score(y_test, y_pred_no_data_aug)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_no_data_aug2 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fc4ca",
   "metadata": {},
   "source": [
    "Accuracy en ``y_test`` aumentando el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "277f1abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "rf_encoder1 = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "rf_encoder1.fit(features_tot, np.around(labels_tot, decimals=0).ravel())\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_encoder1 = rf_encoder1.predict(X_test.to_numpy())\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_encoder1 = accuracy_score(y_test, y_pred_encoder1)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_encoder1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd2943",
   "metadata": {},
   "source": [
    "**Prueba con el segundo autoencoder entrenado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebef0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder3 = models.load_model(\"Modelos/encoder3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1fe3141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10068, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_kaggle_reduc = encoder3.predict(test_kaggle_reduc)\n",
    "\n",
    "labels_tot = np.concatenate((np.reshape(y_train.to_numpy(), (68, 1)), y_test_kaggle_reduc), axis=0)\n",
    "labels_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cf63b",
   "metadata": {},
   "source": [
    "Accuracy en ``y_test`` aumentando el conjunto de datos con las etiquetas generadas por el encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82e4e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "rf_encoder3 = RandomForestClassifier(criterion=\"entropy\", max_depth=20, n_estimators=800, random_state=0)  \n",
    "rf_encoder3.fit(features_tot, np.around(labels_tot, decimals=0).ravel())\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_encoder3 = rf_encoder3.predict(X_test.to_numpy())\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_encoder3 = accuracy_score(y_test, y_pred_encoder3)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_encoder3 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea7227",
   "metadata": {},
   "source": [
    "# Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "198c17e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_acc = [acc_no_data_aug, acc_data_aug_gaussian, acc_data_aug_gaussian2, acc_data_aug_uniform]\n",
    "xaxis = [\"Sin Data Augmentation\", \"Ruido gaussiano I\", \"Ruido gaussiano II\", \"Ruido uniforme\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "barlist = plt.bar(xaxis, results_acc, width=0.2)\n",
    "barlist[0].set_color(\"r\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(bottom=0.7)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "154d03d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_acc = [acc_data_aug_gaussian, acc_data_aug_gaussian2, acc_data_aug_uniform]\n",
    "original_acc = [acc_no_data_aug]*3\n",
    "xaxis = [\"Ruido gaussiano I\", \"Ruido gaussiano II\", \"Ruido uniforme\"]\n",
    "x = np.arange(len(xaxis))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(x-0.1, results_acc, width=0.2, label=\"Accuracy tras Data Augmentation\")\n",
    "plt.bar(x+0.1, original_acc, width=0.2,  label=\"Accuracy sin Data Augmentation\")\n",
    "plt.xticks(range(0, len(xaxis)), xaxis, rotation=0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
