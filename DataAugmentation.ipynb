{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70addaeb",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Uno de los principales obstáculos que se encuentran al intentar hallar la major solución al problema de clasificación, es la escasez de datos para el entrenamiento de los modelos.\n",
    "\n",
    "Este notebook tiene como objetivo implementar y comparar los resultados obtenidos implementando técnicas de Data Augmentation para crear datos sintéticos y poder operar sobre un mayor volumen de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989e8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72411cba",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f7bd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>0.216620</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.353800</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.133020</td>\n",
       "      <td>-0.035222</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257114</td>\n",
       "      <td>0.597229</td>\n",
       "      <td>1.220756</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>-0.435494</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>1.090910</td>\n",
       "      <td>-0.448562</td>\n",
       "      <td>-0.508497</td>\n",
       "      <td>0.350434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.410730</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.242260</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>0.599790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050862</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>0.609465</td>\n",
       "      <td>1.181878</td>\n",
       "      <td>-2.279469</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>-0.012693</td>\n",
       "      <td>-1.244346</td>\n",
       "      <td>-1.080442</td>\n",
       "      <td>-0.788502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.318170</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.539922</td>\n",
       "      <td>-1.495822</td>\n",
       "      <td>1.643866</td>\n",
       "      <td>1.687780</td>\n",
       "      <td>1.521086</td>\n",
       "      <td>-1.988432</td>\n",
       "      <td>-0.267471</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>1.104566</td>\n",
       "      <td>-1.067206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.112830</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0.202750</td>\n",
       "      <td>0.191420</td>\n",
       "      <td>-0.056662</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.593326</td>\n",
       "      <td>1.063052</td>\n",
       "      <td>0.434726</td>\n",
       "      <td>1.604964</td>\n",
       "      <td>-0.359736</td>\n",
       "      <td>0.210107</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>-0.323557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "2       0  0.245850  0.216620 -0.124680 -0.353800  0.161500 -0.002032   \n",
       "13      1  0.410730 -0.031925  0.210700  0.242260  0.320100 -0.419290   \n",
       "53      1  0.070919  0.034179 -0.011755  0.019158  0.024645 -0.032022   \n",
       "41      0  0.087377 -0.052462 -0.007835 -0.112830  0.389380  0.216080   \n",
       "74      0  0.202750  0.191420 -0.056662 -0.157780  0.244040  0.039780   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "2  -0.133020 -0.035222  0.259040  ...  -0.257114   0.597229   1.220756   \n",
       "13 -0.187140  0.168450  0.599790  ...  -0.050862   0.870602   0.609465   \n",
       "53  0.004620  0.318170  0.212550  ...  -1.539922  -1.495822   1.643866   \n",
       "41  0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "74 -0.001503  0.001056 -0.048222  ...   0.044457   0.593326   1.063052   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "2   -0.059213  -0.435494  -0.092971   1.090910  -0.448562  -0.508497   \n",
       "13   1.181878  -2.279469  -0.013484  -0.012693  -1.244346  -1.080442   \n",
       "53   1.687780   1.521086  -1.988432  -0.267471   0.510576   1.104566   \n",
       "41  -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "74   0.434726   1.604964  -0.359736   0.210107   0.355922   0.730287   \n",
       "\n",
       "    SBM_map75  \n",
       "2    0.350434  \n",
       "13  -0.788502  \n",
       "53  -1.067206  \n",
       "41  -0.260920  \n",
       "74  -0.323557  \n",
       "\n",
       "[5 rows x 411 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de entrenamiento\n",
    "trainFNC = pd.read_csv(\"data/train_FNC.csv\")\n",
    "trainSBM = pd.read_csv(\"data/train_SBM.csv\")\n",
    "train_labels = pd.read_csv(\"data/train_labels.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "train = pd.merge(left=trainFNC, right=trainSBM, left_on='Id', right_on='Id')\n",
    "data = pd.merge(left=train_labels, right=train, left_on='Id', right_on='Id')\n",
    "data.drop(\"Id\", inplace=True, axis=1)\n",
    "\n",
    "# Shuffle de los datos de train\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d83db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_partition(data_augmented):\n",
    "    X = data_augmented.iloc[:, 1:]\n",
    "    Y = data_augmented.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1986728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61cfdadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>FNC10</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476127</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>-0.608133</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>-0.637038</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>-0.192434</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.060474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451994</td>\n",
       "      <td>1.123770</td>\n",
       "      <td>2.083006</td>\n",
       "      <td>1.145440</td>\n",
       "      <td>-0.067608</td>\n",
       "      <td>1.202529</td>\n",
       "      <td>0.851587</td>\n",
       "      <td>0.451583</td>\n",
       "      <td>-0.159739</td>\n",
       "      <td>0.192076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.267183</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>-0.261327</td>\n",
       "      <td>0.191869</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>0.088761</td>\n",
       "      <td>0.177048</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696987</td>\n",
       "      <td>1.397832</td>\n",
       "      <td>1.046136</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>-2.192023</td>\n",
       "      <td>-0.369276</td>\n",
       "      <td>0.822225</td>\n",
       "      <td>-0.109342</td>\n",
       "      <td>-0.580476</td>\n",
       "      <td>0.174160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.435452</td>\n",
       "      <td>0.046780</td>\n",
       "      <td>0.243742</td>\n",
       "      <td>0.397030</td>\n",
       "      <td>-0.147821</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>-0.461963</td>\n",
       "      <td>-0.610736</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.400985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>1.906989</td>\n",
       "      <td>-2.661633</td>\n",
       "      <td>-0.193911</td>\n",
       "      <td>0.440873</td>\n",
       "      <td>0.641739</td>\n",
       "      <td>0.918397</td>\n",
       "      <td>-0.758046</td>\n",
       "      <td>0.154701</td>\n",
       "      <td>-0.476647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.204510</td>\n",
       "      <td>-0.036735</td>\n",
       "      <td>-0.760705</td>\n",
       "      <td>-0.740495</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>0.349926</td>\n",
       "      <td>-0.273826</td>\n",
       "      <td>-0.174384</td>\n",
       "      <td>-0.120248</td>\n",
       "      <td>0.175618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974828</td>\n",
       "      <td>-1.997087</td>\n",
       "      <td>-2.083782</td>\n",
       "      <td>1.154107</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>2.332424</td>\n",
       "      <td>0.659124</td>\n",
       "      <td>-0.809445</td>\n",
       "      <td>0.558960</td>\n",
       "      <td>2.790871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599435</td>\n",
       "      <td>-0.166441</td>\n",
       "      <td>0.122431</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.346906</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.274734</td>\n",
       "      <td>0.211510</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-0.033434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.789153</td>\n",
       "      <td>1.578984</td>\n",
       "      <td>1.402592</td>\n",
       "      <td>-1.230440</td>\n",
       "      <td>0.296686</td>\n",
       "      <td>2.806314</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>-0.240682</td>\n",
       "      <td>-0.196948</td>\n",
       "      <td>-1.544345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FNC1      FNC2      FNC3      FNC4      FNC5      FNC6      FNC7  \\\n",
       "0  0.476127  0.064466  0.053238 -0.608133  0.073988 -0.637038  0.113556   \n",
       "1  0.013833  0.267183  0.232178 -0.167151 -0.261327  0.191869  0.406493   \n",
       "2 -0.435452  0.046780  0.243742  0.397030 -0.147821  0.173620 -0.461963   \n",
       "3 -0.204510 -0.036735 -0.760705 -0.740495  0.064668  0.349926 -0.273826   \n",
       "4  0.599435 -0.166441  0.122431  0.011539  0.346906 -0.017430 -0.274734   \n",
       "\n",
       "       FNC8      FNC9     FNC10  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "0 -0.192434 -0.004025 -0.060474  ...  -0.451994   1.123770   2.083006   \n",
       "1  0.088761  0.177048  0.036718  ...   0.696987   1.397832   1.046136   \n",
       "2 -0.610736  0.419753  0.400985  ...   0.160145   1.906989  -2.661633   \n",
       "3 -0.174384 -0.120248  0.175618  ...   0.974828  -1.997087  -2.083782   \n",
       "4  0.211510  0.151012 -0.033434  ...  -0.789153   1.578984   1.402592   \n",
       "\n",
       "   SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  SBM_map75  \n",
       "0   1.145440  -0.067608   1.202529   0.851587   0.451583  -0.159739   0.192076  \n",
       "1  -0.191733  -2.192023  -0.369276   0.822225  -0.109342  -0.580476   0.174160  \n",
       "2  -0.193911   0.440873   0.641739   0.918397  -0.758046   0.154701  -0.476647  \n",
       "3   1.154107  -0.643947   2.332424   0.659124  -0.809445   0.558960   2.790871  \n",
       "4  -1.230440   0.296686   2.806314   0.427184  -0.240682  -0.196948  -1.544345  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de test\n",
    "testFNC = pd.read_csv(\"data/test_FNC.csv\")\n",
    "testSBM = pd.read_csv(\"data/test_SBM.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "test = pd.merge(left=testFNC, right=testSBM, left_on='Id', right_on='Id')\n",
    "test.drop(\"Id\", inplace=True, axis=1)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13bba535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119834, 410)\n"
     ]
    }
   ],
   "source": [
    "labels = data.iloc[:, 0]\n",
    "# features = np.array(data.iloc[:, 1:])\n",
    "features = np.array(data.iloc[:, 1:])\n",
    "features_tot = np.concatenate((features, test))\n",
    "print(features_tot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea0b5c",
   "metadata": {},
   "source": [
    "**Precisión de un modelo de Random Forest sobre el conjunto original de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447b1eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without Data Augmentation: 83.33%\n"
     ]
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [10, 50, 100, 200, 400]\n",
    "}\n",
    "grid_search_RF = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF.fit(X_train, y_train)\n",
    "model_RF_opt = grid_search_RF.best_estimator_\n",
    "# Predicción en partición de test\n",
    "y_pred_RF = model_RF_opt.predict(X_test)\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy without Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010d2b1",
   "metadata": {},
   "source": [
    "# Random noise\n",
    "\n",
    "### Ruigo gaussiano\n",
    "\n",
    "Una primera prueba de introducción de ruido artificial se basará en añadir a los datos originales, valores (ruido) que se tomarán de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de valores para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c268e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del intervalo)\n",
    "max_per_var = features_tot.max(axis=0)\n",
    "min_per_var = features_tot.min(axis=0)\n",
    "std_per_var = (max_per_var - min_per_var) * 0.1\n",
    "std_per_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304cc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090310</td>\n",
       "      <td>0.186641</td>\n",
       "      <td>-0.033887</td>\n",
       "      <td>0.303550</td>\n",
       "      <td>0.144260</td>\n",
       "      <td>0.535870</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>-0.066027</td>\n",
       "      <td>0.068281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064109</td>\n",
       "      <td>-1.416375</td>\n",
       "      <td>-0.588373</td>\n",
       "      <td>1.476591</td>\n",
       "      <td>-0.931430</td>\n",
       "      <td>0.215681</td>\n",
       "      <td>-1.138860</td>\n",
       "      <td>-0.119312</td>\n",
       "      <td>1.291117</td>\n",
       "      <td>1.465796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.138510</td>\n",
       "      <td>0.258360</td>\n",
       "      <td>-0.510770</td>\n",
       "      <td>-0.457780</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>-0.344340</td>\n",
       "      <td>-0.283480</td>\n",
       "      <td>-0.380750</td>\n",
       "      <td>-0.339130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>-0.896406</td>\n",
       "      <td>-1.232269</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>-0.817785</td>\n",
       "      <td>-0.419049</td>\n",
       "      <td>-1.509745</td>\n",
       "      <td>-0.946138</td>\n",
       "      <td>0.259551</td>\n",
       "      <td>-1.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>-0.303650</td>\n",
       "      <td>0.592750</td>\n",
       "      <td>-0.170640</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>-0.471900</td>\n",
       "      <td>-0.180450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527436</td>\n",
       "      <td>-0.014958</td>\n",
       "      <td>-0.682168</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>1.148412</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>1.696830</td>\n",
       "      <td>-0.434430</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.119103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>-0.575757</td>\n",
       "      <td>-0.510545</td>\n",
       "      <td>-0.655821</td>\n",
       "      <td>-0.626826</td>\n",
       "      <td>-0.183842</td>\n",
       "      <td>0.286757</td>\n",
       "      <td>0.562557</td>\n",
       "      <td>0.113185</td>\n",
       "      <td>...</td>\n",
       "      <td>1.879741</td>\n",
       "      <td>-1.258914</td>\n",
       "      <td>1.126362</td>\n",
       "      <td>-0.268733</td>\n",
       "      <td>0.739928</td>\n",
       "      <td>0.638815</td>\n",
       "      <td>0.934721</td>\n",
       "      <td>2.100384</td>\n",
       "      <td>3.440071</td>\n",
       "      <td>-0.320113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.149488</td>\n",
       "      <td>-0.035793</td>\n",
       "      <td>-0.072892</td>\n",
       "      <td>-0.134532</td>\n",
       "      <td>-0.078967</td>\n",
       "      <td>0.029238</td>\n",
       "      <td>0.334085</td>\n",
       "      <td>-0.236176</td>\n",
       "      <td>0.241712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438323</td>\n",
       "      <td>-1.170183</td>\n",
       "      <td>0.237547</td>\n",
       "      <td>1.105830</td>\n",
       "      <td>-0.988333</td>\n",
       "      <td>0.614596</td>\n",
       "      <td>2.344493</td>\n",
       "      <td>0.214602</td>\n",
       "      <td>0.175995</td>\n",
       "      <td>2.294870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386970</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>-0.221020</td>\n",
       "      <td>-0.216810</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.333490</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>0.306680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012167</td>\n",
       "      <td>1.308194</td>\n",
       "      <td>-1.412457</td>\n",
       "      <td>1.490609</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>0.565845</td>\n",
       "      <td>-0.988205</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0.279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173938</td>\n",
       "      <td>-0.180256</td>\n",
       "      <td>-0.183904</td>\n",
       "      <td>0.212437</td>\n",
       "      <td>0.408138</td>\n",
       "      <td>-0.287515</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>0.541885</td>\n",
       "      <td>0.202692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.507154</td>\n",
       "      <td>0.734908</td>\n",
       "      <td>1.163661</td>\n",
       "      <td>0.895043</td>\n",
       "      <td>1.358350</td>\n",
       "      <td>-2.743792</td>\n",
       "      <td>-0.051985</td>\n",
       "      <td>0.379716</td>\n",
       "      <td>0.015072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.385621</td>\n",
       "      <td>0.195405</td>\n",
       "      <td>0.183701</td>\n",
       "      <td>0.274933</td>\n",
       "      <td>0.491690</td>\n",
       "      <td>-0.019830</td>\n",
       "      <td>0.095519</td>\n",
       "      <td>-0.024712</td>\n",
       "      <td>-0.187834</td>\n",
       "      <td>...</td>\n",
       "      <td>1.321553</td>\n",
       "      <td>-1.595880</td>\n",
       "      <td>-0.219030</td>\n",
       "      <td>0.159802</td>\n",
       "      <td>0.080166</td>\n",
       "      <td>1.098231</td>\n",
       "      <td>-0.252857</td>\n",
       "      <td>1.797618</td>\n",
       "      <td>-0.175905</td>\n",
       "      <td>-0.074648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248241</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>-0.122858</td>\n",
       "      <td>0.163344</td>\n",
       "      <td>0.174548</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.201017</td>\n",
       "      <td>-0.219028</td>\n",
       "      <td>-0.159444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>-0.622670</td>\n",
       "      <td>0.115314</td>\n",
       "      <td>-0.473325</td>\n",
       "      <td>-1.615781</td>\n",
       "      <td>-0.477100</td>\n",
       "      <td>-2.181088</td>\n",
       "      <td>1.033173</td>\n",
       "      <td>-0.351526</td>\n",
       "      <td>-0.954194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "60    1.0  0.090310  0.186641 -0.033887  0.303550  0.144260  0.535870   \n",
       "19    1.0 -0.138510  0.258360 -0.510770 -0.457780 -0.440400 -0.344340   \n",
       "31    0.0  0.216780  0.270110  0.087964 -0.303650  0.592750 -0.170640   \n",
       "39    1.0  0.089888 -0.575757 -0.510545 -0.655821 -0.626826 -0.183842   \n",
       "14    1.0 -0.149488 -0.035793 -0.072892 -0.134532 -0.078967  0.029238   \n",
       "43    0.0  0.386970  0.139220 -0.221020 -0.216810 -0.017924  0.139650   \n",
       "69    0.0 -0.173938 -0.180256 -0.183904  0.212437  0.408138 -0.287515   \n",
       "18    1.0  0.385621  0.195405  0.183701  0.274933  0.491690 -0.019830   \n",
       "3     0.0  0.248241  0.016551 -0.122858  0.163344  0.174548 -0.000025   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "60  0.033004 -0.066027  0.068281  ...  -0.064109  -1.416375  -0.588373   \n",
       "19 -0.283480 -0.380750 -0.339130  ...  -0.038365  -0.896406  -1.232269   \n",
       "31 -0.143090 -0.471900 -0.180450  ...  -1.527436  -0.014958  -0.682168   \n",
       "39  0.286757  0.562557  0.113185  ...   1.879741  -1.258914   1.126362   \n",
       "14  0.334085 -0.236176  0.241712  ...   0.438323  -1.170183   0.237547   \n",
       "43  0.333490  0.412210  0.306680  ...   1.012167   1.308194  -1.412457   \n",
       "69  0.102173  0.541885  0.202692  ...   0.215764   0.507154   0.734908   \n",
       "18  0.095519 -0.024712 -0.187834  ...   1.321553  -1.595880  -0.219030   \n",
       "3   0.201017 -0.219028 -0.159444  ...   0.027468  -0.622670   0.115314   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "60   1.476591  -0.931430   0.215681  -1.138860  -0.119312   1.291117   \n",
       "19   0.785572  -0.817785  -0.419049  -1.509745  -0.946138   0.259551   \n",
       "31   0.114895   1.148412   0.434126   1.696830  -0.434430   0.094033   \n",
       "39  -0.268733   0.739928   0.638815   0.934721   2.100384   3.440071   \n",
       "14   1.105830  -0.988333   0.614596   2.344493   0.214602   0.175995   \n",
       "43   1.490609   0.081146   0.564483   0.565845  -0.988205   0.014638   \n",
       "69   1.163661   0.895043   1.358350  -2.743792  -0.051985   0.379716   \n",
       "18   0.159802   0.080166   1.098231  -0.252857   1.797618  -0.175905   \n",
       "3   -0.473325  -1.615781  -0.477100  -2.181088   1.033173  -0.351526   \n",
       "\n",
       "    SBM_map75  \n",
       "10   1.003364  \n",
       "60   1.465796  \n",
       "19  -1.026065  \n",
       "31  -0.119103  \n",
       "39  -0.320113  \n",
       "14   2.294870  \n",
       "43   0.279144  \n",
       "69   0.015072  \n",
       "18  -0.074648  \n",
       "3   -0.954194  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian(original_sample, data=data, std_per_var=std_per_var):\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian = np.empty(features.shape)\n",
    "for i, sample in enumerate(features):\n",
    "    noisy_features_gaussian[i, :] = generate_noisy_sample_gaussian(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian = np.c_[labels, noisy_features_gaussian]\n",
    "\n",
    "noisy_data_gaussian = pd.concat([data, pd.DataFrame(noisy_features_gaussian, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian = noisy_data_gaussian.sample(frac=1, random_state=0)\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian.shape))\n",
    "noisy_data_gaussian.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9535fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066194</td>\n",
       "      <td>0.186641</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.309838</td>\n",
       "      <td>0.161224</td>\n",
       "      <td>0.505312</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>-0.036332</td>\n",
       "      <td>0.052330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082067</td>\n",
       "      <td>-1.465872</td>\n",
       "      <td>-0.759942</td>\n",
       "      <td>1.348701</td>\n",
       "      <td>-0.933341</td>\n",
       "      <td>0.215661</td>\n",
       "      <td>-0.944840</td>\n",
       "      <td>0.076907</td>\n",
       "      <td>1.297998</td>\n",
       "      <td>1.255526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.138510</td>\n",
       "      <td>0.258360</td>\n",
       "      <td>-0.510770</td>\n",
       "      <td>-0.457780</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>-0.344340</td>\n",
       "      <td>-0.283480</td>\n",
       "      <td>-0.380750</td>\n",
       "      <td>-0.339130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>-0.896406</td>\n",
       "      <td>-1.232269</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>-0.817785</td>\n",
       "      <td>-0.419049</td>\n",
       "      <td>-1.509745</td>\n",
       "      <td>-0.946138</td>\n",
       "      <td>0.259551</td>\n",
       "      <td>-1.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>-0.303650</td>\n",
       "      <td>0.592750</td>\n",
       "      <td>-0.170640</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>-0.471900</td>\n",
       "      <td>-0.180450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527436</td>\n",
       "      <td>-0.014958</td>\n",
       "      <td>-0.682168</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>1.148412</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>1.696830</td>\n",
       "      <td>-0.434430</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.119103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038565</td>\n",
       "      <td>-0.575757</td>\n",
       "      <td>-0.512312</td>\n",
       "      <td>-0.647848</td>\n",
       "      <td>-0.610330</td>\n",
       "      <td>-0.163938</td>\n",
       "      <td>0.248598</td>\n",
       "      <td>0.521718</td>\n",
       "      <td>0.094848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.832051</td>\n",
       "      <td>-1.133497</td>\n",
       "      <td>0.749306</td>\n",
       "      <td>-0.126126</td>\n",
       "      <td>0.754504</td>\n",
       "      <td>0.654096</td>\n",
       "      <td>0.776412</td>\n",
       "      <td>2.151346</td>\n",
       "      <td>3.334682</td>\n",
       "      <td>-0.377582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.103280</td>\n",
       "      <td>-0.035793</td>\n",
       "      <td>-0.076679</td>\n",
       "      <td>-0.143135</td>\n",
       "      <td>-0.045720</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>0.329442</td>\n",
       "      <td>-0.210291</td>\n",
       "      <td>0.251205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415332</td>\n",
       "      <td>-0.755140</td>\n",
       "      <td>0.049985</td>\n",
       "      <td>1.128180</td>\n",
       "      <td>-1.001161</td>\n",
       "      <td>0.628155</td>\n",
       "      <td>1.752479</td>\n",
       "      <td>0.238701</td>\n",
       "      <td>0.098952</td>\n",
       "      <td>1.853017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386970</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>-0.221020</td>\n",
       "      <td>-0.216810</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.333490</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>0.306680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012167</td>\n",
       "      <td>1.308194</td>\n",
       "      <td>-1.412457</td>\n",
       "      <td>1.490609</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>0.565845</td>\n",
       "      <td>-0.988205</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0.279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.130397</td>\n",
       "      <td>-0.180256</td>\n",
       "      <td>-0.189844</td>\n",
       "      <td>0.196897</td>\n",
       "      <td>0.393398</td>\n",
       "      <td>-0.273719</td>\n",
       "      <td>0.088168</td>\n",
       "      <td>0.510149</td>\n",
       "      <td>0.219420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.788113</td>\n",
       "      <td>0.348554</td>\n",
       "      <td>1.047856</td>\n",
       "      <td>0.798735</td>\n",
       "      <td>1.318691</td>\n",
       "      <td>-2.225403</td>\n",
       "      <td>-0.130444</td>\n",
       "      <td>0.465368</td>\n",
       "      <td>0.092125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>0.195405</td>\n",
       "      <td>0.187181</td>\n",
       "      <td>0.276078</td>\n",
       "      <td>0.480664</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.086827</td>\n",
       "      <td>-0.111120</td>\n",
       "      <td>-0.184121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.269346</td>\n",
       "      <td>-1.205928</td>\n",
       "      <td>-0.375727</td>\n",
       "      <td>0.036175</td>\n",
       "      <td>0.213618</td>\n",
       "      <td>1.160196</td>\n",
       "      <td>0.059257</td>\n",
       "      <td>1.700660</td>\n",
       "      <td>-0.173049</td>\n",
       "      <td>-0.069488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213273</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>-0.111725</td>\n",
       "      <td>0.148859</td>\n",
       "      <td>0.205018</td>\n",
       "      <td>0.027774</td>\n",
       "      <td>0.183647</td>\n",
       "      <td>-0.225526</td>\n",
       "      <td>-0.145957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>-0.549698</td>\n",
       "      <td>-0.009210</td>\n",
       "      <td>-0.491320</td>\n",
       "      <td>-1.561815</td>\n",
       "      <td>-0.450735</td>\n",
       "      <td>-1.953895</td>\n",
       "      <td>0.939853</td>\n",
       "      <td>-0.303034</td>\n",
       "      <td>-0.781962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "60    1.0  0.066194  0.186641 -0.010201  0.309838  0.161224  0.505312   \n",
       "19    1.0 -0.138510  0.258360 -0.510770 -0.457780 -0.440400 -0.344340   \n",
       "31    0.0  0.216780  0.270110  0.087964 -0.303650  0.592750 -0.170640   \n",
       "39    1.0  0.038565 -0.575757 -0.512312 -0.647848 -0.610330 -0.163938   \n",
       "14    1.0 -0.103280 -0.035793 -0.076679 -0.143135 -0.045720  0.046640   \n",
       "43    0.0  0.386970  0.139220 -0.221020 -0.216810 -0.017924  0.139650   \n",
       "69    0.0 -0.130397 -0.180256 -0.189844  0.196897  0.393398 -0.273719   \n",
       "18    1.0  0.373700  0.195405  0.187181  0.276078  0.480664  0.002400   \n",
       "3     0.0  0.213273  0.016551 -0.111725  0.148859  0.205018  0.027774   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "60  0.017686 -0.036332  0.052330  ...  -0.082067  -1.465872  -0.759942   \n",
       "19 -0.283480 -0.380750 -0.339130  ...  -0.038365  -0.896406  -1.232269   \n",
       "31 -0.143090 -0.471900 -0.180450  ...  -1.527436  -0.014958  -0.682168   \n",
       "39  0.248598  0.521718  0.094848  ...   1.832051  -1.133497   0.749306   \n",
       "14  0.329442 -0.210291  0.251205  ...   0.415332  -0.755140   0.049985   \n",
       "43  0.333490  0.412210  0.306680  ...   1.012167   1.308194  -1.412457   \n",
       "69  0.088168  0.510149  0.219420  ...   0.237800   0.788113   0.348554   \n",
       "18  0.086827 -0.111120 -0.184121  ...   1.269346  -1.205928  -0.375727   \n",
       "3   0.183647 -0.225526 -0.145957  ...   0.018167  -0.549698  -0.009210   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "60   1.348701  -0.933341   0.215661  -0.944840   0.076907   1.297998   \n",
       "19   0.785572  -0.817785  -0.419049  -1.509745  -0.946138   0.259551   \n",
       "31   0.114895   1.148412   0.434126   1.696830  -0.434430   0.094033   \n",
       "39  -0.126126   0.754504   0.654096   0.776412   2.151346   3.334682   \n",
       "14   1.128180  -1.001161   0.628155   1.752479   0.238701   0.098952   \n",
       "43   1.490609   0.081146   0.564483   0.565845  -0.988205   0.014638   \n",
       "69   1.047856   0.798735   1.318691  -2.225403  -0.130444   0.465368   \n",
       "18   0.036175   0.213618   1.160196   0.059257   1.700660  -0.173049   \n",
       "3   -0.491320  -1.561815  -0.450735  -1.953895   0.939853  -0.303034   \n",
       "\n",
       "    SBM_map75  \n",
       "10   1.003364  \n",
       "60   1.255526  \n",
       "19  -1.026065  \n",
       "31  -0.119103  \n",
       "39  -0.377582  \n",
       "14   1.853017  \n",
       "43   0.279144  \n",
       "69   0.092125  \n",
       "18  -0.069488  \n",
       "3   -0.781962  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian(original_sample, data=data, std_per_var=std_per_var):\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian = np.empty(features.shape)\n",
    "for i, sample in enumerate(features):\n",
    "    noisy_features_gaussian[i, :] = generate_noisy_sample_gaussian(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian = np.c_[labels, noisy_features_gaussian]\n",
    "\n",
    "noisy_data_gaussian = pd.concat([data, pd.DataFrame(noisy_features_gaussian, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian = noisy_data_gaussian.sample(frac=1, random_state=0)\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian.shape))\n",
    "noisy_data_gaussian.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9dee9",
   "metadata": {},
   "source": [
    "Precisión del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6449defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 91.43%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_gaussian)\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [10, 50, 100, 200, 400]\n",
    "}\n",
    "grid_search_RF = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF.fit(X_train, y_train)\n",
    "model_RF_opt = grid_search_RF.best_estimator_\n",
    "# Predicción en partición de test\n",
    "y_pred_RF = model_RF_opt.predict(X_test)\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e989c1",
   "metadata": {},
   "source": [
    "Vamos a modificar ahora el método, de modo que los valores generados de ruido se tomen de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de la diferencia entre la media de las variables para pacientes con esquizofrenia y la media de las variables de los individuos de control.\n",
    "\n",
    "La motivación para introducir esta modificación es que podría ser que las distribuciones que definen cada variable sean diferentes cuando se considera a un individuo sano (etiqueta 0) y a un individuo enfermo (etiqueta 1). Si estas distribuciones están lo suficientemente cercanas, introducir un ruido aparentemente pequeño podría modificar una muestra originalmente correspondiente a una clase y generar otra de manera artificial con la misma etiqueta pero que se solapa con la distribución de la etiqueta opuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9c990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = data[data[\"Class\"] == 0]\n",
    "sick = data[data[\"Class\"] == 0]\n",
    "\n",
    "labels_control = control_group.iloc[:, 0]\n",
    "features_control = np.array(control_group.iloc[:, 1:])\n",
    "labels_sick = sick.iloc[:, 0]\n",
    "features_sick = np.array(sick.iloc[:, 1:])\n",
    "\n",
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del intervalo)\n",
    "avg_per_var_control = features_control.mean(axis=0)\n",
    "avg_per_var_sick = features_sick.mean(axis=0)\n",
    "std_per_var = abs((avg_per_var_control - avg_per_var_sick)) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "330f58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.14185</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.210830</td>\n",
       "      <td>0.42343</td>\n",
       "      <td>0.263870</td>\n",
       "      <td>0.298310</td>\n",
       "      <td>-0.088201</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266496</td>\n",
       "      <td>-1.527078</td>\n",
       "      <td>-1.028776</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>-0.938700</td>\n",
       "      <td>0.215549</td>\n",
       "      <td>-0.575946</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.619411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.138510</td>\n",
       "      <td>0.258360</td>\n",
       "      <td>-0.510770</td>\n",
       "      <td>-0.45778</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>-0.344340</td>\n",
       "      <td>-0.283480</td>\n",
       "      <td>-0.380750</td>\n",
       "      <td>-0.339130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>-0.896406</td>\n",
       "      <td>-1.232269</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>-0.817785</td>\n",
       "      <td>-0.419049</td>\n",
       "      <td>-1.509745</td>\n",
       "      <td>-0.946138</td>\n",
       "      <td>0.259551</td>\n",
       "      <td>-1.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>-0.30365</td>\n",
       "      <td>0.592750</td>\n",
       "      <td>-0.170640</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>-0.471900</td>\n",
       "      <td>-0.180450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527436</td>\n",
       "      <td>-0.014958</td>\n",
       "      <td>-0.682168</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>1.148412</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>1.696830</td>\n",
       "      <td>-0.434430</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.119103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.50381</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>-0.182020</td>\n",
       "      <td>-0.112020</td>\n",
       "      <td>-0.29856</td>\n",
       "      <td>0.155450</td>\n",
       "      <td>0.164520</td>\n",
       "      <td>0.297350</td>\n",
       "      <td>-0.107900</td>\n",
       "      <td>0.297230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179212</td>\n",
       "      <td>-0.241914</td>\n",
       "      <td>-0.243907</td>\n",
       "      <td>1.287397</td>\n",
       "      <td>-1.037125</td>\n",
       "      <td>0.703299</td>\n",
       "      <td>0.626871</td>\n",
       "      <td>0.328094</td>\n",
       "      <td>-0.499501</td>\n",
       "      <td>0.516312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386970</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>-0.221020</td>\n",
       "      <td>-0.21681</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.333490</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>0.306680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012167</td>\n",
       "      <td>1.308194</td>\n",
       "      <td>-1.412457</td>\n",
       "      <td>1.490609</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>0.565845</td>\n",
       "      <td>-0.988205</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0.279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>-0.196510</td>\n",
       "      <td>-0.245280</td>\n",
       "      <td>-0.08384</td>\n",
       "      <td>0.304210</td>\n",
       "      <td>-0.180270</td>\n",
       "      <td>-0.008647</td>\n",
       "      <td>0.384610</td>\n",
       "      <td>0.300520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>1.135537</td>\n",
       "      <td>-0.256829</td>\n",
       "      <td>0.222902</td>\n",
       "      <td>0.528734</td>\n",
       "      <td>1.098908</td>\n",
       "      <td>-1.239779</td>\n",
       "      <td>-0.421480</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>0.325227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.330780</td>\n",
       "      <td>0.123580</td>\n",
       "      <td>0.219650</td>\n",
       "      <td>0.29676</td>\n",
       "      <td>0.413950</td>\n",
       "      <td>0.152980</td>\n",
       "      <td>0.026740</td>\n",
       "      <td>-0.452920</td>\n",
       "      <td>-0.166120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733179</td>\n",
       "      <td>-0.723728</td>\n",
       "      <td>-0.621257</td>\n",
       "      <td>-0.844496</td>\n",
       "      <td>0.587749</td>\n",
       "      <td>1.503607</td>\n",
       "      <td>0.652687</td>\n",
       "      <td>1.341002</td>\n",
       "      <td>-0.150862</td>\n",
       "      <td>-0.053879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.11283</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3     FNC4      FNC5      FNC6  \\\n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.14185 -0.148490 -0.085769   \n",
       "60    1.0 -0.020630  0.250100  0.210830  0.42343  0.263870  0.298310   \n",
       "19    1.0 -0.138510  0.258360 -0.510770 -0.45778 -0.440400 -0.344340   \n",
       "31    0.0  0.216780  0.270110  0.087964 -0.30365  0.592750 -0.170640   \n",
       "39    1.0 -0.146210 -0.468630 -0.528800 -0.50381 -0.510520 -0.029113   \n",
       "14    1.0  0.063080 -0.182020 -0.112020 -0.29856  0.155450  0.164520   \n",
       "43    0.0  0.386970  0.139220 -0.221020 -0.21681 -0.017924  0.139650   \n",
       "69    0.0  0.026362 -0.196510 -0.245280 -0.08384  0.304210 -0.180270   \n",
       "18    1.0  0.330780  0.123580  0.219650  0.29676  0.413950  0.152980   \n",
       "3     0.0  0.087377 -0.052462 -0.007835 -0.11283  0.389380  0.216080   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "60 -0.088201  0.081132 -0.025001  ...  -0.266496  -1.527078  -1.028776   \n",
       "19 -0.283480 -0.380750 -0.339130  ...  -0.038365  -0.896406  -1.232269   \n",
       "31 -0.143090 -0.471900 -0.180450  ...  -1.527436  -0.014958  -0.682168   \n",
       "39 -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "14  0.297350 -0.107900  0.297230  ...   0.179212  -0.241914  -0.243907   \n",
       "43  0.333490  0.412210  0.306680  ...   1.012167   1.308194  -1.412457   \n",
       "69 -0.008647  0.384610  0.300520  ...   0.464108   1.135537  -0.256829   \n",
       "18  0.026740 -0.452920 -0.166120  ...   0.733179  -0.723728  -0.621257   \n",
       "3   0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "60   0.437655  -0.938700   0.215549  -0.575946   0.804762   1.351451   \n",
       "19   0.785572  -0.817785  -0.419049  -1.509745  -0.946138   0.259551   \n",
       "31   0.114895   1.148412   0.434126   1.696830  -0.434430   0.094033   \n",
       "39   0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "14   1.287397  -1.037125   0.703299   0.626871   0.328094  -0.499501   \n",
       "43   1.490609   0.081146   0.564483   0.565845  -0.988205   0.014638   \n",
       "69   0.222902   0.528734   1.098908  -1.239779  -0.421480   1.130700   \n",
       "18  -0.844496   0.587749   1.503607   0.652687   1.341002  -0.150862   \n",
       "3   -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "\n",
       "    SBM_map75  \n",
       "10   1.003364  \n",
       "60   0.619411  \n",
       "19  -1.026065  \n",
       "31  -0.119103  \n",
       "39  -0.551440  \n",
       "14   0.516312  \n",
       "43   0.279144  \n",
       "69   0.325227  \n",
       "18  -0.053879  \n",
       "3   -0.260920  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian2(original_sample, data=data, std_per_var=std_per_var):\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian_2 = np.empty(features.shape)\n",
    "for i, sample in enumerate(features):\n",
    "    noisy_features_gaussian_2[i, :] = generate_noisy_sample_gaussian2(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian_2 = np.c_[labels, noisy_features_gaussian_2]\n",
    "\n",
    "noisy_data_gaussian_2 = pd.concat([data, pd.DataFrame(noisy_features_gaussian_2, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian_2 = noisy_data_gaussian_2.sample(frac=1, random_state=0)\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian_2.shape))\n",
    "noisy_data_gaussian_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ca27980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 100.00%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_gaussian_2)\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [10, 50, 100, 200, 400]\n",
    "}\n",
    "grid_search_RF = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF.fit(X_train, y_train)\n",
    "model_RF_opt = grid_search_RF.best_estimator_\n",
    "# Predicción en partición de test\n",
    "y_pred_RF = model_RF_opt.predict(X_test)\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8603",
   "metadata": {},
   "source": [
    "### Ruido uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "724ab306",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_var = features_tot.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10a75640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.202288</td>\n",
       "      <td>0.372532</td>\n",
       "      <td>0.150380</td>\n",
       "      <td>0.407759</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.353758</td>\n",
       "      <td>-0.188391</td>\n",
       "      <td>0.030450</td>\n",
       "      <td>0.039601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341341</td>\n",
       "      <td>-1.454827</td>\n",
       "      <td>-1.091146</td>\n",
       "      <td>0.337247</td>\n",
       "      <td>-0.959441</td>\n",
       "      <td>0.358669</td>\n",
       "      <td>-0.524144</td>\n",
       "      <td>0.914417</td>\n",
       "      <td>1.350999</td>\n",
       "      <td>0.751747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.138510</td>\n",
       "      <td>0.258360</td>\n",
       "      <td>-0.510770</td>\n",
       "      <td>-0.457780</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>-0.344340</td>\n",
       "      <td>-0.283480</td>\n",
       "      <td>-0.380750</td>\n",
       "      <td>-0.339130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>-0.896406</td>\n",
       "      <td>-1.232269</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>-0.817785</td>\n",
       "      <td>-0.419049</td>\n",
       "      <td>-1.509745</td>\n",
       "      <td>-0.946138</td>\n",
       "      <td>0.259551</td>\n",
       "      <td>-1.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>-0.303650</td>\n",
       "      <td>0.592750</td>\n",
       "      <td>-0.170640</td>\n",
       "      <td>-0.143090</td>\n",
       "      <td>-0.471900</td>\n",
       "      <td>-0.180450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527436</td>\n",
       "      <td>-0.014958</td>\n",
       "      <td>-0.682168</td>\n",
       "      <td>0.114895</td>\n",
       "      <td>1.148412</td>\n",
       "      <td>0.434126</td>\n",
       "      <td>1.696830</td>\n",
       "      <td>-0.434430</td>\n",
       "      <td>0.094033</td>\n",
       "      <td>-0.119103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076708</td>\n",
       "      <td>-0.346198</td>\n",
       "      <td>-0.589250</td>\n",
       "      <td>-0.519481</td>\n",
       "      <td>-0.326876</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>-0.115382</td>\n",
       "      <td>0.309488</td>\n",
       "      <td>0.070546</td>\n",
       "      <td>...</td>\n",
       "      <td>1.267428</td>\n",
       "      <td>-0.906161</td>\n",
       "      <td>0.096122</td>\n",
       "      <td>0.789345</td>\n",
       "      <td>0.774628</td>\n",
       "      <td>0.881908</td>\n",
       "      <td>0.527217</td>\n",
       "      <td>2.450039</td>\n",
       "      <td>2.515586</td>\n",
       "      <td>-0.419105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285998</td>\n",
       "      <td>-0.059588</td>\n",
       "      <td>-0.172470</td>\n",
       "      <td>-0.314231</td>\n",
       "      <td>0.339094</td>\n",
       "      <td>0.219968</td>\n",
       "      <td>0.197160</td>\n",
       "      <td>-0.158582</td>\n",
       "      <td>0.361832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104367</td>\n",
       "      <td>-0.169663</td>\n",
       "      <td>-0.306278</td>\n",
       "      <td>1.186990</td>\n",
       "      <td>-1.057866</td>\n",
       "      <td>0.846419</td>\n",
       "      <td>0.678672</td>\n",
       "      <td>0.437749</td>\n",
       "      <td>-0.499953</td>\n",
       "      <td>0.648647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386970</td>\n",
       "      <td>0.139220</td>\n",
       "      <td>-0.221020</td>\n",
       "      <td>-0.216810</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.333490</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>0.306680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012167</td>\n",
       "      <td>1.308194</td>\n",
       "      <td>-1.412457</td>\n",
       "      <td>1.490609</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>0.565845</td>\n",
       "      <td>-0.988205</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>0.279144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249280</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>-0.305730</td>\n",
       "      <td>-0.099511</td>\n",
       "      <td>0.487854</td>\n",
       "      <td>-0.124822</td>\n",
       "      <td>-0.108838</td>\n",
       "      <td>0.333928</td>\n",
       "      <td>0.365122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389263</td>\n",
       "      <td>1.207788</td>\n",
       "      <td>-0.319200</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.507993</td>\n",
       "      <td>1.242028</td>\n",
       "      <td>-1.187978</td>\n",
       "      <td>-0.311825</td>\n",
       "      <td>1.130247</td>\n",
       "      <td>0.457562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.553698</td>\n",
       "      <td>0.246012</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.281089</td>\n",
       "      <td>0.597594</td>\n",
       "      <td>0.208428</td>\n",
       "      <td>-0.073450</td>\n",
       "      <td>-0.503602</td>\n",
       "      <td>-0.101518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658334</td>\n",
       "      <td>-0.651477</td>\n",
       "      <td>-0.683628</td>\n",
       "      <td>-0.944904</td>\n",
       "      <td>0.567008</td>\n",
       "      <td>1.646727</td>\n",
       "      <td>0.704488</td>\n",
       "      <td>1.450657</td>\n",
       "      <td>-0.151315</td>\n",
       "      <td>0.078456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310295</td>\n",
       "      <td>0.069970</td>\n",
       "      <td>-0.068285</td>\n",
       "      <td>-0.128501</td>\n",
       "      <td>0.573024</td>\n",
       "      <td>0.271528</td>\n",
       "      <td>-0.036618</td>\n",
       "      <td>-0.301912</td>\n",
       "      <td>-0.015966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152198</td>\n",
       "      <td>-0.387212</td>\n",
       "      <td>-0.266698</td>\n",
       "      <td>-0.719916</td>\n",
       "      <td>-1.431263</td>\n",
       "      <td>-0.161502</td>\n",
       "      <td>-1.470127</td>\n",
       "      <td>0.703346</td>\n",
       "      <td>0.073186</td>\n",
       "      <td>-0.128584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "60    1.0  0.202288  0.372532  0.150380  0.407759  0.447514  0.353758   \n",
       "19    1.0 -0.138510  0.258360 -0.510770 -0.457780 -0.440400 -0.344340   \n",
       "31    0.0  0.216780  0.270110  0.087964 -0.303650  0.592750 -0.170640   \n",
       "39    1.0  0.076708 -0.346198 -0.589250 -0.519481 -0.326876  0.026335   \n",
       "14    1.0  0.285998 -0.059588 -0.172470 -0.314231  0.339094  0.219968   \n",
       "43    0.0  0.386970  0.139220 -0.221020 -0.216810 -0.017924  0.139650   \n",
       "69    0.0  0.249280 -0.074078 -0.305730 -0.099511  0.487854 -0.124822   \n",
       "18    1.0  0.553698  0.246012  0.159200  0.281089  0.597594  0.208428   \n",
       "3     0.0  0.310295  0.069970 -0.068285 -0.128501  0.573024  0.271528   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "60 -0.188391  0.030450  0.039601  ...  -0.341341  -1.454827  -1.091146   \n",
       "19 -0.283480 -0.380750 -0.339130  ...  -0.038365  -0.896406  -1.232269   \n",
       "31 -0.143090 -0.471900 -0.180450  ...  -1.527436  -0.014958  -0.682168   \n",
       "39 -0.115382  0.309488  0.070546  ...   1.267428  -0.906161   0.096122   \n",
       "14  0.197160 -0.158582  0.361832  ...   0.104367  -0.169663  -0.306278   \n",
       "43  0.333490  0.412210  0.306680  ...   1.012167   1.308194  -1.412457   \n",
       "69 -0.108838  0.333928  0.365122  ...   0.389263   1.207788  -0.319200   \n",
       "18 -0.073450 -0.503602 -0.101518  ...   0.658334  -0.651477  -0.683628   \n",
       "3  -0.036618 -0.301912 -0.015966  ...  -0.152198  -0.387212  -0.266698   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "60   0.337247  -0.959441   0.358669  -0.524144   0.914417   1.350999   \n",
       "19   0.785572  -0.817785  -0.419049  -1.509745  -0.946138   0.259551   \n",
       "31   0.114895   1.148412   0.434126   1.696830  -0.434430   0.094033   \n",
       "39   0.789345   0.774628   0.881908   0.527217   2.450039   2.515586   \n",
       "14   1.186990  -1.057866   0.846419   0.678672   0.437749  -0.499953   \n",
       "43   1.490609   0.081146   0.564483   0.565845  -0.988205   0.014638   \n",
       "69   0.122495   0.507993   1.242028  -1.187978  -0.311825   1.130247   \n",
       "18  -0.944904   0.567008   1.646727   0.704488   1.450657  -0.151315   \n",
       "3   -0.719916  -1.431263  -0.161502  -1.470127   0.703346   0.073186   \n",
       "\n",
       "    SBM_map75  \n",
       "10   1.003364  \n",
       "60   0.751747  \n",
       "19  -1.026065  \n",
       "31  -0.119103  \n",
       "39  -0.419105  \n",
       "14   0.648647  \n",
       "43   0.279144  \n",
       "69   0.457562  \n",
       "18   0.078456  \n",
       "3   -0.128584  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_uniform(original_sample, data=data, std_per_var=std_per_var, \n",
    "                          min_per_var=min_per_var, max_per_var=max_per_var):\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.uniform(avg_per_var[j]-std_per_var[j], avg_per_var[j]+std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_uniform = np.empty(features.shape)\n",
    "for i, sample in enumerate(features):\n",
    "    noisy_features_uniform[i, :] = generate_noisy_sample_uniform(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_uniform = np.c_[labels, noisy_features_uniform]\n",
    "\n",
    "noisy_data_uniform = pd.concat([data, pd.DataFrame(noisy_features_uniform, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_uniform = noisy_data_uniform.sample(frac=1, random_state=0)\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_uniform.shape))\n",
    "noisy_data_uniform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6615e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 91.43%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_uniform)\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [10, 50, 100, 200, 400]\n",
    "}\n",
    "grid_search_RF = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF.fit(X_train, y_train)\n",
    "model_RF_opt = grid_search_RF.best_estimator_\n",
    "# Predicción en partición de test\n",
    "y_pred_RF = model_RF_opt.predict(X_test)\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851437dd",
   "metadata": {},
   "source": [
    "# Pseudo-labeling\n",
    "\n",
    "https://towardsdatascience.com/pseudo-labeling-to-deal-with-small-datasets-what-why-how-fd6f903213af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac493413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c498e7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 5s 7ms/step - loss: 0.7258 - acc: 0.5294\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7108 - acc: 0.5147\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6851 - acc: 0.6324\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.6644 - acc: 0.5588\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5937 - acc: 0.7500\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5847 - acc: 0.7647\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 152us/step - loss: 0.5666 - acc: 0.7500\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4907 - acc: 0.8529\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 742us/step - loss: 0.3897 - acc: 0.8971\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3856 - acc: 0.8235\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3443 - acc: 0.9118\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2270 - acc: 0.9412\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.2743 - acc: 0.9265\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1156 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.1362 - acc: 0.9706\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1105 - acc: 0.9412\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1102 - acc: 0.9706\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0479 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0546 - acc: 0.9853\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 900us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0413 - acc: 0.9706\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0254 - acc: 0.9853\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0013 - acc: 1.0000 \n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 5.6932e-04 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.8070e-04 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.5068e-04 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.6240e-04 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 844us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.4341e-04 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.0906e-04 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.9860e-04 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.0276e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 2.8023e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.8007e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 280us/step - loss: 6.7793e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3037e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.7181e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.6252e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.2535e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 5.9453e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.2236e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2089e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4848e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9520e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 8.8861e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9468e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.7732e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.4527e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.6289e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2541e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 3.2709e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.7995e-05 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.4747e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.1290e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0165 - acc: 0.9853\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.0138e-04 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 751us/step - loss: 3.0826e-04 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 8.4125e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 2.7895e-04 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.8636e-04 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.2561e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 1.9847e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.8842e-04 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0744e-04 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.9394e-04 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.9355e-04 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.4630e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 7.7086e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 2.8224e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 0s/step - loss: 1.3728e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.6997e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.0528e-04 - acc: 1.0000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.1700 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "modelFC.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e57be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_epoch(epoch, val, start, stop):\n",
    "    if epoch < start:\n",
    "        alpha = 0\n",
    "    elif epoch < stop:\n",
    "        alpha = ((epoch-start) / (stop-start)) * val\n",
    "    else:\n",
    "        alpha = val\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc03928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119816, 410)\n",
      "2/2 [==============================] - 2s 155ms/step - loss: 0.6907 - acc: 0.5686 - val_loss: 0.7020 - val_acc: 0.4706\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6811 - acc: 0.5098 - val_loss: 0.6946 - val_acc: 0.4118\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6635 - acc: 0.6078 - val_loss: 0.6874 - val_acc: 0.4706\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6145 - acc: 0.6275 - val_loss: 0.6827 - val_acc: 0.5294\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6082 - acc: 0.7255 - val_loss: 0.6780 - val_acc: 0.5294\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5824 - acc: 0.7059 - val_loss: 0.6692 - val_acc: 0.5294\n",
      "2/2 [==============================] - 3s 149ms/step - loss: 0.5391 - acc: 0.7451 - val_loss: 0.6608 - val_acc: 0.5882\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.4820 - acc: 0.7843 - val_loss: 0.6542 - val_acc: 0.5882\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3530 - acc: 0.9216 - val_loss: 0.6513 - val_acc: 0.6471\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4078 - acc: 0.8235 - val_loss: 0.6551 - val_acc: 0.5882\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3036 - acc: 0.9020 - val_loss: 0.6674 - val_acc: 0.5882\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2389 - acc: 0.9412 - val_loss: 0.6882 - val_acc: 0.5882\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.1565 - acc: 0.9804 - val_loss: 0.7318 - val_acc: 0.6471\n",
      "2/2 [==============================] - 12s 2s/step - loss: 0.1538 - acc: 0.9608 - val_loss: 0.8028 - val_acc: 0.7059\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0708 - acc: 0.9804 - val_loss: 0.9074 - val_acc: 0.7647\n",
      "2/2 [==============================] - 8s 1s/step - loss: 0.0830 - acc: 0.9608 - val_loss: 0.9587 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0639 - acc: 0.9804 - val_loss: 1.0389 - val_acc: 0.8235\n",
      "2/2 [==============================] - 6s 484ms/step - loss: 0.1047 - acc: 0.9412 - val_loss: 0.9212 - val_acc: 0.7059\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.9023 - val_acc: 0.6471\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.9577 - val_acc: 0.7059\n",
      "2/2 [==============================] - 1s 602ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0321 - val_acc: 0.5882\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0266 - acc: 1.0000 - val_loss: 1.0335 - val_acc: 0.6471\n",
      "2/2 [==============================] - 0s 341ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 1.0121 - val_acc: 0.6471\n",
      "2/2 [==============================] - 0s 303ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.0799 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 1.1131 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.1748 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 360ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.2395 - val_acc: 0.8235\n",
      "2/2 [==============================] - 4s 2s/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.3017 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 351ms/step - loss: 6.7964e-04 - acc: 1.0000 - val_loss: 1.3535 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.3591e-04 - acc: 1.0000 - val_loss: 1.3934 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.4200 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 3.9278e-04 - acc: 1.0000 - val_loss: 1.4390 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.4217 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 7.9479e-04 - acc: 1.0000 - val_loss: 1.3974 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 9.9088e-04 - acc: 1.0000 - val_loss: 1.3781 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 5.9080e-04 - acc: 1.0000 - val_loss: 1.3593 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.3362 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.3008 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 4.8795e-04 - acc: 1.0000 - val_loss: 1.2773 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 468ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.2991 - val_acc: 0.8235\n",
      "2/2 [==============================] - 1s 769ms/step - loss: 9.2741e-04 - acc: 1.0000 - val_loss: 1.3566 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0265 - acc: 0.9804 - val_loss: 1.1601 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 313ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.0827 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.0552 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0346 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.0225 - val_acc: 0.7647\n",
      "2/2 [==============================] - 1s 1s/step - loss: 8.3341e-04 - acc: 1.0000 - val_loss: 1.0177 - val_acc: 0.7059\n",
      "2/2 [==============================] - 0s 281ms/step - loss: 1.8851e-04 - acc: 1.0000 - val_loss: 1.0203 - val_acc: 0.7059\n",
      "2/2 [==============================] - 1s 521ms/step - loss: 9.0308e-05 - acc: 1.0000 - val_loss: 1.0240 - val_acc: 0.7059\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 8.7484e-04 - acc: 1.0000 - val_loss: 1.0331 - val_acc: 0.7059\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 4.3896e-04 - acc: 1.0000 - val_loss: 1.0525 - val_acc: 0.7647\n",
      "2/2 [==============================] - 1s 737ms/step - loss: 7.2502e-04 - acc: 1.0000 - val_loss: 1.0740 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 412ms/step - loss: 2.4651e-04 - acc: 1.0000 - val_loss: 1.0940 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 2.4045e-04 - acc: 1.0000 - val_loss: 1.1139 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.4168e-04 - acc: 1.0000 - val_loss: 1.1328 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 349ms/step - loss: 3.1235e-04 - acc: 1.0000 - val_loss: 1.1576 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 3.5974e-04 - acc: 1.0000 - val_loss: 1.1854 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 3.4624e-04 - acc: 1.0000 - val_loss: 1.2060 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 7.9270e-04 - acc: 1.0000 - val_loss: 1.2251 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 3.7691e-04 - acc: 1.0000 - val_loss: 1.2415 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.2506 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9.6877e-05 - acc: 1.0000 - val_loss: 1.2531 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.7054e-04 - acc: 1.0000 - val_loss: 1.2561 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 2.7289e-04 - acc: 1.0000 - val_loss: 1.2624 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.6181e-04 - acc: 1.0000 - val_loss: 1.2642 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.2648e-04 - acc: 1.0000 - val_loss: 1.2713 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.8586e-04 - acc: 1.0000 - val_loss: 1.2776 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 8.9200e-04 - acc: 1.0000 - val_loss: 1.2974 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.4687 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 4.4216e-04 - acc: 1.0000 - val_loss: 1.7446 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.9222e-04 - acc: 1.0000 - val_loss: 1.9725 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 378ms/step - loss: 1.3952e-04 - acc: 1.0000 - val_loss: 2.1489 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0173 - acc: 0.9804 - val_loss: 2.1528 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.0616 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.9488e-04 - acc: 1.0000 - val_loss: 1.9959 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.1115e-04 - acc: 1.0000 - val_loss: 1.9384 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.8899e-04 - acc: 1.0000 - val_loss: 1.8894 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.7041e-04 - acc: 1.0000 - val_loss: 1.8514 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 4.8155e-05 - acc: 1.0000 - val_loss: 1.8200 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9.0943e-05 - acc: 1.0000 - val_loss: 1.7938 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 7.5349e-05 - acc: 1.0000 - val_loss: 1.7707 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9.6982e-05 - acc: 1.0000 - val_loss: 1.7508 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2.1590e-04 - acc: 1.0000 - val_loss: 1.7327 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 5.0312e-05 - acc: 1.0000 - val_loss: 1.7185 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.9761e-05 - acc: 1.0000 - val_loss: 1.7075 - val_acc: 0.8235\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0656e-04 - acc: 1.0000 - val_loss: 1.6992 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.6560e-04 - acc: 1.0000 - val_loss: 1.6965 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.5041e-04 - acc: 1.0000 - val_loss: 1.6951 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6.3718e-04 - acc: 1.0000 - val_loss: 1.6996 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.3516e-04 - acc: 1.0000 - val_loss: 1.7049 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.7228 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.2461e-05 - acc: 1.0000 - val_loss: 1.7386 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 7.4869e-05 - acc: 1.0000 - val_loss: 1.7524 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 8.2533e-05 - acc: 1.0000 - val_loss: 1.7628 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.0916e-05 - acc: 1.0000 - val_loss: 1.7716 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.9868e-05 - acc: 1.0000 - val_loss: 1.7791 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.1162e-05 - acc: 1.0000 - val_loss: 1.7873 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 5.2705e-04 - acc: 1.0000 - val_loss: 1.8013 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 7.3461e-05 - acc: 1.0000 - val_loss: 1.8193 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 4.6434e-04 - acc: 1.0000 - val_loss: 1.8163 - val_acc: 0.8235\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dropout(0.3))\n",
    "modelFC.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "X_tot = np.concatenate((X_train, test))\n",
    "y_train = np.reshape(y_train.to_numpy(), (68, 1))\n",
    "for i in range(1, 101): # 100 épocas\n",
    "    pseudolabels = modelFC.predict(test)\n",
    "    y_tot = np.concatenate((y_train, pseudolabels))\n",
    "    alpha = alpha_epoch(i, 2, 20, 80)\n",
    "    samples = np.concatenate((np.ones(len(y_train)), alpha*np.ones(len(pseudolabels))))\n",
    "    modelFC.fit(X_train, y_train, sample_weight=samples, epochs=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa3e209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step - loss: 1.3676 - acc: 0.7778\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b90ae",
   "metadata": {},
   "source": [
    "# Create submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "021cfa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "def create_submission(pred, test_id=testFNC[\"Id\"]):\n",
    "    submissionDF = pd.DataFrame(list(zip(test_id, pred)), columns=[\"Id\", \"Probability\"])\n",
    "    print(submissionDF.shape) # Comprobación del tamaño, debe ser: (119748, 2)\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y_%Hh%Mmin\")\n",
    "    current_path = pathlib.Path().resolve()\n",
    "    submissionDF.to_csv(f\"{current_path}\\submissions\\MLSP_submission_DataAug_{current_time}.csv\", header=True, index=False)\n",
    "    \n",
    "create_submission(pred=model_RF_opt.predict(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
