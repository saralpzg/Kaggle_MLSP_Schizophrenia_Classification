{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebce530",
   "metadata": {},
   "source": [
    "# Variational Autoencoder\n",
    "\n",
    "Un modelo variational autoencoder (VAE) consiste en un modelo de autoencoder en el que hay ciertas restricciones añadidas, de modo que en lugar de aprender una función arbitraria que se encarga de la compresión (parte encoder) de los datos de entrada, aprende los parámetros de una función de distribución que modelaría estos datos. De este modo, si generamos una muestra a partir ded esta función de distribución, estaremos simulando una nueva muestra para nuestro problema.\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59228c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data partition\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Parameter tunning libraries\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Accuracy function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352eefdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>0.216620</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.353800</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.133020</td>\n",
       "      <td>-0.035222</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257114</td>\n",
       "      <td>0.597229</td>\n",
       "      <td>1.220756</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>-0.435494</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>1.090910</td>\n",
       "      <td>-0.448562</td>\n",
       "      <td>-0.508497</td>\n",
       "      <td>0.350434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.410730</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.242260</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>0.599790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050862</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>0.609465</td>\n",
       "      <td>1.181878</td>\n",
       "      <td>-2.279469</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>-0.012693</td>\n",
       "      <td>-1.244346</td>\n",
       "      <td>-1.080442</td>\n",
       "      <td>-0.788502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.318170</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.539922</td>\n",
       "      <td>-1.495822</td>\n",
       "      <td>1.643866</td>\n",
       "      <td>1.687780</td>\n",
       "      <td>1.521086</td>\n",
       "      <td>-1.988432</td>\n",
       "      <td>-0.267471</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>1.104566</td>\n",
       "      <td>-1.067206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.112830</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0.202750</td>\n",
       "      <td>0.191420</td>\n",
       "      <td>-0.056662</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.593326</td>\n",
       "      <td>1.063052</td>\n",
       "      <td>0.434726</td>\n",
       "      <td>1.604964</td>\n",
       "      <td>-0.359736</td>\n",
       "      <td>0.210107</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>-0.323557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "2       0  0.245850  0.216620 -0.124680 -0.353800  0.161500 -0.002032   \n",
       "13      1  0.410730 -0.031925  0.210700  0.242260  0.320100 -0.419290   \n",
       "53      1  0.070919  0.034179 -0.011755  0.019158  0.024645 -0.032022   \n",
       "41      0  0.087377 -0.052462 -0.007835 -0.112830  0.389380  0.216080   \n",
       "74      0  0.202750  0.191420 -0.056662 -0.157780  0.244040  0.039780   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "2  -0.133020 -0.035222  0.259040  ...  -0.257114   0.597229   1.220756   \n",
       "13 -0.187140  0.168450  0.599790  ...  -0.050862   0.870602   0.609465   \n",
       "53  0.004620  0.318170  0.212550  ...  -1.539922  -1.495822   1.643866   \n",
       "41  0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "74 -0.001503  0.001056 -0.048222  ...   0.044457   0.593326   1.063052   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "2   -0.059213  -0.435494  -0.092971   1.090910  -0.448562  -0.508497   \n",
       "13   1.181878  -2.279469  -0.013484  -0.012693  -1.244346  -1.080442   \n",
       "53   1.687780   1.521086  -1.988432  -0.267471   0.510576   1.104566   \n",
       "41  -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "74   0.434726   1.604964  -0.359736   0.210107   0.355922   0.730287   \n",
       "\n",
       "    SBM_map75  \n",
       "2    0.350434  \n",
       "13  -0.788502  \n",
       "53  -1.067206  \n",
       "41  -0.260920  \n",
       "74  -0.323557  \n",
       "\n",
       "[5 rows x 411 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de entrenamiento\n",
    "trainFNC = pd.read_csv(\"../data/train_FNC.csv\")\n",
    "trainSBM = pd.read_csv(\"../data/train_SBM.csv\")\n",
    "train_labels = pd.read_csv(\"../data/train_labels.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "train = pd.merge(left=trainFNC, right=trainSBM, left_on=\"Id\", right_on=\"Id\")\n",
    "data = pd.merge(left=train_labels, right=train, left_on=\"Id\", right_on=\"Id\")\n",
    "data.drop(\"Id\", inplace=True, axis=1)\n",
    "\n",
    "# Shuffle de los datos de train\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b241a0",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d828656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31de6ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>FNC10</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476127</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>-0.608133</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>-0.637038</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>-0.192434</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.060474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451994</td>\n",
       "      <td>1.123770</td>\n",
       "      <td>2.083006</td>\n",
       "      <td>1.145440</td>\n",
       "      <td>-0.067608</td>\n",
       "      <td>1.202529</td>\n",
       "      <td>0.851587</td>\n",
       "      <td>0.451583</td>\n",
       "      <td>-0.159739</td>\n",
       "      <td>0.192076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.267183</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>-0.261327</td>\n",
       "      <td>0.191869</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>0.088761</td>\n",
       "      <td>0.177048</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696987</td>\n",
       "      <td>1.397832</td>\n",
       "      <td>1.046136</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>-2.192023</td>\n",
       "      <td>-0.369276</td>\n",
       "      <td>0.822225</td>\n",
       "      <td>-0.109342</td>\n",
       "      <td>-0.580476</td>\n",
       "      <td>0.174160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.435452</td>\n",
       "      <td>0.046780</td>\n",
       "      <td>0.243742</td>\n",
       "      <td>0.397030</td>\n",
       "      <td>-0.147821</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>-0.461963</td>\n",
       "      <td>-0.610736</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.400985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>1.906989</td>\n",
       "      <td>-2.661633</td>\n",
       "      <td>-0.193911</td>\n",
       "      <td>0.440873</td>\n",
       "      <td>0.641739</td>\n",
       "      <td>0.918397</td>\n",
       "      <td>-0.758046</td>\n",
       "      <td>0.154701</td>\n",
       "      <td>-0.476647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.204510</td>\n",
       "      <td>-0.036735</td>\n",
       "      <td>-0.760705</td>\n",
       "      <td>-0.740495</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>0.349926</td>\n",
       "      <td>-0.273826</td>\n",
       "      <td>-0.174384</td>\n",
       "      <td>-0.120248</td>\n",
       "      <td>0.175618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974828</td>\n",
       "      <td>-1.997087</td>\n",
       "      <td>-2.083782</td>\n",
       "      <td>1.154107</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>2.332424</td>\n",
       "      <td>0.659124</td>\n",
       "      <td>-0.809445</td>\n",
       "      <td>0.558960</td>\n",
       "      <td>2.790871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599435</td>\n",
       "      <td>-0.166441</td>\n",
       "      <td>0.122431</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.346906</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.274734</td>\n",
       "      <td>0.211510</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-0.033434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.789153</td>\n",
       "      <td>1.578984</td>\n",
       "      <td>1.402592</td>\n",
       "      <td>-1.230440</td>\n",
       "      <td>0.296686</td>\n",
       "      <td>2.806314</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>-0.240682</td>\n",
       "      <td>-0.196948</td>\n",
       "      <td>-1.544345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FNC1      FNC2      FNC3      FNC4      FNC5      FNC6      FNC7  \\\n",
       "0  0.476127  0.064466  0.053238 -0.608133  0.073988 -0.637038  0.113556   \n",
       "1  0.013833  0.267183  0.232178 -0.167151 -0.261327  0.191869  0.406493   \n",
       "2 -0.435452  0.046780  0.243742  0.397030 -0.147821  0.173620 -0.461963   \n",
       "3 -0.204510 -0.036735 -0.760705 -0.740495  0.064668  0.349926 -0.273826   \n",
       "4  0.599435 -0.166441  0.122431  0.011539  0.346906 -0.017430 -0.274734   \n",
       "\n",
       "       FNC8      FNC9     FNC10  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "0 -0.192434 -0.004025 -0.060474  ...  -0.451994   1.123770   2.083006   \n",
       "1  0.088761  0.177048  0.036718  ...   0.696987   1.397832   1.046136   \n",
       "2 -0.610736  0.419753  0.400985  ...   0.160145   1.906989  -2.661633   \n",
       "3 -0.174384 -0.120248  0.175618  ...   0.974828  -1.997087  -2.083782   \n",
       "4  0.211510  0.151012 -0.033434  ...  -0.789153   1.578984   1.402592   \n",
       "\n",
       "   SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  SBM_map75  \n",
       "0   1.145440  -0.067608   1.202529   0.851587   0.451583  -0.159739   0.192076  \n",
       "1  -0.191733  -2.192023  -0.369276   0.822225  -0.109342  -0.580476   0.174160  \n",
       "2  -0.193911   0.440873   0.641739   0.918397  -0.758046   0.154701  -0.476647  \n",
       "3   1.154107  -0.643947   2.332424   0.659124  -0.809445   0.558960   2.790871  \n",
       "4  -1.230440   0.296686   2.806314   0.427184  -0.240682  -0.196948  -1.544345  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de test\n",
    "testFNC = pd.read_csv(\"../data/test_FNC.csv\")\n",
    "testSBM = pd.read_csv(\"../data/test_SBM.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "test_kaggle = pd.merge(left=testFNC, right=testSBM, left_on=\"Id\", right_on=\"Id\")\n",
    "test_kaggle.drop(\"Id\", inplace=True, axis=1)\n",
    "test_kaggle.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46df4879",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "\n",
    "Para crear el variational autoencoder, se utilizarán redes simétricas.\n",
    "\n",
    "Fuente funciones de sampling: https://learnopencv.com/variational-autoencoder-in-tensorflow/#network-fmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966f963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "input_layer = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded = layers.Dense(200, activation=\"relu\")(input_layer)\n",
    "encoded = layers.Dense(100, activation=\"relu\")(encoded)\n",
    "encoded = layers.Dense(50, activation=\"relu\")(encoded)\n",
    "mean = layers.Dense(2, name=\"mean\")(encoded) # PQ 2 UNIDADES???\n",
    "log_var = layers.Dense(2, name=\"log_var\")(encoded)\n",
    "\n",
    "def sampling_reparameterization(distribution_params):\n",
    "    mean, log_var = distribution_params\n",
    "    epsilon = backend.random_normal(shape=backend.shape(mean), mean=0., stddev=1.)\n",
    "    z = mean + backend.exp(log_var / 2) * epsilon # POR QUÉ ESTA DISTRIBUCIÓN??\n",
    "    return z\n",
    "# Capa red sampler\n",
    "sampler = layers.Lambda(sampling_reparameterization)([mean, log_var])\n",
    "\n",
    "# Capas red decoder\n",
    "decoded = layers.Dense(50, activation=\"relu\")(sampler)\n",
    "decoded = layers.Dense(100, activation=\"relu\")(decoded)\n",
    "decoded = layers.Dense(200, activation=\"relu\")(decoded)\n",
    "decoded = layers.Dense(410)(decoded)\n",
    "\n",
    "\n",
    "# Encoder\n",
    "encoder = models.Model(input_layer, (mean, log_var), name=\"Encoder\")\n",
    "# Sampler \n",
    "sampler = models.Model([mean,log_var], sampler,  name=\"Encoder_2\")\n",
    "# Variational Autoencoder\n",
    "vae = models.Model(input_layer, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cfd0ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1404/1404 [==============================] - 12s 5ms/step - loss: 0.1817 - val_loss: 0.1792\n",
      "Epoch 2/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1779 - val_loss: 0.1778\n",
      "Epoch 3/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1772 - val_loss: 0.1775\n",
      "Epoch 4/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1769 - val_loss: 0.1774\n",
      "Epoch 5/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1762 - val_loss: 0.1764\n",
      "Epoch 6/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1757 - val_loss: 0.1758\n",
      "Epoch 7/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1755 - val_loss: 0.1767\n",
      "Epoch 8/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1755 - val_loss: 0.1751\n",
      "Epoch 9/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1753 - val_loss: 0.1758\n",
      "Epoch 10/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1755 - val_loss: 0.1757\n",
      "Epoch 11/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1752 - val_loss: 0.1759\n",
      "Epoch 12/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1753 - val_loss: 0.1759\n",
      "Epoch 13/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1753 - val_loss: 0.1761\n",
      "Epoch 14/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1751 - val_loss: 0.1758\n",
      "Epoch 15/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1747 - val_loss: 0.1754\n",
      "Epoch 16/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1752 - val_loss: 0.1758\n",
      "Epoch 17/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1756 - val_loss: 0.1766\n",
      "Epoch 18/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1758 - val_loss: 0.1769\n",
      "Epoch 19/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1758 - val_loss: 0.1765\n",
      "Epoch 20/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1748 - val_loss: 0.1764\n",
      "Epoch 21/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1750 - val_loss: 0.1753\n",
      "Epoch 22/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1756 - val_loss: 0.1765\n",
      "Epoch 23/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1757 - val_loss: 0.1757\n",
      "Epoch 24/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1754 - val_loss: 0.1761\n",
      "Epoch 25/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1752 - val_loss: 0.1753\n",
      "Epoch 26/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1748 - val_loss: 0.1765\n",
      "Epoch 27/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1750 - val_loss: 0.1787\n",
      "Epoch 28/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1757 - val_loss: 0.1767\n",
      "Epoch 29/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1762 - val_loss: 0.1778\n",
      "Epoch 30/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1769 - val_loss: 0.1765\n",
      "Epoch 31/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1760 - val_loss: 0.1772\n",
      "Epoch 32/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1762 - val_loss: 0.1760\n",
      "Epoch 33/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1758 - val_loss: 0.1766\n",
      "Epoch 34/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1762 - val_loss: 0.1776\n",
      "Epoch 35/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1764 - val_loss: 0.1764\n",
      "Epoch 36/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1760 - val_loss: 0.1777\n",
      "Epoch 37/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1762 - val_loss: 0.1763\n",
      "Epoch 38/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1762 - val_loss: 0.1779\n",
      "Epoch 39/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1761 - val_loss: 0.1769\n",
      "Epoch 40/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1758 - val_loss: 0.1767\n",
      "Epoch 41/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1759 - val_loss: 0.1769\n",
      "Epoch 42/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1762 - val_loss: 0.1762\n",
      "Epoch 43/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1756 - val_loss: 0.1760\n",
      "Epoch 44/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1759 - val_loss: 0.1762\n",
      "Epoch 45/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1760 - val_loss: 0.1760\n",
      "Epoch 46/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1759 - val_loss: 0.1762\n",
      "Epoch 47/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.1763 - val_loss: 0.1759\n",
      "Epoch 48/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1758 - val_loss: 0.1760\n",
      "Epoch 49/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1757 - val_loss: 0.1762\n",
      "Epoch 50/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1763 - val_loss: 0.1775\n",
      "Epoch 51/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1767 - val_loss: 0.1774\n",
      "Epoch 52/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1767 - val_loss: 0.1764\n",
      "Epoch 53/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1760 - val_loss: 0.1761\n",
      "Epoch 54/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1762 - val_loss: 0.1767\n",
      "Epoch 55/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1760 - val_loss: 0.1771\n",
      "Epoch 56/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1758 - val_loss: 0.1781\n",
      "Epoch 57/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1756 - val_loss: 0.1762\n",
      "Epoch 58/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1755 - val_loss: 0.1767\n",
      "Epoch 59/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1754 - val_loss: 0.1762\n",
      "Epoch 60/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1762 - val_loss: 0.1770\n",
      "Epoch 61/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1757 - val_loss: 0.1762\n",
      "Epoch 62/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1755 - val_loss: 0.1775\n",
      "Epoch 63/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1752 - val_loss: 0.1752\n",
      "Epoch 64/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1755 - val_loss: 0.1774\n",
      "Epoch 65/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1753 - val_loss: 0.1763\n",
      "Epoch 66/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1756 - val_loss: 0.1766\n",
      "Epoch 67/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1754 - val_loss: 0.1775\n",
      "Epoch 68/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1756 - val_loss: 0.1758\n",
      "Epoch 69/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1756 - val_loss: 0.1758\n",
      "Epoch 70/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1752 - val_loss: 0.1755\n",
      "Epoch 71/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1754 - val_loss: 0.1757\n",
      "Epoch 72/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1752 - val_loss: 0.1758\n",
      "Epoch 73/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1755 - val_loss: 0.1759\n",
      "Epoch 74/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1753 - val_loss: 0.1754\n",
      "Epoch 75/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1752 - val_loss: 0.1771\n",
      "Epoch 76/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1753 - val_loss: 0.1751\n",
      "Epoch 77/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1750 - val_loss: 0.1751\n",
      "Epoch 78/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1750 - val_loss: 0.1751\n",
      "Epoch 79/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1750 - val_loss: 0.1753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1750 - val_loss: 0.1760\n",
      "Epoch 81/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1751 - val_loss: 0.1754\n",
      "Epoch 82/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1754 - val_loss: 0.1759\n",
      "Epoch 83/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1752 - val_loss: 0.1750\n",
      "Epoch 84/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1749 - val_loss: 0.1758\n",
      "Epoch 85/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1749 - val_loss: 0.1758\n",
      "Epoch 86/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1750 - val_loss: 0.1766\n",
      "Epoch 87/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1749 - val_loss: 0.1751\n",
      "Epoch 88/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1748 - val_loss: 0.1755\n",
      "Epoch 89/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1751 - val_loss: 0.1754\n",
      "Epoch 90/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1750 - val_loss: 0.1751\n",
      "Epoch 91/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1751 - val_loss: 0.1753\n",
      "Epoch 92/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1749 - val_loss: 0.1774\n",
      "Epoch 93/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1751 - val_loss: 0.1756\n",
      "Epoch 94/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1748 - val_loss: 0.1796\n",
      "Epoch 95/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1748 - val_loss: 0.1749\n",
      "Epoch 96/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1748 - val_loss: 0.1749\n",
      "Epoch 97/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1749 - val_loss: 0.1754\n",
      "Epoch 98/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.1747 - val_loss: 0.1764\n",
      "Epoch 99/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1750 - val_loss: 0.1759\n",
      "Epoch 100/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.1746 - val_loss: 0.1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22edbf31eb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilar y entrenar el variational autoencoder\n",
    "vae.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "vae.fit(test_kaggle, test_kaggle, epochs=100, batch_size=64, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf8d5421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error in X_train data prediction: tf.Tensor(438.8, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "438.8000538129105"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.losses import MeanSquaredError, MeanAbsolutePercentageError\n",
    "\n",
    "# Precisión en partición de test (datos no etiquetados)\n",
    "test_kaggle_pred = vae.predict(test_kaggle)\n",
    "\n",
    "# Definición de las métricas\n",
    "mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "mape = MeanAbsolutePercentageError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "# print(\"Mean squared error in X_train data prediction:\", mse(X_train, X_train_pred).numpy())\n",
    "print(\"Mean absolute percentage error in X_train data prediction:\", mape(test_kaggle.to_numpy()[:, 0], test_kaggle_pred[:, 0]))\n",
    "sum(abs((test_kaggle.to_numpy()[:, 0] - test_kaggle_pred[:, 0]) / test_kaggle.to_numpy()[:, 0])) * (100 / len(test_kaggle_pred[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cc607",
   "metadata": {},
   "source": [
    "# Create submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b548e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "def create_submission(pred, test_id=testFNC[\"Id\"]):\n",
    "    '''\n",
    "    Función para generar un csv con las predicciones de un modelo para participar en la competición de Kaggle\n",
    "    '''\n",
    "    submissionDF = pd.DataFrame(list(zip(test_id, pred)), columns=[\"Id\", \"Probability\"])\n",
    "    print(submissionDF.shape) # Comprobación del tamaño, debe ser: (119748, 2)\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y_%Hh%Mmin\")\n",
    "    current_path = pathlib.Path().resolve()\n",
    "    parent_path = current_path.parent\n",
    "    submissionDF.to_csv(f\"{parent_path}\\submissions\\MLSP_submission_VAE_{current_time}.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
