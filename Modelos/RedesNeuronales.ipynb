{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99f259b",
   "metadata": {},
   "source": [
    "# Optimización de un modelo de red neuronal (fully-connected)\n",
    "\n",
    "Este notebook recoge los resultados de la búsqueda del mejor modelo de clasificación mediante una red neuronal densa o fully-connected, ya que el uso de redes convolucionales no parece adecuado para un problema de datos tabulares.\n",
    "\n",
    "Para buscar el mejor modelo posible, se tratará de buscar los mejores hiperparámetros para el número de capas ocultas de la red, su anchura (número de neuronas), posible introducción de términos de regularización, optimizadores, ...\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40286d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librerías de optimización de hiperparámetros\n",
    "import optuna\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar los datos\n",
    "from data_and_submissions import *\n",
    "\n",
    "# Métodos para los entrenamientos con CV\n",
    "from train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea4b44",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3014e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data()\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e18948b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "preprocess = StandardScaler()\n",
    "\n",
    "X_train = preprocess.fit_transform(X_train)\n",
    "X_test = preprocess.fit_transform(X_test)\n",
    "test_kaggle = preprocess.fit_transform(test_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61745a4",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb208b",
   "metadata": {},
   "source": [
    "Para redes neuronales, compararemos los resultados obtenidos construyendo redes a partir de librerías distintas.\n",
    "\n",
    "**Comenzamos con ``MLPClassifier`` de ``sklearn`` y búsqueda de hiperparámetros con ``GridSearchCV``:**\n",
    "\n",
    "Documentación: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b4b39",
   "metadata": {},
   "source": [
    "El método debe recibir arquitecturas de red pre-definidas, por lo que probaremos topologías variadas en cuanto a profundidad, ancho y número de capas.\n",
    "\n",
    "_NOTA: el parámetro ``learning_rate`` sólo se aplica cuando el solver que se esté utilizando sea el \"sgd\", el cual toma el valor constamte por defecto. Podría resultar de especial utilidad cuando toma el valor \"adaptive\", en ese caso mantiene el valor del learning_rate constante mientras la curva de pérdida siga decreciendo, en el momento en que haya dos épocas consecutivas en las que no decrece un mínimo el valor de loss, el learning_rate se divide entre 5._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d163caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_MLPC = MLPClassifier(max_iter=1000, random_state=0)\n",
    "param_grid_MLPC = {\n",
    "    \"hidden_layer_sizes\": [(100, 200, 100, 1), (100, 100, 100, 100, 1), (200, 200, 100, 50, 1), (100, 250, 250, 100, 1)],\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"], # solver \"lbfgs\" no permite hacer los plots más abajo\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"] # únicamente válido junto con el solver \"sgd\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2733f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv_results_MLPC = train_GridSearchCV(model_MLPC, param_grid_MLPC, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d305580c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96fdd2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt = MLPClassifier(activation=\"relu\", hidden_layer_sizes=(100, 250, 250, 100, 1), solver=\"adam\",\n",
    "                               max_iter=1000, random_state=0)\n",
    "model_MLPC_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC = model_MLPC_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b89f6b",
   "metadata": {},
   "source": [
    "_COMPROBACIÓN: la función de activación elegida sólo afecta a las capas ocultas y no a la capa de clasificación en la salida._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8455bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logistic'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLPC_opt.out_activation_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6075466",
   "metadata": {},
   "source": [
    "Las anteriores celdas de código muestran un \"warning\" indicando que el método de computación alcanza el número máximo de iteraciones (épocas de entrenamiento) sin haber llegado a converger.\n",
    "\n",
    "El criterio para considerar que ha habido convergencia está definido en la documentación como: la reducción del valor de la función de loss es inferior a 1e-4 por un número de etapas determinado. \n",
    "\n",
    "La anterior condición por tanto no se está cumpliendo en nuestro entrenamiento, así que vamos a pintar la evolución de la función de pérdida para determinar si estamos cortando el entrenamiento demasiado pronto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a417d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.plot(model_MLPC_opt.loss_curve_)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3d32f",
   "metadata": {},
   "source": [
    "La anterior curva de loss parece tener una tendencia aún claramente descendiente cuando es cortada en la época número 1000. Se va a repetir el entrenamiento incrementando este valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c41d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_MLPC2 = MLPClassifier(max_iter=1500, random_state=0)\n",
    "cv_results_MLPC2 = train_GridSearchCV(model_MLPC2, param_grid_MLPC, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1316b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'identity',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'constant',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'identity',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'invscaling',\n",
       "  'solver': 'adam'},\n",
       " {'activation': 'identity',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC2[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC2, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1039b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "model_MLPC_opt2 = MLPClassifier(activation=\"identity\", hidden_layer_sizes=(200, 200, 100, 50, 1), solver=\"adam\",\n",
    "                                max_iter=1500, random_state=0)\n",
    "model_MLPC_opt2.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC2 = model_MLPC_opt2.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c9b4ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgfUlEQVR4nO3de3hddZ3v8fcnO0kvSa8kTUvvKQUaVEBjQQVBpQiOUvEyFj0O3g4WZXTOzHjEOXO8jGfO44xzZUBrZRgYH50+nBG1jFVARi4CSlOmXNpSSC+0oaVNKSW9p0m+54+9WzZp0qYlKyvZ6/N6nv1kr7V+e+e7uiGfvdb6rd9PEYGZmWVXWdoFmJlZuhwEZmYZ5yAwM8s4B4GZWcY5CMzMMq487QJOVE1NTcyYMSPtMszMhpQVK1bsiIjanrYNuSCYMWMGTU1NaZdhZjakSHqut20+NWRmlnEOAjOzjHMQmJllnIPAzCzjEg0CSZdJWiupWdL1PWwfI+lOSY9LWiXpk0nWY2ZmR0ssCCTlgJuAy4EG4CpJDd2afR5YHRFnAxcDfyupMqmazMzsaEkeEcwFmiNifUS0A0uA+d3aBDBKkoBqYCfQkWBNZmbWTZJBMBnYXLTcUlhX7EZgDrAFeBL4YkR0JVHM2hd2861fPE3bgUNJvL2Z2ZCVZBCoh3XdJz94N7ASOBU4B7hR0uij3ki6RlKTpKbW1taTKmbTzn0sun8d67bvOanXm5mVqiSDoAWYWrQ8hfw3/2KfBO6IvGZgA3Bm9zeKiMUR0RgRjbW1Pd4hfVz1tVUArGvde1KvNzMrVUkGwXJgtqSZhQvAC4Cl3dpsAt4FIKkOOANYn0Qx08aPpLxMrG/1EYGZWbHExhqKiA5J1wF3ATnglohYJWlhYfsi4JvArZKeJH8q6csRsSOJeipyZUwbP5L1PiIwM3uVRAedi4hlwLJu6xYVPd8CXJpkDcXqa6tZv8NHBGZmxTJ1Z/Gs2io27thHZ1f3a9ZmZtmVqSCor62ivbOLlpf2pV2KmdmgkbEgqAbwdQIzsyLZCoKaw11IfZ3AzOywTAXB+KpKxo6sYP0OHxGYmR2WqSCQRH1Nle8lMDMrkqkggEIXUl8jMDM7IoNBUMX23QfZ7cHnzMyALAZBjXsOmZkVy1wQnDYh33PIdxibmeVlLgimja8iVyYfEZiZFWQuCCrLy5g6boSDwMysIHNBAPmeQ76pzMwsL5tBUFPFhh176fLgc2Zm2QyCWROqOdjRxfO79qddiplZ6jIZBIfHHPJQE2ZmCQeBpMskrZXULOn6HrZ/SdLKwuMpSZ2SxidZExSPQurrBGZmiQWBpBxwE3A50ABcJamhuE1EfDsizomIc4CvAPdHxM6kajqsprqSUcPLfcHYzIxkjwjmAs0RsT4i2oElwPxjtL8K+LcE6zlCksccMjMrSDIIJgObi5ZbCuuOImkkcBnw4162XyOpSVJTa2trvxQ3q7bKQWBmRrJBoB7W9dZf833AQ72dFoqIxRHRGBGNtbW1/VLcrNpqXmg7wN6DHf3yfmZmQ1WSQdACTC1angJs6aXtAgbotNBhh3sObXDPITPLuCSDYDkwW9JMSZXk/9gv7d5I0hjgIuBnCdZylMM9h3zB2MyyrjypN46IDknXAXcBOeCWiFglaWFh+6JC0yuBuyNiQL+aTz9lJBKs83UCM8u4xIIAICKWAcu6rVvUbflW4NYk6+jJ8IocU8eN9L0EZpZ5mbyz+LB69xwyM8t4ENRUe/A5M8u8bAdBbRX7D3Wyte1A2qWYmaUm80EAHnPIzLIt00FwWq0nsjczy3QQ1I4aRvWwch8RmFmmZToI8oPPVXleAjPLtEwHAeSHmvCpITPLMgdBbTXP79rPvnYPPmdm2ZT5IJhVuGDswefMLKsyHwSvdCF1EJhZNmU+CGbWVCE5CMwsuzIfBMMrcpw6ZgTrd7gLqZllU+aDAPKnhzwvgZlllYOA/AXjDa17ifDgc2aWPQ4C8hPZ723vZFvbwbRLMTMbcIkGgaTLJK2V1Czp+l7aXCxppaRVku5Psp7e1B8Zc8inh8wsexILAkk54CbgcqABuEpSQ7c2Y4HvAFdExFnAh5Oq51gOdyFd53sJzCyDkjwimAs0R8T6iGgHlgDzu7X5KHBHRGwCiIjtCdbTq4mjhzOyMse67T4iMLPsSTIIJgObi5ZbCuuKnQ6Mk3SfpBWS/qCnN5J0jaQmSU2tra39XqgHnzOzLEsyCNTDuu7dcsqBNwG/B7wb+N+STj/qRRGLI6IxIhpra2v7v1Ly01b6GoGZZVGSQdACTC1angJs6aHNLyNib0TsAB4Azk6wpl7V11bx/K79HDjUmcavNzNLTZJBsByYLWmmpEpgAbC0W5ufARdKKpc0EjgPWJNgTb2qr60mAja+6NNDZpYtiQVBRHQA1wF3kf/jfntErJK0UNLCQps1wC+BJ4BHgZsj4qmkajqW+ppCz6HtDgIzy5byJN88IpYBy7qtW9Rt+dvAt5Osoy88kb2ZZZXvLC4YWVnOqWOGu+eQmWWOg6BIfa17DplZ9jgIitTX5ucv9uBzZpYlDoIi9TVV7D7YQetuDz5nZtnhICgya0J+8Ll1nq3MzDLEQVDkyCiknq3MzDLEQVBk0ujhDK8o8/zFZpYpDoIiZWVipsccMrOMcRB041FIzSxrHATdzKqtZvPOfRzs8OBzZpYNDoJuZtVW0RXw3Iv70i7FzGxAOAi6qa/x/MVmli0Ogm5mHp6/2D2HzCwjHATdVA8rp270MHchNbPMcBD0YFZtNet8asjMMsJB0IP84HN7PPicmWVCokEg6TJJayU1S7q+h+0XS3pZ0srC46tJ1tNX9TXVtB3o4MW97WmXYmaWuMRmKJOUA24C5pGfpH65pKURsbpb0wcj4r1J1XEyXpmtbC811cNSrsbMLFlJHhHMBZojYn1EtANLgPkJ/r5+M6vWXUjNLDuSDILJwOai5ZbCuu7eIulxSb+QdFZPbyTpGklNkppaW1uTqPVVTh07gmHlZb5gbGaZkGQQqId13a++PgZMj4izgX8CftrTG0XE4ohojIjG2tra/q2yB7kyMbOmyl1IzSwTkgyCFmBq0fIUYEtxg4hoi4g9hefLgApJNQnW1GcefM7MsiLJIFgOzJY0U1IlsABYWtxA0kRJKjyfW6jnxQRr6rP6mmo27dxHe0dX2qWYmSUqsV5DEdEh6TrgLiAH3BIRqyQtLGxfBHwIuFZSB7AfWBCDpPP+rAlVdHYFm3bu47TCFJZmZqUosSCAI6d7lnVbt6jo+Y3AjUnWcLIODz737LbdDgIzK2m+s7gXcyaNZtSwcu5/JvleSmZmaXIQ9KKyvIyLzqjlV2u20dk1KM5WmZklwkFwDPMa6tixp52Vm19KuxQzs8Q4CI7hHWdOoCIn7l69Le1SzMwS4yA4htHDKzi//hTuWeUgMLPS5SA4jksb6li/Yy/N2z3chJmVJgfBcVzSUAfA3atfSLkSM7NkOAiOY9KYEbx+8hju8XUCMytRDoI+uLShjpWbd7G97UDapZiZ9TsHQR/MO6uOCPjVmu1pl2Jm1u8cBH1wRt0opo4fwT2+TmBmJahPQSCpSlJZ4fnpkq6QVJFsaYOHJC5tmMhDzS+y52BH2uWYmfWrvh4RPAAMlzQZuBf4JHBrUkUNRvMa6mjv7OIBjz1kZiWmr0GgiNgHfAD4p4i4EmhIrqzBp3H6OMaNrHDvITMrOX0OAklvAT4G/LywLtEhrAeb8lwZ7zyzjnvXbONQpyerMbPS0dcg+CPgK8BPCpPL1AO/TqyqQWpeQx1tBzpYvmFn2qWYmfWbPgVBRNwfEVdExF8VLhrviIgvHO91ki6TtFZSs6Trj9HuzZI6JX3oBGofcG8/vYZh5WUehM7MSkpfew39SNJoSVXAamCtpC8d5zU54CbgcvLXE66SdNR1hUK7vyI/peWgNrKynAtn13DP6m0Mkhk1zcxes76eGmqIiDbg/eSnnpwGfPw4r5kLNEfE+ohoB5YA83to94fAj4EhcbfWvIY6nt+1n9Vb29IuxcysX/Q1CCoK9w28H/hZRBwCjveVeDKwuWi5pbDuiEJ31CuBRRyDpGskNUlqam1Nt/vmu+bUIcHdHprazEpEX4Pge8BGoAp4QNJ04HhfidXDuu7h8Q/AlyOi81hvFBGLI6IxIhpra2v7VnFCaqqH8aZp49yN1MxKRl8vFt8QEZMj4j2R9xzwjuO8rAWYWrQ8BdjSrU0jsETSRuBDwHckvb9Plafo0rPqWL21jZaX9qVdipnZa9bXi8VjJP3d4dMzkv6W/NHBsSwHZkuaKakSWAAsLW4QETMjYkZEzAD+HfhcRPz0hPdigM1rmAjgowIzKwl9PTV0C7Ab+P3Cow34l2O9ICI6gOvI9wZaA9xeuAdhoaSFJ19y+mbWVHHahGoHgZmVhL7eHTwrIj5YtPwNSSuP96KIWEa+l1Hxuh4vDEfEJ/pYy6BwaUMd33tgPS/vO8SYkZkZf8/MSlBfjwj2S7rg8IKktwH7kylpaJjXUEdnV/Cfa31UYGZDW1+PCBYC/yppTGH5JeDqZEoaGs6eMpYJo4Zxz+ptXHnulLTLMTM7aX3tNfR4RJwNvAF4Q0ScC7wz0coGubIycUlDHfetbeXAoWP2fjUzG9ROaIayiGgr3GEM8McJ1DOkzGuoY197J4+sezHtUszMTtprmaqypxvGMuWts06hqjLnQejMbEh7LUGQ+VHXhpXnuPiMCfxqzTa6ujL/z2FmQ9Qxg0DSbkltPTx2A6cOUI2D2ryGOlp3H2Rly660SzEzOynH7DUUEaMGqpCh6h1nTKC8TNyzehtvnDYu7XLMzE7Yazk1ZMCYkRWcVz+eu1e9kHYpZmYnxUHQD+bNqWNd617Wte5JuxQzsxPmIOgH887yIHRmNnQ5CPrB5LEjOOvU0Q4CMxuSHAT95NKGiTy26SVadx9MuxQzsxPiIOgn8xrqiIBfrfFRgZkNLQ6CfjJn0ihmT6jmtoc3EuGby8xs6Eg0CCRdJmmtpGZJ1/ewfb6kJyStLMx8dkFP7zMUSOKzF83i6Rd2c98zrWmXY2bWZ4kFgaQccBNwOdAAXCWpoVuze4GzI+Ic4FPAzUnVMxCuOPtUTh0znO/ety7tUszM+izJI4K5QHNErI+IdmAJML+4QUTsiVfOo1QxxMcvqiwv4zMX1vPohp2seO6ltMsxM+uTJINgMrC5aLmlsO5VJF0p6Wng5+SPCoa0BXOnMnZkBYvu91GBmQ0NSQZBT8NUH/WNPyJ+EhFnAu8HvtnjG0nXFK4hNLW2Du7z7yMry7n6LTO4Z/U2nt22O+1yzMyOK8kgaAGmFi1PAbb01jgiHgBmSarpYdviiGiMiMba2tr+r7SfXf3WGYyoyLHo/vVpl2JmdlxJBsFyYLakmZIqgQXA0uIGkk6TpMLzNwKVwJCf7mt8VSUL5k7lZyuf5/ld+9Mux8zsmBILgojoAK4D7gLWALdHxCpJCyUtLDT7IPCUpJXkexh9JEqkE/5nLqwH4OYHfVRgZoObhtrf3cbGxmhqakq7jD75k9sfZ9mTW3n4+ncyrqoy7XLMLMMkrYiIxp62+c7iBC28qJ79hzq57ZGNaZdiZtYrB0GCZteN4pI5ddz68Eb2tXekXY6ZWY8cBAm79uJZ7Np3iCWPbj5+YzOzFDgIEvam6eOYO3M8Nz+4nkOdXWmXY2Z2FAfBALj24llsefkAS1f2ehuFmVlqHAQD4OLTazlz4igW3b+Orq6h1UvLzEqfg2AASOLai2fx7PY93Pv09rTLMTN7FQfBAPm9109iyrgRfOe+Zk9cY2aDioNggJTnyvjs2+v5r027eHTDzrTLMTM7wkEwgD7cOJVTqir5roeoNrNBxEEwgIZX5PjUBTO5b20ra7a2pV2OmRngIBhw/+386VQPK/fENWY2aDgIBtiYERV89Lxp3Pn4Fja9uC/tcszMHARp+PQFMykvK+P7HqLazAYBB0EK6kYP5wNvnMztTZtp3X0w7XLMLOMcBCm55u31tHd2cctDG9IuxcwyLtEgkHSZpLWSmiVd38P2j0l6ovB4WNLZSdYzmNTXVnPF2afyz7/ZwMYde9Mux8wyLLEgkJQjP/3k5UADcJWkhm7NNgAXRcQbgG8Ci5OqZzD6s/fMoTJXxleXrvLdxmaWmiSPCOYCzRGxPiLagSXA/OIGEfFwRLxUWPwtMCXBegadutHD+ZNLT+eBZ1r5xVMvpF2OmWVUkkEwGSiejaWlsK43nwZ+0dMGSddIapLU1Nra2o8lpu/j50+nYdJo/uLO1ew56FnMzGzgJRkE6mFdj+c/JL2DfBB8uaftEbE4IhojorG2trYfS0xfea6Mv7zydWzbfYC/v+eZtMsxswxKMghagKlFy1OAo2ZmkfQG4GZgfkS8mGA9g9a508Zx1dxp3PrwRlZv8dATZjawkgyC5cBsSTMlVQILgKXFDSRNA+4APh4Rmf46/D/ffQZjR1Tw5z990pPXmNmASiwIIqIDuA64C1gD3B4RqyQtlLSw0OyrwCnAdyStlNSUVD2D3diRlXzlPXN4bNMubm/yRPdmNnA01LotNjY2RlNTaeZFRPCR7/2WZ7bv5j//5GLGV1WmXZKZlQhJKyKisadtvrN4EJHE/7nydew50MG3frEm7XLMLCMcBIPM6XWj+PSFM7m9qYWmjZ7JzMyS5yAYhL74rtlMHjuC//WTpzjU2ZV2OWZW4hwEg9DIynK+9r4G1m7bza0PbUy7HDMrcQ6CQWpeQx3vOnMCf/+rZ9iya3/a5ZhZCXMQDFKS+PoVZ9EVwV/cuTrtcsyshDkIBrGp40fyh++czS9XvcCvn96edjlmVqIcBIPcf7+wnlm1VXxt6SoOHOpMuxwzK0EOgkGusryMb77/dWzauY+bft2cdjlmVoIcBEPAW2fVcOW5k1l0/zrWte5JuxwzKzEOgiHiz94zh+EVOb5yx5N0+N4CM+tHDoIhonbUML7+vrN4dMNOvvkf7kVkZv2nPO0CrO8++KYpPP1CG99/cAOn1Y3i4+dPT7skMysBPiIYYq6/fA7vPHMCX1+6it88uyPtcsysBDgIhphcmfjHBedwWm01n/vhCtb74rGZvUYOgiFo1PAKbr66kfJcGZ+5rYmX9x1KuyQzG8ISDQJJl0laK6lZ0vU9bD9T0iOSDkr60yRrKTVTx4/kex9/E5tf2sfnfrTCo5Sa2UlLLAgk5YCbgMuBBuAqSQ3dmu0EvgD8TVJ1lLI3zxjP/73y9TzU/KLHIzKzk5bkEcFcoDki1kdEO7AEmF/cICK2R8RywOc2TtKHG6fy2Yvq+cFvn+NfH9mYdjlmNgQlGQSTgeJZ2FsK606YpGskNUlqam1t7ZfiSsn/fPeZXDJnAt+4czUPPut/HzM7MUkGgXpYFyfzRhGxOCIaI6Kxtrb2NZZVenJl4h8WnMvsCdV87oeP0bzdPYnMrO+SDIIWYGrR8hRgS4K/L9Oqh5Vz89WNDCsv4zO3LWfXvva0SzKzISLJIFgOzJY0U1IlsABYmuDvy7wp4/I9ibbsOsDnfviYexKZWZ8kFgQR0QFcB9wFrAFuj4hVkhZKWgggaaKkFuCPgT+X1CJpdFI1ZcGbpo/nWx98PQ+ve5GvLV1FxEmdjTOzDEl0rKGIWAYs67ZuUdHzF8ifMrJ+9IE3TuHZ7Xv47n3rmD2hmk++bWbaJZnZIOZB50rUly49g3Xb9/CNO1fz0t52vnjJ6eTKerp+b2ZZ5yEmSlRZmbjhqnP5/cYp3PCfzXziXx7lxT0H0y7LzAYhB0EJG16R468/dDZ/9cHX87sNO3nvP/2Gxza9lHZZZjbIOAgy4CNvnsYd176V8pz4yPce4baHN/oispkd4SDIiNdNHsN/XHchF51ey9eWruILS1ay92BH2mWZ2SDgIMiQMSMrWPzxRr707jP4+RNbmH/TQzRv3512WWaWMgdBxpSVic+/4zR+8OnzeGlvO1fc+BD/8YRv+DbLMgdBRr3ttBp+/oULmTNpNNf96L/4xp2raO/wnchmWeQgyLCJY4az5Jrz+dTbZvIvD21kweJH2Pry/rTLMrMB5iDIuIpcGV99XwM3fvRc1r6wm9+74TfccO+zbGs7kHZpZjZANNS6ETY2NkZTU1PaZZSk5u17+Madq3jw2R3kysQlcybwsfOmc8FpNZT5rmSzIU3Sioho7Gmbh5iwI06bUM0PPn0eG3fs5d+Wb+L/NbVw16ptTBs/kqvmTuPDjVOoqR6Wdplm1s98RGC9OtjRyV2rtvHD3z7H7zbspCIn3n3WRD523nTOrx+P5KMEs6HiWEcEDgLrk+btu/nR7zbz7ys203agg/raKj523nQ++MbJjB1ZmXZ5ZnYcDgLrNwcOdfLzJ7byw989x2ObdlFZXsZZp45mzqT8o2HSKM6YOJrqYT7raDaYOAgsEWu2tvHjFS08+fzLrNnaRtuBV4asmDZ+JHMmjToSEHMmjmbq+BE+nWSWktQuFku6DPhHIAfcHBHf6rZdhe3vAfYBn4iIx5KsyfrPnEmj+fP3NgAQEWx5+QBrtrTx9AttrNm6mzVb27h79TYOf9eoHlbOmRNHMXncCMZXVXJKVSXjDv8cWckp1ZWMrxrGmBEVnjvBbAAlFgSScsBNwDzyE9kvl7Q0IlYXNbscmF14nAd8t/DThhhJTB47gsljR3BJQ92R9fvaO3hm2x7WbG1jzdY2nt66m//atIude9vZ08ugd2WCsSMrGV9VyfiRlYweUc6wihwjKnIMrygr/Cx+vLJuREWOYeVl5MpEea6M8jKRKxMVubLCz27LZWWUlUGuTJRJSJDTK899BGNZkOQRwVygOSLWA0haAswHioNgPvCvkT8/9VtJYyVNioitCdZlA2hkZTnnTB3LOVPHHrXtwKFOdu07xIt7D7Jzb3uPjxf3trNl1wEOdHRyoL2TAx1d7G/v5EBHJwNxVlOCMolcIRjKJMoKASEAgSgsF54fDhF4Zd3hPCm86sh6ODps8gFUtIxete2V9d1r7Tm0eo2yE8y4pCMxi6F7onv8kTdP5TMX1vd7HUkGwWRgc9FyC0d/2++pzWTgVUEg6RrgGoBp06b1e6GWjuEVOSaOyTFxzPATfm1EcLCji4OHujjQ0XkkHPa3d3Kwo4vOrqCjK+jo7KKjK+jsCg51FtZ3FrZ1dRWedxEBXQFdEXR1xSvPjzzyyxHQ2ZX/GcSRMIoIAo6s7woK24rbFH4Wr+PobRQFXHHWFV/P656BvYVib1l5otcGE8/coXWpsl/ESex0UvfxJBkEPYVd9z3vSxsiYjGwGPIXi197aTbUSTpyamgMFWmXYzakJTnWUAswtWh5CtB9vOO+tDEzswQlGQTLgdmSZkqqBBYAS7u1WQr8gfLOB1729QEzs4GV2KmhiOiQdB1wF/nuo7dExCpJCwvbFwHLyHcdbSbfffSTSdVjZmY9S/Q+gohYRv6PffG6RUXPA/h8kjWYmdmxeT4CM7OMcxCYmWWcg8DMLOMcBGZmGTfkRh+V1Ao8d5IvrwF29GM5Q4H3ORu8z9nwWvZ5ekTU9rRhyAXBayGpqbdhWEuV9zkbvM/ZkNQ++9SQmVnGOQjMzDIua0GwOO0CUuB9zgbvczYkss+ZukZgZmZHy9oRgZmZdeMgMDPLuMwEgaTLJK2V1Czp+rTrGQiSNkp6UtJKSU1p15MESbdI2i7pqaJ14yXdI+nZws9xadbY33rZ569Ler7wWa+U9J40a+xPkqZK+rWkNZJWSfpiYX3Jfs7H2OdEPudMXCOQlAOeAeaRnwxnOXBVRKw+5guHOEkbgcaIKNmbbiS9HdhDfu7r1xXW/TWwMyK+VQj9cRHx5TTr7E+97PPXgT0R8Tdp1pYESZOASRHxmKRRwArg/cAnKNHP+Rj7/Psk8Dln5YhgLtAcEesjoh1YAsxPuSbrBxHxALCz2+r5wG2F57eR/x+oZPSyzyUrIrZGxGOF57uBNeTnNi/Zz/kY+5yIrATBZGBz0XILCf6jDiIB3C1phaRr0i5mANUdnumu8HNCyvUMlOskPVE4dVQyp0mKSZoBnAv8jox8zt32GRL4nLMSBOphXemfE4O3RcQbgcuBzxdOKVhp+i4wCzgH2Ar8barVJEBSNfBj4I8ioi3tegZCD/ucyOeclSBoAaYWLU8BtqRUy4CJiC2Fn9uBn5A/RZYF2wrnWA+fa92ecj2Ji4htEdEZEV3A9ymxz1pSBfk/iD+MiDsKq0v6c+5pn5P6nLMSBMuB2ZJmSqoEFgBLU64pUZKqCheZkFQFXAo8dexXlYylwNWF51cDP0uxlgFx+A9iwZWU0GctScA/A2si4u+KNpXs59zbPif1OWei1xBAoZvVPwA54JaI+Mt0K0qWpHryRwGQn5v6R6W4z5L+DbiY/PC824CvAT8FbgemAZuAD0dEyVxc7WWfLyZ/uiCAjcBnD58/H+okXQA8CDwJdBVW/xn5c+Yl+TkfY5+vIoHPOTNBYGZmPcvKqSEzM+uFg8DMLOMcBGZmGecgMDPLOAeBWYoK3XyvleT/Fy01/o/PMkvSnsLPGZI+OgC/74rikW8llQM3Ar8p3CBklgp3H7XMkrQnIqolXQz8aUS89wRem4uIzsSKMxtAPiIwg28BFxbGd/8fknKSvi1peWFwr88CSLq4MEb8j8jf6IOknxYG9VtVPLBfYf6LxyQ9LunewrpPSLqx8Hy6pHsL73+vpGmF9bdKukHSw5LWS/rQQP9jWPaUp12A2SBwPUVHBIU/6C9HxJslDQMeknR3oe1c4HURsaGw/KmI2ClpBLBc0o/Jf8H6PvD2iNggaXwPv/NG8vMJ3CbpU8ANvDKM8iTgAuBM8sMo/Ht/77BZMQeB2dEuBd5Q9G18DDAbaAceLQoBgC9IurLwfGqhXS3wwOF2vQx78BbgA4XnPwD+umjbTwvXDFZLquuPHTI7FgeB2dEE/GFE3PWqlflrCXu7LV8CvCUi9km6DxheeP2JXnwrbn+wWy1mifI1AjPYDYwqWr4LuLYwDDCSTi+M4NrdGOClQgicCZxfWP8IcJGkmYXX93Rq6GHyo+ACfAz4zWvfDbOT4yMCM3gC6JD0OHAr8I/ADOCxwnDArfQ8DeIvgYWSngDWAr8FiIjWwnWGOwr3B2wnP192sS8At0j6UuH9P9nP+2TWZ+4+amaWcT41ZGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnG/X/Sh931xU36tQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_MLPC_opt2.loss_curve_)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af707e",
   "metadata": {},
   "source": [
    "Al aumentar el número de épocas, los resultados varían y el modelo que se retorna ahora como óptimo necesita solamente 25 épocas para converger.\n",
    "\n",
    "Sin embargo, sorprende que este último modelo que ha resultado generar predicciones con un mejor accuracy y que no sobrepasan el primer tope de 1000 iteraciones no haya sido el elegido en la primera búsqueda. Vamos a comparar las precisiones que han alcanzado cada uno de los modelos en el entrenamiento en cada una de las repeticiones de cross-validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb8248d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = {'activation': 'relu',\n",
    "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
    "  'learning_rate': 'constant',\n",
    "  'solver': 'adam'}\n",
    "\n",
    "result2 = {'activation': 'identity',\n",
    "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
    "  'learning_rate': 'constant',\n",
    "  'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd9170b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(cv_results_MLPC[\"params\"]):\n",
    "    if item == result1:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "for i, item in enumerate(cv_results_MLPC[\"params\"]):\n",
    "    if item == result2:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "171e0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO OPT (1000 iter) - Accuracy en primer entrenamiento: 0.6764705882352942\n",
      "MODELO OPT (1500 iter) - Accuracy en primer entrenamiento: 0.676470588235294\n"
     ]
    }
   ],
   "source": [
    "print(\"MODELO OPT (1000 iter) - Accuracy en primer entrenamiento:\", cv_results_MLPC[\"mean_test_score\"][91])\n",
    "print(\"MODELO OPT (1500 iter) - Accuracy en primer entrenamiento:\", cv_results_MLPC[\"mean_test_score\"][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5397be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(cv_results_MLPC2[\"params\"]):\n",
    "    if item == result1:\n",
    "        print(i)\n",
    "        break\n",
    "\n",
    "for i, item in enumerate(cv_results_MLPC2[\"params\"]):\n",
    "    if item == result2:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21cca501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO OPT (1000 iter) - Accuracy en segundo entrenamiento: 0.6617647058823529\n",
      "MODELO OPT (1500 iter) - Accuracy en segundo entrenamiento: 0.676470588235294\n"
     ]
    }
   ],
   "source": [
    "print(\"MODELO OPT (1000 iter) - Accuracy en segundo entrenamiento:\", cv_results_MLPC2[\"mean_test_score\"][91])\n",
    "print(\"MODELO OPT (1500 iter) - Accuracy en segundo entrenamiento:\", cv_results_MLPC2[\"mean_test_score\"][13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d4a85",
   "metadata": {},
   "source": [
    "Se observa que en la primera prueba de ``GridSearchCV`` ambos modelos tienen una accuracy prácticamente idéntica durante el entrenamiento, aunque al no terminar de converger el primero (visto con las 1000 iteraciones), finalmente su accuracy tiene un decimal más y por ser en definitiva mayor, es el único modelo escogido. Sin embargo, al aumentar el margen de iteraciones, mientras que el segundo modelo (1500 iteraciones) no cambia su accuracy, el primero sigue entrenando y el valor final de precisión del entrenamiento en este segundo caso decrece.\n",
    "\n",
    "Por tanto, el óptimo hasta este momento y de acuerdo a las pruebas anteriores es el modelo obtenido en la segunda prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14ede2",
   "metadata": {},
   "source": [
    "La librería ``sklearn`` permite implementar un tercer optimizador, lbfgs, que no se ha incluído en las pruebas anteriores ya que no permite dibujar la curva de loss para hacer las anteriores comprobaciones. Por tanto, vamos ahora a probar y comparar los resultados manualmente incluyendo este optimizador.\n",
    "\n",
    "El solver ``sgd`` no se ha elegido en ninguna de las anteriores pruebas. Como en esta ocasión queremos comprobar si el solver ``lbfgs`` incrementa el accuracy frente a los resultados anteriores, prescindiremos del solver ``sgd`` y la optimización del tipo de learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f906f2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_MLPC3 = MLPClassifier(max_iter=1000, random_state=0)\n",
    "param_grid_MLPC3 = {\n",
    "    \"hidden_layer_sizes\": [(100, 200, 100, 1), (100, 100, 100, 100, 1), (200, 200, 100, 50, 1), (100, 250, 250, 100, 1)],\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"adam\", \"lbfgs\"]\n",
    "}\n",
    "cv_results_MLPC3 = train_GridSearchCV(model_MLPC3, param_grid_MLPC3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8e26327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'relu',\n",
       "  'hidden_layer_sizes': (100, 250, 250, 100, 1),\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC3[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC3, top_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f027b",
   "metadata": {},
   "source": [
    "Si volvemos a utilizar el máximo de 1000 iteraciones, el óptimo es el mismo obtenido en el primer caso. Vamos a repetir el intento ahora con 1500 épocas de máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83e7f5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_MLPC4 = MLPClassifier(max_iter=1500, random_state=0)\n",
    "cv_results_MLPC4 = train_GridSearchCV(model_MLPC4, param_grid_MLPC3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce5d8de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'identity',\n",
       "  'hidden_layer_sizes': (200, 200, 100, 50, 1),\n",
       "  'solver': 'adam'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_GridSearchCV(cv_results_MLPC4[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(cv_results_MLPC4, top_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df63b0",
   "metadata": {},
   "source": [
    "Nuevamente, se obtiene el mismo resultado que en el caso anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b5a47",
   "metadata": {},
   "source": [
    "**Usando la librería \"keras\"**\n",
    "\n",
    "Ahora utilizaremos la librería de ``keras``, por su mayor flexibilidad para intentar mejorar los resultados de la red neuronal.\n",
    "\n",
    "Comenzaremos repitiendo la búsqueda de hiperparámetros, ya que la propia librería de ``keras`` dispone de integración con otras que nos permitirán hacer una búsqueda algo más exhaustiva por ejemplo en cuanto al número de capas y neuronas en estas. Concretamente, vamos a utilizar ``optuna``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9c04e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing, regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be2b93",
   "metadata": {},
   "source": [
    "Documentación:\n",
    "* https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html\n",
    "* https://optuna.org/\n",
    "\n",
    "Para reducir el coste computacional tomaremos de base resultados como la función de activación óptima: \"relu\", que hemos podido obtener con ``GridSearchCV``. Como por el contrario usando ``sklearn`` no hemos podido utilizar el optimizador RMSProp, vamos a probarlo también con ``optuna`` + ``keras`` para ver si mejora nuestros resultados.\n",
    "\n",
    "Búsqueda mediante la librería ``optuna`` probando 2 métodos de búsqueda de hiperparámetros:\n",
    "\n",
    "* **GridSampler:** equivalente a la anterior búsqueda de grid de sklearn. Lo usaremos para que los resultados sean comparables.\n",
    "* **TPE:** algoritmo para hacer una \"búsqueda inteligente\" de hiperparámetros. Debería ahorrar intentos de combinaciones haciendo una selección inteligente de las pruebas. En nuestro caso le permitiremos probar un 10% del número de combinaciones posibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1709fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_Grid(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea2fd41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1881 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.8336 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 454.3410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 103.2015 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5847 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6568 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.8619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4777 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 289.3388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.9215 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6174 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.7513 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.5602 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 733.7194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2641 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 732.3604 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.9429 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3981 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.2822 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.0773 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.9317 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.9149 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.3184 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.3080 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.2053 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.3578 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0565 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 261.4233 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.9781 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 501.9335 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.0976 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.3653 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0579 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 208.9376 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3829 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0476 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3378 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.5042 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 94.5990 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5353 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0193 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0266 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1905 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.3617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.0945 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 323.2704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5442 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 65.8838 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6021 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 591.5588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1304 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 125.3869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0674 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 417.8099 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 219.7325 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 55.2339 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 590.6400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 262.2745 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0369 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.7975 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 553.8687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.3671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.8259 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3980 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 151.1274 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4294 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6705 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.7137 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1065 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 326.9112 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.5982 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.4813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.2204 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 202.2397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1415 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 59.7871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 379.7872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 154.2781 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4679 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.8134 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0563 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3126 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 66.0608 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.9970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2408 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4967 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6894 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.6704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 310.3519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.4343 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6063 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 294.1617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.3929 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.3177 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8105 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0814 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6907 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4590 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5894 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 155.9068 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.2065 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6843 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0946 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 436.7927 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.3127 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3757 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 115.6558 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 728.6428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0774 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.3038 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2435 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.2555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9184 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 235.0943 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0465 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1486 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.2866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1629 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0779 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.3234 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 177.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5674 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 234.1780 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3721 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 361.9267 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.3011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.5372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9722 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 218.5982 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8434 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 99.8412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 116.6062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 147.2498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1118 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0293 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.7645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6340 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 236.9139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 89.9203 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5646 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 588.9958 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 81.0424 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 10.8722 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0143 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5867 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.4029 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6058 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 297.6541 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8729 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8087 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.1021 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8421 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.7355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6207 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.2727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4973 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.2641 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.1560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.4648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0288 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 361.8303 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.5021 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7222 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 357.1632 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.7355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 136.6458 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.6377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 626.1552 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 626.7208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.2317 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0243 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0676 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1449 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0552 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.5010 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1341 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.6701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4379 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4507 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5395 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.2674 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 330.7587 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2978 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.9713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4638 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.6615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0465 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3896 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3272 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6335 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.0347 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3735 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 145.3421 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 233.1591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7716 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.7971 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.6366 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0964 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6182 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 385.3382 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5701 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 79.9830 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.1239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.8602 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 493.6086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5655 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4904 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.9739 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 187.6153 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 562.9263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.2498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0294 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1176 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6956 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.3734 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.7160 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.5992 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5421 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.0977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.7377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.2011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 57.3539 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3097 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 325.2552 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5259 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 861.3040 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4886 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 806.4541 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.9323 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0465 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2875 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 165.1345 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 294.2422 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1156 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3709 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2834 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 555.5832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.6437 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4906 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5218 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 477.6064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6787 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.6749 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 97.9495 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 501.5060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.3095 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4722 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.2433 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0386 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0821 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.8128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 338.0344 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.8436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1401 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 268.1898 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.8013 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.4460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 511.4462 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2379 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 344.1834 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.3514 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.4745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2873 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 315.7592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.7046 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 772.1209 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9691 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0263 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2411 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0808 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.7479 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5637 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.4903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.7194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.9273 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6756 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 79.9372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6283 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8026 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1893 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4891 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.0972 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.6863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 188.0824 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.2672 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0870 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0843 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.7086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 508.8040 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6067 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5938 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.2400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 272.8875 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0267 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8677 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6661 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 289.0944 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 123.0576 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5533 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 396.6765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 378.4745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.9057 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 511.6967 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 98.4652 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6767 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.7984 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1309 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 565.2043 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1764 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5631 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 162.7454 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.5490 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.5714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.8572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0523 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.7497 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 169.6076 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.7138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6675 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.4769 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.4260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.8692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0552 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8998 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.2911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3893 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7281 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0674 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 914.1331 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 344.2219 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4183 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 167.5296 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0527 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 116.1581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2883 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5578 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3506 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5422 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1549 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 740.1528 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.6633 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 109.5457 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2886 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6983 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5834 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 447.6556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 192.7285 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 387.6899 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8381 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9835 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0465 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 207.7852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.1925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2279 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.9285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 116.0011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2757 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0583 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.0383 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.6271 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.0582 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.5420 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 103.1093 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8206 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6791 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5868 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 479.5021 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4038 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 190.8179 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.3241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.2351 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 152.9192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3728 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 602.0352 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 220.2083 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.7681 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.1909 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 181.5071 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1146 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 450.0076 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.5788 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.3396 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 224.4169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 102.0400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 118.5689 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.9839 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 382.3776 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.9831 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.1180 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 11.5722 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 509.4757 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5010 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.4540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.0915 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.6133 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1387 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2961 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 276.7421 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6657 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0563 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6961 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2629 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.8209 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.9230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.3562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 629.7120 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5447 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4770 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1861 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 67.4508 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7880 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 122.2022 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 654.6515 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.2498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 318.5881 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 862.2879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1149 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3952 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.2129 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4853 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 58.4893 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 355.9073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5959 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1579 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 260.4325 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6031 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6681 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0814 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 80.9935 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0420 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 338.2136 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8734 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0901 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.6062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.7503 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2052 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 653.4478 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0825 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 806.4235 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.5644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0379 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3216 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2608 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.5248 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 107.7046 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.9553 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 266.0819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1501 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0810 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0361 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.3999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0825 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 386.3312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 658.9697 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0525 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 495.3698 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4384 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 498.2428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.9675 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.8400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 345.4585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.0960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.7271 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0688 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5204 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8098 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 229.1355 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.3091 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5214 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 96.1292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 376.2668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9306 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0296 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.7396 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.5415 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 266.6486 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.3512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 80.6412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6719 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4718 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 250.9326 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.0081 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.2679 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.8018 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0864 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.0016 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 98.8481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 315.8822 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1742 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8153 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.1986 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 316.7878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 690.4020 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 415.0091 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2857 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.1412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 251.1097 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.3329 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3882 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3326 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0193 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 61.5068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.2528 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 730.3089 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.1975 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 171.6302 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4691 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8149 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.7228 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 659.4890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 209.5416 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5874 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.2885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.6926 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0824 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 126.0341 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6682 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 291.3748 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0268 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 612.1320 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 320.2487 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.0649 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2916 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4442 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 250.3093 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.1716 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 284.2924 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.5290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0246 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0951 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4558 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4159 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 228.4962 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 248.0624 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5640 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.4299 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 741.0540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.3244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 306.1064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3753 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.5363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2597 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2891 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.4281 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.7167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 222.2157 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 79.5233 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1860 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.0413 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 740.0579 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.6650 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6900 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5705 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1406 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0872 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 160.9884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 171.9901 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.5135 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3057 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9310 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0084 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.9950 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.9220 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 390.5818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0705 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.0244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6792 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3965 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8581 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0875 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9568 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 125.0658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1903 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.9128 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.6481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.6954 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2904 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.8473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5996 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 303.2062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0391 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5829 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.7442 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8676 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 80.3323 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3966 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5975 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 804.7042 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.7838 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.4648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1433 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.7822 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8456 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3626 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 624.7367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 561.3774 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5800 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 316.4620 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 374.7068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8115 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.6519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8180 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 656.6124 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6584 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 321.3763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.5809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 304.0519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.4545 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1434 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8647 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 376.2752 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8030 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 97.0306 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.4532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.8932 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.5144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.4486 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9266 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6662 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.3351 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 681.5661 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3576 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0753 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 416.4684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6627 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 135.2740 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 68.2812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5842 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 739.8901 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5947 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 227.9167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 497.4181 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0932 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 108.7937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6717 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0712 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3652 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.8034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 282.5114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 42.2873 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3795 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5675 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 231.9475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0458 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3849 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 917.5063 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 49.1683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0873 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 628.3661 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.5642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0543 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 79.3457 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.8088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 449.2552 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 240.6288 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 410.3033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.1012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8395 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6791 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0689 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.4537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4690 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1414 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4718 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8104 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2398 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.9008 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0477 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 412.6435 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 402.4704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9248 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1886 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.5160 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4047 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2654 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 47.6549 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.1638 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 500.2586 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.7015 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 92.9845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.8669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.3854 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.9303 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 690.1302 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8084 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6605 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5163 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 65.0601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.7474 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.1057 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.5348 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.2266 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 511.4455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2617 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9972 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.2561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6044 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.6528 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 162.7380 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 262.7121 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 494.5669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6746 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7474 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3382 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 102.4006 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0849 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0411 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 233.2875 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1071 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8825 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 179.2254 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6771 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.8130 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 304.1635 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8664 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5244 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0577 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3976 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 266.9423 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6513 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.2907 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0381 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1435 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.0542 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8213 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 210.8865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 485.3158 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1769 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.9998 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.5789 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5769 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0286 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 177.4290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.2797 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5210 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 142.2720 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 193.5073 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0465 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 55.1515 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 288.7098 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.5694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 61.6732 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0535 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4627 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.6590 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1391 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4163 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.8765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 98.7497 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.1256 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7093 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8091 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 412.2914 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.3579 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.7715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0676 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 289.6856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.9542 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3720 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.5412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 474.1534 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2387 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.6071 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.1731 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 138.1400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.0478 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.0019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0876 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 510.3960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 387.8768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6957 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8675 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.7049 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6643 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4910 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5569 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.7148 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.0821 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0271 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 167.8270 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8622 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.7525 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5111 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.4240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6770 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2981 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 345.6761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 148.1214 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6246 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.9910 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.6843 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0462 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6917 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.7018 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.3371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2724 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 346.1445 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0854 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5653 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 410.8304 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 285.2819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.7300 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0823 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3523 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5386 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4738 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 373.4534 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 297.9389 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 535.4720 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.1633 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6259 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5626 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.3413 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 120.9807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2626 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 319.8581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3368 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 83.1099 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0492 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 290.2580 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.2050 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 229.6014 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 206.4231 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 124.9987 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0360 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 134.3597 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 109.5316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2914 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.2686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8096 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0836 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 262.9095 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 67.2425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 166.8741 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3161 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.5944 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0831 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8100 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6739 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1063 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1391 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 534.1870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0586 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 414.6257 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.3765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5423 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.0197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6754 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.3670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5586 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.8144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.9043 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4641 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.0495 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 740.9972 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.0564 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 661.2021 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0543 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6726 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 449.6166 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 331.4161 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6883 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0711 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.5061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 653.2975 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.3017 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5459 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 95.9273 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.8320 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.6909 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 220.9613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8232 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0618 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 368.5946 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1936 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4399 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4629 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5982 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3606 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1462 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3737 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 232.9508 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.4911 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6259 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.3429 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0651 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0703 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.3599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0822 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4949 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.0862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 123.9810 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6113 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0676 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 480.7520 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 658.6813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 452.3742 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.4111 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4027 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2865 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6601 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 90.6342 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.4596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0283 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6680 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0198 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4784 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 548.5185 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0293 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 36.9769 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5496 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 466.6590 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 449.2342 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.1773 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.0822 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3856 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 420.5956 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5171 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 97.1846 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3090 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1413 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 345.6767 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.6358 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 653.5784 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.5512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 111.5735 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7956 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.7333 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0468 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.5002 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.3168 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4226 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4029 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5166 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 467.5865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2865 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 219.2448 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.8741 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9067 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6036 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.5173 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.9532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 221.3428 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1395 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.6794 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 730.0691 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.4316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 124.9179 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5432 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3602 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 500.1693 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 205.2308 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0812 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.5373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 363.3243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.7521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8630 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.7344 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2448 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.0316 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6114 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 498.4493 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5192 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0575 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2854 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6631 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.5542 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.4599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0492 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 198.2768 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.7488 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5609 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0724 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4100 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 344.9937 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 251.4145 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 311.1049 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5522 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1898 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2452 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.9931 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.3255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.6427 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.5007 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.0633 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.8184 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.5515 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 165.0204 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.5423 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.0389 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 129.8155 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6697 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0266 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 188.6064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2709 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 86.3676 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 58.6003 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.1180 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3532 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 96.8648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 122.7995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7210 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.0811 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 272.2665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5214 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 510.5694 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.7693 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8642 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0608 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 657.6456 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 20.1514 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.7466 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.4498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0668 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.6073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 860.5073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.3940 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.2686 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0529 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8577 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 476.2887 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0677 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.7537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5578 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0394 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 448.4891 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1056 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.5863 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 412.2227 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1303 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 65.6621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.5117 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 283.0599 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.4587 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3696 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.1941 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0360 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9775 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6857 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0143 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.8512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.3929 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6723 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7902 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.9430 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.4402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 589.0615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 739.8171 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5881 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3953 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 508.0969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 919.4922 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8665 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 85.3410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1066 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.8180 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.1957 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 172.8374 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 507.2815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.7185 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.2231 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5209 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6710 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5411 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.3838 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0681 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0360 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.3773 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0598 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0498 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.3201 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.0035 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0679 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7064 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1563 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6936 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 48.7098 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 582.9807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 79.5507 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.0369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4849 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2879 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4625 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1412 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 227.7119 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.2457 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8145 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.6074 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0612 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1878 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.7160 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 102.2695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0485 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 84.8798 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.4871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0471 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1167 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0781 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5909 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4662 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8653 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.6071 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.6433 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.6989 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5411 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1569 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.0959 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 65.0075 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.8341 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3705 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4947 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 98.4331 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.3963 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 304.7936 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 227.4829 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.9918 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 413.8329 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.7670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 332.2033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.2643 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.6947 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5542 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 628.4866 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 687.1750 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1179 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1053 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8841 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.7037 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 208.6250 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 149.9969 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6439 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1309 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.6908 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5611 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 150.7840 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.1639 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 41.1028 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6551 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0523 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.8823 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 429.7615 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8135 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3281 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 72.6053 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 36.5453 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.0360 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.0632 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7150 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.5496 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 115.7281 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5728 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 189.2953 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 615.1600 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 733.4462 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 380.2751 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 116.7122 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8455 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3703 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 553.7939 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 386.4486 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0502 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3605 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5496 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0570 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5679 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.5616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0525 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8731 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.8412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 313.3231 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.6482 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2920 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5677 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5721 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.3220 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 60.6410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.2294 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 157.6510 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4650 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.8846 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2609 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0359 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 275.4123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 384.7080 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2223 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1853 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.4513 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6717 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.6415 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.2194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1905 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.9099 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2667 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 241.0787 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2927 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3491 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1071 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0495 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0488 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 289.0514 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1884 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2842 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.1392 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0563 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5194 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.2158 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.4028 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 136.1719 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0871 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.6399 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5921 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8683 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5906 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0698 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2659 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1900 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6032 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 505.5549 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 492.9750 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1068 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8648 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.6301 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9152 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 10.5510 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 361.0703 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 373.8669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.7853 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5205 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.8178 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 734.9548 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3126 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1808 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4990 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0139 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1419 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 106.3293 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 590.9835 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 222.5180 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2838 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 513.3893 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7159 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 47.2403 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5964 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.2140 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 745.2610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 450.0645 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 80.2165 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0560 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 202.4037 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3672 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.0060 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0718 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 146.0589 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0912 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1310 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.5907 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 588.4033 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0291 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 58.2618 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1906 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.1481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1159 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 283.2630 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 560.9180 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0265 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6427 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6078 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4673 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.9622 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.2925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6329 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.3800 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5590 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 446.7373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.1789 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.9149 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.2208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 136.3312 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 500.0101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 535.1257 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8970 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 283.3289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0363 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 178.8572 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.0056 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.5763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2964 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0868 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1063 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.8959 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 413.2519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5204 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 373.1610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6835 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1405 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0711 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4628 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0700 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.3772 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7196 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3197 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0475 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0537 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0812 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 210.4592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 106.8195 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5619 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 311.8419 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 436.6974 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 508.7838 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.2761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 628.1097 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 180.4570 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.4146 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.3206 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 93.2180 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0715 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2733 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8974 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8235 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.0565 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1905 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8111 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 807.0610 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3219 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0290 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5626 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.7409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.0454 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 809.3519 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5293 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.6472 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3649 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2255 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 417.2040 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1069 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 63.7559 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 369.2357 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3514 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.2664 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6481 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1084 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 81.6277 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.3314 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5146 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 448.3810 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0595 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.3575 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0540 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": range(2, 6), \n",
    "                \"n_units\": range(50, 300, 50),\n",
    "                \"dropout\": np.arange(0, 0.6, 0.1),\n",
    "                \"kernel_regularizer\": [0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                \"optimizer\": [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study_Grid = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_Grid.optimize(objectiveNN_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5691260b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 3,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 1,\n",
       "  'optimizer': 'Adam'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_Grid.get_trials())\n",
    "models_same_acc_OptunaSearchCV(study_Grid.get_trials(), top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d211270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 517.6229 - acc: 0.4706 - val_loss: 497.2430 - val_acc: 0.5294\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 492.6998 - acc: 0.5098 - val_loss: 473.0414 - val_acc: 0.5294\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 468.6569 - acc: 0.6078 - val_loss: 449.7201 - val_acc: 0.5294\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 445.4954 - acc: 0.6667 - val_loss: 427.2809 - val_acc: 0.5294\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 423.2144 - acc: 0.6667 - val_loss: 405.7205 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 401.8110 - acc: 0.6863 - val_loss: 385.0305 - val_acc: 0.5882\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 381.2794 - acc: 0.6863 - val_loss: 365.2013 - val_acc: 0.5882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 361.6032 - acc: 0.6863 - val_loss: 346.2188 - val_acc: 0.5882\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 342.7723 - acc: 0.6863 - val_loss: 328.0657 - val_acc: 0.5882\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 324.7696 - acc: 0.7059 - val_loss: 310.7238 - val_acc: 0.6471\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 307.5744 - acc: 0.7255 - val_loss: 294.1726 - val_acc: 0.6471\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 291.1662 - acc: 0.7059 - val_loss: 278.3901 - val_acc: 0.6471\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 275.5231 - acc: 0.7059 - val_loss: 263.3530 - val_acc: 0.6471\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 260.6215 - acc: 0.7059 - val_loss: 249.0377 - val_acc: 0.6471\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 246.4365 - acc: 0.7255 - val_loss: 235.4193 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 235.4418 - acc: 0.5556\n",
      "Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Grid = models.Sequential()\n",
    "modelFC_optuna_Grid.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(1), input_shape=(410,)))\n",
    "modelFC_optuna_Grid.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_Grid.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_Grid.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_Grid.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_Grid.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Grid.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bb2cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveNN_TPE(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación sigmoide\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6846d5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 536.1787 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 592.2588 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.2287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0364 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 85.4573 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 729.8449 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4712 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.6762 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 319.4950 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.6474 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 447.9747 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 591.2845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1171 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5680 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7067 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.0862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6959 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1733 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0692 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3439 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8200 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2410 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1484 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2402 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.4986 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5824 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 581.7957 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 659.4673 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5554 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 371.3850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5584 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3586 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4592 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2377 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 381.2275 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2384 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.8169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.5120 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.1563 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.0704 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.0830 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 58.3845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 265.8005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 631.5249 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 809.3093 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5062 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 232.5293 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 585.6397 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 555.5425 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 553.2687 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 612.9012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5600 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.0972 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.7073 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.4758 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.8460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.9323 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.0727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.4372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.8636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.2242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 385.7628 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 731.5662 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 202.2594 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 264.5695 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 231.1684 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 232.3128 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 630.7800 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 617.3845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 614.3765 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 584.7224 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 614.1658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.8086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 614.0247 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0558 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0463 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0242 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.5285 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.6895 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.6386 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 76.9311 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 83.3143 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.5778 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.8145 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.8540 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.5809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 57.4656 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.4820 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.4004 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 231.8335 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 247.8138 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 202.8728 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 216.0372 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 231.7274 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 265.4896 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 154.9915 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.5220 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.8123 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 615.6019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 474.6643 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.8381 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 501.3460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 525.9831 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7607 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7630 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 554.5156 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 525.4848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0823 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0813 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0818 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0562 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0460 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0241 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0238 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0187 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0188 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.7670 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.9555 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.0613 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.4232 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.9760 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.4539 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.4210 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.4961 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.4199 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 58.7832 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 60.8136 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.4470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.0084 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.9386 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.5628 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.8182 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.3708 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.7436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 249.3216 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 264.7276 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 264.3286 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.5061 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 201.3245 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 247.8566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 266.5208 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 215.9101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4077 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 216.2596 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.8546 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 265.8369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7186 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5809 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7736 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7983 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 617.5400 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 500.1720 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.1517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 584.3722 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.8654 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.8144 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7199 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7370 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 583.8467 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 552.3666 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 556.6489 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3525 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0556 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0821 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0823 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0557 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0824 - accuracy: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_TPE.optimize(objectiveNN_TPE, n_trials=216)\n",
    "# n_trials = (4 x 5 x 6 x 6 x 3) * 0.1 = 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9563b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(study_TPE.get_trials())\n",
    "models_tpe = models_same_acc_OptunaSearchCV(study_TPE.get_trials(), top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95675f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layers': 5, 'n_units': 250, 'dropout': 0.5, 'kernel_regularizer': 0.01, 'optimizer': 'SGD'}\n",
      "{'n_layers': 5, 'n_units': 250, 'dropout': 0.5, 'kernel_regularizer': 1, 'optimizer': 'SGD'}\n",
      "{'n_layers': 5, 'n_units': 250, 'dropout': 0.1, 'kernel_regularizer': 1, 'optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "for model in models_tpe:\n",
    "    if model[\"n_layers\"] == 5 and model[\"n_units\"] == 250:\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d14b938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 13.9574 - acc: 0.5686 - val_loss: 13.7890 - val_acc: 0.5294\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 13.8602 - acc: 0.5882 - val_loss: 13.7848 - val_acc: 0.4118\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 13.7275 - acc: 0.6275 - val_loss: 13.7797 - val_acc: 0.4706\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 14.0099 - acc: 0.4510 - val_loss: 13.7724 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 13.8034 - acc: 0.5294 - val_loss: 13.7609 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 14.0159 - acc: 0.4706 - val_loss: 13.7549 - val_acc: 0.5294\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 13.9029 - acc: 0.4706 - val_loss: 13.7492 - val_acc: 0.4118\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 13.9291 - acc: 0.4510 - val_loss: 13.7368 - val_acc: 0.4118\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 13.7671 - acc: 0.5098 - val_loss: 13.7240 - val_acc: 0.4118\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 13.7099 - acc: 0.4444\n",
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE = models.Sequential()\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01), input_shape=(410,)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(0.01)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91e28ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 179ms/step - loss: 1292.3447 - acc: 0.5686 - val_loss: 1209.7290 - val_acc: 0.5294\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1191.9213 - acc: 0.5882 - val_loss: 1115.8544 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1099.3291 - acc: 0.5882 - val_loss: 1029.2810 - val_acc: 0.4118\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1014.1930 - acc: 0.4314 - val_loss: 949.4018 - val_acc: 0.4118\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 935.3914 - acc: 0.5098 - val_loss: 875.7505 - val_acc: 0.4118\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 862.8985 - acc: 0.4314 - val_loss: 807.8003 - val_acc: 0.4118\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 807.8031 - acc: 0.4444\n",
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE = models.Sequential()\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1), input_shape=(410,)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.5))\n",
    "modelFC_optuna_TPE.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3624c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 196ms/step - loss: 1269.0593 - acc: 0.5490 - val_loss: 1121.1187 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1098.5728 - acc: 0.6667 - val_loss: 1009.3327 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 992.5025 - acc: 0.5686 - val_loss: 923.5599 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 909.6896 - acc: 0.5490 - val_loss: 851.8865 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 839.8885 - acc: 0.5098 - val_loss: 789.3909 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 778.7106 - acc: 0.6078 - val_loss: 733.5001 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 733.5194 - acc: 0.4444\n",
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE = models.Sequential()\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1), input_shape=(410,)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE.add(layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c2a1323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models_tpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac133138",
   "metadata": {},
   "source": [
    "216 es el número de pruebas permitidas a TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a48ee6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.4444444477558136], datetime_start=datetime.datetime(2022, 7, 3, 0, 43, 37, 141780), datetime_complete=datetime.datetime(2022, 7, 3, 0, 43, 38, 146929), params={'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004, 'kernel_regularizer': 1, 'optimizer': 'SGD'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1), 'kernel_regularizer': CategoricalDistribution(choices=(0, 0.0001, 0.001, 0.01, 0.1, 1)), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_TPE.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74f213fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 856.5853 - acc: 0.5294 - val_loss: 801.9028 - val_acc: 0.3529\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 790.1555 - acc: 0.4510 - val_loss: 739.6799 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 728.7551 - acc: 0.5882 - val_loss: 682.3079 - val_acc: 0.3529\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 672.3114 - acc: 0.4118 - val_loss: 629.3793 - val_acc: 0.3529\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 620.1294 - acc: 0.4314 - val_loss: 580.5670 - val_acc: 0.4118\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 571.9380 - acc: 0.7255 - val_loss: 535.5594 - val_acc: 0.4118\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 527.6932 - acc: 0.4902 - val_loss: 494.0273 - val_acc: 0.4118\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 486.7455 - acc: 0.5490 - val_loss: 455.7277 - val_acc: 0.4118\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 448.9972 - acc: 0.6078 - val_loss: 420.4045 - val_acc: 0.4118\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 414.1978 - acc: 0.5686 - val_loss: 387.8220 - val_acc: 0.4118\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 387.8103 - acc: 0.6111\n",
      "Accuracy: 61.11%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE = models.Sequential()\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizers.L2(1), input_shape=(410,)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizers.L2(1)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa25e4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 188ms/step - loss: 0.7607 - acc: 0.5294 - val_loss: 0.7091 - val_acc: 0.3529\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8129 - acc: 0.4510 - val_loss: 0.7067 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6900 - acc: 0.5882 - val_loss: 0.7051 - val_acc: 0.3529\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8278 - acc: 0.4118 - val_loss: 0.7045 - val_acc: 0.3529\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7736 - acc: 0.4118 - val_loss: 0.7035 - val_acc: 0.4118\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5654 - acc: 0.7255 - val_loss: 0.7051 - val_acc: 0.3529\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8254 - acc: 0.5098 - val_loss: 0.7096 - val_acc: 0.4118\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7284 - acc: 0.5294 - val_loss: 0.7087 - val_acc: 0.4706\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6644 - acc: 0.6275 - val_loss: 0.7129 - val_acc: 0.5882\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6751 - acc: 0.5882 - val_loss: 0.7124 - val_acc: 0.5882\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7327 - acc: 0.5490 - val_loss: 0.7090 - val_acc: 0.5294\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7086 - acc: 0.4510 - val_loss: 0.7023 - val_acc: 0.4706\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6228 - acc: 0.6078 - val_loss: 0.7020 - val_acc: 0.5294\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6590 - acc: 0.6471 - val_loss: 0.6995 - val_acc: 0.4706\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6256 - acc: 0.6667\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE = models.Sequential()\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizers.L2(0), input_shape=(410,)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizers.L2(0)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizers.L2(0)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizers.L2(0)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1161928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 152ms/step - loss: 0.7607 - acc: 0.5294 - val_loss: 0.7091 - val_acc: 0.3529\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8129 - acc: 0.4510 - val_loss: 0.7067 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6900 - acc: 0.5882 - val_loss: 0.7051 - val_acc: 0.3529\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8278 - acc: 0.4118 - val_loss: 0.7045 - val_acc: 0.3529\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7736 - acc: 0.4118 - val_loss: 0.7035 - val_acc: 0.4118\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5654 - acc: 0.7255 - val_loss: 0.7051 - val_acc: 0.3529\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8254 - acc: 0.5098 - val_loss: 0.7096 - val_acc: 0.4118\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7284 - acc: 0.5294 - val_loss: 0.7087 - val_acc: 0.4706\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6644 - acc: 0.6275 - val_loss: 0.7129 - val_acc: 0.5882\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6751 - acc: 0.5882 - val_loss: 0.7124 - val_acc: 0.5882\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7327 - acc: 0.5490 - val_loss: 0.7090 - val_acc: 0.5294\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7086 - acc: 0.4510 - val_loss: 0.7023 - val_acc: 0.4706\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6228 - acc: 0.6078 - val_loss: 0.7020 - val_acc: 0.5294\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6590 - acc: 0.6471 - val_loss: 0.6995 - val_acc: 0.4706\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6256 - acc: 0.6667\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE = models.Sequential()\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_TPE.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_TPE.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_TPE.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8da59",
   "metadata": {},
   "source": [
    "Veamos si podemos obtener mejores resultados cambiando la última capa con activación sigmoide por una activación softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "443bedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# En primer lugar, hay que adaptar los datos\n",
    "NUM_CLASSES = 2\n",
    "y_train_softmax = np_utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_softmax = np_utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b767209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveSoftmax_Grid(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación softmax\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b70e2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 79.2948 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9872 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 536.8007 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.6834 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8908 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.5347 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7551 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3590 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8378 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7730 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 54.9730 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5333 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9591 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3360 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6105 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 226.6677 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22.3479 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2603 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6212 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 157.1462 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 25.4469 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9793 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7190 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6054 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 809.9276 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.5082 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9496 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.0027 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6737 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 682.6719 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 12.9436 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0550 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8198 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.9803 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6319 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.9217 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 269.3688 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 78.6268 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.4592 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.8480 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5527 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.2468 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.4439 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.3237 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8678 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8806 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 263.2936 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 18.8095 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 450.5222 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 37.2749 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7893 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9196 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0545 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7318 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 154.7839 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3609 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0172 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9138 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6904 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0155 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.6355 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 82.7212 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1892 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8415 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6277 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6303 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8174 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7037 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8412 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.8052 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9375 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4518 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.4470 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5481 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 144.7708 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7365 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6859 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.3949 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.1610 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 536.5807 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7101 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7985 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.0336 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6803 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 400.7635 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 171.4776 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4753 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 41.9190 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 630.8632 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8128 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 228.1644 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7408 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6327 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6314 - accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 8.5133 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1810 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7419 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 475.0132 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6146 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.8549 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7795 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.3245 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.1253 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3452 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 151.7436 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3548 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0229 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8102 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3895 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.3818 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0012 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7594 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5912 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6880 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7542 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7128 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7103 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.4219 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 153.4789 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8223 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8106 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.0262 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.4125 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0527 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2778 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 195.7359 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3537 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.4096 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6749 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3661 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7330 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8316 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.7508 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9504 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6706 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1625 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9531 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0596 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5292 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 445.4091 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 294.0308 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6490 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.8902 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9195 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2538 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6698 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 294.4799 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7089 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2384 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7635 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7278 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4732 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7600 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3164 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7756 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4409 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9546 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 194.9270 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6878 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2321 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.4092 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4089 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6701 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7559 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1525 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 174.0145 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 50.6168 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9390 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 110.9174 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7581 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 287.0375 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6845 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8767 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6903 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7256 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6456 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.0894 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.9128 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.4782 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.3711 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6198 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9047 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9265 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 179.7176 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6579 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7745 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6171 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7825 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5827 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7663 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.2686 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 208.4881 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7240 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7391 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4334 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7426 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7018 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2906 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 316.3925 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1492 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9551 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6271 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 262.4376 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.1164 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9624 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8193 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.7802 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1957 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6524 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.2463 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 267.8002 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2050 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 71.4889 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5966 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7057 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 116.7487 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.2932 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8348 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7716 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.3135 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.2452 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6861 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3860 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 207.8992 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 90.1735 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.3976 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.8030 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5081 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 81.2869 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8269 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8044 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6737 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1443 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0745 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.3144 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8357 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6783 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7405 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5930 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2683 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9957 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7188 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 249.3965 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5190 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9602 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.2496 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9197 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.5373 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4584 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.1877 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9703 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2488 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3541 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6478 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1263 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.8549 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8078 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.2468 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7545 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6218 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 389.5207 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5731 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.8676 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3226 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5240 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 353.6728 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2621 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.9340 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8039 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 460.7860 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2906 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 589.7671 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 183.8885 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6917 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 65.8489 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9361 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8951 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9229 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2484 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7015 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0311 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7241 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9446 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.0612 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8219 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.7431 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7865 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.1161 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8775 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1814 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1578 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.5056 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 179.4699 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7604 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.8550 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7695 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.9707 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7026 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5745 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1675 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2721 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.1308 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5287 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7563 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5203 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9558 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2391 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8184 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3354 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6878 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.3713 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7217 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8480 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0738 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 85.3759 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6206 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 232.8311 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4636 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1485 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0125 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7677 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.7299 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.9141 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7268 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2125 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2414 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 256.2023 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5650 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2051 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8038 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.1675 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 57.7764 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.5107 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 234.8262 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9477 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8868 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2496 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2025 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2096 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0521 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 29.8146 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 234.5850 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6890 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 495.5248 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 58.5636 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7161 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5986 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9997 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5844 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.5876 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.1503 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.9983 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6723 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6628 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 197.7132 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.1827 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5175 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.2979 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7152 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.5533 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6110 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9775 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9109 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 223.4100 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9028 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6625 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0977 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 915.8860 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2259 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 658.1891 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.3007 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7706 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0140 - accuracy: 0.3889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9382 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9422 - accuracy: 0.2222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7843 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7725 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 207.6414 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0552 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 321.2360 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8421 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9420 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5500 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5383 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 613.6083 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7343 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1558 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0851 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7593 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2512 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7632 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 451.5394 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0243 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9766 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7875 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8067 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3215 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.6631 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.5942 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 445.6548 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4502 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 52.0445 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0793 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7269 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.5767 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9096 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6007 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7513 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.5979 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7387 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1596 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 384.1550 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 316.9267 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6838 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6953 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.5012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 37.9898 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.0396 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 410.5313 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8759 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5527 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9952 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 93.5616 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8211 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.2331 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9393 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 385.4000 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9294 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 125.9302 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 504.6748 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2290 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6923 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7499 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0180 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8848 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6862 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 107.6943 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6113 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0771 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9381 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6865 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.7908 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.7905 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3052 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0879 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1066 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.7512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.2465 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4787 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8344 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0238 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7548 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.2519 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8644 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.9725 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 222.2898 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7983 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.6086 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7468 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0421 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0207 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.7545 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7833 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9503 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 557.7614 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.2386 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7084 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.4754 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.7082 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7203 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 262.0882 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6821 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.1378 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7155 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7747 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5359 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.3034 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 266.6666 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3180 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7110 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8095 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 132.3757 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9537 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1004 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 432.1077 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3465 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 321.3942 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.1340 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 409.4561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.0146 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2946 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.3888 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8004 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 356.2418 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.3230 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.6039 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6689 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.9978 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0915 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1056 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 130.1987 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.5135 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6654 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8217 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.9134 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2001 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.5183 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9545 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7322 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5401 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.0184 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6942 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7704 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 171.9461 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.2930 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7124 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3089 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.3853 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.3282 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.8709 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6905 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2288 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6923 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3259 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 45.3518 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6202 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1114 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8638 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2029 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8963 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6884 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1035 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 919.8925 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6820 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 231.7498 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3026 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 470.0365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6928 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 148.2943 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7318 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8835 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7228 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1355 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0974 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8184 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8597 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 695.0482 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8697 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3632 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.5766 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7872 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7870 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8308 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0536 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.6970 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9677 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0763 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4042 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7868 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7011 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3510 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 448.7733 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 195.0172 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7000 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6820 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 361.2726 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8053 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4842 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.5521 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6644 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7115 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 221.1976 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.1123 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4493 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.1583 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8635 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 152.8058 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7776 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0425 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7013 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.4298 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7155 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 83.2069 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7000 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 51.9521 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.1638 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 178.7818 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6424 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6853 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6166 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.5557 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5116 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1937 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6546 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0889 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7746 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7510 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2801 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 478.0052 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6411 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6930 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1398 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5645 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6450 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0694 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9093 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6588 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6136 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 223.6388 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8316 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.8065 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4534 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9324 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8518 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 229.5615 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0003 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8999 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 602.3960 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 170.4871 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.3457 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.1911 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0585 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3600 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7501 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 194.1852 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9469 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8676 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 284.0462 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.4671 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7091 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 24.3983 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9000 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.6524 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 99.2606 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7494 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7868 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7088 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.6575 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8307 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4802 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7103 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7229 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 221.9868 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7449 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1580 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9093 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 79.8241 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.1641 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5988 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6634 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 556.2783 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1118 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6464 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.1688 - accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 70.1063 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6435 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8245 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.6900 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9184 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6205 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7089 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 134.5582 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7726 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0228 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8226 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7223 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3704 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0600 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7109 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7516 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3776 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9000 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7868 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.9378 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8072 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5603 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.7120 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 489.6089 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7726 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5981 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3411 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2634 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7473 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8521 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8709 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9932 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9951 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.4203 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.7160 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 161.5995 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 513.5029 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 73.8218 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6891 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7368 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 236.6212 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8914 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8124 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8796 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.7801 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 608.2748 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0005 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7257 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.2340 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7196 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 50.9968 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 135.7669 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1229 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8780 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.0550 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0593 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2720 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7783 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 79.6101 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.6417 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 250.4251 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4647 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6961 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6138 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.3524 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6396 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.4942 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5677 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9473 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1553 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6265 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 536.0737 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2100 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 423.8611 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6425 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6197 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7603 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7476 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8289 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2497 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5844 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9689 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 219.8613 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2365 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 106.9426 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.6600 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 227.1351 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9553 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8272 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2849 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8108 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8088 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7539 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7293 - accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1015 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 30.9093 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8991 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7241 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7024 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8151 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7824 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6102 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8794 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 339.3939 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7934 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 518.3658 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7326 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.1308 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7971 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.9507 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9757 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 496.6703 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 23.4724 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7737 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.0721 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 375.9644 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.8393 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6933 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.3696 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7497 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2368 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4240 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6385 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6547 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 229.6550 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9258 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7085 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6829 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.7003 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6934 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2873 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.5641 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 184.9839 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6223 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6634 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2546 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9024 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1799 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 70.6205 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.8377 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7660 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 289.5546 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.2956 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 807.5444 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 72.8940 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2628 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2209 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 320.9204 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 73.7194 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.3026 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9445 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 56.5669 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8652 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6768 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.0395 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9417 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 101.3424 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 209.2421 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8343 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5092 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 97.8021 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7075 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 282.6163 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 731.7975 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7381 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 411.7807 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0262 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.9981 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5056 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 281.8145 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 98.0804 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7436 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2823 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7111 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8049 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7113 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7429 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7042 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.5619 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.2305 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 734.6407 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6417 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.9518 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1145 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7915 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9871 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 191.4699 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1255 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2862 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4490 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 283.1821 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 504.5093 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.9976 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8308 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 345.2036 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.6654 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4996 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7628 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 116.2013 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3002 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7231 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2160 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 273.9762 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8811 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 422.8137 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 250.1358 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8460 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.2962 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2762 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7304 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0619 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 326.2293 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.7930 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7695 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9273 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 300.0631 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.1285 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8341 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6829 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5316 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3869 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7436 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6085 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 273.9921 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6839 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0112 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 177.3200 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0375 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8476 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2660 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8258 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.4394 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 536.3386 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.0624 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 362.0728 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2935 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.8908 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1954 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8343 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6695 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8025 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0590 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7602 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9875 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.4934 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.5732 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7352 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 206.7372 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 61.0692 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7260 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9492 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3258 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7814 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7677 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8720 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1391 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6869 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2282 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5983 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.2720 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 741.5594 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7820 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.1643 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1815 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2078 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6306 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8469 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7791 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 163.2181 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4237 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 354.7404 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.8708 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9995 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3096 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5981 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7238 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.6584 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8627 - accuracy: 0.1667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7130 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 108.3749 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 403.2499 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6884 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7508 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 296.0358 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.3885 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2496 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6593 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.3968 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7393 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7383 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6224 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8559 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.4297 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 53.1621 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1524 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1613 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3583 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 45.6546 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 306.8647 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6696 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4128 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.0142 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0334 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5192 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.3367 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6829 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3511 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7561 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 171.1481 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7399 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7866 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6766 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8642 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.0542 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5412 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8019 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.4502 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2480 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5724 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1062 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3409 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.2970 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5460 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9789 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7933 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4682 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5624 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 808.8530 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.0790 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.8894 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8041 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3141 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6734 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6514 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4281 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6877 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.2174 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8644 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3417 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5892 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1916 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0248 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 370.4649 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6193 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 562.2979 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2369 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 250.3085 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0990 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6941 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 152.4309 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2663 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6978 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 53.7789 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4588 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 415.3685 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1264 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3854 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 136.6511 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.4630 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 357.7410 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7749 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 45.8908 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6894 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8609 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5497 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 479.3602 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9945 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9074 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5093 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 67.9523 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.5086 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7077 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9640 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0713 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.5877 - accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 40.6561 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.1909 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9088 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2325 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1601 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8066 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5999 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.7593 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6201 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 862.4490 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7655 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6545 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 262.9325 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6842 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3438 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.2751 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0372 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.5620 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7014 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6944 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5459 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 258.8725 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3500 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 220.6792 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 284.7284 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0245 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0250 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 107.7424 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3374 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1445 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 96.0095 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0805 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 72.5952 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1432 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 189.5272 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 36.2859 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5679 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1866 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 289.6636 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6284 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6481 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0647 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 345.1574 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.2489 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.8026 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.7677 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8101 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6023 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6457 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7554 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 690.0817 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.4735 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0740 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.1086 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 100.0649 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2724 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6647 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 302.1888 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 287.7696 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6714 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4165 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5442 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 415.0716 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1473 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5265 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4142 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6459 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5894 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.7172 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5015 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2887 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7829 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1659 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5002 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7360 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4641 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7082 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7525 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.2730 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2223 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1334 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1136 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6502 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 360.9055 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 417.7363 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2945 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9396 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5694 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6352 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6968 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2384 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8763 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7578 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1508 - accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9630 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.8191 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1478 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8026 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 499.7804 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.3932 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.8742 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 560.3217 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.5784 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 435.5579 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5824 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.9161 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4448 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6940 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.4054 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.6993 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6677 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6368 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7128 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.7582 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.5767 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 234.6707 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2167 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7471 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.3105 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1396 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7040 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5788 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.2289 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.5526 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 92.1579 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 114.7630 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 507.4607 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0933 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5166 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7131 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6229 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3452 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4020 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.0997 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7512 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3150 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6714 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9106 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7035 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3068 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.2525 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 264.7564 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7867 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5047 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6649 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 417.8236 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8975 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2865 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7716 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.2426 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 130.8799 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1473 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2566 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2521 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7528 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6986 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.3489 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7247 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3120 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 683.3616 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.2112 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3260 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.6986 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.0140 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7727 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6812 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 505.7343 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.3608 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6593 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2055 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 524.9080 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 152.2480 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3528 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.3659 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2505 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.9985 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9286 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7614 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8326 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0911 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2944 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.3184 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7027 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9565 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8017 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6852 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.6374 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 452.7568 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.3216 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9991 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 321.5049 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6920 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 109.4911 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 84.5493 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9755 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.3717 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9925 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6307 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0211 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7242 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7838 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2862 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7670 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7128 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0288 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4211 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9289 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7285 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 99.4328 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 46.2475 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.8106 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7379 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3313 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8482 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6968 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.9481 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6039 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.5830 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6787 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.8936 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7060 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6034 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8019 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 40.2148 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0946 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8537 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.1943 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8367 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7352 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 648.7041 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 650.6292 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2427 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 417.0202 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9373 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9686 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5401 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 29.0295 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9720 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 284.5021 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.2997 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.7847 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7324 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 311.9653 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6467 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9835 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6974 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 278.8785 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7295 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5962 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.3323 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4201 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7274 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.2909 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.3004 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4635 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0751 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5803 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 589.9011 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.5012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 43.7164 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5193 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6822 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6965 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.5744 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2382 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1540 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0898 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 734.3582 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6369 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9894 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.8550 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8340 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3603 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3821 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7197 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 214.6151 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 68.4848 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6921 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6777 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4432 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0920 - accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7307 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2591 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.5142 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.9249 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7692 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6719 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0261 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 100.9646 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 415.8761 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6655 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6537 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9536 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 590.7019 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6448 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7474 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1944 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9473 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8787 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6159 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 481.4879 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0219 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7281 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 277.0996 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.4327 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7591 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8502 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7492 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9965 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7336 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.0510 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7488 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8012 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9867 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5267 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 551.8586 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 116.4100 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 473.9774 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7394 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6104 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.4058 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1983 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8580 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3396 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0678 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 213.2671 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3213 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 267.7747 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4861 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.7881 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.1738 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6960 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 291.3590 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 356.1318 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7917 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3378 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7187 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 414.5224 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7172 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6170 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 49.4647 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7728 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 116.6817 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7608 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 98.8447 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3594 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.5921 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 345.5667 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0534 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.5105 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 428.5783 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7066 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 350.1133 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3322 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9751 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.2261 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8633 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7150 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9614 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0933 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7759 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7266 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9650 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9409 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 425.4634 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9607 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 562.3707 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.4123 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4250 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.6373 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4842 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2135 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.0571 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3495 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7862 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3981 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0309 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2027 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8844 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8442 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4182 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9621 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5890 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 592.4688 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2689 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6697 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2588 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.5460 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5919 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 384.3138 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6894 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1516 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 254.4449 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6940 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 163.2272 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4752 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2231 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.0347 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 535.8312 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3693 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6293 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0469 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 77.0561 - accuracy: 0.2222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2448 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 199.5459 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9383 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3190 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.8132 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7526 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4764 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9181 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8571 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6680 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6865 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2307 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2127 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1454 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8108 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7756 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7569 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7989 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 117.6097 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.0297 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9770 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7876 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4308 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8198 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6753 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5502 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7039 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1736 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7285 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7712 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3952 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7722 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 916.6512 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.7764 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5143 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.5200 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3735 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 57.2823 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0650 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5819 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7640 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.5660 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9415 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7777 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 133.2957 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7952 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5002 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 375.5101 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 246.2070 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 362.1085 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7202 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7367 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4972 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 75.5905 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 80.6298 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6977 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.7572 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9425 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7376 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0533 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0173 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.5750 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0171 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 121.5983 - accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5991 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6420 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 413.6197 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8027 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4540 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.7862 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9625 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8390 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 180.3170 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 498.6125 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 389.4966 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8185 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.7260 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2085 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8654 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 393.4794 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9210 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.2872 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7029 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7421 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5921 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 209.5521 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7253 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2652 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 379.7256 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8902 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 16.3797 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8682 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5068 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.8939 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8206 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 47.8725 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2640 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0013 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6920 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2207 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5844 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0015 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0026 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7143 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9392 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 613.2024 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2128 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2930 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6840 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6961 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 39.3215 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4055 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6071 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7019 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 376.0689 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6762 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8934 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6816 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7521 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8003 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1746 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.8786 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 276.7834 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7936 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.0876 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 774.3182 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 336.9324 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 227.2680 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7187 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.0049 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7213 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0790 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7216 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0032 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 652.7186 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 602.3683 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6785 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8628 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.1519 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8900 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7413 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 150.1842 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7847 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7267 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6254 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6640 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 317.1259 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.8317 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0546 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.9450 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5809 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.1326 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.4349 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 206.3814 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.3094 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8310 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0748 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2049 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9359 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 63.8412 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9306 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.5375 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2358 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6979 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 52.0475 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6734 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 150.2224 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0218 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4883 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 129.8313 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 316.7282 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2876 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 464.8892 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2609 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3626 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2272 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1767 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6915 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8385 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 15.8448 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.0819 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.7614 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.9194 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4513 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 589.2045 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.5941 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.4327 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 536.4288 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.0197 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6739 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.7039 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 217.5009 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1401 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5568 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0880 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 288.9810 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 151.0649 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7659 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 71.6452 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 27.7699 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8451 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9416 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.1794 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0003 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7119 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1655 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5085 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 38.5586 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.7013 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7890 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8723 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.8619 - accuracy: 0.2222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6433 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6846 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7175 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7708 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 408.2739 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.2214 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4968 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 125.8277 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7536 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.3693 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 513.5923 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.9246 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.7121 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7615 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7058 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0075 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6933 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3592 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5174 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8096 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0520 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 40.5012 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1831 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7632 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5611 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 222.0103 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1840 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7311 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6324 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 151.5038 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 171.7254 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7785 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3059 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.1944 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 180.8870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7747 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7794 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.7682 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 390.4664 - accuracy: 0.3889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4081 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8840 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 21.7550 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7629 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.1378 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6800 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3905 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4837 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6645 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5758 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6720 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.1644 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 60.6149 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7840 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2727 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9050 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.9034 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.9647 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2443 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7529 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2534 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7383 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 51.7599 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1669 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 412.8465 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 146.1203 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6190 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 489.3000 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3919 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6448 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3984 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.6732 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6014 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.1331 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 74.8898 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4038 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.6230 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7792 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7470 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7191 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 275.3148 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6737 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1150 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6569 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0033 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2967 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1379 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8674 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6873 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.1447 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9917 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7823 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6713 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9238 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8117 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0517 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7252 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0065 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.0732 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 86.8440 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7021 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.7830 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6959 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4394 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.8470 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2079 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 37.6215 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8499 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4080 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.6332 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7327 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6917 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7936 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9674 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5727 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7107 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2623 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8204 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 17.0460 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3409 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0671 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7066 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.5126 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8441 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.5020 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6665 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9123 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 60.3364 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 202.8221 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7550 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9010 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9182 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7422 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1919 - accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2899 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1417 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6853 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1049 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5005 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4916 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.0410 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8017 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6898 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6393 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 632.6924 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0564 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3153 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8041 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 130.8516 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9142 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3882 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6906 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2870 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.7032 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8726 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9540 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7772 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0784 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 16.8752 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.5481 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8169 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 49.3354 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.2157 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.2554 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4823 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 143.4979 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.8346 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6544 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.3346 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7694 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6962 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 400.8462 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9693 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5462 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0911 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6291 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7091 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.7482 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.9942 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 393.7202 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 306.8979 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7031 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8154 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4686 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8374 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 91.2890 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 25.2489 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4339 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7485 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6806 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9462 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 245.2803 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 242.6992 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.8443 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.3461 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 180.3247 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6672 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5811 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.7430 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6320 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.5449 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.1751 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2268 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0242 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 87.4892 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.8893 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5066 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8764 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6823 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.4885 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.6721 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2311 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.2828 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9112 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1152 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7202 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 111.4411 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9851 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.4650 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.4909 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8287 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 626.7195 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6312 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4115 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.7582 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7174 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8863 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 228.2422 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8979 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 396.7287 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 274.0497 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 181.5534 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0038 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.2369 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0910 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 118.4623 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 209.3789 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 250.6421 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6409 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7187 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4089 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2310 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7967 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6895 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.8901 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 354.8213 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.2832 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7203 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.2129 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7779 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8041 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.5554 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.2517 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 294.7627 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6829 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1934 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 251.0924 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9713 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2234 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 126.7450 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7314 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2362 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2339 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2229 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8350 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4890 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2659 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6516 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 476.9194 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7813 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6808 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0033 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.9265 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 193.0266 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.0870 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.0879 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.0934 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3756 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4912 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8564 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 384.2396 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1322 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7905 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.3736 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 154.0733 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6510 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1759 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 87.9017 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.4995 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3977 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 451.5940 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 62.4696 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.4039 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8005 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 275.7115 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2364 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8081 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 346.5269 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0735 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1445 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8038 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2400 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 808.0769 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0598 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0292 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7091 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0977 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.1603 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7760 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5286 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7490 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 553.3676 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8570 - accuracy: 0.2778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.4445 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8305 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 138.4501 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6472 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 13.7565 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.4004 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 87.6088 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6298 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 272.0642 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 320.5446 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 614.6005 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7125 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7893 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7301 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 500.0803 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6637 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.9742 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9695 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0603 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6974 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.2910 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1705 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8864 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 120.8903 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 54.5104 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8442 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 615.0922 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7462 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.9600 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.9070 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8604 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 686.9089 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7150 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8711 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6842 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6764 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.6209 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3990 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 332.5900 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7636 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0810 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7774 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8880 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7747 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 65.0070 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 42.2620 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7678 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0653 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1287 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7139 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.3585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 187.8200 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 46.4908 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0719 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 29.0363 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5070 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 149.3149 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7418 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.2628 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8823 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5341 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3238 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8780 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7659 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3207 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1885 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 535.5994 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8146 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 509.7407 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 62.4375 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 101.0634 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 100.0851 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 248.9030 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7654 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1656 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5907 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 556.9332 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 64.0266 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8137 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.4062 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 196.1412 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8458 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 232.4201 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6280 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 260.0175 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3189 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7125 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 393.6420 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 28.1716 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.2906 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 177.5689 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 713.1585 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6939 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.9716 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 77.3108 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7551 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7013 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4087 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 22.7565 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2899 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5134 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9979 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6622 - accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 19.4020 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6686 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7462 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6605 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 360.5400 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 193.9050 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 18.1489 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0898 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 51.4187 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7535 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7526 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6874 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7867 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 19.3861 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.6840 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6458 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6257 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4999 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 34.9508 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 317.4650 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1989 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.2349 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8915 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9482 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7943 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9458 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7354 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5908 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5230 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 33.2461 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 363.6325 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7532 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7721 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 43.8657 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7188 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2742 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 303.4348 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 98.8662 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.6104 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1868 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 124.7771 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 186.6656 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9945 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.1628 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 330.6823 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6982 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 492.9125 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5641 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 125.9161 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3588 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 628.8435 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 235.0278 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5118 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.6012 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 26.1635 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7791 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7145 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 328.4341 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9196 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1322 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7251 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 75.9908 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 18.7136 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8043 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.7731 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 327.2912 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0481 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7550 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3781 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.9552 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 277.9478 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4898 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2714 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3727 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0675 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3598 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8412 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 31.4436 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.5559 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 61.0846 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6073 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 116.6033 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6590 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7366 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 60.3121 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7119 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6744 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 551.7192 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8032 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7072 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5771 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0741 - accuracy: 0.5556\n"
     ]
    }
   ],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"n_layers\": range(2, 6), \n",
    "                \"n_units\": range(50, 300, 50),\n",
    "                \"dropout\": np.arange(0, 0.6, 0.1),\n",
    "                \"kernel_regularizer\": [0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                \"optimizer\": [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "studySoftmax_Grid = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "studySoftmax_Grid.optimize(objectiveSoftmax_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64f63924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 2,\n",
       "  'n_units': 100,\n",
       "  'dropout': 0.30000000000000004,\n",
       "  'kernel_regularizer': 0.01,\n",
       "  'optimizer': 'SGD'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0.001,\n",
       "  'optimizer': 'RMSprop'},\n",
       " {'n_layers': 5,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.2,\n",
       "  'kernel_regularizer': 0.001,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 4,\n",
       "  'n_units': 200,\n",
       "  'dropout': 0.0,\n",
       "  'kernel_regularizer': 0,\n",
       "  'optimizer': 'Adam'},\n",
       " {'n_layers': 3,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.4,\n",
       "  'kernel_regularizer': 0.0001,\n",
       "  'optimizer': 'RMSprop'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(studySoftmax_Grid.get_trials())\n",
    "models_same_acc_OptunaSearchCV(studySoftmax_Grid.get_trials(), top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e5e3b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 1.5075 - acc: 0.5882 - val_loss: 1.5001 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.5304 - acc: 0.4706 - val_loss: 1.4901 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.4589 - acc: 0.5882 - val_loss: 1.4768 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.4533 - acc: 0.6471 - val_loss: 1.4611 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4087 - acc: 0.7255 - val_loss: 1.4429 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4211 - acc: 0.6275 - val_loss: 1.4238 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3313 - acc: 0.8235 - val_loss: 1.4043 - val_acc: 0.6471\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.2838 - acc: 0.8235 - val_loss: 1.3802 - val_acc: 0.7059\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2530 - acc: 0.8039 - val_loss: 1.3500 - val_acc: 0.7647\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1600 - acc: 0.8824 - val_loss: 1.3148 - val_acc: 0.7059\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0294 - acc: 0.9412 - val_loss: 1.2800 - val_acc: 0.7647\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9853 - acc: 0.9608 - val_loss: 1.2541 - val_acc: 0.7647\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9037 - acc: 1.0000 - val_loss: 1.2496 - val_acc: 0.7647\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8796 - acc: 0.9804 - val_loss: 1.2711 - val_acc: 0.8235\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8407 - acc: 1.0000 - val_loss: 1.3055 - val_acc: 0.8235\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8134 - acc: 1.0000 - val_loss: 1.3115 - val_acc: 0.8235\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.7850 - acc: 1.0000 - val_loss: 1.3138 - val_acc: 0.8235\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7692 - acc: 1.0000 - val_loss: 1.3324 - val_acc: 0.7647\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7634 - acc: 1.0000 - val_loss: 1.3467 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6955 - acc: 0.6667\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Grid_softmax = models.Sequential()\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001), \n",
    "                                             input_shape=(410,)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.001)))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dropout(0.2))\n",
    "modelFC_optuna_Grid_softmax.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_optuna_Grid_softmax.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_Grid_softmax.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Grid_softmax.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91d41c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveSoftmax_TPE(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy para una red neuronal con activación softmax\n",
    "    '''\n",
    "    modelFC_optuna = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    regularization = trial.suggest_categorical(\"kernel_regularizer\", [0, 0.0001, 0.001, 0.01, 0.1, 1])\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna.add(layers.Dense(num_hidden, activation=\"relu\", kernel_regularizer=regularizers.L2(regularization)))\n",
    "        modelFC_optuna.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna.compile(loss=\"categorical_crossentropy\", optimizer=optimizers, metrics=[\"accuracy\"])\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c552f735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step - loss: 357.7457 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 590.6211 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7350 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8436 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 81.4107 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 771.1399 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0561 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 23.7121 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 346.2152 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 78.7379 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 615.5834 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 584.3633 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0562 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7276 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.9502 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7640 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.2501 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 78.2007 - accuracy: 0.8889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 63.2132 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 34.0476 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 318.7434 - accuracy: 0.2222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 308.5221 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 403.9059 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7005 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8029 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 64.5336 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8591 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9166 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2834 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1531 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0511 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0539 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7152 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4388 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0338 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7152 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4898 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5648 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6877 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0754 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6879 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6077 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8838 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4159 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3784 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 95.8417 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5281 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 299.1025 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 44.6263 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0647 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4831 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3793 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1897 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 732.8246 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8516 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3371 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 79.5591 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6852 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0133 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8102 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 326.5013 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.1314 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7305 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3947 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 64.9597 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 622.5339 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.0318 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8608 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0719 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6220 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5926 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5693 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9413 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5848 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7893 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7434 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6951 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 66.4396 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 456.9581 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2300 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6963 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1650 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6578 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0878 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6324 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7117 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9565 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7455 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 44.4761 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7870 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7716 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7187 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8020 - accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9306 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7003 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 554.3813 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0894 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7798 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9086 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8767 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8772 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7749 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8657 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 50.4507 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7529 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6807 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.4392 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.7784 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 636.2859 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8255 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5874 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9508 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 83.8082 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5615 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6372 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 369.3751 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8146 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1732 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8944 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6430 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9920 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8635 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2384 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0225 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8892 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1567 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 55.8142 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0754 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8249 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6248 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2248 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1031 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3184 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9519 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1518 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5131 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6241 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.7792 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9894 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6147 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.3148 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3195 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3380 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.9490 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6517 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.5171 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7071 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0038 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.9464 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.1597 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.2109 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.1208 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 283.0371 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5767 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9905 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9299 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3096 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7824 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1302 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7645 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.4968 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5023 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7530 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5577 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7926 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 25.7229 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9005 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6337 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0053 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7485 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7081 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7303 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8662 - accuracy: 0.3333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2686 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3231 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7965 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6946 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 731.5424 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8159 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2774 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6900 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3549 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5825 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 82.0571 - accuracy: 0.3889\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4845 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8557 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7780 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9389 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7446 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1091 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8626 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2804 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6249 - accuracy: 0.7778\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9813 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.4942 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7242 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1898 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.1978 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9044 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9004 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7293 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7047 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4341 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8088 - accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6684 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7263 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.4443 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1126 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.0559 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4422 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.4956 - accuracy: 0.6111\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6224 - accuracy: 0.7222\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6715 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8321 - accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9863 - accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "studySoftmax_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "studySoftmax_TPE.optimize(objectiveSoftmax_TPE, n_trials=216)\n",
    "# n_trials = (4 x 5 x 6 x 6 x 3) * 0.1 = 216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4cfd980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_layers': 5,\n",
       "  'n_units': 150,\n",
       "  'dropout': 0.1,\n",
       "  'kernel_regularizer': 0.1,\n",
       "  'optimizer': 'SGD'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_acc = top_acc_OptunaSearchCV(studySoftmax_TPE.get_trials())\n",
    "models_same_acc_OptunaSearchCV(studySoftmax_TPE.get_trials(), top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cdf62f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=18, values=[0.8888888955116272], datetime_start=datetime.datetime(2022, 7, 3, 2, 1, 4, 673838), datetime_complete=datetime.datetime(2022, 7, 3, 2, 1, 5, 925074), params={'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'kernel_regularizer': 0.1, 'optimizer': 'SGD'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1), 'kernel_regularizer': CategoricalDistribution(choices=(0, 0.0001, 0.001, 0.01, 0.1, 1)), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=18, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studySoftmax_TPE.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19d7dcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 82.5780 - acc: 0.5686 - val_loss: 82.0513 - val_acc: 0.3529\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 81.9542 - acc: 0.3922 - val_loss: 81.4004 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 81.2773 - acc: 0.5490 - val_loss: 80.7557 - val_acc: 0.3529\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 80.6401 - acc: 0.5686 - val_loss: 80.1161 - val_acc: 0.3529\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 80.0036 - acc: 0.5490 - val_loss: 79.4815 - val_acc: 0.4706\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 79.3661 - acc: 0.5098 - val_loss: 78.8521 - val_acc: 0.5294\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 78.7274 - acc: 0.5882 - val_loss: 78.2288 - val_acc: 0.4706\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 78.1143 - acc: 0.5686 - val_loss: 77.6091 - val_acc: 0.5294\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 77.5020 - acc: 0.5686 - val_loss: 76.9952 - val_acc: 0.5294\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 76.8811 - acc: 0.4902 - val_loss: 76.3861 - val_acc: 0.5294\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 76.2602 - acc: 0.6667 - val_loss: 75.7822 - val_acc: 0.5294\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 75.7797 - acc: 0.5000\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_TPE_softmax = models.Sequential()\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1),\n",
    "                                            input_shape=(410,)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizers.L2(0.1)))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_TPE_softmax.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_optuna_TPE_softmax.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_optuna_TPE_softmax.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_TPE_softmax.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa31a6",
   "metadata": {},
   "source": [
    "Obtenemos un mayor accuracy utilizando la activación softmax. Sin embargo, parece que la red tiene un problema de sobreajuste. Vamos a tratar de reducir esta diferencia probando distintos tipos de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddc9d896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 0.6826 - acc: 0.5686 - val_loss: 0.6321 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5491 - acc: 0.7255 - val_loss: 0.5449 - val_acc: 0.8235\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2874 - acc: 0.9608 - val_loss: 0.4808 - val_acc: 0.8235\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2832 - acc: 0.8824 - val_loss: 1.4154 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4606 - acc: 0.8431 - val_loss: 0.4541 - val_acc: 0.7059\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.4503 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.4612 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4476 - acc: 0.8889\n",
      "Accuracy : 88.89% ----- Regularización: None \n",
      "\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 235ms/step - loss: 0.6908 - acc: 0.5490 - val_loss: 0.6602 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5952 - acc: 0.6471 - val_loss: 0.6676 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4646 - acc: 0.8039 - val_loss: 0.7404 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3168 - acc: 0.8824 - val_loss: 0.6688 - val_acc: 0.7647\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1293 - acc: 1.0000 - val_loss: 0.9230 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0666 - acc: 1.0000 - val_loss: 0.8326 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.5416 - val_acc: 0.7059\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.9422 - val_acc: 0.7647\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.8858 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6068 - acc: 0.8333\n",
      "Accuracy : 83.33% ----- Regularización: l1 \n",
      "\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 0.6851 - acc: 0.5686 - val_loss: 0.6678 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5931 - acc: 0.6667 - val_loss: 0.7296 - val_acc: 0.6471\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4681 - acc: 0.7647 - val_loss: 0.8234 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3093 - acc: 0.9412 - val_loss: 0.8019 - val_acc: 0.7647\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1507 - acc: 0.9804 - val_loss: 1.1311 - val_acc: 0.6471\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0768 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.5294\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.6976 - val_acc: 0.5882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8220 - val_acc: 0.7059\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.8327 - val_acc: 0.6471\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8160 - acc: 0.7222\n",
      "Accuracy : 72.22% ----- Regularización: l2 \n",
      "\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 0.6893 - acc: 0.4510 - val_loss: 0.6878 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5906 - acc: 0.6471 - val_loss: 0.8122 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5085 - acc: 0.7255 - val_loss: 0.6951 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2444 - acc: 1.0000 - val_loss: 0.7203 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0699 - acc: 1.0000 - val_loss: 1.0157 - val_acc: 0.7059\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 1.0366 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9169 - val_acc: 0.6471\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.1239 - val_acc: 0.6471\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.0979 - val_acc: 0.6471\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.1169 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1226 - acc: 0.7222\n",
      "Accuracy : 72.22% ----- Regularización: l1_l2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "regularizers = [None, \"l1\", \"l2\", \"l1_l2\"]\n",
    "\n",
    "for regularizer in regularizers:\n",
    "    modelFC_optuna_Grid_softmax = models.Sequential()\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\"))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\"))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\"))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(150, activation=\"relu\"))\n",
    "    modelFC_optuna_Grid_softmax.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    modelFC_optuna_Grid_softmax.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "    es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna_Grid_softmax.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy = modelFC_optuna_Grid_softmax.evaluate(X_test, y_test_softmax)\n",
    "    print(\"Accuracy : {:0.2f}% ----- Regularización: {} \\n\".format(accuracy * 100, regularizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eebafe",
   "metadata": {},
   "source": [
    "### Función de pérdida personalizada\n",
    "\n",
    "Otra posibilidad es tratar de tener en cuenta los datos con peores resultados en el backpropagation, es decir, asignar un mayor peso a esos datos. Esta es la idea del método \"AdaBoost\" que sin embargo no está actualmente implementado en keras. Una alternativa es definir propiamente otra función de loss personalizada.\n",
    "\n",
    "Fuente: https://stackoverflow.com/questions/48720197/weight-samples-if-incorrect-guessed-in-binary-cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad055d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, tp_weight=0.5, tn_weight=0.5, fp_weight=1, fn_weight=1):\n",
    "    '''\n",
    "    Función de pérdida personalizada para el optimizador de una red neuronal.\n",
    "    El método recibe las predicciones y el valor real de la clasificación, así como los pesos que se desea asignar a los\n",
    "    clasificaciones tanto erróneas como acertadas.\n",
    "    '''\n",
    "#     print(\"NEW ITER ------\")\n",
    "#     print(\"Y_TRUE:\", tf.print(y_true))\n",
    "#     print(\"Y_PRED:\", tf.print(y_pred))\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_classes = tf.keras.backend.greater_equal(y_pred, 0.5)\n",
    "    y_pred_classes_float = tf.keras.backend.cast(y_pred_classes, tf.keras.backend.floatx())\n",
    "    y_true_float = tf.keras.backend.cast(y_true, tf.keras.backend.floatx())\n",
    "    \n",
    "#     print(\"\\n\")\n",
    "#     print(\"1:\", tf.print(y_pred_classes_float))\n",
    "#     print(\"2:\", tf.print(y_true_float))\n",
    "\n",
    "    # Get misclassified examples\n",
    "    wrongly_classified = tf.keras.backend.not_equal(y_true_float, y_pred_classes_float)\n",
    "    wrongly_classified_float = tf.keras.backend.cast(wrongly_classified, tf.keras.backend.floatx())\n",
    "    wrongly_classified_float2 = tf.gather(wrongly_classified_float, [0], axis=1)\n",
    "    \n",
    "#     print(\"3:\", tf.print(wrongly_classified_float2))\n",
    "    \n",
    "    # Get correctly classified examples\n",
    "    correctly_classified = tf.keras.backend.equal(y_true_float, y_pred_classes_float)\n",
    "    correctly_classified_float = tf.keras.backend.cast(correctly_classified, tf.keras.backend.floatx())\n",
    "    correctly_classified_float2 = tf.gather(correctly_classified_float, [0], axis=1)\n",
    "    \n",
    "#     print(\"4:\", tf.print(correctly_classified_float2))\n",
    "\n",
    "    # Get tp, fp, tn, fn\n",
    "    tp = correctly_classified_float * y_true_float\n",
    "    tn = correctly_classified_float * (1 - y_true_float)\n",
    "    fp = wrongly_classified_float * y_true_float\n",
    "    fn = wrongly_classified_float * (1 - y_true_float)\n",
    "\n",
    "    # Get weights\n",
    "    weight = tp_weight * tp + fp_weight * fp + tn_weight * tn + fn_weight * fn\n",
    "    weight2 = tf.gather(weight, [0], axis=1)\n",
    "    weight3 = tf.math.reduce_sum(weight2, axis=1)\n",
    "#     print(\"TN_W\", tn)\n",
    "#     tf.print(tp)\n",
    "#     tf.print(tp2)\n",
    "#     tf.print(weight3)\n",
    "    \n",
    "    loss = tf.keras.metrics.binary_crossentropy(y_true, y_pred)\n",
    "#     tf.print(loss)\n",
    "    weighted_loss = loss * weight3\n",
    "#     tf.print(weighted_loss)\n",
    "    \n",
    "#     weighted_loss2 = tf.gather(weighted_loss, [0], axis=1)\n",
    "    \n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73f781",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que los anteriores ``tp``, ``fn``, ... son tensores (vectores de ``tensorflow``) y por tanto, el resultado guardado en ``weight`` es igualmente otro tensor, no un único valor numérico.\n",
    "\n",
    "_NOTA: se entienden los positivos como aquellas muestras correspondientes con una etiqueta \"1\" (enfermos) y por tanto como negativos los registros con etiqueta \"0\" (grupo de control)._\n",
    "\n",
    "Vamos a probar cómo funciona la función personalizada sobre los modelos de redes neuronales que peores resultados han obtenido para comprobar si de este modo podemos mejorar sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9bb9f5a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.5306 - acc: 0.5098 - val_loss: 0.4859 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4283 - acc: 0.7059 - val_loss: 0.4530 - val_acc: 0.6471\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3334 - acc: 0.8235 - val_loss: 0.4740 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2332 - acc: 0.9020 - val_loss: 0.4568 - val_acc: 0.7059\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1204 - acc: 0.9804 - val_loss: 0.4746 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0468 - acc: 1.0000 - val_loss: 0.3448 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.2940 - val_acc: 0.8235\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4290 - val_acc: 0.8235\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4033 - val_acc: 0.7647\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.4145 - val_acc: 0.7647\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.4270 - val_acc: 0.7647\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5148 - acc: 0.8889\n",
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_CL = models.Sequential()\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_CL.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_CL.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_CL.compile(loss=custom_loss, optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_CL.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_CL.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd16fe8",
   "metadata": {},
   "source": [
    "### Sample-weight\n",
    "\n",
    "Una alternativa a lo anterior, sería usar un vector de pesos propio y pasarlo a la función ``fit`` del modelo, a través del parámetro ``sample_weight``, en lugar de definir una función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "065bb881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 170ms/step - loss: 0.3418 - acc: 0.5882 - val_loss: 0.3174 - val_acc: 0.5882\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.2318 - acc: 0.7255 - val_loss: 0.2629 - val_acc: 0.7059\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.1168 - acc: 0.9020 - val_loss: 0.2408 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.2301 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1631 - val_acc: 0.6471\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1534 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0171 - acc: 0.9804 - val_loss: 0.0695 - val_acc: 0.5294\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.0540 - val_acc: 0.6471\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.7059\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 6.9570e-04 - acc: 1.0000 - val_loss: 0.1776 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.9242e-04 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 0.8235\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.1914e-04 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 2.6941e-04 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.3213e-04 - acc: 1.0000 - val_loss: 0.1616 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2.0263e-04 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.7837e-04 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.8824\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.5763e-04 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.3951e-04 - acc: 1.0000 - val_loss: 0.1678 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.2198e-04 - acc: 1.0000 - val_loss: 0.1702 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0704e-04 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9.4490e-05 - acc: 1.0000 - val_loss: 0.1751 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 8.3502e-05 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 7.4014e-05 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 6.5577e-05 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.8259e-05 - acc: 1.0000 - val_loss: 0.1845 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 5.1701e-05 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 4.5930e-05 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.0814e-05 - acc: 1.0000 - val_loss: 0.1920 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.6248e-05 - acc: 1.0000 - val_loss: 0.1945 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.2222e-05 - acc: 1.0000 - val_loss: 0.1970 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 2.8600e-05 - acc: 1.0000 - val_loss: 0.1996 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.5364e-05 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.2497e-05 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.9926e-05 - acc: 1.0000 - val_loss: 0.2069 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.7646e-05 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.5631e-05 - acc: 1.0000 - val_loss: 0.2115 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 1.3827e-05 - acc: 1.0000 - val_loss: 0.2139 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.2214e-05 - acc: 1.0000 - val_loss: 0.2166 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 1.0797e-05 - acc: 1.0000 - val_loss: 0.2190 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.5555e-06 - acc: 1.0000 - val_loss: 0.2216 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 8.4535e-06 - acc: 1.0000 - val_loss: 0.2242 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 7.4818e-06 - acc: 1.0000 - val_loss: 0.2269 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6.6251e-06 - acc: 1.0000 - val_loss: 0.2294 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.8649e-06 - acc: 1.0000 - val_loss: 0.2319 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 5.1860e-06 - acc: 1.0000 - val_loss: 0.2346 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.5859e-06 - acc: 1.0000 - val_loss: 0.2371 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 4.0577e-06 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.5893e-06 - acc: 1.0000 - val_loss: 0.2425 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.1776e-06 - acc: 1.0000 - val_loss: 0.2453 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.8149e-06 - acc: 1.0000 - val_loss: 0.2482 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.4956e-06 - acc: 1.0000 - val_loss: 0.2508 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 2.2142e-06 - acc: 1.0000 - val_loss: 0.2536 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.9652e-06 - acc: 1.0000 - val_loss: 0.2564 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.7452e-06 - acc: 1.0000 - val_loss: 0.2593 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.5513e-06 - acc: 1.0000 - val_loss: 0.2620 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.3805e-06 - acc: 1.0000 - val_loss: 0.2648 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.2288e-06 - acc: 1.0000 - val_loss: 0.2677 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.0948e-06 - acc: 1.0000 - val_loss: 0.2705 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 9.7596e-07 - acc: 1.0000 - val_loss: 0.2734 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.7077e-07 - acc: 1.0000 - val_loss: 0.2763 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 7.7780e-07 - acc: 1.0000 - val_loss: 0.2792 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 6.9515e-07 - acc: 1.0000 - val_loss: 0.2822 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6.2163e-07 - acc: 1.0000 - val_loss: 0.2851 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 5.5604e-07 - acc: 1.0000 - val_loss: 0.2881 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.9785e-07 - acc: 1.0000 - val_loss: 0.2909 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.4638e-07 - acc: 1.0000 - val_loss: 0.2938 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.0049e-07 - acc: 1.0000 - val_loss: 0.2967 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.5970e-07 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.2349e-07 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 2.9107e-07 - acc: 1.0000 - val_loss: 0.3050 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2.6225e-07 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.3647e-07 - acc: 1.0000 - val_loss: 0.3104 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.1347e-07 - acc: 1.0000 - val_loss: 0.3131 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.9299e-07 - acc: 1.0000 - val_loss: 0.3158 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.7461e-07 - acc: 1.0000 - val_loss: 0.3184 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.5822e-07 - acc: 1.0000 - val_loss: 0.3210 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.4349e-07 - acc: 1.0000 - val_loss: 0.3235 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.3034e-07 - acc: 1.0000 - val_loss: 0.3261 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1843e-07 - acc: 1.0000 - val_loss: 0.3285 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.0785e-07 - acc: 1.0000 - val_loss: 0.3311 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9.8266e-08 - acc: 1.0000 - val_loss: 0.3335 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 8.9734e-08 - acc: 1.0000 - val_loss: 0.3359 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 8.1984e-08 - acc: 1.0000 - val_loss: 0.3383 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 7.5081e-08 - acc: 1.0000 - val_loss: 0.3406 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 6.8810e-08 - acc: 1.0000 - val_loss: 0.3429 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.3179e-08 - acc: 1.0000 - val_loss: 0.3452 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.8093e-08 - acc: 1.0000 - val_loss: 0.3473 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 5.3460e-08 - acc: 1.0000 - val_loss: 0.3495 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 4.9298e-08 - acc: 1.0000 - val_loss: 0.3516 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.5485e-08 - acc: 1.0000 - val_loss: 0.3536 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 4.2053e-08 - acc: 1.0000 - val_loss: 0.3555 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.8970e-08 - acc: 1.0000 - val_loss: 0.3574 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.6137e-08 - acc: 1.0000 - val_loss: 0.3592 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.3568e-08 - acc: 1.0000 - val_loss: 0.3610 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.1245e-08 - acc: 1.0000 - val_loss: 0.3628 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.9094e-08 - acc: 1.0000 - val_loss: 0.3645 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 2.7173e-08 - acc: 1.0000 - val_loss: 0.3662 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.5407e-08 - acc: 1.0000 - val_loss: 0.3678 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 2.3780e-08 - acc: 1.0000 - val_loss: 0.3694 - val_acc: 0.7647\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2.2272e-08 - acc: 1.0000 - val_loss: 0.3709 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5757 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_SW = models.Sequential()\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_SW.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_SW.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_SW.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "\n",
    "args = y_train_softmax.astype(bool)\n",
    "y_pred = modelFC_SW.predict(X_train)\n",
    "samples = 1 - y_pred[args]\n",
    "for epoch in range(100):\n",
    "    modelFC_SW.fit(X_train, y_train_softmax, epochs=1, validation_split=0.25, sample_weight=samples)\n",
    "    y_pred = modelFC_SW.predict(X_train)\n",
    "    samples = 1 - y_pred[args]\n",
    "    \n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_SW.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570984a",
   "metadata": {},
   "source": [
    "### Pseudo-labeling\n",
    "\n",
    "Fuente: https://towardsdatascience.com/pseudo-labeling-to-deal-with-small-datasets-what-why-how-fd6f903213af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04feba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_epoch(epoch, val, start, stop):\n",
    "    if epoch < start:\n",
    "        alpha = 0\n",
    "    elif epoch < stop:\n",
    "        alpha = ((epoch-start) / (stop-start)) * val\n",
    "    else:\n",
    "        alpha = val\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7172a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "start = 15\n",
    "stop = 90\n",
    "alpha_values = [0.25, 0.5, 0.75, 1]\n",
    "iters = 100\n",
    "\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "\n",
    "test_reduc = test_kaggle.iloc[:10000, :]\n",
    "X_tot = np.concatenate((X_train, test_reduc))\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for i in range(iters):\n",
    "        pseudolabels = modelFC.predict(test_reduc).squeeze()\n",
    "        alpha_t = alpha_epoch(i+1, alpha, start, stop)\n",
    "        samples = np.concatenate((np.ones(len(y_train)), alpha_t*np.ones(len(pseudolabels))))\n",
    "        modelFC.fit(X_train, y_train_softmax, sample_weight=samples, epochs=1, validation_split=0.25, verbose = 0)\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy_pl = modelFC.evaluate(X_test, y_test_softmax)\n",
    "    print(\"Accuracy: {:0.2f}% ------- alpha = {:0.2f}\".format(accuracy_pl * 100, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3114c",
   "metadata": {},
   "source": [
    "Vamos a pintar la evolución del valor del peso $\\alpha$ (función $\\alpha(t)$) elegido a lo largo de 100 iteraciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4838bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start = 15\n",
    "stop = 90\n",
    "alpha_values = 1\n",
    "iters = 100\n",
    "\n",
    "alpha_per_epoch = []\n",
    "for i in range(iters):\n",
    "    alpha_per_epoch.append(alpha_epoch(i+1, alpha, start, stop))\n",
    "    \n",
    "# Pintamos el vector\n",
    "plt.plot(alpha_per_epoch)\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(r\"$\\alpha(t)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaed770",
   "metadata": {},
   "source": [
    "Una alternativa a lo anterior es modificar el vector de ``sample_weight`` para que en lugar de valores constantes, la ponderación se multiplique por el error cometido en la clasificación de cada muestra, es decir, involucrar en la expresión de los pesos el vector de loss.\n",
    "\n",
    "Para el conjunto etiquetado de datos el valor de la pérdida se calcula fácilmente con la clasificación real. Sin embargo, para las pseudolabels no se dispone de esta información. El procedimiento en este caso será, asumiendo que la performance del modelo de clasificación va progresivamente mejorando, calcular el loss como la diferencia absoluta entre las pseudolabels de la iteración en curso con las de la iteración anterior.\n",
    "\n",
    "$\\color{red}{\\text{ESTÁ MAL PLANTEADO. PODRÍA PENALIZARSE MENOS MUESTRAS CONSISTENTEMENTE ERRÓNEAS Y MÁS LAS QUE AVANZAN HACIA UNA MEJORA}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03218853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "start = 15\n",
    "stop = 90\n",
    "alpha_values = [0.25, 0.5, 0.75, 1]\n",
    "iters = 100\n",
    "\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "\n",
    "test_reduc = test_kaggle.iloc[:1000, :]\n",
    "X_tot = np.concatenate((X_train, test_reduc))\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    old_pseudolabels = np.ones((1000, 2))\n",
    "    for i in range(iters):\n",
    "        new_pseudolabels = modelFC.predict(test_reduc)\n",
    "        alpha_t = alpha_epoch(i+1, alpha, start, stop)\n",
    "        loss_pl = np.abs(new_pseudolabels - old_pseudolabels)\n",
    "        old_pseudolabels = new_pseudolabels\n",
    "        samples = np.concatenate((np.ones(len(y_train)), alpha_t*(loss_pl[:, 0] + loss_pl[:, 1])))\n",
    "        # ESTÁ BIEN HACER LA SUMA? COMO HAGO MERGE DE LAS DOS DIMENSIONES??\n",
    "        modelFC.fit(X_train, y_train_softmax, sample_weight=samples, epochs=1, validation_split=0.25, verbose = 0)\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy = modelFC.evaluate(X_test, y_test_softmax)\n",
    "    print(\"Accuracy: {:0.2f}% ------- alpha = {:0.2f}\".format(accuracy * 100, alpha))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
