{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación de resultados de predicción utilizando distintos modelos\n",
    "\n",
    "Este notebook recoge los resultados de varios entrenamientos, probando modelos diferentes (Ranfom Forest, XGBoost, distintas configuraciones de redes neuronales, ...) para comparar su performance y tratar de escoger el óptimo para nuestro problema.\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data partition\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Parameter tunning libraries\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Accuracy function\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>0.216620</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.353800</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.133020</td>\n",
       "      <td>-0.035222</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257114</td>\n",
       "      <td>0.597229</td>\n",
       "      <td>1.220756</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>-0.435494</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>1.090910</td>\n",
       "      <td>-0.448562</td>\n",
       "      <td>-0.508497</td>\n",
       "      <td>0.350434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.410730</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.242260</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>0.599790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050862</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>0.609465</td>\n",
       "      <td>1.181878</td>\n",
       "      <td>-2.279469</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>-0.012693</td>\n",
       "      <td>-1.244346</td>\n",
       "      <td>-1.080442</td>\n",
       "      <td>-0.788502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.318170</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.539922</td>\n",
       "      <td>-1.495822</td>\n",
       "      <td>1.643866</td>\n",
       "      <td>1.687780</td>\n",
       "      <td>1.521086</td>\n",
       "      <td>-1.988432</td>\n",
       "      <td>-0.267471</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>1.104566</td>\n",
       "      <td>-1.067206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.112830</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0.202750</td>\n",
       "      <td>0.191420</td>\n",
       "      <td>-0.056662</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.593326</td>\n",
       "      <td>1.063052</td>\n",
       "      <td>0.434726</td>\n",
       "      <td>1.604964</td>\n",
       "      <td>-0.359736</td>\n",
       "      <td>0.210107</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>-0.323557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "2       0  0.245850  0.216620 -0.124680 -0.353800  0.161500 -0.002032   \n",
       "13      1  0.410730 -0.031925  0.210700  0.242260  0.320100 -0.419290   \n",
       "53      1  0.070919  0.034179 -0.011755  0.019158  0.024645 -0.032022   \n",
       "41      0  0.087377 -0.052462 -0.007835 -0.112830  0.389380  0.216080   \n",
       "74      0  0.202750  0.191420 -0.056662 -0.157780  0.244040  0.039780   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "2  -0.133020 -0.035222  0.259040  ...  -0.257114   0.597229   1.220756   \n",
       "13 -0.187140  0.168450  0.599790  ...  -0.050862   0.870602   0.609465   \n",
       "53  0.004620  0.318170  0.212550  ...  -1.539922  -1.495822   1.643866   \n",
       "41  0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "74 -0.001503  0.001056 -0.048222  ...   0.044457   0.593326   1.063052   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "2   -0.059213  -0.435494  -0.092971   1.090910  -0.448562  -0.508497   \n",
       "13   1.181878  -2.279469  -0.013484  -0.012693  -1.244346  -1.080442   \n",
       "53   1.687780   1.521086  -1.988432  -0.267471   0.510576   1.104566   \n",
       "41  -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "74   0.434726   1.604964  -0.359736   0.210107   0.355922   0.730287   \n",
       "\n",
       "    SBM_map75  \n",
       "2    0.350434  \n",
       "13  -0.788502  \n",
       "53  -1.067206  \n",
       "41  -0.260920  \n",
       "74  -0.323557  \n",
       "\n",
       "[5 rows x 411 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de entrenamiento\n",
    "trainFNC = pd.read_csv(\"data/train_FNC.csv\")\n",
    "trainSBM = pd.read_csv(\"data/train_SBM.csv\")\n",
    "train_labels = pd.read_csv(\"data/train_labels.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "train = pd.merge(left=trainFNC, right=trainSBM, left_on='Id', right_on='Id')\n",
    "data = pd.merge(left=train_labels, right=train, left_on='Id', right_on='Id')\n",
    "data.drop(\"Id\", inplace=True, axis=1)\n",
    "\n",
    "# Shuffle de los datos de train\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>FNC10</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476127</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>-0.608133</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>-0.637038</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>-0.192434</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.060474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451994</td>\n",
       "      <td>1.123770</td>\n",
       "      <td>2.083006</td>\n",
       "      <td>1.145440</td>\n",
       "      <td>-0.067608</td>\n",
       "      <td>1.202529</td>\n",
       "      <td>0.851587</td>\n",
       "      <td>0.451583</td>\n",
       "      <td>-0.159739</td>\n",
       "      <td>0.192076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.267183</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>-0.261327</td>\n",
       "      <td>0.191869</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>0.088761</td>\n",
       "      <td>0.177048</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696987</td>\n",
       "      <td>1.397832</td>\n",
       "      <td>1.046136</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>-2.192023</td>\n",
       "      <td>-0.369276</td>\n",
       "      <td>0.822225</td>\n",
       "      <td>-0.109342</td>\n",
       "      <td>-0.580476</td>\n",
       "      <td>0.174160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.435452</td>\n",
       "      <td>0.046780</td>\n",
       "      <td>0.243742</td>\n",
       "      <td>0.397030</td>\n",
       "      <td>-0.147821</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>-0.461963</td>\n",
       "      <td>-0.610736</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.400985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>1.906989</td>\n",
       "      <td>-2.661633</td>\n",
       "      <td>-0.193911</td>\n",
       "      <td>0.440873</td>\n",
       "      <td>0.641739</td>\n",
       "      <td>0.918397</td>\n",
       "      <td>-0.758046</td>\n",
       "      <td>0.154701</td>\n",
       "      <td>-0.476647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.204510</td>\n",
       "      <td>-0.036735</td>\n",
       "      <td>-0.760705</td>\n",
       "      <td>-0.740495</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>0.349926</td>\n",
       "      <td>-0.273826</td>\n",
       "      <td>-0.174384</td>\n",
       "      <td>-0.120248</td>\n",
       "      <td>0.175618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974828</td>\n",
       "      <td>-1.997087</td>\n",
       "      <td>-2.083782</td>\n",
       "      <td>1.154107</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>2.332424</td>\n",
       "      <td>0.659124</td>\n",
       "      <td>-0.809445</td>\n",
       "      <td>0.558960</td>\n",
       "      <td>2.790871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599435</td>\n",
       "      <td>-0.166441</td>\n",
       "      <td>0.122431</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.346906</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.274734</td>\n",
       "      <td>0.211510</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-0.033434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.789153</td>\n",
       "      <td>1.578984</td>\n",
       "      <td>1.402592</td>\n",
       "      <td>-1.230440</td>\n",
       "      <td>0.296686</td>\n",
       "      <td>2.806314</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>-0.240682</td>\n",
       "      <td>-0.196948</td>\n",
       "      <td>-1.544345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FNC1      FNC2      FNC3      FNC4      FNC5      FNC6      FNC7  \\\n",
       "0  0.476127  0.064466  0.053238 -0.608133  0.073988 -0.637038  0.113556   \n",
       "1  0.013833  0.267183  0.232178 -0.167151 -0.261327  0.191869  0.406493   \n",
       "2 -0.435452  0.046780  0.243742  0.397030 -0.147821  0.173620 -0.461963   \n",
       "3 -0.204510 -0.036735 -0.760705 -0.740495  0.064668  0.349926 -0.273826   \n",
       "4  0.599435 -0.166441  0.122431  0.011539  0.346906 -0.017430 -0.274734   \n",
       "\n",
       "       FNC8      FNC9     FNC10  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "0 -0.192434 -0.004025 -0.060474  ...  -0.451994   1.123770   2.083006   \n",
       "1  0.088761  0.177048  0.036718  ...   0.696987   1.397832   1.046136   \n",
       "2 -0.610736  0.419753  0.400985  ...   0.160145   1.906989  -2.661633   \n",
       "3 -0.174384 -0.120248  0.175618  ...   0.974828  -1.997087  -2.083782   \n",
       "4  0.211510  0.151012 -0.033434  ...  -0.789153   1.578984   1.402592   \n",
       "\n",
       "   SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  SBM_map75  \n",
       "0   1.145440  -0.067608   1.202529   0.851587   0.451583  -0.159739   0.192076  \n",
       "1  -0.191733  -2.192023  -0.369276   0.822225  -0.109342  -0.580476   0.174160  \n",
       "2  -0.193911   0.440873   0.641739   0.918397  -0.758046   0.154701  -0.476647  \n",
       "3   1.154107  -0.643947   2.332424   0.659124  -0.809445   0.558960   2.790871  \n",
       "4  -1.230440   0.296686   2.806314   0.427184  -0.240682  -0.196948  -1.544345  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de test\n",
    "testFNC = pd.read_csv(\"data/test_FNC.csv\")\n",
    "testSBM = pd.read_csv(\"data/test_SBM.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "test = pd.merge(left=testFNC, right=testSBM, left_on='Id', right_on='Id')\n",
    "test.drop(\"Id\", inplace=True, axis=1)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar el entrenamiento y el ajuste de parámetros\n",
    "def train_model(model, param_grid):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=4)\n",
    "    # cv = 4 porque así: el conjunto de validation tiene un 0.25 del tamaño de train y: 0.25 * 0.8 = 0.2\n",
    "    #                    el conjunto de train tiene un 0.75 del tamaño de train y: 0.75 * 0.8 = 0.6\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Parámetros óptimos:\", grid_search.best_params_)\n",
    "    print(\"Modelo óptimo:\", grid_search.best_estimator_)\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 750}\n",
      "Modelo óptimo: RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=750,\n",
      "                       random_state=0)\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 10, 15, 20, None]\n",
    "}\n",
    "model_RF_opt = train_model(model_RF, param_grid_RF)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF = model_RF_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Predicción en test para kaggle\n",
    "y_pred_kaggle_RF = model_RF_opt.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 600}\n",
      "Modelo óptimo: RandomForestClassifier(criterion='entropy', max_depth=4, n_estimators=600,\n",
      "                       random_state=0)\n",
      "Accuracy: 72.22%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": range(100, 1100, 100),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": range(1, 21)\n",
    "}\n",
    "model_RF_opt = train_model(model_RF, param_grid_RF)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF = model_RF_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Predicción en test para kaggle\n",
    "y_pred_kaggle_RF = model_RF_opt.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería ``optuna`` es un framework específico para la optimización de hiperparámetros. Por tanto, permite hacer búsquedas mucho más complejas que ``GridSearchCV`` de ``sklearn``, lo que será de especial utilidad en modelos de redes neuronales. A modo de prueba de uso, repetiremos el proceso de búsqueda anterior utilizando esta librería para ver el rendimiento, se espera que los resultados sean iguales si no mejores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveRF2(trial):\n",
    "    \n",
    "    n_estimators =  trial.suggest_int(\"n_estimators\", 100, 1000, 100) # optuna incluye en el rango el máximo y el mínimo\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 20)\n",
    "    \n",
    "    modelRF_optuna = RandomForestClassifier(criterion = criterion, max_depth = max_depth, n_estimators = n_estimators, \n",
    "                                            random_state=0)\n",
    "    \n",
    "    modelRF_optuna.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_RF_optuna = modelRF_optuna.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_RF_optuna)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:05:39,482]\u001b[0m A new study created in memory with name: no-name-0886cf8a-5ee8-4dd9-8662-0af780b1a976\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:40,348]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 600, 'criterion': 'gini', 'max_depth': 11}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:41,095]\u001b[0m Trial 1 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 500, 'criterion': 'gini', 'max_depth': 18}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:42,704]\u001b[0m Trial 2 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:43,769]\u001b[0m Trial 3 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 600, 'criterion': 'gini', 'max_depth': 2}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:43,984]\u001b[0m Trial 4 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:45,441]\u001b[0m Trial 5 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:45,753]\u001b[0m Trial 6 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:46,644]\u001b[0m Trial 7 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 600, 'criterion': 'gini', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:47,342]\u001b[0m Trial 8 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 500, 'criterion': 'gini', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:48,933]\u001b[0m Trial 9 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:50,873]\u001b[0m Trial 10 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:53,187]\u001b[0m Trial 11 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:54,332]\u001b[0m Trial 12 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:55,838]\u001b[0m Trial 13 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:57,122]\u001b[0m Trial 14 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 3}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:58,762]\u001b[0m Trial 15 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:05:59,230]\u001b[0m Trial 16 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:00,946]\u001b[0m Trial 17 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:02,351]\u001b[0m Trial 18 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:03,768]\u001b[0m Trial 19 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:04,404]\u001b[0m Trial 20 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:05,944]\u001b[0m Trial 21 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:07,494]\u001b[0m Trial 22 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:08,138]\u001b[0m Trial 23 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:09,757]\u001b[0m Trial 24 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:11,624]\u001b[0m Trial 25 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:12,632]\u001b[0m Trial 26 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 1}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:14,071]\u001b[0m Trial 27 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:15,568]\u001b[0m Trial 28 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:16,834]\u001b[0m Trial 29 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:17,929]\u001b[0m Trial 30 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:19,372]\u001b[0m Trial 31 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:21,415]\u001b[0m Trial 32 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:22,764]\u001b[0m Trial 33 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:23,458]\u001b[0m Trial 34 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:24,815]\u001b[0m Trial 35 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:26,257]\u001b[0m Trial 36 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:27,612]\u001b[0m Trial 37 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:06:28,139]\u001b[0m Trial 38 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 400, 'criterion': 'gini', 'max_depth': 3}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:28,669]\u001b[0m Trial 39 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:28,844]\u001b[0m Trial 40 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:29,637]\u001b[0m Trial 41 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:30,281]\u001b[0m Trial 42 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:32,259]\u001b[0m Trial 43 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:33,398]\u001b[0m Trial 44 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:34,798]\u001b[0m Trial 45 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:36,512]\u001b[0m Trial 46 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:38,292]\u001b[0m Trial 47 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:39,795]\u001b[0m Trial 48 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:41,108]\u001b[0m Trial 49 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:42,722]\u001b[0m Trial 50 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:44,091]\u001b[0m Trial 51 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:45,410]\u001b[0m Trial 52 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:46,789]\u001b[0m Trial 53 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:48,455]\u001b[0m Trial 54 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:50,091]\u001b[0m Trial 55 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:51,537]\u001b[0m Trial 56 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:52,942]\u001b[0m Trial 57 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:54,607]\u001b[0m Trial 58 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:54,977]\u001b[0m Trial 59 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:56,095]\u001b[0m Trial 60 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:57,696]\u001b[0m Trial 61 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:06:59,937]\u001b[0m Trial 62 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:01,562]\u001b[0m Trial 63 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:03,010]\u001b[0m Trial 64 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:05,070]\u001b[0m Trial 65 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:06,621]\u001b[0m Trial 66 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:07,249]\u001b[0m Trial 67 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:08,039]\u001b[0m Trial 68 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:09,620]\u001b[0m Trial 69 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:11,641]\u001b[0m Trial 70 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:13,065]\u001b[0m Trial 71 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:14,827]\u001b[0m Trial 72 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:16,592]\u001b[0m Trial 73 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:17,985]\u001b[0m Trial 74 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:19,434]\u001b[0m Trial 75 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:07:21,070]\u001b[0m Trial 76 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:22,580]\u001b[0m Trial 77 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:23,690]\u001b[0m Trial 78 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:25,277]\u001b[0m Trial 79 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:27,298]\u001b[0m Trial 80 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:29,094]\u001b[0m Trial 81 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:30,676]\u001b[0m Trial 82 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:32,498]\u001b[0m Trial 83 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:33,894]\u001b[0m Trial 84 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:34,527]\u001b[0m Trial 85 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:35,160]\u001b[0m Trial 86 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:36,580]\u001b[0m Trial 87 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:38,634]\u001b[0m Trial 88 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:39,608]\u001b[0m Trial 89 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:40,886]\u001b[0m Trial 90 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:42,718]\u001b[0m Trial 91 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:44,583]\u001b[0m Trial 92 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:46,259]\u001b[0m Trial 93 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:47,857]\u001b[0m Trial 94 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:49,687]\u001b[0m Trial 95 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:51,303]\u001b[0m Trial 96 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:52,827]\u001b[0m Trial 97 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:54,891]\u001b[0m Trial 98 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:56,528]\u001b[0m Trial 99 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:07:57,998]\u001b[0m Trial 100 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:00,106]\u001b[0m Trial 101 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:01,740]\u001b[0m Trial 102 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:03,265]\u001b[0m Trial 103 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:05,137]\u001b[0m Trial 104 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:06,852]\u001b[0m Trial 105 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:08,102]\u001b[0m Trial 106 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:09,429]\u001b[0m Trial 107 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:10,546]\u001b[0m Trial 108 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:12,085]\u001b[0m Trial 109 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:12,416]\u001b[0m Trial 110 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:13,695]\u001b[0m Trial 111 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:15,157]\u001b[0m Trial 112 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:17,000]\u001b[0m Trial 113 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:08:18,521]\u001b[0m Trial 114 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:19,977]\u001b[0m Trial 115 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:21,754]\u001b[0m Trial 116 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:23,243]\u001b[0m Trial 117 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:24,273]\u001b[0m Trial 118 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:25,868]\u001b[0m Trial 119 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:27,986]\u001b[0m Trial 120 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:29,307]\u001b[0m Trial 121 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:30,607]\u001b[0m Trial 122 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:31,127]\u001b[0m Trial 123 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:32,971]\u001b[0m Trial 124 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:33,799]\u001b[0m Trial 125 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:34,907]\u001b[0m Trial 126 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:36,149]\u001b[0m Trial 127 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:37,928]\u001b[0m Trial 128 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:38,791]\u001b[0m Trial 129 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:39,408]\u001b[0m Trial 130 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:40,807]\u001b[0m Trial 131 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:42,457]\u001b[0m Trial 132 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:43,481]\u001b[0m Trial 133 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:45,234]\u001b[0m Trial 134 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:46,077]\u001b[0m Trial 135 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:46,695]\u001b[0m Trial 136 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:47,546]\u001b[0m Trial 137 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:48,957]\u001b[0m Trial 138 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:50,907]\u001b[0m Trial 139 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:52,748]\u001b[0m Trial 140 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:53,849]\u001b[0m Trial 141 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:55,949]\u001b[0m Trial 142 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:57,598]\u001b[0m Trial 143 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:08:59,170]\u001b[0m Trial 144 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:01,363]\u001b[0m Trial 145 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:02,983]\u001b[0m Trial 146 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:04,618]\u001b[0m Trial 147 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:06,627]\u001b[0m Trial 148 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:08,394]\u001b[0m Trial 149 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:09,036]\u001b[0m Trial 150 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:10,725]\u001b[0m Trial 151 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:09:12,854]\u001b[0m Trial 152 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:14,380]\u001b[0m Trial 153 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:15,866]\u001b[0m Trial 154 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:17,772]\u001b[0m Trial 155 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:19,549]\u001b[0m Trial 156 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:20,988]\u001b[0m Trial 157 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:22,593]\u001b[0m Trial 158 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:24,242]\u001b[0m Trial 159 finished with value: 0.5555555555555556 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 1}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:25,798]\u001b[0m Trial 160 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:27,317]\u001b[0m Trial 161 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:29,172]\u001b[0m Trial 162 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:30,781]\u001b[0m Trial 163 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:32,351]\u001b[0m Trial 164 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:34,012]\u001b[0m Trial 165 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:35,743]\u001b[0m Trial 166 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:37,009]\u001b[0m Trial 167 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:38,290]\u001b[0m Trial 168 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:40,058]\u001b[0m Trial 169 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:41,732]\u001b[0m Trial 170 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:43,010]\u001b[0m Trial 171 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:44,308]\u001b[0m Trial 172 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:46,177]\u001b[0m Trial 173 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:47,619]\u001b[0m Trial 174 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:48,948]\u001b[0m Trial 175 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:50,339]\u001b[0m Trial 176 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:52,286]\u001b[0m Trial 177 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:53,328]\u001b[0m Trial 178 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:54,786]\u001b[0m Trial 179 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:56,394]\u001b[0m Trial 180 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:58,010]\u001b[0m Trial 181 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:09:59,583]\u001b[0m Trial 182 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:01,320]\u001b[0m Trial 183 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:03,180]\u001b[0m Trial 184 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:03,920]\u001b[0m Trial 185 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:04,624]\u001b[0m Trial 186 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:05,404]\u001b[0m Trial 187 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:07,138]\u001b[0m Trial 188 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:07,984]\u001b[0m Trial 189 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:10:08,865]\u001b[0m Trial 190 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:09,514]\u001b[0m Trial 191 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:10,226]\u001b[0m Trial 192 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:11,786]\u001b[0m Trial 193 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:12,307]\u001b[0m Trial 194 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:14,229]\u001b[0m Trial 195 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:16,101]\u001b[0m Trial 196 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:17,703]\u001b[0m Trial 197 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:19,616]\u001b[0m Trial 198 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:21,392]\u001b[0m Trial 199 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:23,114]\u001b[0m Trial 200 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:25,160]\u001b[0m Trial 201 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:26,946]\u001b[0m Trial 202 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:27,589]\u001b[0m Trial 203 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:29,348]\u001b[0m Trial 204 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:31,302]\u001b[0m Trial 205 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:32,958]\u001b[0m Trial 206 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:34,512]\u001b[0m Trial 207 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:36,580]\u001b[0m Trial 208 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:38,302]\u001b[0m Trial 209 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:39,883]\u001b[0m Trial 210 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:41,896]\u001b[0m Trial 211 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:43,670]\u001b[0m Trial 212 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:45,219]\u001b[0m Trial 213 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:47,207]\u001b[0m Trial 214 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:48,021]\u001b[0m Trial 215 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:48,603]\u001b[0m Trial 216 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 400, 'criterion': 'gini', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:50,294]\u001b[0m Trial 217 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:50,964]\u001b[0m Trial 218 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:52,661]\u001b[0m Trial 219 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:54,707]\u001b[0m Trial 220 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:55,305]\u001b[0m Trial 221 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:55,936]\u001b[0m Trial 222 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:57,773]\u001b[0m Trial 223 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:58,013]\u001b[0m Trial 224 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:10:59,933]\u001b[0m Trial 225 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:01,290]\u001b[0m Trial 226 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:02,751]\u001b[0m Trial 227 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:11:04,592]\u001b[0m Trial 228 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:06,206]\u001b[0m Trial 229 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:07,700]\u001b[0m Trial 230 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:09,434]\u001b[0m Trial 231 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:11,137]\u001b[0m Trial 232 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:12,448]\u001b[0m Trial 233 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 2}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:14,077]\u001b[0m Trial 234 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:14,929]\u001b[0m Trial 235 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:15,781]\u001b[0m Trial 236 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:16,490]\u001b[0m Trial 237 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:17,190]\u001b[0m Trial 238 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:18,671]\u001b[0m Trial 239 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:20,140]\u001b[0m Trial 240 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:21,748]\u001b[0m Trial 241 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:23,021]\u001b[0m Trial 242 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:24,273]\u001b[0m Trial 243 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:25,820]\u001b[0m Trial 244 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:27,402]\u001b[0m Trial 245 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:28,893]\u001b[0m Trial 246 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:30,517]\u001b[0m Trial 247 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:32,558]\u001b[0m Trial 248 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:33,779]\u001b[0m Trial 249 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:35,044]\u001b[0m Trial 250 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:36,518]\u001b[0m Trial 251 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:38,092]\u001b[0m Trial 252 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:39,722]\u001b[0m Trial 253 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:40,557]\u001b[0m Trial 254 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 600, 'criterion': 'gini', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:42,049]\u001b[0m Trial 255 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:43,642]\u001b[0m Trial 256 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:45,126]\u001b[0m Trial 257 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:46,566]\u001b[0m Trial 258 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:48,388]\u001b[0m Trial 259 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:50,201]\u001b[0m Trial 260 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:51,765]\u001b[0m Trial 261 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:53,723]\u001b[0m Trial 262 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:55,238]\u001b[0m Trial 263 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:56,520]\u001b[0m Trial 264 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:11:57,742]\u001b[0m Trial 265 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:11:59,506]\u001b[0m Trial 266 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:01,241]\u001b[0m Trial 267 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:02,787]\u001b[0m Trial 268 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:03,414]\u001b[0m Trial 269 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:04,456]\u001b[0m Trial 270 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:05,193]\u001b[0m Trial 271 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 400, 'criterion': 'gini', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:06,879]\u001b[0m Trial 272 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:07,518]\u001b[0m Trial 273 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:08,152]\u001b[0m Trial 274 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:09,691]\u001b[0m Trial 275 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:11,461]\u001b[0m Trial 276 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:12,617]\u001b[0m Trial 277 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:14,238]\u001b[0m Trial 278 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:14,792]\u001b[0m Trial 279 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:16,765]\u001b[0m Trial 280 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:17,359]\u001b[0m Trial 281 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:18,003]\u001b[0m Trial 282 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:19,560]\u001b[0m Trial 283 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:22,060]\u001b[0m Trial 284 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:23,017]\u001b[0m Trial 285 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:24,663]\u001b[0m Trial 286 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:25,323]\u001b[0m Trial 287 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:26,435]\u001b[0m Trial 288 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:28,399]\u001b[0m Trial 289 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:29,849]\u001b[0m Trial 290 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:30,400]\u001b[0m Trial 291 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:31,935]\u001b[0m Trial 292 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:32,939]\u001b[0m Trial 293 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:34,095]\u001b[0m Trial 294 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:35,762]\u001b[0m Trial 295 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:36,616]\u001b[0m Trial 296 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:37,482]\u001b[0m Trial 297 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:38,491]\u001b[0m Trial 298 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:40,070]\u001b[0m Trial 299 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:40,825]\u001b[0m Trial 300 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:41,513]\u001b[0m Trial 301 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:42,196]\u001b[0m Trial 302 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:44,365]\u001b[0m Trial 303 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:12:46,033]\u001b[0m Trial 304 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:47,747]\u001b[0m Trial 305 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:49,764]\u001b[0m Trial 306 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:51,702]\u001b[0m Trial 307 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:52,369]\u001b[0m Trial 308 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:52,941]\u001b[0m Trial 309 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:54,211]\u001b[0m Trial 310 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:54,699]\u001b[0m Trial 311 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:56,558]\u001b[0m Trial 312 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:57,316]\u001b[0m Trial 313 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:58,972]\u001b[0m Trial 314 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:12:59,889]\u001b[0m Trial 315 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:01,043]\u001b[0m Trial 316 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:02,519]\u001b[0m Trial 317 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:04,065]\u001b[0m Trial 318 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:06,068]\u001b[0m Trial 319 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:07,961]\u001b[0m Trial 320 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:09,641]\u001b[0m Trial 321 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:11,561]\u001b[0m Trial 322 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:13,414]\u001b[0m Trial 323 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:15,064]\u001b[0m Trial 324 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:16,886]\u001b[0m Trial 325 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:18,875]\u001b[0m Trial 326 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:20,516]\u001b[0m Trial 327 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:22,261]\u001b[0m Trial 328 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:24,355]\u001b[0m Trial 329 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:25,784]\u001b[0m Trial 330 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:26,499]\u001b[0m Trial 331 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:28,354]\u001b[0m Trial 332 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:30,347]\u001b[0m Trial 333 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:32,005]\u001b[0m Trial 334 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:33,811]\u001b[0m Trial 335 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:35,800]\u001b[0m Trial 336 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:37,444]\u001b[0m Trial 337 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:39,232]\u001b[0m Trial 338 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:41,250]\u001b[0m Trial 339 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:42,924]\u001b[0m Trial 340 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:44,607]\u001b[0m Trial 341 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:13:46,651]\u001b[0m Trial 342 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:48,353]\u001b[0m Trial 343 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:49,979]\u001b[0m Trial 344 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:51,506]\u001b[0m Trial 345 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:53,143]\u001b[0m Trial 346 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:54,781]\u001b[0m Trial 347 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:56,652]\u001b[0m Trial 348 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:13:58,378]\u001b[0m Trial 349 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:00,049]\u001b[0m Trial 350 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:01,622]\u001b[0m Trial 351 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:03,457]\u001b[0m Trial 352 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:04,915]\u001b[0m Trial 353 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:06,304]\u001b[0m Trial 354 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 3}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:07,095]\u001b[0m Trial 355 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:08,958]\u001b[0m Trial 356 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:10,542]\u001b[0m Trial 357 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:12,219]\u001b[0m Trial 358 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:14,139]\u001b[0m Trial 359 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:14,948]\u001b[0m Trial 360 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:16,436]\u001b[0m Trial 361 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:17,888]\u001b[0m Trial 362 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:19,776]\u001b[0m Trial 363 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:21,395]\u001b[0m Trial 364 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:22,857]\u001b[0m Trial 365 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:24,744]\u001b[0m Trial 366 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:26,443]\u001b[0m Trial 367 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:27,862]\u001b[0m Trial 368 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:29,186]\u001b[0m Trial 369 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:31,127]\u001b[0m Trial 370 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:32,219]\u001b[0m Trial 371 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:33,819]\u001b[0m Trial 372 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:35,341]\u001b[0m Trial 373 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:37,202]\u001b[0m Trial 374 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:38,555]\u001b[0m Trial 375 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:39,906]\u001b[0m Trial 376 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:41,396]\u001b[0m Trial 377 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:43,053]\u001b[0m Trial 378 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:44,390]\u001b[0m Trial 379 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 21:14:45,742]\u001b[0m Trial 380 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:47,324]\u001b[0m Trial 381 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:48,690]\u001b[0m Trial 382 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:50,198]\u001b[0m Trial 383 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:51,809]\u001b[0m Trial 384 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:53,630]\u001b[0m Trial 385 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:54,978]\u001b[0m Trial 386 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:56,220]\u001b[0m Trial 387 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:57,291]\u001b[0m Trial 388 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:14:59,364]\u001b[0m Trial 389 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:01,136]\u001b[0m Trial 390 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:02,450]\u001b[0m Trial 391 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:04,205]\u001b[0m Trial 392 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:05,754]\u001b[0m Trial 393 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:07,069]\u001b[0m Trial 394 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:08,340]\u001b[0m Trial 395 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:09,826]\u001b[0m Trial 396 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:11,732]\u001b[0m Trial 397 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:13,150]\u001b[0m Trial 398 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 21:15:14,551]\u001b[0m Trial 399 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=0)  # Asegurar los reproducibilidad de los resultados\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objectiveRF2, n_trials=400)\n",
    "# n_trials = 10 x 2 x 20 = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=2, values=[0.8888888888888888], datetime_start=datetime.datetime(2022, 5, 18, 21, 5, 41, 95013), datetime_complete=datetime.datetime(2022, 5, 18, 21, 5, 42, 704134), params={'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}, distributions={'n_estimators': IntUniformDistribution(high=1000, low=100, step=100), 'criterion': CategoricalDistribution(choices=('gini', 'entropy')), 'max_depth': IntUniformDistribution(high=20, low=1, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveRF(trial):\n",
    "    \n",
    "    n_estimators =  trial.suggest_int(\"n_estimators\", 50, 1000, 50) # optuna incluye en el rango el máximo y el mínimo\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 20)\n",
    "    \n",
    "    modelRF_optuna = RandomForestClassifier(criterion = criterion, max_depth = max_depth, n_estimators = n_estimators, \n",
    "                                            random_state=0)\n",
    "    \n",
    "    modelRF_optuna.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_RF_optuna = modelRF_optuna.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_RF_optuna)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:02:16,004]\u001b[0m A new study created in memory with name: no-name-dea93b4b-31af-4107-95ca-4fefdd1960ca\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:16,841]\u001b[0m Trial 0 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 550, 'criterion': 'gini', 'max_depth': 11}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:17,519]\u001b[0m Trial 1 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 450, 'criterion': 'gini', 'max_depth': 18}. Best is trial 0 with value: 0.6666666666666666.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:19,103]\u001b[0m Trial 2 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:19,924]\u001b[0m Trial 3 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 600, 'criterion': 'gini', 'max_depth': 2}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:20,016]\u001b[0m Trial 4 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:21,692]\u001b[0m Trial 5 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:21,910]\u001b[0m Trial 6 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:22,680]\u001b[0m Trial 7 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 550, 'criterion': 'gini', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:23,415]\u001b[0m Trial 8 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 500, 'criterion': 'gini', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:24,480]\u001b[0m Trial 9 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 650, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:26,158]\u001b[0m Trial 10 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:27,742]\u001b[0m Trial 11 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:29,091]\u001b[0m Trial 12 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:30,727]\u001b[0m Trial 13 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:32,088]\u001b[0m Trial 14 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 3}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:32,668]\u001b[0m Trial 15 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:33,781]\u001b[0m Trial 16 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:35,365]\u001b[0m Trial 17 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:36,591]\u001b[0m Trial 18 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:38,032]\u001b[0m Trial 19 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:39,697]\u001b[0m Trial 20 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:41,376]\u001b[0m Trial 21 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:42,817]\u001b[0m Trial 22 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:44,011]\u001b[0m Trial 23 finished with value: 0.5555555555555556 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 1}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:45,187]\u001b[0m Trial 24 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:46,472]\u001b[0m Trial 25 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:48,135]\u001b[0m Trial 26 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:48,796]\u001b[0m Trial 27 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:50,213]\u001b[0m Trial 28 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:51,525]\u001b[0m Trial 29 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:52,452]\u001b[0m Trial 30 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:54,395]\u001b[0m Trial 31 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:56,216]\u001b[0m Trial 32 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:57,781]\u001b[0m Trial 33 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:02:59,541]\u001b[0m Trial 34 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:01,496]\u001b[0m Trial 35 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:02,584]\u001b[0m Trial 36 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 750, 'criterion': 'gini', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:03,949]\u001b[0m Trial 37 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:03:05,345]\u001b[0m Trial 38 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:06,992]\u001b[0m Trial 39 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 2}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:07,965]\u001b[0m Trial 40 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 650, 'criterion': 'gini', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:09,549]\u001b[0m Trial 41 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:11,384]\u001b[0m Trial 42 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:12,812]\u001b[0m Trial 43 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:14,350]\u001b[0m Trial 44 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:16,137]\u001b[0m Trial 45 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:17,016]\u001b[0m Trial 46 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:17,202]\u001b[0m Trial 47 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:18,804]\u001b[0m Trial 48 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:20,466]\u001b[0m Trial 49 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:22,521]\u001b[0m Trial 50 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:23,778]\u001b[0m Trial 51 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:25,125]\u001b[0m Trial 52 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:26,648]\u001b[0m Trial 53 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:27,948]\u001b[0m Trial 54 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:29,080]\u001b[0m Trial 55 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:30,537]\u001b[0m Trial 56 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:31,996]\u001b[0m Trial 57 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 850, 'criterion': 'gini', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:32,420]\u001b[0m Trial 58 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:33,784]\u001b[0m Trial 59 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:35,465]\u001b[0m Trial 60 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:37,408]\u001b[0m Trial 61 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:39,024]\u001b[0m Trial 62 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:40,624]\u001b[0m Trial 63 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:42,477]\u001b[0m Trial 64 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:44,139]\u001b[0m Trial 65 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:45,614]\u001b[0m Trial 66 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:47,526]\u001b[0m Trial 67 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:49,239]\u001b[0m Trial 68 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:50,633]\u001b[0m Trial 69 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:51,998]\u001b[0m Trial 70 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:53,723]\u001b[0m Trial 71 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:55,276]\u001b[0m Trial 72 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:56,595]\u001b[0m Trial 73 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:57,582]\u001b[0m Trial 74 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 550, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:03:59,181]\u001b[0m Trial 75 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:04:00,594]\u001b[0m Trial 76 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:02,257]\u001b[0m Trial 77 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:03,920]\u001b[0m Trial 78 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:05,363]\u001b[0m Trial 79 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:06,760]\u001b[0m Trial 80 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:08,361]\u001b[0m Trial 81 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:10,038]\u001b[0m Trial 82 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:11,701]\u001b[0m Trial 83 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:13,364]\u001b[0m Trial 84 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:14,854]\u001b[0m Trial 85 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:16,266]\u001b[0m Trial 86 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:16,940]\u001b[0m Trial 87 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:17,961]\u001b[0m Trial 88 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 650, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:19,639]\u001b[0m Trial 89 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:21,208]\u001b[0m Trial 90 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:22,430]\u001b[0m Trial 91 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:23,843]\u001b[0m Trial 92 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:25,381]\u001b[0m Trial 93 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:26,856]\u001b[0m Trial 94 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:28,722]\u001b[0m Trial 95 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:29,757]\u001b[0m Trial 96 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:31,294]\u001b[0m Trial 97 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:32,848]\u001b[0m Trial 98 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:34,856]\u001b[0m Trial 99 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:36,596]\u001b[0m Trial 100 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:38,181]\u001b[0m Trial 101 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:39,812]\u001b[0m Trial 102 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:41,599]\u001b[0m Trial 103 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:43,028]\u001b[0m Trial 104 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:44,519]\u001b[0m Trial 105 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:46,213]\u001b[0m Trial 106 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:47,406]\u001b[0m Trial 107 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 750, 'criterion': 'gini', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:48,957]\u001b[0m Trial 108 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:50,558]\u001b[0m Trial 109 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:52,204]\u001b[0m Trial 110 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:53,523]\u001b[0m Trial 111 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:54,730]\u001b[0m Trial 112 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:56,567]\u001b[0m Trial 113 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:04:58,213]\u001b[0m Trial 114 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:04:59,720]\u001b[0m Trial 115 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:01,224]\u001b[0m Trial 116 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:03,202]\u001b[0m Trial 117 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:04,895]\u001b[0m Trial 118 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:06,214]\u001b[0m Trial 119 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:06,842]\u001b[0m Trial 120 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:08,442]\u001b[0m Trial 121 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:09,258]\u001b[0m Trial 122 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:10,826]\u001b[0m Trial 123 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:11,223]\u001b[0m Trial 124 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:12,662]\u001b[0m Trial 125 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:13,618]\u001b[0m Trial 126 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:15,281]\u001b[0m Trial 127 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:16,772]\u001b[0m Trial 128 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:17,776]\u001b[0m Trial 129 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:19,501]\u001b[0m Trial 130 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:21,116]\u001b[0m Trial 131 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:22,655]\u001b[0m Trial 132 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:24,059]\u001b[0m Trial 133 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:25,651]\u001b[0m Trial 134 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:27,124]\u001b[0m Trial 135 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:28,826]\u001b[0m Trial 136 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:30,717]\u001b[0m Trial 137 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:32,380]\u001b[0m Trial 138 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:33,979]\u001b[0m Trial 139 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:35,956]\u001b[0m Trial 140 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:37,258]\u001b[0m Trial 141 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:38,498]\u001b[0m Trial 142 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:40,147]\u001b[0m Trial 143 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:42,186]\u001b[0m Trial 144 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:43,707]\u001b[0m Trial 145 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:45,369]\u001b[0m Trial 146 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:47,597]\u001b[0m Trial 147 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:49,400]\u001b[0m Trial 148 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:50,671]\u001b[0m Trial 149 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 850, 'criterion': 'gini', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:52,444]\u001b[0m Trial 150 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:54,075]\u001b[0m Trial 151 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:05:55,565]\u001b[0m Trial 152 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:57,260]\u001b[0m Trial 153 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:05:59,081]\u001b[0m Trial 154 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:00,915]\u001b[0m Trial 155 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:02,751]\u001b[0m Trial 156 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:04,445]\u001b[0m Trial 157 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:05,936]\u001b[0m Trial 158 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:07,237]\u001b[0m Trial 159 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:07,335]\u001b[0m Trial 160 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:09,246]\u001b[0m Trial 161 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:10,751]\u001b[0m Trial 162 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:12,100]\u001b[0m Trial 163 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:13,496]\u001b[0m Trial 164 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:15,174]\u001b[0m Trial 165 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:16,666]\u001b[0m Trial 166 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:18,203]\u001b[0m Trial 167 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:18,954]\u001b[0m Trial 168 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:20,680]\u001b[0m Trial 169 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:22,404]\u001b[0m Trial 170 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:24,320]\u001b[0m Trial 171 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:26,562]\u001b[0m Trial 172 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:28,524]\u001b[0m Trial 173 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:30,313]\u001b[0m Trial 174 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:31,374]\u001b[0m Trial 175 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:32,132]\u001b[0m Trial 176 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 3}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:33,594]\u001b[0m Trial 177 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:35,082]\u001b[0m Trial 178 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:36,674]\u001b[0m Trial 179 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:38,314]\u001b[0m Trial 180 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:39,868]\u001b[0m Trial 181 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:41,356]\u001b[0m Trial 182 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:43,192]\u001b[0m Trial 183 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:44,592]\u001b[0m Trial 184 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:46,124]\u001b[0m Trial 185 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:47,793]\u001b[0m Trial 186 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:49,717]\u001b[0m Trial 187 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:51,161]\u001b[0m Trial 188 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:52,808]\u001b[0m Trial 189 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:06:54,816]\u001b[0m Trial 190 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:56,401]\u001b[0m Trial 191 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:06:58,017]\u001b[0m Trial 192 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:00,072]\u001b[0m Trial 193 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:01,641]\u001b[0m Trial 194 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:03,210]\u001b[0m Trial 195 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:03,562]\u001b[0m Trial 196 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:05,687]\u001b[0m Trial 197 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:07,402]\u001b[0m Trial 198 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:09,012]\u001b[0m Trial 199 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:10,926]\u001b[0m Trial 200 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:12,620]\u001b[0m Trial 201 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:14,300]\u001b[0m Trial 202 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:16,135]\u001b[0m Trial 203 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:17,813]\u001b[0m Trial 204 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:19,303]\u001b[0m Trial 205 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:21,297]\u001b[0m Trial 206 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:22,990]\u001b[0m Trial 207 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:24,512]\u001b[0m Trial 208 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:26,285]\u001b[0m Trial 209 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:28,183]\u001b[0m Trial 210 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:29,767]\u001b[0m Trial 211 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:31,838]\u001b[0m Trial 212 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:33,501]\u001b[0m Trial 213 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:35,148]\u001b[0m Trial 214 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:36,966]\u001b[0m Trial 215 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:38,666]\u001b[0m Trial 216 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:40,294]\u001b[0m Trial 217 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:41,956]\u001b[0m Trial 218 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:43,967]\u001b[0m Trial 219 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:45,551]\u001b[0m Trial 220 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:47,321]\u001b[0m Trial 221 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:49,030]\u001b[0m Trial 222 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:50,631]\u001b[0m Trial 223 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:52,137]\u001b[0m Trial 224 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:53,847]\u001b[0m Trial 225 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:55,337]\u001b[0m Trial 226 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:07:56,671]\u001b[0m Trial 227 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:07:58,303]\u001b[0m Trial 228 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:00,076]\u001b[0m Trial 229 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:01,488]\u001b[0m Trial 230 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:02,364]\u001b[0m Trial 231 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 550, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:02,960]\u001b[0m Trial 232 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:04,656]\u001b[0m Trial 233 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:05,692]\u001b[0m Trial 234 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:07,164]\u001b[0m Trial 235 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:08,578]\u001b[0m Trial 236 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:09,909]\u001b[0m Trial 237 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:11,746]\u001b[0m Trial 238 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:13,094]\u001b[0m Trial 239 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:14,678]\u001b[0m Trial 240 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:16,531]\u001b[0m Trial 241 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:18,146]\u001b[0m Trial 242 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:19,746]\u001b[0m Trial 243 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:21,645]\u001b[0m Trial 244 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:22,695]\u001b[0m Trial 245 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:23,385]\u001b[0m Trial 246 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:24,044]\u001b[0m Trial 247 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:25,332]\u001b[0m Trial 248 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:26,836]\u001b[0m Trial 249 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:28,531]\u001b[0m Trial 250 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:29,803]\u001b[0m Trial 251 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:31,230]\u001b[0m Trial 252 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:32,971]\u001b[0m Trial 253 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:34,633]\u001b[0m Trial 254 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:36,045]\u001b[0m Trial 255 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:37,583]\u001b[0m Trial 256 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:39,076]\u001b[0m Trial 257 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:40,642]\u001b[0m Trial 258 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:42,162]\u001b[0m Trial 259 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:43,936]\u001b[0m Trial 260 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:45,160]\u001b[0m Trial 261 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:46,351]\u001b[0m Trial 262 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:48,082]\u001b[0m Trial 263 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:49,691]\u001b[0m Trial 264 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:50,367]\u001b[0m Trial 265 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:08:51,356]\u001b[0m Trial 266 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:52,814]\u001b[0m Trial 267 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:53,349]\u001b[0m Trial 268 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:55,215]\u001b[0m Trial 269 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:56,547]\u001b[0m Trial 270 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:57,647]\u001b[0m Trial 271 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:59,544]\u001b[0m Trial 272 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:08:59,796]\u001b[0m Trial 273 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:01,285]\u001b[0m Trial 274 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:02,823]\u001b[0m Trial 275 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:04,407]\u001b[0m Trial 276 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:06,384]\u001b[0m Trial 277 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:07,892]\u001b[0m Trial 278 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:09,569]\u001b[0m Trial 279 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:10,164]\u001b[0m Trial 280 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:11,733]\u001b[0m Trial 281 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:13,286]\u001b[0m Trial 282 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:14,045]\u001b[0m Trial 283 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:15,734]\u001b[0m Trial 284 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:17,145]\u001b[0m Trial 285 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:18,966]\u001b[0m Trial 286 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:20,737]\u001b[0m Trial 287 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:22,307]\u001b[0m Trial 288 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:24,109]\u001b[0m Trial 289 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:25,961]\u001b[0m Trial 290 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:27,294]\u001b[0m Trial 291 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:28,551]\u001b[0m Trial 292 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:29,914]\u001b[0m Trial 293 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 650, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:31,610]\u001b[0m Trial 294 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:33,051]\u001b[0m Trial 295 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:34,735]\u001b[0m Trial 296 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:36,644]\u001b[0m Trial 297 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:38,166]\u001b[0m Trial 298 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:39,813]\u001b[0m Trial 299 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:41,697]\u001b[0m Trial 300 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:43,185]\u001b[0m Trial 301 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:44,676]\u001b[0m Trial 302 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:46,418]\u001b[0m Trial 303 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 3}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:09:47,657]\u001b[0m Trial 304 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:49,492]\u001b[0m Trial 305 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:51,516]\u001b[0m Trial 306 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:53,053]\u001b[0m Trial 307 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:54,607]\u001b[0m Trial 308 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:56,394]\u001b[0m Trial 309 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:58,045]\u001b[0m Trial 310 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:09:59,830]\u001b[0m Trial 311 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:01,855]\u001b[0m Trial 312 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:03,517]\u001b[0m Trial 313 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:05,289]\u001b[0m Trial 314 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:07,078]\u001b[0m Trial 315 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:08,788]\u001b[0m Trial 316 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:10,687]\u001b[0m Trial 317 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:12,443]\u001b[0m Trial 318 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:13,776]\u001b[0m Trial 319 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:15,141]\u001b[0m Trial 320 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:17,149]\u001b[0m Trial 321 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:18,701]\u001b[0m Trial 322 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:20,238]\u001b[0m Trial 323 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:22,263]\u001b[0m Trial 324 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:23,847]\u001b[0m Trial 325 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:25,337]\u001b[0m Trial 326 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:27,094]\u001b[0m Trial 327 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:28,522]\u001b[0m Trial 328 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:29,934]\u001b[0m Trial 329 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:31,443]\u001b[0m Trial 330 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:33,072]\u001b[0m Trial 331 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:34,546]\u001b[0m Trial 332 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:36,304]\u001b[0m Trial 333 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:38,044]\u001b[0m Trial 334 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:38,765]\u001b[0m Trial 335 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:39,380]\u001b[0m Trial 336 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:40,069]\u001b[0m Trial 337 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:40,930]\u001b[0m Trial 338 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:43,126]\u001b[0m Trial 339 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:44,915]\u001b[0m Trial 340 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:46,547]\u001b[0m Trial 341 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:10:48,758]\u001b[0m Trial 342 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:50,518]\u001b[0m Trial 343 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:52,351]\u001b[0m Trial 344 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:54,499]\u001b[0m Trial 345 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:56,147]\u001b[0m Trial 346 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:10:57,887]\u001b[0m Trial 347 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:00,056]\u001b[0m Trial 348 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:01,527]\u001b[0m Trial 349 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:03,190]\u001b[0m Trial 350 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:04,086]\u001b[0m Trial 351 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:04,742]\u001b[0m Trial 352 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:06,235]\u001b[0m Trial 353 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:07,787]\u001b[0m Trial 354 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:09,542]\u001b[0m Trial 355 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:11,678]\u001b[0m Trial 356 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:13,058]\u001b[0m Trial 357 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:14,673]\u001b[0m Trial 358 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:16,353]\u001b[0m Trial 359 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:17,858]\u001b[0m Trial 360 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:19,270]\u001b[0m Trial 361 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:20,949]\u001b[0m Trial 362 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:22,424]\u001b[0m Trial 363 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:23,820]\u001b[0m Trial 364 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:25,387]\u001b[0m Trial 365 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:27,161]\u001b[0m Trial 366 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:28,572]\u001b[0m Trial 367 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:30,000]\u001b[0m Trial 368 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:31,771]\u001b[0m Trial 369 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:33,609]\u001b[0m Trial 370 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:35,003]\u001b[0m Trial 371 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:36,624]\u001b[0m Trial 372 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:38,110]\u001b[0m Trial 373 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 1}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:39,492]\u001b[0m Trial 374 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:40,982]\u001b[0m Trial 375 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:42,645]\u001b[0m Trial 376 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:44,088]\u001b[0m Trial 377 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:45,514]\u001b[0m Trial 378 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:47,207]\u001b[0m Trial 379 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:11:48,872]\u001b[0m Trial 380 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:50,189]\u001b[0m Trial 381 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:51,601]\u001b[0m Trial 382 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:52,291]\u001b[0m Trial 383 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:54,221]\u001b[0m Trial 384 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:55,632]\u001b[0m Trial 385 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:56,872]\u001b[0m Trial 386 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:11:58,816]\u001b[0m Trial 387 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:00,213]\u001b[0m Trial 388 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 850, 'criterion': 'gini', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:00,980]\u001b[0m Trial 389 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:02,456]\u001b[0m Trial 390 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:03,900]\u001b[0m Trial 391 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:05,469]\u001b[0m Trial 392 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:06,112]\u001b[0m Trial 393 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:07,928]\u001b[0m Trial 394 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:09,311]\u001b[0m Trial 395 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:10,646]\u001b[0m Trial 396 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:12,168]\u001b[0m Trial 397 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:12,672]\u001b[0m Trial 398 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:14,364]\u001b[0m Trial 399 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:15,556]\u001b[0m Trial 400 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:17,115]\u001b[0m Trial 401 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:18,635]\u001b[0m Trial 402 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:20,285]\u001b[0m Trial 403 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:21,686]\u001b[0m Trial 404 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:23,088]\u001b[0m Trial 405 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 2}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:24,886]\u001b[0m Trial 406 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:26,255]\u001b[0m Trial 407 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:27,403]\u001b[0m Trial 408 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:28,925]\u001b[0m Trial 409 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:29,451]\u001b[0m Trial 410 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:31,111]\u001b[0m Trial 411 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:32,318]\u001b[0m Trial 412 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:34,118]\u001b[0m Trial 413 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:34,942]\u001b[0m Trial 414 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:35,731]\u001b[0m Trial 415 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 3}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:37,443]\u001b[0m Trial 416 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:38,295]\u001b[0m Trial 417 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:12:39,938]\u001b[0m Trial 418 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:40,713]\u001b[0m Trial 419 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:42,627]\u001b[0m Trial 420 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:44,115]\u001b[0m Trial 421 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:45,862]\u001b[0m Trial 422 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:46,932]\u001b[0m Trial 423 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:48,797]\u001b[0m Trial 424 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:49,780]\u001b[0m Trial 425 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:51,576]\u001b[0m Trial 426 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:52,886]\u001b[0m Trial 427 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:54,500]\u001b[0m Trial 428 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:55,739]\u001b[0m Trial 429 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:57,661]\u001b[0m Trial 430 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:12:58,470]\u001b[0m Trial 431 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:00,216]\u001b[0m Trial 432 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:01,620]\u001b[0m Trial 433 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:02,914]\u001b[0m Trial 434 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:04,527]\u001b[0m Trial 435 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:05,759]\u001b[0m Trial 436 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:07,125]\u001b[0m Trial 437 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:08,905]\u001b[0m Trial 438 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:10,532]\u001b[0m Trial 439 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:11,997]\u001b[0m Trial 440 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:13,717]\u001b[0m Trial 441 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:15,055]\u001b[0m Trial 442 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:16,246]\u001b[0m Trial 443 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:17,657]\u001b[0m Trial 444 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:18,677]\u001b[0m Trial 445 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:20,116]\u001b[0m Trial 446 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:21,500]\u001b[0m Trial 447 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 650, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:22,995]\u001b[0m Trial 448 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:24,542]\u001b[0m Trial 449 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:26,678]\u001b[0m Trial 450 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:28,242]\u001b[0m Trial 451 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:29,936]\u001b[0m Trial 452 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:31,752]\u001b[0m Trial 453 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:33,619]\u001b[0m Trial 454 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:35,225]\u001b[0m Trial 455 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:13:37,035]\u001b[0m Trial 456 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:38,560]\u001b[0m Trial 457 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:39,937]\u001b[0m Trial 458 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:41,353]\u001b[0m Trial 459 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:42,984]\u001b[0m Trial 460 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:44,256]\u001b[0m Trial 461 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 550, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:45,215]\u001b[0m Trial 462 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:45,890]\u001b[0m Trial 463 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:46,576]\u001b[0m Trial 464 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:47,513]\u001b[0m Trial 465 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:49,140]\u001b[0m Trial 466 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:51,249]\u001b[0m Trial 467 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:52,661]\u001b[0m Trial 468 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:54,346]\u001b[0m Trial 469 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:55,727]\u001b[0m Trial 470 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:57,534]\u001b[0m Trial 471 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:13:59,179]\u001b[0m Trial 472 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:01,305]\u001b[0m Trial 473 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:02,973]\u001b[0m Trial 474 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:04,772]\u001b[0m Trial 475 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:06,785]\u001b[0m Trial 476 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:08,267]\u001b[0m Trial 477 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:10,099]\u001b[0m Trial 478 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:12,003]\u001b[0m Trial 479 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:13,508]\u001b[0m Trial 480 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:14,982]\u001b[0m Trial 481 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:17,127]\u001b[0m Trial 482 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:18,987]\u001b[0m Trial 483 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:20,658]\u001b[0m Trial 484 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:22,925]\u001b[0m Trial 485 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:24,361]\u001b[0m Trial 486 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:26,211]\u001b[0m Trial 487 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:28,366]\u001b[0m Trial 488 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:30,086]\u001b[0m Trial 489 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:31,947]\u001b[0m Trial 490 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:33,999]\u001b[0m Trial 491 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:35,725]\u001b[0m Trial 492 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:36,249]\u001b[0m Trial 493 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:14:36,996]\u001b[0m Trial 494 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:38,780]\u001b[0m Trial 495 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:40,991]\u001b[0m Trial 496 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:42,587]\u001b[0m Trial 497 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:44,257]\u001b[0m Trial 498 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:46,166]\u001b[0m Trial 499 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:47,895]\u001b[0m Trial 500 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:49,706]\u001b[0m Trial 501 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:51,715]\u001b[0m Trial 502 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:53,598]\u001b[0m Trial 503 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:55,190]\u001b[0m Trial 504 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:57,246]\u001b[0m Trial 505 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:14:58,996]\u001b[0m Trial 506 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:00,532]\u001b[0m Trial 507 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:02,526]\u001b[0m Trial 508 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:04,386]\u001b[0m Trial 509 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:05,901]\u001b[0m Trial 510 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:07,484]\u001b[0m Trial 511 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:09,345]\u001b[0m Trial 512 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:11,101]\u001b[0m Trial 513 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:12,702]\u001b[0m Trial 514 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:14,556]\u001b[0m Trial 515 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:16,176]\u001b[0m Trial 516 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:18,010]\u001b[0m Trial 517 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:20,064]\u001b[0m Trial 518 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:21,756]\u001b[0m Trial 519 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:23,255]\u001b[0m Trial 520 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:25,204]\u001b[0m Trial 521 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:27,051]\u001b[0m Trial 522 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:28,546]\u001b[0m Trial 523 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:30,221]\u001b[0m Trial 524 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:31,720]\u001b[0m Trial 525 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:33,278]\u001b[0m Trial 526 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:33,507]\u001b[0m Trial 527 finished with value: 0.6111111111111112 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:35,397]\u001b[0m Trial 528 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:37,132]\u001b[0m Trial 529 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:38,407]\u001b[0m Trial 530 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:40,018]\u001b[0m Trial 531 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:15:40,814]\u001b[0m Trial 532 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:42,452]\u001b[0m Trial 533 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:44,108]\u001b[0m Trial 534 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:46,025]\u001b[0m Trial 535 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:47,622]\u001b[0m Trial 536 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:48,292]\u001b[0m Trial 537 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:48,985]\u001b[0m Trial 538 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:50,843]\u001b[0m Trial 539 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:52,746]\u001b[0m Trial 540 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:54,351]\u001b[0m Trial 541 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:56,110]\u001b[0m Trial 542 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:58,101]\u001b[0m Trial 543 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:15:59,697]\u001b[0m Trial 544 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:01,791]\u001b[0m Trial 545 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:03,561]\u001b[0m Trial 546 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:05,220]\u001b[0m Trial 547 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:06,683]\u001b[0m Trial 548 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:07,704]\u001b[0m Trial 549 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:09,518]\u001b[0m Trial 550 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:11,236]\u001b[0m Trial 551 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:11,907]\u001b[0m Trial 552 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:12,792]\u001b[0m Trial 553 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:14,820]\u001b[0m Trial 554 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:15,548]\u001b[0m Trial 555 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:16,482]\u001b[0m Trial 556 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:17,142]\u001b[0m Trial 557 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:18,753]\u001b[0m Trial 558 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:19,553]\u001b[0m Trial 559 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:21,272]\u001b[0m Trial 560 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:22,837]\u001b[0m Trial 561 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:24,641]\u001b[0m Trial 562 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:25,464]\u001b[0m Trial 563 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:26,861]\u001b[0m Trial 564 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:28,433]\u001b[0m Trial 565 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:30,304]\u001b[0m Trial 566 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:31,909]\u001b[0m Trial 567 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:33,875]\u001b[0m Trial 568 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:35,635]\u001b[0m Trial 569 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:16:37,252]\u001b[0m Trial 570 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:39,143]\u001b[0m Trial 571 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:40,512]\u001b[0m Trial 572 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:41,996]\u001b[0m Trial 573 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:43,782]\u001b[0m Trial 574 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:45,181]\u001b[0m Trial 575 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:46,579]\u001b[0m Trial 576 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:48,308]\u001b[0m Trial 577 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:49,952]\u001b[0m Trial 578 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:51,364]\u001b[0m Trial 579 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:52,608]\u001b[0m Trial 580 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:54,026]\u001b[0m Trial 581 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:55,633]\u001b[0m Trial 582 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:56,451]\u001b[0m Trial 583 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:57,170]\u001b[0m Trial 584 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:58,009]\u001b[0m Trial 585 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 550, 'criterion': 'gini', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:16:59,674]\u001b[0m Trial 586 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:00,678]\u001b[0m Trial 587 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:02,370]\u001b[0m Trial 588 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:03,760]\u001b[0m Trial 589 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:05,287]\u001b[0m Trial 590 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:07,114]\u001b[0m Trial 591 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:08,427]\u001b[0m Trial 592 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:09,850]\u001b[0m Trial 593 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:11,478]\u001b[0m Trial 594 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:12,983]\u001b[0m Trial 595 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:14,319]\u001b[0m Trial 596 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:15,821]\u001b[0m Trial 597 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:17,440]\u001b[0m Trial 598 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:18,804]\u001b[0m Trial 599 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:20,202]\u001b[0m Trial 600 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:21,773]\u001b[0m Trial 601 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:23,338]\u001b[0m Trial 602 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:24,717]\u001b[0m Trial 603 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:26,004]\u001b[0m Trial 604 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 850, 'criterion': 'gini', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:27,665]\u001b[0m Trial 605 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:29,218]\u001b[0m Trial 606 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:30,011]\u001b[0m Trial 607 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:17:31,854]\u001b[0m Trial 608 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:33,865]\u001b[0m Trial 609 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:35,411]\u001b[0m Trial 610 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:36,743]\u001b[0m Trial 611 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:38,273]\u001b[0m Trial 612 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:39,820]\u001b[0m Trial 613 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:41,298]\u001b[0m Trial 614 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:42,736]\u001b[0m Trial 615 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:43,965]\u001b[0m Trial 616 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:45,758]\u001b[0m Trial 617 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:47,278]\u001b[0m Trial 618 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:48,672]\u001b[0m Trial 619 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:50,154]\u001b[0m Trial 620 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:51,728]\u001b[0m Trial 621 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:52,994]\u001b[0m Trial 622 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:54,155]\u001b[0m Trial 623 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:55,842]\u001b[0m Trial 624 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:57,292]\u001b[0m Trial 625 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:17:58,909]\u001b[0m Trial 626 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:00,441]\u001b[0m Trial 627 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:02,205]\u001b[0m Trial 628 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:03,575]\u001b[0m Trial 629 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:04,872]\u001b[0m Trial 630 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:06,256]\u001b[0m Trial 631 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:08,321]\u001b[0m Trial 632 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:09,597]\u001b[0m Trial 633 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:10,926]\u001b[0m Trial 634 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:12,730]\u001b[0m Trial 635 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:14,259]\u001b[0m Trial 636 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:16,029]\u001b[0m Trial 637 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:17,556]\u001b[0m Trial 638 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:19,405]\u001b[0m Trial 639 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:20,862]\u001b[0m Trial 640 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:21,559]\u001b[0m Trial 641 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 450, 'criterion': 'gini', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:21,873]\u001b[0m Trial 642 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:23,369]\u001b[0m Trial 643 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:25,067]\u001b[0m Trial 644 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:26,421]\u001b[0m Trial 645 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:18:27,826]\u001b[0m Trial 646 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:29,552]\u001b[0m Trial 647 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:30,789]\u001b[0m Trial 648 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:32,126]\u001b[0m Trial 649 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:33,219]\u001b[0m Trial 650 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 650, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:34,565]\u001b[0m Trial 651 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:36,116]\u001b[0m Trial 652 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:37,977]\u001b[0m Trial 653 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:39,290]\u001b[0m Trial 654 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:40,705]\u001b[0m Trial 655 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:42,459]\u001b[0m Trial 656 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:43,832]\u001b[0m Trial 657 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:45,408]\u001b[0m Trial 658 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:46,710]\u001b[0m Trial 659 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:47,545]\u001b[0m Trial 660 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:49,136]\u001b[0m Trial 661 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:50,374]\u001b[0m Trial 662 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:51,608]\u001b[0m Trial 663 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:53,246]\u001b[0m Trial 664 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:53,765]\u001b[0m Trial 665 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:55,093]\u001b[0m Trial 666 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:56,493]\u001b[0m Trial 667 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:18:58,571]\u001b[0m Trial 668 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:00,294]\u001b[0m Trial 669 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:01,608]\u001b[0m Trial 670 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:03,813]\u001b[0m Trial 671 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:05,539]\u001b[0m Trial 672 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:06,237]\u001b[0m Trial 673 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:06,831]\u001b[0m Trial 674 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 350, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:07,628]\u001b[0m Trial 675 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:09,554]\u001b[0m Trial 676 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:10,949]\u001b[0m Trial 677 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:12,281]\u001b[0m Trial 678 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:13,956]\u001b[0m Trial 679 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:15,791]\u001b[0m Trial 680 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:17,086]\u001b[0m Trial 681 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:18,199]\u001b[0m Trial 682 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 750, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:19,527]\u001b[0m Trial 683 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:19:20,989]\u001b[0m Trial 684 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:23,297]\u001b[0m Trial 685 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:25,243]\u001b[0m Trial 686 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:27,092]\u001b[0m Trial 687 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:29,147]\u001b[0m Trial 688 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:30,639]\u001b[0m Trial 689 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:32,285]\u001b[0m Trial 690 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:34,200]\u001b[0m Trial 691 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:35,704]\u001b[0m Trial 692 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:37,588]\u001b[0m Trial 693 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:39,644]\u001b[0m Trial 694 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:41,336]\u001b[0m Trial 695 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:42,859]\u001b[0m Trial 696 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:44,772]\u001b[0m Trial 697 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:46,561]\u001b[0m Trial 698 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:48,067]\u001b[0m Trial 699 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:49,697]\u001b[0m Trial 700 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:51,236]\u001b[0m Trial 701 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:52,883]\u001b[0m Trial 702 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:54,780]\u001b[0m Trial 703 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:56,554]\u001b[0m Trial 704 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:56,861]\u001b[0m Trial 705 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:58,326]\u001b[0m Trial 706 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:19:59,879]\u001b[0m Trial 707 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:01,825]\u001b[0m Trial 708 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:03,627]\u001b[0m Trial 709 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:05,322]\u001b[0m Trial 710 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:07,096]\u001b[0m Trial 711 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:08,711]\u001b[0m Trial 712 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:10,277]\u001b[0m Trial 713 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:12,273]\u001b[0m Trial 714 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:13,967]\u001b[0m Trial 715 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:15,490]\u001b[0m Trial 716 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:17,136]\u001b[0m Trial 717 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 2}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:17,595]\u001b[0m Trial 718 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:18,923]\u001b[0m Trial 719 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:20,523]\u001b[0m Trial 720 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:22,264]\u001b[0m Trial 721 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:20:23,864]\u001b[0m Trial 722 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:25,402]\u001b[0m Trial 723 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:27,348]\u001b[0m Trial 724 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:29,041]\u001b[0m Trial 725 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:30,500]\u001b[0m Trial 726 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:32,116]\u001b[0m Trial 727 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:34,029]\u001b[0m Trial 728 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:35,519]\u001b[0m Trial 729 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:36,870]\u001b[0m Trial 730 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:38,302]\u001b[0m Trial 731 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:39,865]\u001b[0m Trial 732 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:41,592]\u001b[0m Trial 733 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:42,940]\u001b[0m Trial 734 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:44,462]\u001b[0m Trial 735 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:46,186]\u001b[0m Trial 736 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:47,991]\u001b[0m Trial 737 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:49,498]\u001b[0m Trial 738 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:51,114]\u001b[0m Trial 739 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:52,932]\u001b[0m Trial 740 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:54,533]\u001b[0m Trial 741 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:56,164]\u001b[0m Trial 742 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:58,031]\u001b[0m Trial 743 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:20:59,710]\u001b[0m Trial 744 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:01,200]\u001b[0m Trial 745 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:02,956]\u001b[0m Trial 746 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:04,800]\u001b[0m Trial 747 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:06,487]\u001b[0m Trial 748 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:08,274]\u001b[0m Trial 749 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:10,097]\u001b[0m Trial 750 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:11,712]\u001b[0m Trial 751 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:13,826]\u001b[0m Trial 752 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:15,569]\u001b[0m Trial 753 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:17,326]\u001b[0m Trial 754 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:19,319]\u001b[0m Trial 755 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:21,122]\u001b[0m Trial 756 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:22,721]\u001b[0m Trial 757 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:24,669]\u001b[0m Trial 758 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:26,127]\u001b[0m Trial 759 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:21:27,743]\u001b[0m Trial 760 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:29,671]\u001b[0m Trial 761 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:31,399]\u001b[0m Trial 762 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:32,777]\u001b[0m Trial 763 finished with value: 0.5555555555555556 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 1}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:34,504]\u001b[0m Trial 764 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:36,498]\u001b[0m Trial 765 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:38,410]\u001b[0m Trial 766 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:40,088]\u001b[0m Trial 767 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:41,861]\u001b[0m Trial 768 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:43,444]\u001b[0m Trial 769 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:45,187]\u001b[0m Trial 770 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:47,398]\u001b[0m Trial 771 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:49,123]\u001b[0m Trial 772 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:50,552]\u001b[0m Trial 773 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:52,214]\u001b[0m Trial 774 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:53,910]\u001b[0m Trial 775 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:55,539]\u001b[0m Trial 776 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:57,516]\u001b[0m Trial 777 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:21:59,289]\u001b[0m Trial 778 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:00,261]\u001b[0m Trial 779 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 550, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:01,643]\u001b[0m Trial 780 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 950, 'criterion': 'gini', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:03,556]\u001b[0m Trial 781 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:05,108]\u001b[0m Trial 782 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:06,160]\u001b[0m Trial 783 finished with value: 0.7777777777777778 and parameters: {'n_estimators': 650, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:07,697]\u001b[0m Trial 784 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:09,518]\u001b[0m Trial 785 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:11,400]\u001b[0m Trial 786 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:12,875]\u001b[0m Trial 787 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:14,396]\u001b[0m Trial 788 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 850, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:16,390]\u001b[0m Trial 789 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:18,005]\u001b[0m Trial 790 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:19,542]\u001b[0m Trial 791 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:21,534]\u001b[0m Trial 792 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:23,196]\u001b[0m Trial 793 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 950, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:24,639]\u001b[0m Trial 794 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:26,380]\u001b[0m Trial 795 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:28,186]\u001b[0m Trial 796 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:29,205]\u001b[0m Trial 797 finished with value: 0.7222222222222222 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 17}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-18 20:22:30,852]\u001b[0m Trial 798 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n",
      "\u001b[32m[I 2022-05-18 20:22:32,608]\u001b[0m Trial 799 finished with value: 0.8888888888888888 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 2 with value: 0.8888888888888888.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=0)  # Asegurar los reproducibilidad de los resultados\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objectiveRF, n_trials=800)\n",
    "# n_trials = 20 x 2 x 20 = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=2, values=[0.8888888888888888], datetime_start=datetime.datetime(2022, 5, 18, 20, 2, 17, 519838), datetime_complete=datetime.datetime(2022, 5, 18, 20, 2, 19, 103135), params={'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 11}, distributions={'n_estimators': IntUniformDistribution(high=1000, low=50, step=50), 'criterion': CategoricalDistribution(choices=('gini', 'entropy')), 'max_depth': IntUniformDistribution(high=20, low=1, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "modelRF_optuna = RandomForestClassifier(criterion = \"entropy\", max_depth = 11, n_estimators = 1000, random_state=0)\n",
    "    \n",
    "modelRF_optuna.fit(X_train, y_train)\n",
    "\n",
    "y_pred_RF_optuna = modelRF_optuna.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_optuna)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRUEBA DE ``optuna`` CON CROSS-VALIDATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:17:28,586]\u001b[0m A new study created in memory with name: no-name-1fa07c84-aea0-42d4-a197-af748cf3f2f9\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:17:31,950]\u001b[0m Trial 0 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:17:35,161]\u001b[0m Trial 1 finished with value: 0.6029411764705883 and parameters: {'n_estimators': 600, 'criterion': 'gini', 'max_depth': 15}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:17:41,096]\u001b[0m Trial 2 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:17:41,721]\u001b[0m Trial 3 finished with value: 0.6176470588235294 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 2}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:17:47,059]\u001b[0m Trial 4 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 20}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:17:48,429]\u001b[0m Trial 5 finished with value: 0.6323529411764706 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'max_depth': 4}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:17:52,279]\u001b[0m Trial 6 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:17:56,394]\u001b[0m Trial 7 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:01,386]\u001b[0m Trial 8 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 20}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:04,452]\u001b[0m Trial 9 finished with value: 0.6470588235294117 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 3}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:06,882]\u001b[0m Trial 10 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:08,911]\u001b[0m Trial 11 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:11,940]\u001b[0m Trial 12 finished with value: 0.6323529411764706 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:14,379]\u001b[0m Trial 13 finished with value: 0.6323529411764706 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:16,519]\u001b[0m Trial 14 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:17,389]\u001b[0m Trial 15 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:21,209]\u001b[0m Trial 16 finished with value: 0.573529411764706 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 1}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:24,167]\u001b[0m Trial 17 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:26,239]\u001b[0m Trial 18 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:29,932]\u001b[0m Trial 19 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:30,935]\u001b[0m Trial 20 finished with value: 0.573529411764706 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 1}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:33,088]\u001b[0m Trial 21 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:36,533]\u001b[0m Trial 22 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:41,240]\u001b[0m Trial 23 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:46,118]\u001b[0m Trial 24 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:50,790]\u001b[0m Trial 25 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:18:56,716]\u001b[0m Trial 26 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 1000, 'criterion': 'gini', 'max_depth': 9}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:01,059]\u001b[0m Trial 27 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 0 with value: 0.6911764705882353.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:06,175]\u001b[0m Trial 28 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:11,124]\u001b[0m Trial 29 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:16,074]\u001b[0m Trial 30 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:21,074]\u001b[0m Trial 31 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:26,419]\u001b[0m Trial 32 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:32,664]\u001b[0m Trial 33 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:37,290]\u001b[0m Trial 34 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:43,720]\u001b[0m Trial 35 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:49,296]\u001b[0m Trial 36 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:19:54,487]\u001b[0m Trial 37 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:20:01,380]\u001b[0m Trial 38 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:05,939]\u001b[0m Trial 39 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:11,871]\u001b[0m Trial 40 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:17,069]\u001b[0m Trial 41 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:22,334]\u001b[0m Trial 42 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:26,524]\u001b[0m Trial 43 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:32,445]\u001b[0m Trial 44 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:37,612]\u001b[0m Trial 45 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:42,000]\u001b[0m Trial 46 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:47,447]\u001b[0m Trial 47 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:51,043]\u001b[0m Trial 48 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:20:55,142]\u001b[0m Trial 49 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:00,448]\u001b[0m Trial 50 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:05,860]\u001b[0m Trial 51 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:11,438]\u001b[0m Trial 52 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:17,563]\u001b[0m Trial 53 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:22,108]\u001b[0m Trial 54 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:28,070]\u001b[0m Trial 55 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:33,383]\u001b[0m Trial 56 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:37,900]\u001b[0m Trial 57 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:44,434]\u001b[0m Trial 58 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:49,570]\u001b[0m Trial 59 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:53,575]\u001b[0m Trial 60 finished with value: 0.676470588235294 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:21:58,781]\u001b[0m Trial 61 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:04,123]\u001b[0m Trial 62 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:10,130]\u001b[0m Trial 63 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:14,857]\u001b[0m Trial 64 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:19,961]\u001b[0m Trial 65 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:25,893]\u001b[0m Trial 66 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:30,689]\u001b[0m Trial 67 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:34,709]\u001b[0m Trial 68 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:39,883]\u001b[0m Trial 69 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:47,111]\u001b[0m Trial 70 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:52,549]\u001b[0m Trial 71 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:22:57,709]\u001b[0m Trial 72 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:03,580]\u001b[0m Trial 73 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:08,752]\u001b[0m Trial 74 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:13,150]\u001b[0m Trial 75 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:23:18,365]\u001b[0m Trial 76 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:23,723]\u001b[0m Trial 77 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:28,432]\u001b[0m Trial 78 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:33,739]\u001b[0m Trial 79 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:39,440]\u001b[0m Trial 80 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:44,737]\u001b[0m Trial 81 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:49,996]\u001b[0m Trial 82 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:54,651]\u001b[0m Trial 83 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:23:59,916]\u001b[0m Trial 84 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:05,806]\u001b[0m Trial 85 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:11,146]\u001b[0m Trial 86 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:15,108]\u001b[0m Trial 87 finished with value: 0.676470588235294 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:20,423]\u001b[0m Trial 88 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:24,961]\u001b[0m Trial 89 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:25,791]\u001b[0m Trial 90 finished with value: 0.6176470588235294 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 2}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:31,107]\u001b[0m Trial 91 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:36,488]\u001b[0m Trial 92 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:41,813]\u001b[0m Trial 93 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:48,147]\u001b[0m Trial 94 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:53,568]\u001b[0m Trial 95 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:24:59,512]\u001b[0m Trial 96 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:04,699]\u001b[0m Trial 97 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:09,887]\u001b[0m Trial 98 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:12,898]\u001b[0m Trial 99 finished with value: 0.6323529411764706 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:16,868]\u001b[0m Trial 100 finished with value: 0.676470588235294 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:22,275]\u001b[0m Trial 101 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:27,737]\u001b[0m Trial 102 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:33,191]\u001b[0m Trial 103 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:34,708]\u001b[0m Trial 104 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:40,726]\u001b[0m Trial 105 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:45,949]\u001b[0m Trial 106 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:50,454]\u001b[0m Trial 107 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:25:56,668]\u001b[0m Trial 108 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:01,840]\u001b[0m Trial 109 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:06,947]\u001b[0m Trial 110 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:12,019]\u001b[0m Trial 111 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:17,432]\u001b[0m Trial 112 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:22,617]\u001b[0m Trial 113 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:26:27,850]\u001b[0m Trial 114 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:33,089]\u001b[0m Trial 115 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:37,757]\u001b[0m Trial 116 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:43,209]\u001b[0m Trial 117 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:48,960]\u001b[0m Trial 118 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:54,383]\u001b[0m Trial 119 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:26:59,677]\u001b[0m Trial 120 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:04,962]\u001b[0m Trial 121 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:10,093]\u001b[0m Trial 122 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:15,569]\u001b[0m Trial 123 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:20,868]\u001b[0m Trial 124 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:26,030]\u001b[0m Trial 125 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:31,547]\u001b[0m Trial 126 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:36,061]\u001b[0m Trial 127 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:42,033]\u001b[0m Trial 128 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:47,256]\u001b[0m Trial 129 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:52,536]\u001b[0m Trial 130 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:27:57,946]\u001b[0m Trial 131 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:03,238]\u001b[0m Trial 132 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:08,511]\u001b[0m Trial 133 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:13,230]\u001b[0m Trial 134 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:18,638]\u001b[0m Trial 135 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:23,791]\u001b[0m Trial 136 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:28,464]\u001b[0m Trial 137 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:33,768]\u001b[0m Trial 138 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:39,132]\u001b[0m Trial 139 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:44,376]\u001b[0m Trial 140 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:49,875]\u001b[0m Trial 141 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:28:55,240]\u001b[0m Trial 142 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:00,701]\u001b[0m Trial 143 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:06,204]\u001b[0m Trial 144 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:09,865]\u001b[0m Trial 145 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:15,809]\u001b[0m Trial 146 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:21,357]\u001b[0m Trial 147 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:26,830]\u001b[0m Trial 148 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:32,292]\u001b[0m Trial 149 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:38,642]\u001b[0m Trial 150 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:44,918]\u001b[0m Trial 151 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:29:50,886]\u001b[0m Trial 152 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:29:56,204]\u001b[0m Trial 153 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:01,616]\u001b[0m Trial 154 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:07,083]\u001b[0m Trial 155 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:12,412]\u001b[0m Trial 156 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:17,480]\u001b[0m Trial 157 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:23,566]\u001b[0m Trial 158 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:29,231]\u001b[0m Trial 159 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:35,084]\u001b[0m Trial 160 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:40,453]\u001b[0m Trial 161 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:45,823]\u001b[0m Trial 162 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:51,234]\u001b[0m Trial 163 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:30:56,424]\u001b[0m Trial 164 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:01,796]\u001b[0m Trial 165 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:07,246]\u001b[0m Trial 166 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:11,884]\u001b[0m Trial 167 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:18,021]\u001b[0m Trial 168 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:23,265]\u001b[0m Trial 169 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:28,549]\u001b[0m Trial 170 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:34,125]\u001b[0m Trial 171 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:39,796]\u001b[0m Trial 172 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:44,997]\u001b[0m Trial 173 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:50,251]\u001b[0m Trial 174 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:31:55,419]\u001b[0m Trial 175 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:00,744]\u001b[0m Trial 176 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:06,158]\u001b[0m Trial 177 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:11,450]\u001b[0m Trial 178 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:16,049]\u001b[0m Trial 179 finished with value: 0.676470588235294 and parameters: {'n_estimators': 700, 'criterion': 'gini', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:20,950]\u001b[0m Trial 180 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:26,213]\u001b[0m Trial 181 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:31,399]\u001b[0m Trial 182 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:36,789]\u001b[0m Trial 183 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:42,175]\u001b[0m Trial 184 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:47,357]\u001b[0m Trial 185 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:52,729]\u001b[0m Trial 186 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:32:58,071]\u001b[0m Trial 187 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:03,263]\u001b[0m Trial 188 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:09,172]\u001b[0m Trial 189 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:33:14,402]\u001b[0m Trial 190 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:19,587]\u001b[0m Trial 191 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:24,681]\u001b[0m Trial 192 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:30,073]\u001b[0m Trial 193 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:35,448]\u001b[0m Trial 194 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:40,522]\u001b[0m Trial 195 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:45,934]\u001b[0m Trial 196 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:51,193]\u001b[0m Trial 197 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:33:56,417]\u001b[0m Trial 198 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:01,685]\u001b[0m Trial 199 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:06,782]\u001b[0m Trial 200 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:11,946]\u001b[0m Trial 201 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:17,240]\u001b[0m Trial 202 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:22,371]\u001b[0m Trial 203 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:27,771]\u001b[0m Trial 204 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:33,223]\u001b[0m Trial 205 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:38,734]\u001b[0m Trial 206 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:43,959]\u001b[0m Trial 207 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:49,316]\u001b[0m Trial 208 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:34:54,186]\u001b[0m Trial 209 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 3}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:00,467]\u001b[0m Trial 210 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:05,700]\u001b[0m Trial 211 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:10,969]\u001b[0m Trial 212 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:16,188]\u001b[0m Trial 213 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:21,487]\u001b[0m Trial 214 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:26,881]\u001b[0m Trial 215 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:32,344]\u001b[0m Trial 216 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:37,723]\u001b[0m Trial 217 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:43,029]\u001b[0m Trial 218 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:48,268]\u001b[0m Trial 219 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:50,073]\u001b[0m Trial 220 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 300, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:35:55,368]\u001b[0m Trial 221 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:00,797]\u001b[0m Trial 222 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:06,260]\u001b[0m Trial 223 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:11,776]\u001b[0m Trial 224 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:17,266]\u001b[0m Trial 225 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:22,453]\u001b[0m Trial 226 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:27,853]\u001b[0m Trial 227 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:36:33,482]\u001b[0m Trial 228 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:38,744]\u001b[0m Trial 229 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:44,283]\u001b[0m Trial 230 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:49,670]\u001b[0m Trial 231 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:54,539]\u001b[0m Trial 232 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:36:59,785]\u001b[0m Trial 233 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:05,282]\u001b[0m Trial 234 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:10,514]\u001b[0m Trial 235 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:15,810]\u001b[0m Trial 236 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:20,898]\u001b[0m Trial 237 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:26,165]\u001b[0m Trial 238 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:30,942]\u001b[0m Trial 239 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:36,229]\u001b[0m Trial 240 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:41,515]\u001b[0m Trial 241 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:46,734]\u001b[0m Trial 242 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:51,936]\u001b[0m Trial 243 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:37:57,088]\u001b[0m Trial 244 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:02,230]\u001b[0m Trial 245 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:07,517]\u001b[0m Trial 246 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:13,066]\u001b[0m Trial 247 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:18,195]\u001b[0m Trial 248 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:23,471]\u001b[0m Trial 249 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:28,319]\u001b[0m Trial 250 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:33,503]\u001b[0m Trial 251 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:38,917]\u001b[0m Trial 252 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:44,226]\u001b[0m Trial 253 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:49,393]\u001b[0m Trial 254 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:38:54,689]\u001b[0m Trial 255 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:00,526]\u001b[0m Trial 256 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:05,777]\u001b[0m Trial 257 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:10,329]\u001b[0m Trial 258 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:15,454]\u001b[0m Trial 259 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:20,612]\u001b[0m Trial 260 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:25,773]\u001b[0m Trial 261 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:31,109]\u001b[0m Trial 262 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:36,401]\u001b[0m Trial 263 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:41,621]\u001b[0m Trial 264 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:46,811]\u001b[0m Trial 265 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:39:52,348]\u001b[0m Trial 266 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:39:57,969]\u001b[0m Trial 267 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:03,477]\u001b[0m Trial 268 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:08,959]\u001b[0m Trial 269 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:13,134]\u001b[0m Trial 270 finished with value: 0.676470588235294 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:17,691]\u001b[0m Trial 271 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:23,055]\u001b[0m Trial 272 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:28,199]\u001b[0m Trial 273 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:33,341]\u001b[0m Trial 274 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:39,437]\u001b[0m Trial 275 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:44,816]\u001b[0m Trial 276 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:50,018]\u001b[0m Trial 277 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:55,229]\u001b[0m Trial 278 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:40:55,968]\u001b[0m Trial 279 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:01,255]\u001b[0m Trial 280 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:06,417]\u001b[0m Trial 281 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:11,717]\u001b[0m Trial 282 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:16,749]\u001b[0m Trial 283 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:21,411]\u001b[0m Trial 284 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:26,661]\u001b[0m Trial 285 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:30,118]\u001b[0m Trial 286 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 500, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:35,227]\u001b[0m Trial 287 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:40,562]\u001b[0m Trial 288 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:42,027]\u001b[0m Trial 289 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:47,343]\u001b[0m Trial 290 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:53,996]\u001b[0m Trial 291 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:41:59,378]\u001b[0m Trial 292 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:04,554]\u001b[0m Trial 293 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 4}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:09,863]\u001b[0m Trial 294 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:14,314]\u001b[0m Trial 295 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 5}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:19,563]\u001b[0m Trial 296 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:24,702]\u001b[0m Trial 297 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:29,887]\u001b[0m Trial 298 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:35,199]\u001b[0m Trial 299 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:40,662]\u001b[0m Trial 300 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:45,983]\u001b[0m Trial 301 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:51,311]\u001b[0m Trial 302 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:42:56,799]\u001b[0m Trial 303 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:43:02,093]\u001b[0m Trial 304 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:07,347]\u001b[0m Trial 305 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:12,650]\u001b[0m Trial 306 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:17,840]\u001b[0m Trial 307 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:22,415]\u001b[0m Trial 308 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:27,704]\u001b[0m Trial 309 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:30,546]\u001b[0m Trial 310 finished with value: 0.6323529411764706 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:35,851]\u001b[0m Trial 311 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:41,054]\u001b[0m Trial 312 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:46,419]\u001b[0m Trial 313 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:51,878]\u001b[0m Trial 314 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 9}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:43:57,120]\u001b[0m Trial 315 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:03,205]\u001b[0m Trial 316 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:08,519]\u001b[0m Trial 317 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:13,860]\u001b[0m Trial 318 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:19,258]\u001b[0m Trial 319 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:23,956]\u001b[0m Trial 320 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:30,219]\u001b[0m Trial 321 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:35,836]\u001b[0m Trial 322 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:41,406]\u001b[0m Trial 323 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:46,634]\u001b[0m Trial 324 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 12}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:51,820]\u001b[0m Trial 325 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:44:56,384]\u001b[0m Trial 326 finished with value: 0.5588235294117647 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 1}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:01,887]\u001b[0m Trial 327 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:06,681]\u001b[0m Trial 328 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:12,068]\u001b[0m Trial 329 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:17,235]\u001b[0m Trial 330 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:22,985]\u001b[0m Trial 331 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:29,140]\u001b[0m Trial 332 finished with value: 0.676470588235294 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 3}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:34,714]\u001b[0m Trial 333 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:40,438]\u001b[0m Trial 334 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:45,754]\u001b[0m Trial 335 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:51,181]\u001b[0m Trial 336 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:45:57,194]\u001b[0m Trial 337 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:02,698]\u001b[0m Trial 338 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:08,156]\u001b[0m Trial 339 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:13,763]\u001b[0m Trial 340 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:19,438]\u001b[0m Trial 341 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:46:25,008]\u001b[0m Trial 342 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 11}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:29,916]\u001b[0m Trial 343 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 10}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:35,965]\u001b[0m Trial 344 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:41,247]\u001b[0m Trial 345 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:46,862]\u001b[0m Trial 346 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:52,275]\u001b[0m Trial 347 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 15}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:46:57,397]\u001b[0m Trial 348 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:01,393]\u001b[0m Trial 349 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 600, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:07,085]\u001b[0m Trial 350 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:12,376]\u001b[0m Trial 351 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:17,246]\u001b[0m Trial 352 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:22,829]\u001b[0m Trial 353 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:28,584]\u001b[0m Trial 354 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:34,210]\u001b[0m Trial 355 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:39,598]\u001b[0m Trial 356 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:44,736]\u001b[0m Trial 357 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:51,259]\u001b[0m Trial 358 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:52,907]\u001b[0m Trial 359 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:47:58,275]\u001b[0m Trial 360 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:03,676]\u001b[0m Trial 361 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:09,862]\u001b[0m Trial 362 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:13,031]\u001b[0m Trial 363 finished with value: 0.6323529411764706 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:20,698]\u001b[0m Trial 364 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:27,170]\u001b[0m Trial 365 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:33,377]\u001b[0m Trial 366 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:39,227]\u001b[0m Trial 367 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:44,862]\u001b[0m Trial 368 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:49,968]\u001b[0m Trial 369 finished with value: 0.6470588235294118 and parameters: {'n_estimators': 800, 'criterion': 'gini', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:48:56,053]\u001b[0m Trial 370 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:01,560]\u001b[0m Trial 371 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:08,006]\u001b[0m Trial 372 finished with value: 0.6764705882352942 and parameters: {'n_estimators': 1000, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:13,376]\u001b[0m Trial 373 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 7}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:18,260]\u001b[0m Trial 374 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:23,866]\u001b[0m Trial 375 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 8}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:29,463]\u001b[0m Trial 376 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:34,887]\u001b[0m Trial 377 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:40,489]\u001b[0m Trial 378 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:45,938]\u001b[0m Trial 379 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-19 17:49:51,418]\u001b[0m Trial 380 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 6}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:49:56,843]\u001b[0m Trial 381 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:02,313]\u001b[0m Trial 382 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:08,261]\u001b[0m Trial 383 finished with value: 0.6617647058823529 and parameters: {'n_estimators': 900, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:13,885]\u001b[0m Trial 384 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:19,302]\u001b[0m Trial 385 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:24,835]\u001b[0m Trial 386 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:30,381]\u001b[0m Trial 387 finished with value: 0.676470588235294 and parameters: {'n_estimators': 900, 'criterion': 'gini', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:35,091]\u001b[0m Trial 388 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 14}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:40,670]\u001b[0m Trial 389 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 13}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:46,128]\u001b[0m Trial 390 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 16}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:51,440]\u001b[0m Trial 391 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:50:56,806]\u001b[0m Trial 392 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 18}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:51:02,286]\u001b[0m Trial 393 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:51:07,835]\u001b[0m Trial 394 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:51:13,806]\u001b[0m Trial 395 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:51:19,557]\u001b[0m Trial 396 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 17}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:51:24,888]\u001b[0m Trial 397 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:51:30,360]\u001b[0m Trial 398 finished with value: 0.7058823529411764 and parameters: {'n_estimators': 800, 'criterion': 'entropy', 'max_depth': 19}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n",
      "\u001b[32m[I 2022-05-19 17:51:35,130]\u001b[0m Trial 399 finished with value: 0.6911764705882353 and parameters: {'n_estimators': 700, 'criterion': 'entropy', 'max_depth': 20}. Best is trial 28 with value: 0.7058823529411764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": optuna.distributions.IntUniformDistribution(100, 1000, 100),\n",
    "    \"criterion\": optuna.distributions.CategoricalDistribution([\"gini\", \"entropy\"]),\n",
    "    \"max_depth\": optuna.distributions.IntUniformDistribution(1, 20)\n",
    "}\n",
    "\n",
    "optuna_search = optuna.integration.OptunaSearchCV(model_RF, param_grid_RF, cv=4, n_trials=400, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "y_pred_RF = optuna_search.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{SI ESTOY HACIENDO UNA BÚSQUEDA EXACTAMENTE CON LOS MISMOS PARÁMETROS POR QUÉ ES DISTINTO??}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'gamma': 0, 'learning_rate': 0.5, 'max_depth': 0}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=0,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.5, max_delta_step=None, max_depth=0,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 72.22%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "# model_XGB = XGBClassifier(eval_metric=\"logloss\")\n",
    "model_XGB = XGBClassifier(eval_metric=\"logloss\", random_state=0)\n",
    "param_grid_XGB = {\n",
    "    \"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "    \"learning_rate\": [0.001, 0.05, 0.1, 0.5],\n",
    "    \"gamma\": [0, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [5, 6, 10, 15, 20, 0] # 0 = ninguna restricción\n",
    "#     \"gamma\": [0],\n",
    "#     \"max_depth\": [6, 10] # 0 = ninguna restricción\n",
    "}\n",
    "model_XGB_opt = train_model(model_XGB, param_grid_XGB)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_XGB = model_XGB_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_XGB)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Predicción en test para kaggle\n",
    "y_pred_kaggle_XGB = model_XGB_opt.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{EL RESULTADO EMPEORA PROBANDO MÁS PARÁMETROS???}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales\n",
    "\n",
    "### Usando la librería \"sklearn\", clasificador: MLPClassifier\n",
    "\n",
    "Documentación: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (200, 200, 100, 50, 1), 'solver': 'lbfgs', 'validation_fraction': 0.25}\n",
      "Modelo óptimo: MLPClassifier(activation='tanh', alpha=0.001,\n",
      "              hidden_layer_sizes=(200, 200, 100, 50, 1), random_state=0,\n",
      "              solver='lbfgs', validation_fraction=0.25)\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "model_MLPC = MLPClassifier(random_state=0)\n",
    "param_grid_MLPC = {\n",
    "    \"hidden_layer_sizes\": [(100, 200, 100, 1), (100, 100, 100, 100, 1), (200, 200, 100, 50, 1), (100, 250, 250, 100, 1)],\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"], # Tiene sentido probar identity y relu?\n",
    "    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"alpha\": [0, 0.0001, 0.001, 0.01, 0.1], # L2 regularization\n",
    "#     \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    \"validation_fraction\": [0.25]\n",
    "}\n",
    "model_MLPC_opt = train_model(model_MLPC, param_grid_MLPC)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_MLPC = model_MLPC_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_MLPC)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Predicción en test para kaggle\n",
    "y_pred_kaggle_MLPC = model_MLPC_opt.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando la librería \"keras\"\n",
    "\n",
    "Ahora utilizaremos la librería de ``keras``, por su mayor flexibilidad para intentar mejorar los resultados de la red neuronal.\n",
    "\n",
    "Comenzaremos repitiendo la búsqueda de hiperparámetros, ya que la propia librería de ``keras`` dispone de integración con otras que nos permitirán hacer una búsqueda algo más exhaustiva por ejemplo en cuanto al número de capas y neuronas en estas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización de los hiperparámetros usando la librería: ``optuna``**\n",
    "\n",
    "Documentación:\n",
    "* https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html\n",
    "* https://optuna.org/\n",
    "\n",
    "Tomaremos de base algunas de los resultados que hemos podido obtener con ``GridSearchCV`` para reducir el coste computacional. Por ejemplo, utilizaremos el optimizador óptimo recomendado por ese método: Adam, al igual que la función de activación: relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El objetivo es definir una función que será optimizada. En este caso, nos interesa maximizar el accuracy.\n",
    "def objectiveAdam(trial):\n",
    "    modelFC_optuna_Adam = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna_Adam.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "        modelFC_optuna_Adam.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna_Adam.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    modelFC_optuna_Adam.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna_Adam.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna_Adam.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:27,982]\u001b[0m A new study created in memory with name: no-name-822a6abd-8efd-45aa-a81d-86bb9583847f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:29,010]\u001b[0m Trial 0 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:29,944]\u001b[0m Trial 1 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:30,862]\u001b[0m Trial 2 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:31,771]\u001b[0m Trial 3 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:32,642]\u001b[0m Trial 4 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:33,442]\u001b[0m Trial 5 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:34,572]\u001b[0m Trial 6 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:35,850]\u001b[0m Trial 7 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:36,629]\u001b[0m Trial 8 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:37,704]\u001b[0m Trial 9 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:38,652]\u001b[0m Trial 10 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:39,953]\u001b[0m Trial 11 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:40,953]\u001b[0m Trial 12 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:41,823]\u001b[0m Trial 13 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:42,770]\u001b[0m Trial 14 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:43,651]\u001b[0m Trial 15 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:44,697]\u001b[0m Trial 16 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:45,674]\u001b[0m Trial 17 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:47,122]\u001b[0m Trial 18 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:48,230]\u001b[0m Trial 19 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:49,215]\u001b[0m Trial 20 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:50,070]\u001b[0m Trial 21 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:51,494]\u001b[0m Trial 22 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:52,548]\u001b[0m Trial 23 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:53,350]\u001b[0m Trial 24 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:54,212]\u001b[0m Trial 25 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:55,325]\u001b[0m Trial 26 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:56,145]\u001b[0m Trial 27 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:56,915]\u001b[0m Trial 28 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:57,846]\u001b[0m Trial 29 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:58,703]\u001b[0m Trial 30 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:06:59,443]\u001b[0m Trial 31 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:00,272]\u001b[0m Trial 32 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:01,113]\u001b[0m Trial 33 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:01,973]\u001b[0m Trial 34 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:02,922]\u001b[0m Trial 35 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:03,877]\u001b[0m Trial 36 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:04,856]\u001b[0m Trial 37 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:05,920]\u001b[0m Trial 38 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:07,489]\u001b[0m Trial 39 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:08,625]\u001b[0m Trial 40 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:09,533]\u001b[0m Trial 41 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:10,463]\u001b[0m Trial 42 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:11,567]\u001b[0m Trial 43 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:12,392]\u001b[0m Trial 44 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:13,249]\u001b[0m Trial 45 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:14,341]\u001b[0m Trial 46 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:15,460]\u001b[0m Trial 47 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:16,652]\u001b[0m Trial 48 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:17,665]\u001b[0m Trial 49 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:18,529]\u001b[0m Trial 50 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:19,287]\u001b[0m Trial 51 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:20,131]\u001b[0m Trial 52 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:20,973]\u001b[0m Trial 53 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:22,164]\u001b[0m Trial 54 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:22,941]\u001b[0m Trial 55 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:23,823]\u001b[0m Trial 56 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:24,658]\u001b[0m Trial 57 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:25,661]\u001b[0m Trial 58 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:26,701]\u001b[0m Trial 59 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:27,697]\u001b[0m Trial 60 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:29,279]\u001b[0m Trial 61 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:30,221]\u001b[0m Trial 62 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:31,166]\u001b[0m Trial 63 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:32,319]\u001b[0m Trial 64 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:33,273]\u001b[0m Trial 65 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:34,317]\u001b[0m Trial 66 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:35,704]\u001b[0m Trial 67 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:36,709]\u001b[0m Trial 68 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:37,640]\u001b[0m Trial 69 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:38,495]\u001b[0m Trial 70 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:39,313]\u001b[0m Trial 71 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:40,109]\u001b[0m Trial 72 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:40,857]\u001b[0m Trial 73 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:41,765]\u001b[0m Trial 74 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:42,611]\u001b[0m Trial 75 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:43,426]\u001b[0m Trial 76 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:44,218]\u001b[0m Trial 77 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:45,052]\u001b[0m Trial 78 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:45,885]\u001b[0m Trial 79 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:46,692]\u001b[0m Trial 80 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:47,509]\u001b[0m Trial 81 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:48,544]\u001b[0m Trial 82 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:49,959]\u001b[0m Trial 83 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:51,043]\u001b[0m Trial 84 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:52,034]\u001b[0m Trial 85 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:52,989]\u001b[0m Trial 86 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:54,091]\u001b[0m Trial 87 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:55,141]\u001b[0m Trial 88 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:56,103]\u001b[0m Trial 89 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:57,060]\u001b[0m Trial 90 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:58,014]\u001b[0m Trial 91 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:58,936]\u001b[0m Trial 92 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:07:59,866]\u001b[0m Trial 93 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:00,909]\u001b[0m Trial 94 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.5}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:01,950]\u001b[0m Trial 95 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:02,971]\u001b[0m Trial 96 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:04,112]\u001b[0m Trial 97 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:05,321]\u001b[0m Trial 98 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:06,662]\u001b[0m Trial 99 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:07,562]\u001b[0m Trial 100 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.2}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:08,425]\u001b[0m Trial 101 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 50, 'dropout': 0.1}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:09,891]\u001b[0m Trial 102 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:10,714]\u001b[0m Trial 103 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:11,508]\u001b[0m Trial 104 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:12,343]\u001b[0m Trial 105 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:13,176]\u001b[0m Trial 106 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:13,956]\u001b[0m Trial 107 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.0}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:14,772]\u001b[0m Trial 108 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:15,574]\u001b[0m Trial 109 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:16,368]\u001b[0m Trial 110 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:17,187]\u001b[0m Trial 111 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:18,013]\u001b[0m Trial 112 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:18,825]\u001b[0m Trial 113 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:19,971]\u001b[0m Trial 114 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:20,771]\u001b[0m Trial 115 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:21,602]\u001b[0m Trial 116 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:22,391]\u001b[0m Trial 117 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:23,218]\u001b[0m Trial 118 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:08:24,192]\u001b[0m Trial 119 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objectiveAdam, n_trials=120)\n",
    "# n_trials = 4 x 5 x 6 = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.4444444477558136], datetime_start=datetime.datetime(2022, 5, 21, 20, 6, 27, 985976), datetime_complete=datetime.datetime(2022, 5, 21, 20, 6, 29, 9574), params={'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red con los parámetros optimizados es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 173ms/step - loss: 0.6907 - acc: 0.5686 - val_loss: 0.7020 - val_acc: 0.4706\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6908 - acc: 0.5490 - val_loss: 0.6967 - val_acc: 0.4118\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6219 - acc: 0.7255 - val_loss: 0.6908 - val_acc: 0.3529\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6492 - acc: 0.6471 - val_loss: 0.6842 - val_acc: 0.5294\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6124 - acc: 0.6275 - val_loss: 0.6722 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5017 - acc: 0.8235 - val_loss: 0.6597 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5774 - acc: 0.6667 - val_loss: 0.6501 - val_acc: 0.6471\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4641 - acc: 0.8627 - val_loss: 0.6373 - val_acc: 0.5294\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3752 - acc: 0.9216 - val_loss: 0.6285 - val_acc: 0.5882\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3086 - acc: 0.9608 - val_loss: 0.6302 - val_acc: 0.5882\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3575 - acc: 0.9216 - val_loss: 0.6420 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5175 - acc: 0.7778\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Adam = models.Sequential()\n",
    "modelFC_optuna_Adam.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_Adam.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_Adam.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_Adam.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_Adam.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0563)\n",
    "modelFC_optuna_Adam.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "modelFC_optuna_Adam.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "# modelFC_optuna_Adam.fit(X_train, y_train, epochs=100, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Adam.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{SI NO FIJAMOS SEMILLA ALGUNAS EJECUCIONES SI MEJORAN EL RESULTADO DE sklearn}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en la búsqueda de hiperparámetros de ``sklearn`` no hemos podido utilizar el optimizador RMSProp, vamos a probarlo también con ``optuna`` + ``keras`` para ver si mejora nuestros resultados. Repetimos por tanto el código anterior para buscar si hay un optimizador que permita tener mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El objetivo es definir una función que será optimizada. En este caso, nos interesa maximizar el accuracy.\n",
    "def objectiveAdam3(trial):\n",
    "    modelFC_optuna_Adam = models.Sequential()\n",
    "\n",
    "    # Se utiliza el objeto \"trial\" para asignar las posibilidades a los hiperparámetros.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna_Adam.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "        modelFC_optuna_Adam.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna_Adam.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\", \"Adam\"])\n",
    "    modelFC_optuna_Adam.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        optimizer=optimizers,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna_Adam.fit(X_train, y_train, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna_Adam.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:42:55,125]\u001b[0m A new study created in memory with name: no-name-ca04e70e-0de1-48f8-8e8b-1c36b6984d29\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:42:56,420]\u001b[0m Trial 0 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:42:57,690]\u001b[0m Trial 1 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:42:59,064]\u001b[0m Trial 2 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:00,835]\u001b[0m Trial 3 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:02,012]\u001b[0m Trial 4 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:06,908]\u001b[0m Trial 5 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:08,314]\u001b[0m Trial 6 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:09,580]\u001b[0m Trial 7 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:10,592]\u001b[0m Trial 8 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:11,542]\u001b[0m Trial 9 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 50, 'dropout': 0.30000000000000004, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:13,301]\u001b[0m Trial 10 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:14,244]\u001b[0m Trial 11 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:15,475]\u001b[0m Trial 12 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:16,452]\u001b[0m Trial 13 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.4, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:17,877]\u001b[0m Trial 14 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.5, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:19,012]\u001b[0m Trial 15 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:20,408]\u001b[0m Trial 16 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:21,730]\u001b[0m Trial 17 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:22,672]\u001b[0m Trial 18 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:23,860]\u001b[0m Trial 19 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 100, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:25,076]\u001b[0m Trial 20 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:26,377]\u001b[0m Trial 21 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:27,392]\u001b[0m Trial 22 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:28,611]\u001b[0m Trial 23 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:29,777]\u001b[0m Trial 24 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.4, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:30,948]\u001b[0m Trial 25 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:32,830]\u001b[0m Trial 26 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:33,823]\u001b[0m Trial 27 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:34,905]\u001b[0m Trial 28 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:36,002]\u001b[0m Trial 29 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:36,928]\u001b[0m Trial 30 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:38,045]\u001b[0m Trial 31 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:39,170]\u001b[0m Trial 32 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:40,105]\u001b[0m Trial 33 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:41,254]\u001b[0m Trial 34 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:43,000]\u001b[0m Trial 35 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:44,452]\u001b[0m Trial 36 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:45,784]\u001b[0m Trial 37 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:47,005]\u001b[0m Trial 38 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:48,466]\u001b[0m Trial 39 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:49,557]\u001b[0m Trial 40 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.5, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:50,795]\u001b[0m Trial 41 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:51,916]\u001b[0m Trial 42 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:53,056]\u001b[0m Trial 43 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:54,190]\u001b[0m Trial 44 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:55,134]\u001b[0m Trial 45 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:57,116]\u001b[0m Trial 46 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:58,635]\u001b[0m Trial 47 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:43:59,728]\u001b[0m Trial 48 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:00,811]\u001b[0m Trial 49 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:01,775]\u001b[0m Trial 50 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:03,031]\u001b[0m Trial 51 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 50, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:04,160]\u001b[0m Trial 52 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:05,551]\u001b[0m Trial 53 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:06,532]\u001b[0m Trial 54 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:07,670]\u001b[0m Trial 55 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:09,052]\u001b[0m Trial 56 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:10,043]\u001b[0m Trial 57 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:11,268]\u001b[0m Trial 58 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:12,633]\u001b[0m Trial 59 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:13,935]\u001b[0m Trial 60 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:15,387]\u001b[0m Trial 61 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:17,114]\u001b[0m Trial 62 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:18,908]\u001b[0m Trial 63 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:20,427]\u001b[0m Trial 64 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:21,923]\u001b[0m Trial 65 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:23,674]\u001b[0m Trial 66 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:25,169]\u001b[0m Trial 67 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:26,304]\u001b[0m Trial 68 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:27,656]\u001b[0m Trial 69 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.4, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:28,808]\u001b[0m Trial 70 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:29,697]\u001b[0m Trial 71 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:30,857]\u001b[0m Trial 72 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:31,782]\u001b[0m Trial 73 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:32,923]\u001b[0m Trial 74 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:33,984]\u001b[0m Trial 75 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:34,918]\u001b[0m Trial 76 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:35,951]\u001b[0m Trial 77 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 50, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:36,908]\u001b[0m Trial 78 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:37,875]\u001b[0m Trial 79 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:38,738]\u001b[0m Trial 80 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:40,032]\u001b[0m Trial 81 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:41,128]\u001b[0m Trial 82 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:42,216]\u001b[0m Trial 83 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:43,319]\u001b[0m Trial 84 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:44,553]\u001b[0m Trial 85 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:45,878]\u001b[0m Trial 86 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:47,069]\u001b[0m Trial 87 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:48,944]\u001b[0m Trial 88 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:50,207]\u001b[0m Trial 89 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:51,883]\u001b[0m Trial 90 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:53,468]\u001b[0m Trial 91 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:55,143]\u001b[0m Trial 92 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:56,503]\u001b[0m Trial 93 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:57,908]\u001b[0m Trial 94 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:44:59,334]\u001b[0m Trial 95 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:00,435]\u001b[0m Trial 96 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:01,797]\u001b[0m Trial 97 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:02,916]\u001b[0m Trial 98 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:04,061]\u001b[0m Trial 99 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:05,296]\u001b[0m Trial 100 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:06,719]\u001b[0m Trial 101 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:07,898]\u001b[0m Trial 102 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:08,966]\u001b[0m Trial 103 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:10,047]\u001b[0m Trial 104 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:11,087]\u001b[0m Trial 105 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:12,172]\u001b[0m Trial 106 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:13,176]\u001b[0m Trial 107 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:14,883]\u001b[0m Trial 108 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:15,936]\u001b[0m Trial 109 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:16,935]\u001b[0m Trial 110 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:17,918]\u001b[0m Trial 111 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:18,854]\u001b[0m Trial 112 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:19,837]\u001b[0m Trial 113 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:20,727]\u001b[0m Trial 114 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:21,611]\u001b[0m Trial 115 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:22,510]\u001b[0m Trial 116 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:23,756]\u001b[0m Trial 117 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:24,967]\u001b[0m Trial 118 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:26,295]\u001b[0m Trial 119 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:27,477]\u001b[0m Trial 120 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:28,611]\u001b[0m Trial 121 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:29,958]\u001b[0m Trial 122 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:31,092]\u001b[0m Trial 123 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:32,280]\u001b[0m Trial 124 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:33,353]\u001b[0m Trial 125 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:34,417]\u001b[0m Trial 126 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:35,510]\u001b[0m Trial 127 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:36,595]\u001b[0m Trial 128 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:37,706]\u001b[0m Trial 129 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:38,790]\u001b[0m Trial 130 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:40,869]\u001b[0m Trial 131 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:42,344]\u001b[0m Trial 132 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:43,813]\u001b[0m Trial 133 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:45,245]\u001b[0m Trial 134 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:46,329]\u001b[0m Trial 135 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:47,703]\u001b[0m Trial 136 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:48,767]\u001b[0m Trial 137 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:49,895]\u001b[0m Trial 138 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:51,135]\u001b[0m Trial 139 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:52,315]\u001b[0m Trial 140 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:53,499]\u001b[0m Trial 141 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:54,774]\u001b[0m Trial 142 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:56,122]\u001b[0m Trial 143 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:57,366]\u001b[0m Trial 144 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:58,496]\u001b[0m Trial 145 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:45:59,644]\u001b[0m Trial 146 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:00,715]\u001b[0m Trial 147 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:01,849]\u001b[0m Trial 148 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:02,942]\u001b[0m Trial 149 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:04,087]\u001b[0m Trial 150 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:05,169]\u001b[0m Trial 151 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:06,858]\u001b[0m Trial 152 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:07,836]\u001b[0m Trial 153 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:08,825]\u001b[0m Trial 154 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:10,124]\u001b[0m Trial 155 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:11,073]\u001b[0m Trial 156 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:12,328]\u001b[0m Trial 157 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:13,311]\u001b[0m Trial 158 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:14,374]\u001b[0m Trial 159 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:15,420]\u001b[0m Trial 160 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:16,393]\u001b[0m Trial 161 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:17,658]\u001b[0m Trial 162 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:18,531]\u001b[0m Trial 163 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:19,505]\u001b[0m Trial 164 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:20,426]\u001b[0m Trial 165 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:22,562]\u001b[0m Trial 166 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:23,496]\u001b[0m Trial 167 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:24,544]\u001b[0m Trial 168 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:25,790]\u001b[0m Trial 169 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:26,761]\u001b[0m Trial 170 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:27,879]\u001b[0m Trial 171 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:28,990]\u001b[0m Trial 172 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:30,088]\u001b[0m Trial 173 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:31,328]\u001b[0m Trial 174 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:32,443]\u001b[0m Trial 175 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:33,548]\u001b[0m Trial 176 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:35,385]\u001b[0m Trial 177 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:36,499]\u001b[0m Trial 178 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:37,733]\u001b[0m Trial 179 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:38,759]\u001b[0m Trial 180 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:40,120]\u001b[0m Trial 181 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:41,420]\u001b[0m Trial 182 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:42,770]\u001b[0m Trial 183 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:44,134]\u001b[0m Trial 184 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:45,330]\u001b[0m Trial 185 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:46,412]\u001b[0m Trial 186 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:48,064]\u001b[0m Trial 187 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:49,222]\u001b[0m Trial 188 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:50,723]\u001b[0m Trial 189 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:52,183]\u001b[0m Trial 190 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:53,733]\u001b[0m Trial 191 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:55,168]\u001b[0m Trial 192 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:56,622]\u001b[0m Trial 193 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:58,018]\u001b[0m Trial 194 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:46:59,190]\u001b[0m Trial 195 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:00,640]\u001b[0m Trial 196 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:02,745]\u001b[0m Trial 197 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:03,916]\u001b[0m Trial 198 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:05,089]\u001b[0m Trial 199 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:06,417]\u001b[0m Trial 200 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:07,593]\u001b[0m Trial 201 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:08,994]\u001b[0m Trial 202 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:10,152]\u001b[0m Trial 203 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:11,486]\u001b[0m Trial 204 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:13,387]\u001b[0m Trial 205 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:14,578]\u001b[0m Trial 206 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:15,952]\u001b[0m Trial 207 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:17,035]\u001b[0m Trial 208 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:18,252]\u001b[0m Trial 209 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:19,313]\u001b[0m Trial 210 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:20,505]\u001b[0m Trial 211 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:21,667]\u001b[0m Trial 212 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:22,786]\u001b[0m Trial 213 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:23,856]\u001b[0m Trial 214 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:25,183]\u001b[0m Trial 215 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:26,451]\u001b[0m Trial 216 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:27,483]\u001b[0m Trial 217 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:28,523]\u001b[0m Trial 218 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:30,238]\u001b[0m Trial 219 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:31,182]\u001b[0m Trial 220 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:32,107]\u001b[0m Trial 221 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:33,048]\u001b[0m Trial 222 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:34,108]\u001b[0m Trial 223 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:35,139]\u001b[0m Trial 224 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:36,278]\u001b[0m Trial 225 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:37,414]\u001b[0m Trial 226 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:38,701]\u001b[0m Trial 227 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:39,747]\u001b[0m Trial 228 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:40,774]\u001b[0m Trial 229 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:41,718]\u001b[0m Trial 230 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:42,666]\u001b[0m Trial 231 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:43,629]\u001b[0m Trial 232 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:44,604]\u001b[0m Trial 233 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:45,859]\u001b[0m Trial 234 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:47,143]\u001b[0m Trial 235 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:48,085]\u001b[0m Trial 236 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:49,079]\u001b[0m Trial 237 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:50,343]\u001b[0m Trial 238 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:51,383]\u001b[0m Trial 239 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:52,749]\u001b[0m Trial 240 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:53,794]\u001b[0m Trial 241 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:54,906]\u001b[0m Trial 242 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:55,865]\u001b[0m Trial 243 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:57,801]\u001b[0m Trial 244 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:59,055]\u001b[0m Trial 245 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:47:59,982]\u001b[0m Trial 246 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:01,063]\u001b[0m Trial 247 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:02,022]\u001b[0m Trial 248 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:02,944]\u001b[0m Trial 249 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:04,082]\u001b[0m Trial 250 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:05,459]\u001b[0m Trial 251 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:06,597]\u001b[0m Trial 252 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:07,827]\u001b[0m Trial 253 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:08,935]\u001b[0m Trial 254 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:10,081]\u001b[0m Trial 255 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:11,250]\u001b[0m Trial 256 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:12,356]\u001b[0m Trial 257 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:13,624]\u001b[0m Trial 258 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:14,711]\u001b[0m Trial 259 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:15,796]\u001b[0m Trial 260 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:16,938]\u001b[0m Trial 261 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:18,064]\u001b[0m Trial 262 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:19,150]\u001b[0m Trial 263 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:22,447]\u001b[0m Trial 264 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:23,542]\u001b[0m Trial 265 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:24,589]\u001b[0m Trial 266 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:26,373]\u001b[0m Trial 267 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:27,449]\u001b[0m Trial 268 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:28,837]\u001b[0m Trial 269 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:29,919]\u001b[0m Trial 270 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:30,974]\u001b[0m Trial 271 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:32,017]\u001b[0m Trial 272 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:33,099]\u001b[0m Trial 273 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:34,212]\u001b[0m Trial 274 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:35,328]\u001b[0m Trial 275 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:36,757]\u001b[0m Trial 276 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:38,493]\u001b[0m Trial 277 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:39,918]\u001b[0m Trial 278 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:41,500]\u001b[0m Trial 279 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.4, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:42,930]\u001b[0m Trial 280 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:44,495]\u001b[0m Trial 281 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:46,018]\u001b[0m Trial 282 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:47,581]\u001b[0m Trial 283 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:48,664]\u001b[0m Trial 284 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:50,722]\u001b[0m Trial 285 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:51,881]\u001b[0m Trial 286 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:57,853]\u001b[0m Trial 287 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:48:58,977]\u001b[0m Trial 288 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:00,367]\u001b[0m Trial 289 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:01,572]\u001b[0m Trial 290 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:03,099]\u001b[0m Trial 291 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:04,391]\u001b[0m Trial 292 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:05,695]\u001b[0m Trial 293 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:06,913]\u001b[0m Trial 294 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:08,116]\u001b[0m Trial 295 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:09,179]\u001b[0m Trial 296 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:10,511]\u001b[0m Trial 297 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:11,769]\u001b[0m Trial 298 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:12,927]\u001b[0m Trial 299 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:14,092]\u001b[0m Trial 300 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:15,418]\u001b[0m Trial 301 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:16,665]\u001b[0m Trial 302 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:17,823]\u001b[0m Trial 303 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:18,947]\u001b[0m Trial 304 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:20,093]\u001b[0m Trial 305 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:21,194]\u001b[0m Trial 306 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:23,072]\u001b[0m Trial 307 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:24,203]\u001b[0m Trial 308 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:25,358]\u001b[0m Trial 309 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.5, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:26,434]\u001b[0m Trial 310 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:27,771]\u001b[0m Trial 311 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:28,807]\u001b[0m Trial 312 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:29,889]\u001b[0m Trial 313 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:30,905]\u001b[0m Trial 314 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:31,884]\u001b[0m Trial 315 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:33,129]\u001b[0m Trial 316 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:34,246]\u001b[0m Trial 317 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:35,342]\u001b[0m Trial 318 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:36,481]\u001b[0m Trial 319 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:37,563]\u001b[0m Trial 320 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:38,917]\u001b[0m Trial 321 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:40,156]\u001b[0m Trial 322 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:41,235]\u001b[0m Trial 323 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:42,464]\u001b[0m Trial 324 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:43,562]\u001b[0m Trial 325 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:44,674]\u001b[0m Trial 326 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:45,837]\u001b[0m Trial 327 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:47,619]\u001b[0m Trial 328 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:48,849]\u001b[0m Trial 329 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:50,173]\u001b[0m Trial 330 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:51,955]\u001b[0m Trial 331 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:53,306]\u001b[0m Trial 332 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:54,482]\u001b[0m Trial 333 finished with value: 0.4444444477558136 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:55,581]\u001b[0m Trial 334 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:56,701]\u001b[0m Trial 335 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.2, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:57,692]\u001b[0m Trial 336 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:58,957]\u001b[0m Trial 337 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:49:59,949]\u001b[0m Trial 338 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:00,929]\u001b[0m Trial 339 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:01,925]\u001b[0m Trial 340 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:02,890]\u001b[0m Trial 341 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:03,900]\u001b[0m Trial 342 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:04,879]\u001b[0m Trial 343 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:05,870]\u001b[0m Trial 344 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:06,920]\u001b[0m Trial 345 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:07,945]\u001b[0m Trial 346 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:08,945]\u001b[0m Trial 347 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:10,025]\u001b[0m Trial 348 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:11,025]\u001b[0m Trial 349 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:12,018]\u001b[0m Trial 350 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:13,346]\u001b[0m Trial 351 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:14,435]\u001b[0m Trial 352 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:15,744]\u001b[0m Trial 353 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:16,727]\u001b[0m Trial 354 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:17,731]\u001b[0m Trial 355 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:19,389]\u001b[0m Trial 356 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:20,410]\u001b[0m Trial 357 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:21,502]\u001b[0m Trial 358 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-22 12:50:22,727]\u001b[0m Trial 359 finished with value: 0.4444444477558136 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.4444444477558136.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objectiveAdam3, n_trials=360)\n",
    "# n_trials = 4 x 5 x 6 x 3 = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.4444444477558136], datetime_start=datetime.datetime(2022, 5, 22, 12, 42, 55, 133312), datetime_complete=datetime.datetime(2022, 5, 22, 12, 42, 56, 420145), params={'n_layers': 4, 'n_units': 200, 'dropout': 0.30000000000000004, 'optimizer': 'Adam'}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1), 'optimizer': CategoricalDistribution(choices=('RMSprop', 'SGD', 'Adam'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos si podemos obtener mejores resultados cambiando la última capa con activación sigmoide por una activación softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "y_train_softmax = np_utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_softmax = np_utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveAdam2(trial):\n",
    "    modelFC_optuna_Adam = models.Sequential()\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5, 1)\n",
    "    num_hidden = trial.suggest_int(\"n_units\", 50, 250, 50)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 0.5, step=0.1)\n",
    "    for i in range(n_layers):\n",
    "        modelFC_optuna_Adam.add(layers.Dense(num_hidden, activation=\"relu\"))\n",
    "        modelFC_optuna_Adam.add(layers.Dropout(rate=dropout))\n",
    "    modelFC_optuna_Adam.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "#     learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1)\n",
    "    modelFC_optuna_Adam.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5)\n",
    "    modelFC_optuna_Adam.fit(X_train, y_train_softmax, callbacks=[es], epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    loss, accuracy = modelFC_optuna_Adam.evaluate(X_test, y_test_softmax)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:37:53,015]\u001b[0m A new study created in memory with name: no-name-0cb25dfd-6558-4f41-a047-12d6919f97cb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5719 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:37:54,219]\u001b[0m Trial 0 finished with value: 0.7222222089767456 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.0}. Best is trial 0 with value: 0.7222222089767456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5185 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:37:55,263]\u001b[0m Trial 1 finished with value: 0.8333333134651184 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6618 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:37:56,656]\u001b[0m Trial 2 finished with value: 0.8333333134651184 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8139 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:37:57,681]\u001b[0m Trial 3 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6548 - accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:37:58,574]\u001b[0m Trial 4 finished with value: 0.5555555820465088 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4941 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:37:59,703]\u001b[0m Trial 5 finished with value: 0.7777777910232544 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5189 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:00,445]\u001b[0m Trial 6 finished with value: 0.7222222089767456 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5714 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:01,464]\u001b[0m Trial 7 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 100, 'dropout': 0.4}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6391 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:02,259]\u001b[0m Trial 8 finished with value: 0.5 and parameters: {'n_layers': 3, 'n_units': 50, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5757 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:03,161]\u001b[0m Trial 9 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6746 - accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:04,099]\u001b[0m Trial 10 finished with value: 0.6111111044883728 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.5}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6512 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:05,164]\u001b[0m Trial 11 finished with value: 0.7222222089767456 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6150 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:06,467]\u001b[0m Trial 12 finished with value: 0.7222222089767456 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5533 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:07,859]\u001b[0m Trial 13 finished with value: 0.7222222089767456 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.4}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6500 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:08,922]\u001b[0m Trial 14 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6419 - accuracy: 0.5556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:09,931]\u001b[0m Trial 15 finished with value: 0.5555555820465088 and parameters: {'n_layers': 5, 'n_units': 150, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5221 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:11,732]\u001b[0m Trial 16 finished with value: 0.7222222089767456 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.4}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4994 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:13,098]\u001b[0m Trial 17 finished with value: 0.7222222089767456 and parameters: {'n_layers': 5, 'n_units': 200, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6787 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:14,280]\u001b[0m Trial 18 finished with value: 0.7222222089767456 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5897 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:15,586]\u001b[0m Trial 19 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.5}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6445 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:16,629]\u001b[0m Trial 20 finished with value: 0.7777777910232544 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6676 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:17,702]\u001b[0m Trial 21 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5553 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:19,028]\u001b[0m Trial 22 finished with value: 0.7222222089767456 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5750 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:20,075]\u001b[0m Trial 23 finished with value: 0.8333333134651184 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4836 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:21,211]\u001b[0m Trial 24 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6725 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:22,114]\u001b[0m Trial 25 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5187 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:23,148]\u001b[0m Trial 26 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6137 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:24,353]\u001b[0m Trial 27 finished with value: 0.6666666865348816 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5470 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:25,849]\u001b[0m Trial 28 finished with value: 0.7222222089767456 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5868 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:26,899]\u001b[0m Trial 29 finished with value: 0.6666666865348816 and parameters: {'n_layers': 4, 'n_units': 50, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6721 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:28,095]\u001b[0m Trial 30 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 250, 'dropout': 0.4}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5742 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:29,115]\u001b[0m Trial 31 finished with value: 0.7222222089767456 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4208 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:30,023]\u001b[0m Trial 32 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6773 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:31,247]\u001b[0m Trial 33 finished with value: 0.6666666865348816 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6211 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:32,275]\u001b[0m Trial 34 finished with value: 0.6666666865348816 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5905 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:33,595]\u001b[0m Trial 35 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5032 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:34,515]\u001b[0m Trial 36 finished with value: 0.7222222089767456 and parameters: {'n_layers': 2, 'n_units': 100, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6178 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:36,019]\u001b[0m Trial 37 finished with value: 0.7222222089767456 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5043 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:37,212]\u001b[0m Trial 38 finished with value: 0.7222222089767456 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6104 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:38,274]\u001b[0m Trial 39 finished with value: 0.7222222089767456 and parameters: {'n_layers': 4, 'n_units': 100, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5005 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:39,115]\u001b[0m Trial 40 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5951 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:40,380]\u001b[0m Trial 41 finished with value: 0.7777777910232544 and parameters: {'n_layers': 5, 'n_units': 100, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:41,428]\u001b[0m Trial 42 finished with value: 0.4444444477558136 and parameters: {'n_layers': 5, 'n_units': 50, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9214 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:42,801]\u001b[0m Trial 43 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5957 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:43,646]\u001b[0m Trial 44 finished with value: 0.8333333134651184 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4655 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:44,454]\u001b[0m Trial 45 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9149 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:45,401]\u001b[0m Trial 46 finished with value: 0.6666666865348816 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4911 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:46,400]\u001b[0m Trial 47 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4989 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:47,339]\u001b[0m Trial 48 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6397 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:48,306]\u001b[0m Trial 49 finished with value: 0.6666666865348816 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5312 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:49,127]\u001b[0m Trial 50 finished with value: 0.7222222089767456 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6299 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:49,946]\u001b[0m Trial 51 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4401 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:50,661]\u001b[0m Trial 52 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5253 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:51,779]\u001b[0m Trial 53 finished with value: 0.8333333134651184 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5588 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:53,030]\u001b[0m Trial 54 finished with value: 0.8333333134651184 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5322 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:53,851]\u001b[0m Trial 55 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5766 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:54,673]\u001b[0m Trial 56 finished with value: 0.7222222089767456 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4795 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:55,594]\u001b[0m Trial 57 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7237 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:56,798]\u001b[0m Trial 58 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4917 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:57,775]\u001b[0m Trial 59 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5922 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:38:58,666]\u001b[0m Trial 60 finished with value: 0.6666666865348816 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6808 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:00,474]\u001b[0m Trial 61 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4595 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:01,953]\u001b[0m Trial 62 finished with value: 0.7222222089767456 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.30000000000000004}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5179 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:03,307]\u001b[0m Trial 63 finished with value: 0.7222222089767456 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6005 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:04,496]\u001b[0m Trial 64 finished with value: 0.8333333134651184 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5046 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:05,545]\u001b[0m Trial 65 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4702 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:06,478]\u001b[0m Trial 66 finished with value: 0.7222222089767456 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5798 - accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:07,512]\u001b[0m Trial 67 finished with value: 0.6111111044883728 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.4}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7079 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:08,740]\u001b[0m Trial 68 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0704 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:10,544]\u001b[0m Trial 69 finished with value: 0.8333333134651184 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5169 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:11,446]\u001b[0m Trial 70 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5036 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:12,479]\u001b[0m Trial 71 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5773 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:13,684]\u001b[0m Trial 72 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.7185 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:14,829]\u001b[0m Trial 73 finished with value: 0.6666666865348816 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7025 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:15,824]\u001b[0m Trial 74 finished with value: 0.7222222089767456 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9806 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:16,979]\u001b[0m Trial 75 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5740 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:18,182]\u001b[0m Trial 76 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 200, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8222 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:19,486]\u001b[0m Trial 77 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1438 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:20,772]\u001b[0m Trial 78 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5197 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:21,965]\u001b[0m Trial 79 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5708 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:22,807]\u001b[0m Trial 80 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4697 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:23,746]\u001b[0m Trial 81 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7290 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:24,875]\u001b[0m Trial 82 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5256 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:26,044]\u001b[0m Trial 83 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8218 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:27,166]\u001b[0m Trial 84 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5561 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:28,020]\u001b[0m Trial 85 finished with value: 0.7222222089767456 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6271 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:29,455]\u001b[0m Trial 86 finished with value: 0.7222222089767456 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6517 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:30,589]\u001b[0m Trial 87 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5863 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:31,730]\u001b[0m Trial 88 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6969 - accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:32,767]\u001b[0m Trial 89 finished with value: 0.4444444477558136 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.5}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5816 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:33,802]\u001b[0m Trial 90 finished with value: 0.7222222089767456 and parameters: {'n_layers': 4, 'n_units': 150, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5430 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:34,853]\u001b[0m Trial 91 finished with value: 0.7222222089767456 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4902 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:35,683]\u001b[0m Trial 92 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5349 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:36,626]\u001b[0m Trial 93 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5435 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:37,739]\u001b[0m Trial 94 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5727 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:38,665]\u001b[0m Trial 95 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5213 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:39,541]\u001b[0m Trial 96 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.2}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5114 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:40,552]\u001b[0m Trial 97 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4773 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:41,578]\u001b[0m Trial 98 finished with value: 0.8333333134651184 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5169 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:42,636]\u001b[0m Trial 99 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5087 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:43,911]\u001b[0m Trial 100 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4866 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:44,759]\u001b[0m Trial 101 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6014 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:45,678]\u001b[0m Trial 102 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5147 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:46,820]\u001b[0m Trial 103 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6012 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:48,011]\u001b[0m Trial 104 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5567 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:49,300]\u001b[0m Trial 105 finished with value: 0.8333333134651184 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9147 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:50,346]\u001b[0m Trial 106 finished with value: 0.8333333134651184 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7004 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:51,522]\u001b[0m Trial 107 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 150, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9139 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:52,653]\u001b[0m Trial 108 finished with value: 0.7777777910232544 and parameters: {'n_layers': 3, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7836 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:53,607]\u001b[0m Trial 109 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6935 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:54,469]\u001b[0m Trial 110 finished with value: 0.8333333134651184 and parameters: {'n_layers': 3, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6960 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:56,426]\u001b[0m Trial 111 finished with value: 0.7777777910232544 and parameters: {'n_layers': 4, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4433 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:57,381]\u001b[0m Trial 112 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5369 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:58,199]\u001b[0m Trial 113 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5772 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:39:59,352]\u001b[0m Trial 114 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6404 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:40:00,292]\u001b[0m Trial 115 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5541 - accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:40:01,296]\u001b[0m Trial 116 finished with value: 0.7222222089767456 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:40:02,561]\u001b[0m Trial 117 finished with value: 0.7777777910232544 and parameters: {'n_layers': 2, 'n_units': 200, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4794 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:40:03,469]\u001b[0m Trial 118 finished with value: 0.8333333134651184 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.1}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5700 - accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-21 20:40:04,258]\u001b[0m Trial 119 finished with value: 0.6666666865348816 and parameters: {'n_layers': 2, 'n_units': 250, 'dropout': 0.0}. Best is trial 1 with value: 0.8333333134651184.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creamos un objeto \"study\" y buscamos la optimización de la función objetivo.\n",
    "study = optuna.create_study(direction='maximize', sampler= sampler)\n",
    "study.optimize(objectiveAdam2, n_trials=120)\n",
    "# n_trials = 4 x 5 x 6 = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=1, values=[0.8333333134651184], datetime_start=datetime.datetime(2022, 5, 21, 20, 37, 54, 220165), datetime_complete=datetime.datetime(2022, 5, 21, 20, 37, 55, 263822), params={'n_layers': 4, 'n_units': 150, 'dropout': 0.1}, distributions={'n_layers': IntUniformDistribution(high=5, low=2, step=1), 'n_units': IntUniformDistribution(high=250, low=50, step=50), 'dropout': DiscreteUniformDistribution(high=0.5, low=0.0, q=0.1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red con los parámetros optimizados es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.6795 - acc: 0.5882 - val_loss: 0.6637 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6501 - acc: 0.6078 - val_loss: 0.6491 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6010 - acc: 0.6471 - val_loss: 0.6312 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5579 - acc: 0.6863 - val_loss: 0.6098 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4996 - acc: 0.8235 - val_loss: 0.5840 - val_acc: 0.6471\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4269 - acc: 0.8627 - val_loss: 0.5587 - val_acc: 0.6471\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3470 - acc: 0.9216 - val_loss: 0.5343 - val_acc: 0.7059\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2822 - acc: 0.9608 - val_loss: 0.5059 - val_acc: 0.7059\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2003 - acc: 1.0000 - val_loss: 0.4896 - val_acc: 0.7059\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1130 - acc: 1.0000 - val_loss: 0.5001 - val_acc: 0.7059\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0650 - acc: 1.0000 - val_loss: 0.5027 - val_acc: 0.7059\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0429 - acc: 1.0000 - val_loss: 0.5239 - val_acc: 0.7647\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.6013 - val_acc: 0.7647\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.6897 - val_acc: 0.7647\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.7421 - val_acc: 0.7647\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7781 - val_acc: 0.7647\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8005 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9614 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Adam = models.Sequential()\n",
    "modelFC_optuna_Adam.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_Adam.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_Adam.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_Adam.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.1))\n",
    "modelFC_optuna_Adam.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0955)\n",
    "# modelFC_optuna_Adam.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "modelFC_optuna_Adam.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "modelFC_optuna_Adam.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Adam.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un mayor accuracy utilizando la activación softmax. Sin embargo, parece que ahora la red tiene un problema de sobreajuste, ya que por ejemplo en la última época hay una diferencia entre la precisión en train y en validación del 17% aproximadamente. Vamos a tratar de reducir esta diferencia probando distintos tipos de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizers = [\"l1\", \"l2\", \"l1_l2\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9214 - acc: 0.7222\n",
      "Accuracy : 72.22% ----- Regularización: l1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7063 - acc: 0.7778\n",
      "Accuracy : 77.78% ----- Regularización: l2\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9461 - acc: 0.7778\n",
      "Accuracy : 77.78% ----- Regularización: l1_l2\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3579 - acc: 0.8333\n",
      "Accuracy : 83.33% ----- Regularización: None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "for regularizer in regularizers:\n",
    "    modelFC_optuna_Adam = models.Sequential()\n",
    "    modelFC_optuna_Adam.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "    modelFC_optuna_Adam.add(layers.Dropout(0.1))\n",
    "    modelFC_optuna_Adam.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "    modelFC_optuna_Adam.add(layers.Dropout(0.1))\n",
    "    modelFC_optuna_Adam.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "    modelFC_optuna_Adam.add(layers.Dropout(0.1))\n",
    "    modelFC_optuna_Adam.add(layers.Dense(150, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "    modelFC_optuna_Adam.add(layers.Dropout(0.1))\n",
    "    modelFC_optuna_Adam.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "    modelFC_optuna_Adam.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "#     es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "    modelFC_optuna_Adam.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy = modelFC_optuna_Adam.evaluate(X_test, y_test_softmax)\n",
    "    print(\"Accuracy : {:0.2f}% ----- Regularización: {}\".format(accuracy * 100, regularizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{COMO PUEDE SER QUE CON NONE + CALLBACK NO SE ALCANCE AL VALOR ANTERIOR??}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener en cuenta los datos con peores resultados en el backpropagation (mayor peso de esos datos) -> cambiar el loss (sample_weight)\n",
    "\n",
    "IDEA: the idea of penalizing more where you don't perform well made me think of something that is called \"AdaBoost\"\n",
    "\n",
    "Fuente: https://stackoverflow.com/questions/48720197/weight-samples-if-incorrect-guessed-in-binary-cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, tp_weight=0.2, tn_weight=0.2, fp_weight=1.2, fn_weight=1.2):\n",
    "    # Get predictions\n",
    "    y_pred_classes = tf.keras.backend.greater_equal(y_pred, 0.5)\n",
    "    y_pred_classes_float = tf.keras.backend.cast(y_pred_classes, tf.keras.backend.floatx())\n",
    "    y_true_float = tf.keras.backend.cast(y_true, tf.keras.backend.floatx())\n",
    "    tf.keras.backend.print_tensor(y_pred_classes)\n",
    "\n",
    "    # Get misclassified examples\n",
    "    wrongly_classified = tf.keras.backend.not_equal(y_true_float, y_pred_classes_float)\n",
    "    wrongly_classified_float = tf.keras.backend.cast(wrongly_classified, tf.keras.backend.floatx())\n",
    "\n",
    "    # Get correctly classified examples\n",
    "    correctly_classified = tf.keras.backend.equal(y_true_float, y_pred_classes_float)\n",
    "    correctly_classified_float = tf.keras.backend.cast(wrongly_classified, tf.keras.backend.floatx())\n",
    "\n",
    "    # Get tp, fp, tn, fn\n",
    "    tp = correctly_classified_float * y_true_float\n",
    "    tn = correctly_classified_float * (1 - y_true_float)\n",
    "    fp = wrongly_classified_float * y_true_float\n",
    "    fn = wrongly_classified_float * (1 - y_true_float)\n",
    "\n",
    "    # Get weights\n",
    "    weight_tensor = tp_weight * tp + fp_weight * fp + tn_weight * tn + fn_weight * fn\n",
    "\n",
    "    loss = tf.keras.metrics.binary_crossentropy(y_true, y_pred)\n",
    "    weighted_loss = loss * weight_tensor\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[0]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1522 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_optuna_Adam = models.Sequential()\n",
    "modelFC_optuna_Adam.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_Adam.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_Adam.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_Adam.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC_optuna_Adam.add(layers.Dropout(0.3))\n",
    "modelFC_optuna_Adam.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC_optuna_Adam.compile(loss=custom_loss, optimizer=\"adam\", metrics=[\"acc\"])\n",
    "# es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "# modelFC_optuna_Adam.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "modelFC_optuna_Adam.fit(X_train, y_train, epochs=100, validation_split=0.25, verbose=0)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC_optuna_Adam.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque algunas configuraciones de hiperparámetros con ``keras`` + ``optuna`` dan lugar a resultados con mejores precisiones (por ejemplo 88.89%) que los resultados obtenidos haciendo la búsqueda con ``sklearn`` (83.33%), se ha observado que los modelos optimizados con la primera librería tienen unos resultados muy sensibles a las re-ejecuciones del código. Por tanto, ya que ``keras`` es una librería más flexible y con más opciones de configuración de la red neuronal, el siguiente apartado se centrará en una búsqueda manual de los hiperparámetros, partiendo de la topología de red \"óptima\" de acuerdo a ``GridSearchCV`` de ``sklearn`` y tomando como base para la búsqueda los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.7133 - acc: 0.4386 - val_loss: 0.6592 - val_acc: 0.8182\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5821 - acc: 0.7544 - val_loss: 0.6682 - val_acc: 0.7273\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4990 - acc: 0.7895 - val_loss: 0.6715 - val_acc: 0.7273\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3992 - acc: 0.9474 - val_loss: 0.6420 - val_acc: 0.8182\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2997 - acc: 1.0000 - val_loss: 0.6326 - val_acc: 0.8182\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2025 - acc: 1.0000 - val_loss: 0.6740 - val_acc: 0.8182\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4795 - acc: 0.7778\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(100, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(50, activation=\"relu\"))\n",
    "modelFC.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC.fit(X_train, y_train, epochs=100, validation_split=0.15, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red tiene un claro sobreajuste a los datos de train, vamos a tratar de imponer restricciones de regularización para reducir la diferencia de accuracy con el resto de conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 34.8134 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Regularización: l1 - Tasa de Dropout: 0.1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.7224 - acc: 0.8333\n",
      "Accuracy : 83.33% ----- Regularización: l2 - Tasa de Dropout: 0.1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.7515 - acc: 0.6667\n",
      "Accuracy : 66.67% ----- Regularización: l1_l2 - Tasa de Dropout: 0.1\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5843 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Regularización: None - Tasa de Dropout: 0.1\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 36.0505 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Regularización: l1 - Tasa de Dropout: 0.2\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.1796 - acc: 0.8333\n",
      "Accuracy : 83.33% ----- Regularización: l2 - Tasa de Dropout: 0.2\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 40.1670 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l1_l2 - Tasa de Dropout: 0.2\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5940 - acc: 0.6667\n",
      "Accuracy : 66.67% ----- Regularización: None - Tasa de Dropout: 0.2\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 37.1209 - acc: 0.5556\n",
      "Accuracy : 55.56% ----- Regularización: l1 - Tasa de Dropout: 0.30000000000000004\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7861 - acc: 0.7778\n",
      "Accuracy : 77.78% ----- Regularización: l2 - Tasa de Dropout: 0.30000000000000004\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 37.7582 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1_l2 - Tasa de Dropout: 0.30000000000000004\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6193 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Regularización: None - Tasa de Dropout: 0.30000000000000004\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 34.3442 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l1 - Tasa de Dropout: 0.4\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2118 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l2 - Tasa de Dropout: 0.4\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 39.3175 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l1_l2 - Tasa de Dropout: 0.4\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6496 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Regularización: None - Tasa de Dropout: 0.4\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 36.2640 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1 - Tasa de Dropout: 0.5\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3071 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l2 - Tasa de Dropout: 0.5\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 33.8429 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1_l2 - Tasa de Dropout: 0.5\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6542 - acc: 0.5556\n",
      "Accuracy : 55.56% ----- Regularización: None - Tasa de Dropout: 0.5\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 37.3366 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1 - Tasa de Dropout: 0.6\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.1521 - acc: 0.7222\n",
      "Accuracy : 72.22% ----- Regularización: l2 - Tasa de Dropout: 0.6\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 39.3930 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1_l2 - Tasa de Dropout: 0.6\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6976 - acc: 0.3889\n",
      "Accuracy : 38.89% ----- Regularización: None - Tasa de Dropout: 0.6\n"
     ]
    }
   ],
   "source": [
    "dropout_rates = np.arange(0.1, 0.7, 0.1)\n",
    "\n",
    "for rate in dropout_rates:\n",
    "    for regularizer in regularizers:\n",
    "        modelFC = models.Sequential()\n",
    "        modelFC.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "        modelFC.add(layers.Dropout(rate))\n",
    "        modelFC.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "        modelFC.add(layers.Dropout(rate))\n",
    "        modelFC.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "        modelFC.add(layers.Dropout(rate))\n",
    "        modelFC.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "        modelFC.add(layers.Dropout(rate))\n",
    "        modelFC.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "        es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "        modelFC.fit(X_train, y_train, epochs=100, validation_split=0.15, callbacks=[es], verbose=0)\n",
    "\n",
    "        # Precisión en partición de test\n",
    "        loss, accuracy = modelFC.evaluate(X_test, y_test)\n",
    "        print(\"Accuracy : {:0.2f}% ----- Regularización: {} - Tasa de Dropout: {}\".format(accuracy * 100, regularizer, rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También anteriormente se comprobó que colocar una función de activación softmax en la última capa podía dar lugar a mayor precisión. Repetimos el código anterior con este cambio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 36.9820 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1 - Tasa de Dropout: 0.1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.8618 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Regularización: l2 - Tasa de Dropout: 0.1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 40.1163 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1_l2 - Tasa de Dropout: 0.1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4722 - acc: 0.7778\n",
      "Accuracy : 77.78% ----- Regularización: None - Tasa de Dropout: 0.1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 35.7505 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1 - Tasa de Dropout: 0.2\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8960 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l2 - Tasa de Dropout: 0.2\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 38.9039 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l1_l2 - Tasa de Dropout: 0.2\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6884 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: None - Tasa de Dropout: 0.2\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 36.9158 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1 - Tasa de Dropout: 0.30000000000000004\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9228 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l2 - Tasa de Dropout: 0.30000000000000004\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 40.0000 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l1_l2 - Tasa de Dropout: 0.30000000000000004\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6722 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: None - Tasa de Dropout: 0.30000000000000004\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 31.8328 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Regularización: l1 - Tasa de Dropout: 0.4\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1288 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l2 - Tasa de Dropout: 0.4\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 40.2036 - acc: 0.5556\n",
      "Accuracy : 55.56% ----- Regularización: l1_l2 - Tasa de Dropout: 0.4\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6722 - acc: 0.6667\n",
      "Accuracy : 66.67% ----- Regularización: None - Tasa de Dropout: 0.4\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 34.2336 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1 - Tasa de Dropout: 0.5\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.1026 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l2 - Tasa de Dropout: 0.5\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.7624 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l1_l2 - Tasa de Dropout: 0.5\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6859 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: None - Tasa de Dropout: 0.5\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 29.9302 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: l1 - Tasa de Dropout: 0.6\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.2779 - acc: 0.5000\n",
      "Accuracy : 50.00% ----- Regularización: l2 - Tasa de Dropout: 0.6\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 36.4886 - acc: 0.5556\n",
      "Accuracy : 55.56% ----- Regularización: l1_l2 - Tasa de Dropout: 0.6\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6827 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Regularización: None - Tasa de Dropout: 0.6\n"
     ]
    }
   ],
   "source": [
    "for rate in dropout_rates:\n",
    "    for regularizer in regularizers:\n",
    "        modelFC = models.Sequential()\n",
    "        modelFC.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "        modelFC.add(layers.Dropout(rate))\n",
    "        modelFC.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "        modelFC.add(layers.Dropout(rate))\n",
    "        modelFC.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "        modelFC.add(layers.Dropout(rate))\n",
    "        modelFC.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "        modelFC.add(layers.Dropout(rate))\n",
    "        modelFC.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "        modelFC.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "        es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "        modelFC.fit(X_train, y_train_softmax, epochs=100, validation_split=0.15, callbacks=[es], verbose=0)\n",
    "\n",
    "        # Precisión en partición de test\n",
    "        loss, accuracy = modelFC.evaluate(X_test, y_test_softmax)\n",
    "        print(\"Accuracy : {:0.2f}% ----- Regularización: {} - Tasa de Dropout: {}\".format(accuracy * 100, regularizer, rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso obtenemos mejores resultados con la capa final con función sigmoide. Que tiene varias configuraciones que alcanzan un accuracy del 83.33% (coincide con lo obtenido con ``GridSearchCV``).\n",
    "\n",
    "Con ``sklearn`` pudimos buscar la función de optimización más adecuada (Adam), pero no sus parámetros, por lo que ahora trataremos de optimizar el ``learning_rate``. Tomaremos del código anterior el modelo con regularización L2 y una tasa de Dropout = 0.2, ya que son de los valores que mejor precisión alcanzan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 4.7039 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Optimizador Adam con learning rate = 1e-07\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.7067 - acc: 0.2778\n",
      "Accuracy : 27.78% ----- Optimizador Adam con learning rate = 1e-06\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7042 - acc: 0.4444\n",
      "Accuracy : 44.44% ----- Optimizador Adam con learning rate = 1e-05\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5796 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Optimizador Adam con learning rate = 0.0001\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0018 - acc: 0.6111\n",
      "Accuracy : 61.11% ----- Optimizador Adam con learning rate = 0.001\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3671 - acc: 0.8333\n",
      "Accuracy : 83.33% ----- Optimizador Adam con learning rate = 0.01\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 39.3935 - acc: 0.7778\n",
      "Accuracy : 77.78% ----- Optimizador Adam con learning rate = 0.1\n"
     ]
    }
   ],
   "source": [
    "lr_range = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "for rate in lr_range:\n",
    "    modelFC = models.Sequential()\n",
    "    modelFC.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "    modelFC.add(layers.Dropout(0.2))\n",
    "    modelFC.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "    modelFC.add(layers.Dropout(0.2))\n",
    "    modelFC.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "    modelFC.add(layers.Dropout(0.2))\n",
    "    modelFC.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "    modelFC.add(layers.Dropout(0.2))\n",
    "    modelFC.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=rate)\n",
    "    modelFC.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "    es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "    modelFC.fit(X_train, y_train, epochs=100, validation_split=0.15, callbacks=[es], verbose=0)\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy = modelFC.evaluate(X_test, y_test)\n",
    "    print(\"Accuracy : {:0.2f}% ----- Optimizador Adam con learning rate = {}\".format(accuracy * 100, rate))\n",
    "    \n",
    "# También muy sensible a los cambios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a imprimir por pantalla el proceso de entrenamiento de este modelo optimizado a mano para ver los resultados obtenidos y si se produce o no aún sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 4.5205 - acc: 0.5088 - val_loss: 3.5769 - val_acc: 0.7273\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.4350 - acc: 0.5614 - val_loss: 2.7237 - val_acc: 0.6364\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.5351 - acc: 0.6667 - val_loss: 2.1652 - val_acc: 0.6364\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.8166 - acc: 0.8596 - val_loss: 1.6541 - val_acc: 0.7273\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2467 - acc: 0.9474 - val_loss: 1.7561 - val_acc: 0.7273\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9572 - acc: 0.9825 - val_loss: 1.4963 - val_acc: 0.6364\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2947 - acc: 0.8889\n",
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "modelFC = models.Sequential()\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC.add(layers.Dropout(0.2))\n",
    "modelFC.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "modelFC.add(layers.Dropout(0.2))\n",
    "modelFC.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "modelFC.add(layers.Dropout(0.2))\n",
    "modelFC.add(layers.Dense(50, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "modelFC.add(layers.Dropout(0.2))\n",
    "modelFC.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "modelFC.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC.fit(X_train, y_train, epochs=100, validation_split=0.15, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{Sigue teniendo mucho sobreajuste}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda manual para la optimización de los hiperparámetros (antiguo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 0.7385 - acc: 0.4902 - val_loss: 0.6319 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5424 - acc: 0.7647 - val_loss: 0.6307 - val_acc: 0.7647\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4023 - acc: 0.9608 - val_loss: 0.6773 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2890 - acc: 0.9216 - val_loss: 0.7575 - val_acc: 0.4706\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2222 - acc: 0.9804 - val_loss: 0.6835 - val_acc: 0.7647\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1623 - acc: 0.9804 - val_loss: 0.6624 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0969 - acc: 1.0000 - val_loss: 0.6794 - val_acc: 0.7647\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0593 - acc: 1.0000 - val_loss: 0.6473 - val_acc: 0.5882\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.6626 - val_acc: 0.5882\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.7044 - val_acc: 0.7647\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.6991 - val_acc: 0.5882\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.7001 - val_acc: 0.5882\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7597 - val_acc: 0.7059\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.7680 - val_acc: 0.6471\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.7721 - val_acc: 0.5882\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.7980 - val_acc: 0.6471\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.7996 - val_acc: 0.6471\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8102 - val_acc: 0.6471\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.8428 - val_acc: 0.6471\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8624 - val_acc: 0.6471\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8659 - val_acc: 0.6471\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8721 - val_acc: 0.6471\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8890 - val_acc: 0.6471\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8913 - val_acc: 0.6471\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 8.4907e-04 - acc: 1.0000 - val_loss: 0.9005 - val_acc: 0.6471\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 7.2130e-04 - acc: 1.0000 - val_loss: 0.9100 - val_acc: 0.6471\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 6.0643e-04 - acc: 1.0000 - val_loss: 0.9237 - val_acc: 0.6471\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 5.1872e-04 - acc: 1.0000 - val_loss: 0.9388 - val_acc: 0.6471\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 4.5549e-04 - acc: 1.0000 - val_loss: 0.9444 - val_acc: 0.6471\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.8667e-04 - acc: 1.0000 - val_loss: 0.9761 - val_acc: 0.7059\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.3493e-04 - acc: 1.0000 - val_loss: 0.9917 - val_acc: 0.7059\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.8748e-04 - acc: 1.0000 - val_loss: 1.0011 - val_acc: 0.7059\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 2.4611e-04 - acc: 1.0000 - val_loss: 1.0029 - val_acc: 0.6471\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.1196e-04 - acc: 1.0000 - val_loss: 1.0221 - val_acc: 0.7059\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.8535e-04 - acc: 1.0000 - val_loss: 1.0179 - val_acc: 0.6471\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.5977e-04 - acc: 1.0000 - val_loss: 1.0492 - val_acc: 0.7059\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3829e-04 - acc: 1.0000 - val_loss: 1.0404 - val_acc: 0.7059\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2026e-04 - acc: 1.0000 - val_loss: 1.0508 - val_acc: 0.7059\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0245e-04 - acc: 1.0000 - val_loss: 1.0783 - val_acc: 0.7059\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.8637e-05 - acc: 1.0000 - val_loss: 1.0887 - val_acc: 0.7059\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 7.7065e-05 - acc: 1.0000 - val_loss: 1.1089 - val_acc: 0.7059\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.7470e-05 - acc: 1.0000 - val_loss: 1.1118 - val_acc: 0.7059\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 5.8869e-05 - acc: 1.0000 - val_loss: 1.1201 - val_acc: 0.7059\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 5.1157e-05 - acc: 1.0000 - val_loss: 1.1476 - val_acc: 0.7059\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.4653e-05 - acc: 1.0000 - val_loss: 1.1461 - val_acc: 0.7059\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.8861e-05 - acc: 1.0000 - val_loss: 1.1675 - val_acc: 0.7059\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.4336e-05 - acc: 1.0000 - val_loss: 1.1911 - val_acc: 0.7059\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.0029e-05 - acc: 1.0000 - val_loss: 1.2000 - val_acc: 0.7059\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.6072e-05 - acc: 1.0000 - val_loss: 1.2064 - val_acc: 0.7059\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2637e-05 - acc: 1.0000 - val_loss: 1.2197 - val_acc: 0.7059\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.9848e-05 - acc: 1.0000 - val_loss: 1.2279 - val_acc: 0.7059\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7491e-05 - acc: 1.0000 - val_loss: 1.2363 - val_acc: 0.7059\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5319e-05 - acc: 1.0000 - val_loss: 1.2560 - val_acc: 0.7059\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.3488e-05 - acc: 1.0000 - val_loss: 1.2643 - val_acc: 0.7059\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1938e-05 - acc: 1.0000 - val_loss: 1.2838 - val_acc: 0.7059\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0474e-05 - acc: 1.0000 - val_loss: 1.2916 - val_acc: 0.7059\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 9.1590e-06 - acc: 1.0000 - val_loss: 1.2953 - val_acc: 0.7059\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 8.0522e-06 - acc: 1.0000 - val_loss: 1.3121 - val_acc: 0.7059\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 7.0674e-06 - acc: 1.0000 - val_loss: 1.3230 - val_acc: 0.7059\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 6.2223e-06 - acc: 1.0000 - val_loss: 1.3275 - val_acc: 0.7059\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 5.4705e-06 - acc: 1.0000 - val_loss: 1.3421 - val_acc: 0.7059\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.8478e-06 - acc: 1.0000 - val_loss: 1.3556 - val_acc: 0.7059\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.2967e-06 - acc: 1.0000 - val_loss: 1.3513 - val_acc: 0.7059\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.8003e-06 - acc: 1.0000 - val_loss: 1.3628 - val_acc: 0.7059\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.3931e-06 - acc: 1.0000 - val_loss: 1.3998 - val_acc: 0.7059\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.9816e-06 - acc: 1.0000 - val_loss: 1.4028 - val_acc: 0.7059\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.6109e-06 - acc: 1.0000 - val_loss: 1.4073 - val_acc: 0.7059\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3133e-06 - acc: 1.0000 - val_loss: 1.4085 - val_acc: 0.7059\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0721e-06 - acc: 1.0000 - val_loss: 1.4404 - val_acc: 0.7059\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.8185e-06 - acc: 1.0000 - val_loss: 1.4367 - val_acc: 0.7059\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6009e-06 - acc: 1.0000 - val_loss: 1.4461 - val_acc: 0.7059\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4234e-06 - acc: 1.0000 - val_loss: 1.4616 - val_acc: 0.7059\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2720e-06 - acc: 1.0000 - val_loss: 1.4731 - val_acc: 0.7059\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1292e-06 - acc: 1.0000 - val_loss: 1.4834 - val_acc: 0.7059\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0037e-06 - acc: 1.0000 - val_loss: 1.4787 - val_acc: 0.7059\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 8.9372e-07 - acc: 1.0000 - val_loss: 1.5028 - val_acc: 0.7059\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 8.0330e-07 - acc: 1.0000 - val_loss: 1.5190 - val_acc: 0.7059\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 7.1232e-07 - acc: 1.0000 - val_loss: 1.5188 - val_acc: 0.7059\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 6.3562e-07 - acc: 1.0000 - val_loss: 1.5348 - val_acc: 0.7059\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.6678e-07 - acc: 1.0000 - val_loss: 1.5391 - val_acc: 0.7059\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.0735e-07 - acc: 1.0000 - val_loss: 1.5408 - val_acc: 0.7059\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 4.5283e-07 - acc: 1.0000 - val_loss: 1.5435 - val_acc: 0.7059\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.0738e-07 - acc: 1.0000 - val_loss: 1.5744 - val_acc: 0.7059\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.6801e-07 - acc: 1.0000 - val_loss: 1.5888 - val_acc: 0.7059\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.2810e-07 - acc: 1.0000 - val_loss: 1.5920 - val_acc: 0.7059\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.9483e-07 - acc: 1.0000 - val_loss: 1.5957 - val_acc: 0.7059\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.6540e-07 - acc: 1.0000 - val_loss: 1.5948 - val_acc: 0.7059\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.3774e-07 - acc: 1.0000 - val_loss: 1.6082 - val_acc: 0.7059\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1640e-07 - acc: 1.0000 - val_loss: 1.6287 - val_acc: 0.7059\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.9498e-07 - acc: 1.0000 - val_loss: 1.6306 - val_acc: 0.7059\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7612e-07 - acc: 1.0000 - val_loss: 1.6412 - val_acc: 0.7059\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5982e-07 - acc: 1.0000 - val_loss: 1.6474 - val_acc: 0.7059\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.4439e-07 - acc: 1.0000 - val_loss: 1.6510 - val_acc: 0.7059\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3190e-07 - acc: 1.0000 - val_loss: 1.6539 - val_acc: 0.7059\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2037e-07 - acc: 1.0000 - val_loss: 1.6761 - val_acc: 0.7059\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1012e-07 - acc: 1.0000 - val_loss: 1.6770 - val_acc: 0.7059\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0115e-07 - acc: 1.0000 - val_loss: 1.6727 - val_acc: 0.7059\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 9.2545e-08 - acc: 1.0000 - val_loss: 1.6838 - val_acc: 0.7059\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.4531e-08 - acc: 1.0000 - val_loss: 1.6932 - val_acc: 0.7059\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 7.7768e-08 - acc: 1.0000 - val_loss: 1.7052 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2297 - acc: 0.7778\n",
      "Accuracy: 77.78%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelFC1 = models.Sequential()\n",
    "modelFC1.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC1.add(layers.Dense(200, activation=\"relu\"))\n",
    "modelFC1.add(layers.Dense(100, activation=\"relu\"))\n",
    "modelFC1.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC1.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "modelFC1.fit(X_train, y_train, epochs=100, validation_split=0.25)\n",
    "# Se utilizan 100 épocas ya que como se irá viendo, incluso con estas épocas la red sobreajusta.\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC1.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Predicción en test para kaggle\n",
    "y_pred_kaggle_FC1 = modelFC1.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras probar una configuración cualquiera en el bloque anterior, vemos que tenemos un gran problema de sobreajuste (100% en el conjunto de train y diferencia de un 30% aproximadamente con la precisión en el conjunto de validación). Vamos a introducir unos términos de regularización para evitar esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 176ms/step - loss: 2.0341 - acc: 0.5098 - val_loss: 1.9356 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8778 - acc: 0.6275 - val_loss: 1.8620 - val_acc: 0.7647\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8085 - acc: 0.6471 - val_loss: 1.8049 - val_acc: 0.6471\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7317 - acc: 0.6667 - val_loss: 1.7663 - val_acc: 0.6471\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.6955 - acc: 0.6863 - val_loss: 1.7382 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5640 - acc: 0.8431 - val_loss: 1.7126 - val_acc: 0.5882\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5509 - acc: 0.8235 - val_loss: 1.6727 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5890 - acc: 0.6667\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelFC2 = models.Sequential()\n",
    "modelFC2.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC2.add(layers.Dropout(0.5))\n",
    "modelFC2.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "modelFC2.add(layers.Dropout(0.5))\n",
    "modelFC2.add(layers.Dense(100, activation=\"relu\"))\n",
    "modelFC2.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "modelFC2.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "# Detenemos el entrenamiento si hay más de 5 épocas en las que no hay una ganancia en el conjunto de validación del 1%\n",
    "modelFC2.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC2.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, sobre la red anterior, buscaremos el ajuste de los parámetros.\n",
    "\n",
    "Al compilar el modelo, la función de pérdida (``binary_crossentropy``) es la adecuada porque estamos en un problema de clasificación binaria e igualmente para la métrica (``acc``), pero podemos probar varias opciones para el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Entrenando para el optimizador: adadelta -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.0219 - acc: 0.5556\n",
      "----- Entrenando para el optimizador: adagrad -----\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0501 - acc: 0.3889\n",
      "----- Entrenando para el optimizador: adam -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6028 - acc: 0.5556\n",
      "----- Entrenando para el optimizador: adamax -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8739 - acc: 0.4444\n",
      "----- Entrenando para el optimizador: rmsprop -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4074 - acc: 0.7778\n",
      "----- Entrenando para el optimizador: sgd -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9864 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'adadelta': 0.5555555820465088,\n",
       " 'adagrad': 0.3888888955116272,\n",
       " 'adam': 0.5555555820465088,\n",
       " 'adamax': 0.4444444477558136,\n",
       " 'rmsprop': 0.7777777910232544,\n",
       " 'sgd': 0.5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST OPTIMIZER FUNCTION\n",
    "optimizers_range = [\"adadelta\", \"adagrad\", \"adam\", \"adamax\", \"rmsprop\", \"sgd\"]\n",
    "acc = {}\n",
    "\n",
    "for optimizer in optimizers_range:\n",
    "    print(f\"----- Entrenando para el optimizador: {optimizer} -----\")\n",
    "    # Definir y entrenar el modelo\n",
    "    modelFC2 = models.Sequential()\n",
    "    modelFC2.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "    modelFC2.add(layers.Dropout(0.5))\n",
    "    modelFC2.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "    modelFC2.add(layers.Dropout(0.5))\n",
    "    modelFC2.add(layers.Dense(100, activation=\"relu\"))\n",
    "    modelFC2.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    modelFC2.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "    es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "    modelFC2.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es], verbose=0)\n",
    "    # verbose=0 oculta el informe del proceso en cada época\n",
    "\n",
    "    # Precisión en partición de test\n",
    "    loss, accuracy = modelFC2.evaluate(X_test, y_test)\n",
    "    acc[optimizer] = accuracy\n",
    "    \n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vista de que el mayor accuracy se tiene para el optimizador ``RMSprop``, vamos a optimizar los parámetros del mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Entrenando el optimizador RMSprop con un lr=0.0001 y un momentum=0 -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0338 - acc: 0.3889\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.0001 y un momentum=0.001 -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9832 - acc: 0.3889\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.0001 y un momentum=0.1 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9626 - acc: 0.4444\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.001 y un momentum=0 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5417 - acc: 0.6111\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.001 y un momentum=0.001 -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5551 - acc: 0.7222\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.001 y un momentum=0.1 -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4580 - acc: 0.7222\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.01 y un momentum=0 -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7889 - acc: 0.7778\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.01 y un momentum=0.001 -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9195 - acc: 0.7778\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.01 y un momentum=0.1 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9762 - acc: 0.7778\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.05 y un momentum=0 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.4201 - acc: 0.7778\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.05 y un momentum=0.001 -----\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3279 - acc: 0.4444\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.05 y un momentum=0.1 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.9976 - acc: 0.6667\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.1 y un momentum=0 -----\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 15.5016 - acc: 0.5556\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.1 y un momentum=0.001 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 10.6634 - acc: 0.6111\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.1 y un momentum=0.1 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 9.5124 - acc: 0.5000\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.5 y un momentum=0 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3122.3616 - acc: 0.5556\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.5 y un momentum=0.001 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5618.5869 - acc: 0.7222\n",
      "----- Entrenando el optimizador RMSprop con un lr=0.5 y un momentum=0.1 -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3086.8550 - acc: 0.3333\n",
      "Valor óptimo de los hiperparámetros: lr=0.01; momentum=0\n",
      "Se logra un accuracy de 77.78%\n"
     ]
    }
   ],
   "source": [
    "# BEST RMSPROP HYPERPARAMETERS\n",
    "lr_range = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5]\n",
    "moment_range = [0, 0.001, 0.1]\n",
    "acc = 0\n",
    "\n",
    "for lr in lr_range:\n",
    "    for moment in moment_range:\n",
    "        print(f\"----- Entrenando el optimizador RMSprop con un lr={lr} y un momentum={moment} -----\")\n",
    "        # Definir y entrenar el modelo\n",
    "        modelFC2 = models.Sequential()\n",
    "        modelFC2.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "        modelFC2.add(layers.Dropout(0.5))\n",
    "        modelFC2.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "        modelFC2.add(layers.Dropout(0.5))\n",
    "        modelFC2.add(layers.Dense(100, activation=\"relu\"))\n",
    "        modelFC2.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr, momentum=moment)\n",
    "        modelFC2.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "        es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "        modelFC2.fit(X_train, y_train, epochs=100, validation_split=0.25, callbacks=[es], verbose=0)\n",
    "\n",
    "        # Precisión en partición de test\n",
    "        loss, accuracy = modelFC2.evaluate(X_test, y_test)\n",
    "        if accuracy > acc:\n",
    "            best_lr = lr\n",
    "            best_momentum = moment\n",
    "            acc = accuracy\n",
    "    \n",
    "print(f\"Valor óptimo de los hiperparámetros: lr={best_lr}; momentum={best_momentum}\")\n",
    "print(\"Se logra un accuracy de {:0.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ajustar algunos parámetros de la función ``fit``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Entrenando el modelo con un tamaño de batch de 5         y un porcentaje de datos de validación de 15.0% -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7452 - acc: 0.6667\n",
      "----- Entrenando el modelo con un tamaño de batch de 5         y un porcentaje de datos de validación de 20.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1207 - acc: 0.6111\n",
      "----- Entrenando el modelo con un tamaño de batch de 5         y un porcentaje de datos de validación de 25.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8624 - acc: 0.8333\n",
      "----- Entrenando el modelo con un tamaño de batch de 5         y un porcentaje de datos de validación de 30.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6088 - acc: 0.7778\n",
      "----- Entrenando el modelo con un tamaño de batch de 5         y un porcentaje de datos de validación de 40.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6625 - acc: 0.6111\n",
      "----- Entrenando el modelo con un tamaño de batch de 10         y un porcentaje de datos de validación de 15.0% -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9655 - acc: 0.7222\n",
      "----- Entrenando el modelo con un tamaño de batch de 10         y un porcentaje de datos de validación de 20.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8606 - acc: 0.7778\n",
      "----- Entrenando el modelo con un tamaño de batch de 10         y un porcentaje de datos de validación de 25.0% -----\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1894 - acc: 0.7778\n",
      "----- Entrenando el modelo con un tamaño de batch de 10         y un porcentaje de datos de validación de 30.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9865 - acc: 0.7222\n",
      "----- Entrenando el modelo con un tamaño de batch de 10         y un porcentaje de datos de validación de 40.0% -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6853 - acc: 0.6667\n",
      "----- Entrenando el modelo con un tamaño de batch de 15         y un porcentaje de datos de validación de 15.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9858 - acc: 0.7778\n",
      "----- Entrenando el modelo con un tamaño de batch de 15         y un porcentaje de datos de validación de 20.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2781 - acc: 0.6667\n",
      "----- Entrenando el modelo con un tamaño de batch de 15         y un porcentaje de datos de validación de 25.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1886 - acc: 0.7222\n",
      "----- Entrenando el modelo con un tamaño de batch de 15         y un porcentaje de datos de validación de 30.0% -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1143 - acc: 0.7778\n",
      "----- Entrenando el modelo con un tamaño de batch de 15         y un porcentaje de datos de validación de 40.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4090 - acc: 0.7778\n",
      "----- Entrenando el modelo con un tamaño de batch de 20         y un porcentaje de datos de validación de 15.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7491 - acc: 0.8333\n",
      "----- Entrenando el modelo con un tamaño de batch de 20         y un porcentaje de datos de validación de 20.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9694 - acc: 0.6667\n",
      "----- Entrenando el modelo con un tamaño de batch de 20         y un porcentaje de datos de validación de 25.0% -----\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8543 - acc: 0.7778\n",
      "----- Entrenando el modelo con un tamaño de batch de 20         y un porcentaje de datos de validación de 30.0% -----\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9343 - acc: 0.7222\n",
      "----- Entrenando el modelo con un tamaño de batch de 20         y un porcentaje de datos de validación de 40.0% -----\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6672 - acc: 0.6111\n",
      "Valor óptimo de los hiperparámetros: batch_size=5; validation_split=0.25\n",
      "Se logra un accuracy de 83.33%\n"
     ]
    }
   ],
   "source": [
    "# BEST FIT FUNCTION HYPERPARAMETERS\n",
    "batch_size_range = [5, 10, 15, 20] # Al hacer la partición de test, nos quedan 68 entradas de datos\n",
    "val_split_range = [0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "acc = 0\n",
    "\n",
    "for batch_size in batch_size_range:\n",
    "    for val_split in val_split_range:\n",
    "        print(f\"----- Entrenando el modelo con un tamaño de batch de {batch_size} \\\n",
    "        y un porcentaje de datos de validación de {val_split*100}% -----\")\n",
    "        # Definir y entrenar el modelo\n",
    "        modelFC2 = models.Sequential()\n",
    "        modelFC2.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "        modelFC2.add(layers.Dropout(0.5))\n",
    "        modelFC2.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "        modelFC2.add(layers.Dropout(0.5))\n",
    "        modelFC2.add(layers.Dense(100, activation=\"relu\"))\n",
    "        modelFC2.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=best_lr, momentum=best_momentum)\n",
    "        modelFC2.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "        es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "        modelFC2.fit(X_train, y_train, epochs=100, batch_size=batch_size, validation_split=val_split, callbacks=[es], verbose=0)\n",
    "\n",
    "        # Precisión en partición de test\n",
    "        loss, accuracy = modelFC2.evaluate(X_test, y_test)\n",
    "        if accuracy > acc:\n",
    "            best_batch_size = batch_size\n",
    "            best_val_split = val_split\n",
    "            acc = accuracy\n",
    "    \n",
    "print(f\"Valor óptimo de los hiperparámetros: batch_size={best_batch_size}; validation_split={best_val_split}\")\n",
    "print(\"Se logra un accuracy de {:0.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 18ms/step - loss: 1.8068 - acc: 0.4902 - val_loss: 1.1421 - val_acc: 0.7059\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0872 - acc: 0.4902 - val_loss: 0.8710 - val_acc: 0.7059\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7586 - acc: 0.7451 - val_loss: 1.0913 - val_acc: 0.7059\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3600 - acc: 0.9412 - val_loss: 5.2507 - val_acc: 0.5294\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2411 - acc: 0.8039 - val_loss: 0.8056 - val_acc: 0.7059\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6949 - acc: 0.8431 - val_loss: 0.9574 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6054 - acc: 0.8431 - val_loss: 1.0039 - val_acc: 0.7647\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3323 - acc: 0.9412 - val_loss: 2.9974 - val_acc: 0.6471\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6001 - acc: 0.8431 - val_loss: 1.2739 - val_acc: 0.7647\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3239 - acc: 0.9608 - val_loss: 1.2952 - val_acc: 0.7647\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1896 - acc: 0.9608 - val_loss: 0.9052 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0983 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelFC2 = models.Sequential()\n",
    "modelFC2.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC2.add(layers.Dropout(0.5))\n",
    "modelFC2.add(layers.Dense(200, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "modelFC2.add(layers.Dropout(0.5))\n",
    "modelFC2.add(layers.Dense(100, activation=\"relu\"))\n",
    "modelFC2.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=best_lr, momentum=best_momentum)\n",
    "modelFC2.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "modelFC2.fit(X_train, y_train, epochs=100, batch_size=best_batch_size, validation_split=best_val_split, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC2.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sigue habiendo una gran diferencia entre la precisión en el conjunto de validación y en el de entrenamiento, vamos a tratar de reducirla cambiando la topología de la red.\n",
    "\n",
    "$\\color{red}{\\text{¿Está mal hecho que busque la mejor estructura de la red después del ajuste de los parámetros?}}$\n",
    "Si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 12.0956 - acc: 0.4902 - val_loss: 4.5607 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.7107 - acc: 0.5294 - val_loss: 2.8128 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.5648 - acc: 0.5490 - val_loss: 2.3293 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.2777 - acc: 0.5294 - val_loss: 2.2114 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.1971 - acc: 0.5490 - val_loss: 2.2162 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.2517 - acc: 0.5490 - val_loss: 2.1974 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2413 - acc: 0.4444\n",
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelFC3 = models.Sequential()\n",
    "modelFC3.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC3.add(layers.Dropout(0.5))\n",
    "modelFC3.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l1\"))\n",
    "modelFC3.add(layers.Dropout(0.5))\n",
    "modelFC3.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l1\"))\n",
    "modelFC3.add(layers.Dropout(0.5))\n",
    "modelFC3.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l1\"))\n",
    "modelFC3.add(layers.Dropout(0.5))\n",
    "modelFC3.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=best_lr, momentum=best_momentum)\n",
    "modelFC3.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "modelFC3.fit(X_train, y_train, epochs=100, batch_size=best_batch_size, validation_split=best_val_split, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC3.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 22ms/step - loss: 13.5708 - acc: 0.5098 - val_loss: 5.0148 - val_acc: 0.8235\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.0705 - acc: 0.5490 - val_loss: 3.1077 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.8113 - acc: 0.6078 - val_loss: 2.5500 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.4462 - acc: 0.4902 - val_loss: 2.3053 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2729 - acc: 0.4510 - val_loss: 2.2208 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2082 - acc: 0.5294 - val_loss: 2.2032 - val_acc: 0.5882\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2075 - acc: 0.4444\n",
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelFC4 = models.Sequential()\n",
    "modelFC4.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC4.add(layers.Dropout(0.5))\n",
    "modelFC4.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l1_l2\"))\n",
    "modelFC4.add(layers.Dropout(0.5))\n",
    "modelFC4.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l1_l2\"))\n",
    "modelFC4.add(layers.Dropout(0.5))\n",
    "modelFC4.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l1_l2\"))\n",
    "modelFC4.add(layers.Dropout(0.5))\n",
    "modelFC4.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=best_lr, momentum=best_momentum)\n",
    "modelFC4.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "modelFC4.fit(X_train, y_train, epochs=100, batch_size=best_batch_size, validation_split=best_val_split, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC4.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 21ms/step - loss: 2.8688 - acc: 0.5098 - val_loss: 1.6835 - val_acc: 0.4118\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.3549 - acc: 0.7059 - val_loss: 2.1897 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9615 - acc: 0.5490 - val_loss: 1.2474 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2266 - acc: 0.5882 - val_loss: 1.0481 - val_acc: 0.6471\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8608 - acc: 0.7647 - val_loss: 0.9755 - val_acc: 0.8235\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8653 - acc: 0.7647 - val_loss: 1.1740 - val_acc: 0.7647\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8634 - acc: 0.7255 - val_loss: 0.7729 - val_acc: 0.8235\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4374 - acc: 0.9216 - val_loss: 0.8469 - val_acc: 0.8235\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3717 - acc: 0.9216 - val_loss: 1.4813 - val_acc: 0.7647\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6584 - acc: 0.8235 - val_loss: 1.3721 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9456 - acc: 0.8333\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelFC5 = models.Sequential()\n",
    "modelFC5.add(layers.Dense(100, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC5.add(layers.Dropout(0.5))\n",
    "modelFC5.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "modelFC5.add(layers.Dropout(0.5))\n",
    "modelFC5.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "modelFC5.add(layers.Dropout(0.5))\n",
    "modelFC5.add(layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l2\"))\n",
    "modelFC5.add(layers.Dropout(0.5))\n",
    "modelFC5.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=best_lr, momentum=best_momentum)\n",
    "modelFC5.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor='val_acc', min_delta=0.01, patience=5)\n",
    "modelFC5.fit(X_train, y_train, epochs=100, batch_size=best_batch_size, validation_split=best_val_split, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = modelFC5.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos probado diferentes topologías para la red hasta encontrar una que ha permitido obtener unos mejores resultados. La regularización que mejor funciona, tanto para no limitar excesivamente el entrenamiento de la red como para acortar las diferencias en el accuracy en train y validation, ha sido la regularización ``L2``. Tras esto, la diferencia en accuracy en las últimas etapas se ha reducido hasta llegar al 6%.\n",
    "\n",
    "$\\color{red}{\\text{Los resultados aún así oscilan bastante si se re-ejecuta el código.}}$\n",
    "$\\color{red}{\\text{El número de capas y de neuronas un poco a ciegas...}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "\n",
    "Idea: el encoder puede ayudar a \"recrear\" etiquetas de los datos de test proporcionados en kaggle, del que no se dispone de la clasificación verdadera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17963/17963 [==============================] - 65s 3ms/step - loss: 0.1215 - val_loss: 0.0189\n",
      "Epoch 2/100\n",
      "17963/17963 [==============================] - 61s 3ms/step - loss: 0.0137 - val_loss: 0.0147\n",
      "Epoch 3/100\n",
      "17963/17963 [==============================] - 62s 3ms/step - loss: 0.0071 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "17963/17963 [==============================] - 59s 3ms/step - loss: -0.0044 - val_loss: -0.0081\n",
      "Epoch 5/100\n",
      "17963/17963 [==============================] - 57s 3ms/step - loss: -0.0028 - val_loss: 0.0049\n",
      "Epoch 6/100\n",
      "17963/17963 [==============================] - 55s 3ms/step - loss: 0.0087 - val_loss: 0.0133\n",
      "Epoch 7/100\n",
      "17963/17963 [==============================] - 56s 3ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 8/100\n",
      "17963/17963 [==============================] - 53s 3ms/step - loss: 0.0050 - val_loss: -0.0041\n",
      "Epoch 9/100\n",
      "17963/17963 [==============================] - 54s 3ms/step - loss: -0.0045 - val_loss: -0.0130\n",
      "Epoch 10/100\n",
      "17963/17963 [==============================] - 56s 3ms/step - loss: -0.0087 - val_loss: -0.0076\n",
      "Epoch 11/100\n",
      "17963/17963 [==============================] - 57s 3ms/step - loss: -0.0105 - val_loss: -0.0165\n",
      "Epoch 12/100\n",
      "17963/17963 [==============================] - 56s 3ms/step - loss: -0.0133 - val_loss: -0.0157\n",
      "Epoch 13/100\n",
      "17963/17963 [==============================] - 57s 3ms/step - loss: -0.0200 - val_loss: -0.0166\n",
      "Epoch 14/100\n",
      "17963/17963 [==============================] - 57s 3ms/step - loss: -0.0265 - val_loss: -0.0357\n",
      "Epoch 15/100\n",
      "17963/17963 [==============================] - 54s 3ms/step - loss: -0.0348 - val_loss: -0.0383\n",
      "Epoch 16/100\n",
      "17963/17963 [==============================] - 56s 3ms/step - loss: -0.0425 - val_loss: -0.0430\n",
      "Epoch 17/100\n",
      "17963/17963 [==============================] - 57s 3ms/step - loss: -0.0494 - val_loss: -0.0522\n",
      "Epoch 18/100\n",
      "17963/17963 [==============================] - 61s 3ms/step - loss: -0.0560 - val_loss: -0.0575\n",
      "Epoch 19/100\n",
      "17963/17963 [==============================] - 61s 3ms/step - loss: -0.0612 - val_loss: -0.0610\n",
      "Epoch 20/100\n",
      "17963/17963 [==============================] - 61s 3ms/step - loss: -0.0653 - val_loss: -0.0737\n",
      "Epoch 21/100\n",
      "17963/17963 [==============================] - 61s 3ms/step - loss: -0.0762 - val_loss: -0.0932\n",
      "Epoch 22/100\n",
      "17963/17963 [==============================] - 63s 4ms/step - loss: -0.0933 - val_loss: -0.0937\n",
      "Epoch 23/100\n",
      "17963/17963 [==============================] - 63s 4ms/step - loss: -0.0996 - val_loss: -0.1103\n",
      "Epoch 24/100\n",
      "17963/17963 [==============================] - 63s 4ms/step - loss: -0.1098 - val_loss: -0.1120\n",
      "Epoch 25/100\n",
      "17963/17963 [==============================] - 63s 4ms/step - loss: -0.1104 - val_loss: -0.1132\n",
      "Epoch 26/100\n",
      "17963/17963 [==============================] - 65s 4ms/step - loss: -0.1129 - val_loss: -0.1128\n",
      "Epoch 27/100\n",
      "17963/17963 [==============================] - 66s 4ms/step - loss: -0.1148 - val_loss: -0.1115\n",
      "Epoch 28/100\n",
      "17963/17963 [==============================] - 69s 4ms/step - loss: -0.1176 - val_loss: -0.1152\n",
      "Epoch 29/100\n",
      "17963/17963 [==============================] - 195s 11ms/step - loss: -0.1185 - val_loss: -0.1153\n",
      "Epoch 30/100\n",
      "17963/17963 [==============================] - 70s 4ms/step - loss: -0.1194 - val_loss: -0.1157\n",
      "Epoch 31/100\n",
      "17963/17963 [==============================] - 74s 4ms/step - loss: -0.1205 - val_loss: -0.1202\n",
      "Epoch 32/100\n",
      "17963/17963 [==============================] - 83s 5ms/step - loss: -0.1208 - val_loss: -0.1235\n",
      "Epoch 33/100\n",
      "17963/17963 [==============================] - 81s 4ms/step - loss: -0.1191 - val_loss: -0.1189\n",
      "Epoch 34/100\n",
      "17963/17963 [==============================] - 77s 4ms/step - loss: -0.1193 - val_loss: -0.1190\n",
      "Epoch 35/100\n",
      "17963/17963 [==============================] - 75s 4ms/step - loss: -0.1174 - val_loss: -0.1102\n",
      "Epoch 36/100\n",
      "17963/17963 [==============================] - 74s 4ms/step - loss: -0.1178 - val_loss: -0.1115\n",
      "Epoch 37/100\n",
      "17963/17963 [==============================] - 72s 4ms/step - loss: -0.1125 - val_loss: -0.1136\n",
      "Epoch 38/100\n",
      "17963/17963 [==============================] - 72s 4ms/step - loss: -0.1074 - val_loss: -0.1000\n",
      "Epoch 39/100\n",
      "17963/17963 [==============================] - 70s 4ms/step - loss: -0.1025 - val_loss: -0.1060\n",
      "Epoch 40/100\n",
      "17963/17963 [==============================] - 74s 4ms/step - loss: -0.1010 - val_loss: -0.0990\n",
      "Epoch 41/100\n",
      "17963/17963 [==============================] - 74s 4ms/step - loss: -0.0966 - val_loss: -0.0954\n",
      "Epoch 42/100\n",
      "17963/17963 [==============================] - 74s 4ms/step - loss: -0.0890 - val_loss: -0.0878\n",
      "Epoch 43/100\n",
      "17963/17963 [==============================] - 79s 4ms/step - loss: -0.0748 - val_loss: -0.0688\n",
      "Epoch 44/100\n",
      "17963/17963 [==============================] - 77s 4ms/step - loss: -0.0671 - val_loss: -0.0592\n",
      "Epoch 45/100\n",
      "17963/17963 [==============================] - 77s 4ms/step - loss: -0.0582 - val_loss: -0.0591\n",
      "Epoch 46/100\n",
      "17963/17963 [==============================] - 78s 4ms/step - loss: -0.0621 - val_loss: -0.0527\n",
      "Epoch 47/100\n",
      "17963/17963 [==============================] - 80s 4ms/step - loss: -0.0534 - val_loss: -0.0427\n",
      "Epoch 48/100\n",
      "17963/17963 [==============================] - 73s 4ms/step - loss: -0.0474 - val_loss: -0.0385\n",
      "Epoch 49/100\n",
      "17963/17963 [==============================] - 74s 4ms/step - loss: -0.0411 - val_loss: -0.0300\n",
      "Epoch 50/100\n",
      "17963/17963 [==============================] - 75s 4ms/step - loss: -0.0292 - val_loss: -0.0208\n",
      "Epoch 51/100\n",
      "17963/17963 [==============================] - 76s 4ms/step - loss: -0.0176 - val_loss: -0.0148\n",
      "Epoch 52/100\n",
      "17963/17963 [==============================] - 77s 4ms/step - loss: -0.0127 - val_loss: -0.0123\n",
      "Epoch 53/100\n",
      "17963/17963 [==============================] - 79s 4ms/step - loss: -0.0036 - val_loss: 0.0159\n",
      "Epoch 54/100\n",
      "17963/17963 [==============================] - 81s 5ms/step - loss: 0.0047 - val_loss: 0.0137\n",
      "Epoch 55/100\n",
      "17963/17963 [==============================] - 81s 5ms/step - loss: 0.0067 - val_loss: 0.0157\n",
      "Epoch 56/100\n",
      "17963/17963 [==============================] - 83s 5ms/step - loss: 0.0083 - val_loss: 0.0152\n",
      "Epoch 57/100\n",
      "17963/17963 [==============================] - 84s 5ms/step - loss: 0.0191 - val_loss: 0.0205\n",
      "Epoch 58/100\n",
      "17963/17963 [==============================] - 84s 5ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 59/100\n",
      "17963/17963 [==============================] - 85s 5ms/step - loss: 0.0284 - val_loss: 0.0357\n",
      "Epoch 60/100\n",
      "17963/17963 [==============================] - 87s 5ms/step - loss: 0.0394 - val_loss: 0.0465\n",
      "Epoch 61/100\n",
      "17963/17963 [==============================] - 87s 5ms/step - loss: 0.0527 - val_loss: 0.0582\n",
      "Epoch 62/100\n",
      "17963/17963 [==============================] - 88s 5ms/step - loss: 0.0642 - val_loss: 0.0671\n",
      "Epoch 63/100\n",
      "17963/17963 [==============================] - 91s 5ms/step - loss: 0.0732 - val_loss: 0.0629\n",
      "Epoch 64/100\n",
      "17963/17963 [==============================] - 92s 5ms/step - loss: 0.0738 - val_loss: 0.1062\n",
      "Epoch 65/100\n",
      "17963/17963 [==============================] - 91s 5ms/step - loss: 0.0879 - val_loss: 0.0872\n",
      "Epoch 66/100\n",
      "17963/17963 [==============================] - 91s 5ms/step - loss: 0.0898 - val_loss: 0.0982\n",
      "Epoch 67/100\n",
      "17963/17963 [==============================] - 87s 5ms/step - loss: 0.0979 - val_loss: 0.1053\n",
      "Epoch 68/100\n",
      "17963/17963 [==============================] - 89s 5ms/step - loss: 0.1050 - val_loss: 0.1043\n",
      "Epoch 69/100\n",
      "17963/17963 [==============================] - 87s 5ms/step - loss: 0.1123 - val_loss: 0.1111\n",
      "Epoch 70/100\n",
      "17963/17963 [==============================] - 88s 5ms/step - loss: 0.1228 - val_loss: 0.1235\n",
      "Epoch 71/100\n",
      "17963/17963 [==============================] - 89s 5ms/step - loss: 0.1213 - val_loss: 0.1120\n",
      "Epoch 72/100\n",
      "17963/17963 [==============================] - 90s 5ms/step - loss: 0.1254 - val_loss: 0.1322\n",
      "Epoch 73/100\n",
      "17963/17963 [==============================] - 97s 5ms/step - loss: 0.1317 - val_loss: 0.1392\n",
      "Epoch 74/100\n",
      "17963/17963 [==============================] - 94s 5ms/step - loss: 0.1338 - val_loss: 0.1344\n",
      "Epoch 75/100\n",
      "17963/17963 [==============================] - 98s 5ms/step - loss: 0.1359 - val_loss: 0.1304\n",
      "Epoch 76/100\n",
      "17963/17963 [==============================] - 93s 5ms/step - loss: 0.1365 - val_loss: 0.1390\n",
      "Epoch 77/100\n",
      "17963/17963 [==============================] - 95s 5ms/step - loss: 0.1390 - val_loss: 0.1326\n",
      "Epoch 78/100\n",
      "17963/17963 [==============================] - 95s 5ms/step - loss: 0.1385 - val_loss: 0.1566\n",
      "Epoch 79/100\n",
      "17963/17963 [==============================] - 96s 5ms/step - loss: 0.1450 - val_loss: 0.1445\n",
      "Epoch 80/100\n",
      "17963/17963 [==============================] - 15474s 861ms/step - loss: 0.1439 - val_loss: 0.1639\n",
      "Epoch 81/100\n",
      "17963/17963 [==============================] - 112s 6ms/step - loss: 0.1498 - val_loss: 0.1518\n",
      "Epoch 82/100\n",
      "17963/17963 [==============================] - 123s 7ms/step - loss: 0.1583 - val_loss: 0.1568\n",
      "Epoch 83/100\n",
      "17963/17963 [==============================] - 116s 6ms/step - loss: 0.1797 - val_loss: 0.1763\n",
      "Epoch 84/100\n",
      "17963/17963 [==============================] - 114s 6ms/step - loss: 0.1851 - val_loss: 0.1831\n",
      "Epoch 85/100\n",
      "17963/17963 [==============================] - 108s 6ms/step - loss: 0.1917 - val_loss: 0.1977\n",
      "Epoch 86/100\n",
      "17963/17963 [==============================] - 109s 6ms/step - loss: 0.1959 - val_loss: 0.2080\n",
      "Epoch 87/100\n",
      "17963/17963 [==============================] - 116s 6ms/step - loss: 0.2018 - val_loss: 0.2054\n",
      "Epoch 88/100\n",
      "17963/17963 [==============================] - 117s 7ms/step - loss: 0.2112 - val_loss: 0.2197\n",
      "Epoch 89/100\n",
      "17963/17963 [==============================] - 117s 7ms/step - loss: 0.2165 - val_loss: 0.2207\n",
      "Epoch 90/100\n",
      "17963/17963 [==============================] - 120s 7ms/step - loss: 0.2455 - val_loss: 0.2420\n",
      "Epoch 91/100\n",
      "17963/17963 [==============================] - 120s 7ms/step - loss: 0.2560 - val_loss: 0.2630\n",
      "Epoch 92/100\n",
      "17963/17963 [==============================] - 113s 6ms/step - loss: 0.2558 - val_loss: 0.2624\n",
      "Epoch 93/100\n",
      "17963/17963 [==============================] - 116s 6ms/step - loss: 0.2615 - val_loss: 0.2672\n",
      "Epoch 94/100\n",
      "17963/17963 [==============================] - 115s 6ms/step - loss: 0.2711 - val_loss: 0.2750\n",
      "Epoch 95/100\n",
      "17963/17963 [==============================] - 117s 6ms/step - loss: 0.2747 - val_loss: 0.2753\n",
      "Epoch 96/100\n",
      "17963/17963 [==============================] - 119s 7ms/step - loss: 0.2879 - val_loss: 0.3059\n",
      "Epoch 97/100\n",
      "17963/17963 [==============================] - 438s 24ms/step - loss: 0.3015 - val_loss: 0.3071\n",
      "Epoch 98/100\n",
      "17963/17963 [==============================] - 119s 7ms/step - loss: 0.3229 - val_loss: 0.3247\n",
      "Epoch 99/100\n",
      "17963/17963 [==============================] - 138s 8ms/step - loss: 0.3353 - val_loss: 0.3420\n",
      "Epoch 100/100\n",
      "17963/17963 [==============================] - 147s 8ms/step - loss: 0.3354 - val_loss: 0.3309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be38588940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "input_layer = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded = layers.Dense(200, activation=\"relu\")(input_layer)\n",
    "encoded = layers.Dense(100, activation=\"relu\")(encoded)\n",
    "encoded = layers.Dense(50, activation=\"relu\")(encoded)\n",
    "# Capas red decoder\n",
    "# IDEA: una técnica frecuente es usar una red simétrica\n",
    "decoded = layers.Dense(50, activation=\"relu\")(encoded)\n",
    "decoded = layers.Dense(100, activation=\"relu\")(decoded)\n",
    "decoded = layers.Dense(200, activation=\"relu\")(decoded)\n",
    "decoded = layers.Dense(410)(decoded)\n",
    "\n",
    "# Encoder\n",
    "encoder = models.Model(input_layer, encoded)\n",
    "\n",
    "# Autoencoder (lo que nos sirve para generar las etiquetas)\n",
    "autoencoder = models.Model(input_layer, decoded)\n",
    "\n",
    "# Compilar y entrenar el autoencoder\n",
    "best_batch_size= 5\n",
    "\n",
    "autoencoder.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")\n",
    "autoencoder.fit(test, test, epochs=100, batch_size=best_batch_size, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error in X_train data prediction: tf.Tensor(546.0757, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import MeanSquaredError, MeanAbsolutePercentageError\n",
    "# from keras.losses import Reduction\n",
    "\n",
    "# Precisión en partición de test\n",
    "test_pred = autoencoder.predict(test)\n",
    "\n",
    "# X_test_matrix = np.array(X_test)\n",
    "# diff = X_test_matrix - X_test_pred\n",
    "# dims = diff.shape\n",
    "# total_elem = dims[0]*dims[1]\n",
    "# elem_no_estim = (np.abs(diff) > 0.1).sum()\n",
    "# print(\"De los {} elementos que tiene la matriz de datos de test, hay {} que no se han estimado de manera exacta ({:0.2f}%).\"\\\n",
    "#       .format(total_elem, elem_no_estim, elem_no_estim*100/total_elem))\n",
    "# Hemos dado un margen de error en la precisión del [-0.1, 0.1]. ¿¿SBM??\n",
    "# Métricas: mape, mse\n",
    "\n",
    "mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "mape = MeanAbsolutePercentageError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "# print(\"Mean squared error in X_train data prediction:\", mse(X_train, X_train_pred).numpy())\n",
    "print(\"Mean absolute percentage error in X_train data prediction:\", mape(test.to_numpy()[:, 0], test_pred[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4761265   0.0138327  -0.4354521  -0.2045103   0.5994351   0.4546196\n",
      " -0.3229979   0.741983   -0.00258061  0.1579147 ]\n",
      "[0.25765443 0.24804187 0.24442351 0.26963007 0.30078018 0.25982392\n",
      " 0.28501105 0.23901677 0.225407   0.27071762]\n"
     ]
    }
   ],
   "source": [
    "print(test.to_numpy()[0:10, 0])\n",
    "print(test_pred[0:10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138.178062369424"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs((test.to_numpy()[0:10, 0] - test_pred[0:10, 0]) / test.to_numpy()[0:10, 0])) * (100 / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546.0756804117381"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs((test.to_numpy()[:, 0] - test_pred[:, 0]) / test.to_numpy()[:, 0])) * (100 / len(test_pred[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save(\"autoencoder.h5\")\n",
    "encoder.save(\"encoder.h5\")\n",
    "# autoencoder = models.load_model(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos entrenado la red autoencoder, el componente encoder de la misma ya contará con unos pesos entrenados con el objetivo de comprimir los datos de entrada. Por tanto, podemos considerar de manera independiente esta red encoder y volver a entrenarla como una red para clasificación, con la ventaja de que se parte de un modelo inicializado no con unos pesos aleatorios, sino unos pesos optimizados para un problema similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AÑADIR CAPA DE CLASIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 2s 67ms/step - loss: 0.7704 - acc: 0.4510 - val_loss: 0.7989 - val_acc: 0.3529\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.7536 - acc: 0.4510 - val_loss: 0.7844 - val_acc: 0.4118\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.7446 - acc: 0.4314 - val_loss: 0.7750 - val_acc: 0.4118\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.7364 - acc: 0.4118 - val_loss: 0.7695 - val_acc: 0.4118\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.7317 - acc: 0.4510 - val_loss: 0.7638 - val_acc: 0.4706\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.7263 - acc: 0.4510 - val_loss: 0.7545 - val_acc: 0.4706\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.7209 - acc: 0.4314 - val_loss: 0.7478 - val_acc: 0.4706\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.7154 - acc: 0.4510 - val_loss: 0.7452 - val_acc: 0.4118\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.7127 - acc: 0.5098 - val_loss: 0.7429 - val_acc: 0.4118\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.7102 - acc: 0.5098 - val_loss: 0.7364 - val_acc: 0.5294\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.7058 - acc: 0.5882 - val_loss: 0.7349 - val_acc: 0.4706\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.7042 - acc: 0.5882 - val_loss: 0.7303 - val_acc: 0.5294\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.7011 - acc: 0.5490 - val_loss: 0.7268 - val_acc: 0.5294\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.6982 - acc: 0.5686 - val_loss: 0.7265 - val_acc: 0.5294\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6965 - acc: 0.5882 - val_loss: 0.7233 - val_acc: 0.4706\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.6942 - acc: 0.6078 - val_loss: 0.7203 - val_acc: 0.4706\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.6928 - acc: 0.5686 - val_loss: 0.7177 - val_acc: 0.5294\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6904 - acc: 0.5294 - val_loss: 0.7162 - val_acc: 0.5294\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.6890 - acc: 0.5098 - val_loss: 0.7162 - val_acc: 0.5294\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6883 - acc: 0.5294 - val_loss: 0.7166 - val_acc: 0.5294\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.6868 - acc: 0.5294 - val_loss: 0.7147 - val_acc: 0.5294\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - acc: 0.5294 - val_loss: 0.7131 - val_acc: 0.5294\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6841 - acc: 0.5294 - val_loss: 0.7118 - val_acc: 0.5882\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.6834 - acc: 0.5490 - val_loss: 0.7102 - val_acc: 0.5294\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.6815 - acc: 0.5490 - val_loss: 0.7091 - val_acc: 0.5294\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.6810 - acc: 0.5098 - val_loss: 0.7081 - val_acc: 0.5294\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 47ms/step - loss: 0.6796 - acc: 0.5098 - val_loss: 0.7071 - val_acc: 0.5294\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.6788 - acc: 0.5294 - val_loss: 0.7064 - val_acc: 0.5294\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.6780 - acc: 0.5294 - val_loss: 0.7069 - val_acc: 0.5294\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.6765 - acc: 0.5294 - val_loss: 0.7067 - val_acc: 0.5294\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.6757 - acc: 0.5294 - val_loss: 0.7076 - val_acc: 0.5294\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 0.6746 - acc: 0.5490 - val_loss: 0.7082 - val_acc: 0.5294\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.6743 - acc: 0.5490 - val_loss: 0.7074 - val_acc: 0.5294\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.6732 - acc: 0.5490 - val_loss: 0.7077 - val_acc: 0.5294\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6718 - acc: 0.5686 - val_loss: 0.7064 - val_acc: 0.5294\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.5686 - val_loss: 0.7058 - val_acc: 0.5294\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.6700 - acc: 0.5686 - val_loss: 0.7063 - val_acc: 0.5294\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6693 - acc: 0.5882 - val_loss: 0.7054 - val_acc: 0.5294\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6680 - acc: 0.5882 - val_loss: 0.7050 - val_acc: 0.5294\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.6675 - acc: 0.5882 - val_loss: 0.7054 - val_acc: 0.5294\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.6662 - acc: 0.5882 - val_loss: 0.7050 - val_acc: 0.5294\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.6652 - acc: 0.5882 - val_loss: 0.7056 - val_acc: 0.5294\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.6645 - acc: 0.6078 - val_loss: 0.7051 - val_acc: 0.5294\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6634 - acc: 0.6078 - val_loss: 0.7045 - val_acc: 0.5294\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6634 - acc: 0.5882 - val_loss: 0.7048 - val_acc: 0.5294\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.6619 - acc: 0.6078 - val_loss: 0.7044 - val_acc: 0.5294\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6610 - acc: 0.6078 - val_loss: 0.7038 - val_acc: 0.5294\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.6602 - acc: 0.6078 - val_loss: 0.7034 - val_acc: 0.5294\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.6597 - acc: 0.5882 - val_loss: 0.7033 - val_acc: 0.5294\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.6587 - acc: 0.6078 - val_loss: 0.7032 - val_acc: 0.5294\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.6577 - acc: 0.6078 - val_loss: 0.7026 - val_acc: 0.5294\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.6569 - acc: 0.6078 - val_loss: 0.7025 - val_acc: 0.5294\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.6564 - acc: 0.6078 - val_loss: 0.7024 - val_acc: 0.5294\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.6559 - acc: 0.6078 - val_loss: 0.7020 - val_acc: 0.5294\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.6547 - acc: 0.5882 - val_loss: 0.7019 - val_acc: 0.5294\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.6546 - acc: 0.5882 - val_loss: 0.7021 - val_acc: 0.5294\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.6532 - acc: 0.5882 - val_loss: 0.7018 - val_acc: 0.5294\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.6524 - acc: 0.5882 - val_loss: 0.7017 - val_acc: 0.5294\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.6512 - acc: 0.5882 - val_loss: 0.7024 - val_acc: 0.5294\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6502 - acc: 0.6078 - val_loss: 0.7022 - val_acc: 0.5294\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6496 - acc: 0.5882 - val_loss: 0.7021 - val_acc: 0.5294\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.6485 - acc: 0.6078 - val_loss: 0.7018 - val_acc: 0.5294\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.6482 - acc: 0.6078 - val_loss: 0.7018 - val_acc: 0.5294\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.6475 - acc: 0.5882 - val_loss: 0.7024 - val_acc: 0.5294\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.6464 - acc: 0.6078 - val_loss: 0.7022 - val_acc: 0.5294\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6452 - acc: 0.6078 - val_loss: 0.7018 - val_acc: 0.5294\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.6447 - acc: 0.5882 - val_loss: 0.7017 - val_acc: 0.5294\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6441 - acc: 0.5882 - val_loss: 0.7018 - val_acc: 0.5294\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.6430 - acc: 0.6078 - val_loss: 0.7017 - val_acc: 0.5294\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6427 - acc: 0.5882 - val_loss: 0.7015 - val_acc: 0.5294\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.6416 - acc: 0.5882 - val_loss: 0.7013 - val_acc: 0.5294\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6408 - acc: 0.5882 - val_loss: 0.7021 - val_acc: 0.5294\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.6399 - acc: 0.5882 - val_loss: 0.7021 - val_acc: 0.5294\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.6389 - acc: 0.5882 - val_loss: 0.7022 - val_acc: 0.5294\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.6383 - acc: 0.5882 - val_loss: 0.7020 - val_acc: 0.5294\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.6377 - acc: 0.6078 - val_loss: 0.7022 - val_acc: 0.5294\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.6375 - acc: 0.6078 - val_loss: 0.7031 - val_acc: 0.5294\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6355 - acc: 0.6078 - val_loss: 0.7040 - val_acc: 0.5294\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6348 - acc: 0.6275 - val_loss: 0.7043 - val_acc: 0.5294\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6344 - acc: 0.6275 - val_loss: 0.7043 - val_acc: 0.5294\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6339 - acc: 0.6275 - val_loss: 0.7041 - val_acc: 0.5294\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.6331 - acc: 0.6275 - val_loss: 0.7038 - val_acc: 0.5294\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.6322 - acc: 0.6078 - val_loss: 0.7046 - val_acc: 0.5294\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.6313 - acc: 0.6275 - val_loss: 0.7046 - val_acc: 0.5294\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6312 - acc: 0.6078 - val_loss: 0.7053 - val_acc: 0.5294\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6301 - acc: 0.6275 - val_loss: 0.7054 - val_acc: 0.5294\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.6293 - acc: 0.6275 - val_loss: 0.7053 - val_acc: 0.5294\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.6287 - acc: 0.6275 - val_loss: 0.7063 - val_acc: 0.5294\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.6279 - acc: 0.6275 - val_loss: 0.7068 - val_acc: 0.5294\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6268 - acc: 0.6078 - val_loss: 0.7067 - val_acc: 0.5294\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.6266 - acc: 0.6275 - val_loss: 0.7073 - val_acc: 0.4706\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.6254 - acc: 0.6078 - val_loss: 0.7068 - val_acc: 0.5294\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6253 - acc: 0.6078 - val_loss: 0.7064 - val_acc: 0.5294\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6253 - acc: 0.6275 - val_loss: 0.7063 - val_acc: 0.5294\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.6243 - acc: 0.6471 - val_loss: 0.7060 - val_acc: 0.5294\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.6236 - acc: 0.6471 - val_loss: 0.7063 - val_acc: 0.5294\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.6227 - acc: 0.6275 - val_loss: 0.7062 - val_acc: 0.5294\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.6225 - acc: 0.6078 - val_loss: 0.7060 - val_acc: 0.5294\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6223 - acc: 0.6275 - val_loss: 0.7064 - val_acc: 0.5294\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.6214 - acc: 0.6078 - val_loss: 0.7071 - val_acc: 0.4706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1be478f54f0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_model = encoder # loading the previously saved model.\n",
    "\n",
    "new_model = models.Sequential()\n",
    "new_model.add(prev_model)\n",
    "new_model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Congelar los pesos de todas las capas a excepción de la última\n",
    "for layer in new_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "new_model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "new_model.fit(X_train, y_train, epochs=100, batch_size=best_batch_size, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6641 - acc: 0.5556\n",
      "Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "# Precisión en partición de test\n",
    "loss, accuracy = new_model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder\n",
    "\n",
    "El objetivo es que la red encoder aprenda la distribución generadora de los datos.\n",
    "Esto permitirá generar nuevas muestras.\n",
    "\n",
    "In VAE, we optimize two loss functions: reconstruction loss and KL-divergence loss. We will learn about them in detail in the next section. For now, remember that the reconstruction loss ensures that the images generated by the decoder are similar to the input or the ones in the dataset. While the KL-divergence measures the divergence between a pair of probability distributions, in this case, the pair of distributions being the latent vector Z (sampled from $Z_{\\mu}$ and $Z_{\\sigma}$) and unit normal distribution $\\mathcal{N}(0, 1)$. KL-divergence ensures that the latent-variables are close to the standard normal distribution.\n",
    "\n",
    "Partimos de la misma red encoder, sólo que esta vez la última capa se descompone ahora en dos capas (Dense), generando concretamente los vectores mean y log_variance (latent-variables, las cuales se espera que sigan una distribución normal).\n",
    "\n",
    "Referencia: https://learnopencv.com/variational-autoencoder-in-tensorflow/#network-fmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{REVISAR ENTERO}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir y entrenar el modelo\n",
    "input_layer = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded = layers.Dense(100, activation=\"relu\")(input_layer)\n",
    "encoded = layers.Dropout(0.5)(encoded)\n",
    "encoded = layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l2\")(encoded)\n",
    "encoded = layers.Dropout(0.5)(encoded)\n",
    "encoded = layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l2\")(encoded)\n",
    "encoded = layers.Dropout(0.5)(encoded)\n",
    "encoded = layers.Dense(100, activation=\"relu\", kernel_regularizer=\"l2\")(encoded)\n",
    "encoded = layers.Dropout(0.5)(encoded)\n",
    "mean = layers.Dense(2, name=\"mean\")(encoded)\n",
    "log_var = layers.Dense(2, name=\"log_var\")(encoded)\n",
    "\n",
    "# Red de sampleo\n",
    "def sampling_reparameterization(distribution_params):\n",
    "    mean, log_var = distribution_params\n",
    "    epsilon = backend.random_normal(shape=backend.shape(mean), mean=0., stddev=1.)\n",
    "    z = mean + backend.exp(log_var / 2) * epsilon\n",
    "    return z\n",
    "sample = layers.Lambda(sampling_reparameterization)([mean, log_var])\n",
    "# A Lambda layer comes in handy when you want to pass a tensor to a custom function that isn’t already included in tensorflow\n",
    "\n",
    "# Capas red decoder\n",
    "decoded = layers.Dense(410, activation=\"sigmoid\")(sample)\n",
    "\n",
    "\n",
    "# Encoder\n",
    "encoder = models.Model(input_layer, (mean, log_var), name=\"Encoder\")\n",
    "# Sampler \n",
    "sampler = models.Model([mean,log_var], sample,  name=\"Encoder_2\")\n",
    "# Autoencoder\n",
    "autoencoder = models.Model(input_layer, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De los 7380 elementos que tiene la matriz de datos de test, hay 6308 que no se han estimado de manera exacta (85.47%).\n"
     ]
    }
   ],
   "source": [
    "X_test_pred = autoencoder.predict(X_test)\n",
    "\n",
    "X_test_matrix = np.array(X_test)\n",
    "diff = X_test_matrix - X_test_pred\n",
    "dims = diff.shape\n",
    "total_elem = dims[0]*dims[1]\n",
    "elem_no_estim = (diff < -0.1).sum() + (diff > 0.1).sum()\n",
    "print(\"De los {} elementos que tiene la matriz de datos de test, hay {} que no se han estimado de manera exacta ({:0.2f}%).\"\\\n",
    "      .format(total_elem, elem_no_estim, elem_no_estim*100/total_elem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119748, 2)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "def create_submission(pred, method, test_id=testFNC[\"Id\"]):\n",
    "    submissionDF = pd.DataFrame(list(zip(test_id, pred)), columns=[\"Id\", \"Probability\"])\n",
    "    print(submissionDF.shape) # Comprobación del tamaño, debe ser: (119748, 2)\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y_%Hh%Mmin\")\n",
    "    current_path = pathlib.Path().resolve()\n",
    "    submissionDF.to_csv(f\"{current_path}\\submissions\\MLSP_submission_{method}_{current_time}.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
