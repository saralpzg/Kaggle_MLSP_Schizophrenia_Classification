{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d66f63",
   "metadata": {},
   "source": [
    "# Comparación de técnicas de preprocesamiento de los datos\n",
    "\n",
    "En este notebook se van a probar distintos métodos de preprocesado de los datos para entrenar todas las alternativas con un mismo modelo (_XGBoost_) y comparar los resultados mediante el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f2591ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data partition\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Model evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, mutual_info_classif, RFE, SelectFromModel\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374022c8",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c38871d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>0.216620</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.353800</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.133020</td>\n",
       "      <td>-0.035222</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257114</td>\n",
       "      <td>0.597229</td>\n",
       "      <td>1.220756</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>-0.435494</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>1.090910</td>\n",
       "      <td>-0.448562</td>\n",
       "      <td>-0.508497</td>\n",
       "      <td>0.350434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.410730</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.242260</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>0.599790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050862</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>0.609465</td>\n",
       "      <td>1.181878</td>\n",
       "      <td>-2.279469</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>-0.012693</td>\n",
       "      <td>-1.244346</td>\n",
       "      <td>-1.080442</td>\n",
       "      <td>-0.788502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.318170</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.539922</td>\n",
       "      <td>-1.495822</td>\n",
       "      <td>1.643866</td>\n",
       "      <td>1.687780</td>\n",
       "      <td>1.521086</td>\n",
       "      <td>-1.988432</td>\n",
       "      <td>-0.267471</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>1.104566</td>\n",
       "      <td>-1.067206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.112830</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0.202750</td>\n",
       "      <td>0.191420</td>\n",
       "      <td>-0.056662</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.593326</td>\n",
       "      <td>1.063052</td>\n",
       "      <td>0.434726</td>\n",
       "      <td>1.604964</td>\n",
       "      <td>-0.359736</td>\n",
       "      <td>0.210107</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>-0.323557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "2       0  0.245850  0.216620 -0.124680 -0.353800  0.161500 -0.002032   \n",
       "13      1  0.410730 -0.031925  0.210700  0.242260  0.320100 -0.419290   \n",
       "53      1  0.070919  0.034179 -0.011755  0.019158  0.024645 -0.032022   \n",
       "41      0  0.087377 -0.052462 -0.007835 -0.112830  0.389380  0.216080   \n",
       "74      0  0.202750  0.191420 -0.056662 -0.157780  0.244040  0.039780   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "2  -0.133020 -0.035222  0.259040  ...  -0.257114   0.597229   1.220756   \n",
       "13 -0.187140  0.168450  0.599790  ...  -0.050862   0.870602   0.609465   \n",
       "53  0.004620  0.318170  0.212550  ...  -1.539922  -1.495822   1.643866   \n",
       "41  0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "74 -0.001503  0.001056 -0.048222  ...   0.044457   0.593326   1.063052   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "2   -0.059213  -0.435494  -0.092971   1.090910  -0.448562  -0.508497   \n",
       "13   1.181878  -2.279469  -0.013484  -0.012693  -1.244346  -1.080442   \n",
       "53   1.687780   1.521086  -1.988432  -0.267471   0.510576   1.104566   \n",
       "41  -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "74   0.434726   1.604964  -0.359736   0.210107   0.355922   0.730287   \n",
       "\n",
       "    SBM_map75  \n",
       "2    0.350434  \n",
       "13  -0.788502  \n",
       "53  -1.067206  \n",
       "41  -0.260920  \n",
       "74  -0.323557  \n",
       "\n",
       "[5 rows x 411 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de entrenamiento\n",
    "trainFNC = pd.read_csv(\"data/train_FNC.csv\")\n",
    "trainSBM = pd.read_csv(\"data/train_SBM.csv\")\n",
    "train_labels = pd.read_csv(\"data/train_labels.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos (FNC y SBM)\n",
    "train = pd.merge(left=trainFNC, right=trainSBM, left_on='Id', right_on='Id')\n",
    "data = pd.merge(left=train_labels, right=train, left_on='Id', right_on='Id')\n",
    "data.drop(\"Id\", inplace=True, axis=1)\n",
    "\n",
    "# Shuffle de los datos de train\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488be98e",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424917ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28999cd",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8717295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model_XGB = XGBClassifier(eval_metric=\"logloss\")\n",
    "param_grid_XGB = {\n",
    "    \"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "    \"learning_rate\": [0.001, 0.05, 0.1, 0.5]\n",
    "}\n",
    "grid_search_XGB = GridSearchCV(estimator=model_XGB, param_grid=param_grid_XGB, cv=4)\n",
    "# cv = 4 porque así: el conjunto de validation tiene un 0.25 del tamaño de train y: 0.25 * 0.8 = 0.2\n",
    "#                    el conjunto de train tiene un 0.75 del tamaño de train y: 0.75 * 0.8 = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75329541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar el entrenamiento y el ajuste de parámetros\n",
    "def train_model(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
    "    grid_search_XGB.fit(X_train, y_train)\n",
    "    model_XGB_opt = grid_search_XGB.best_estimator_\n",
    "    \n",
    "    # Predicción en partición de test\n",
    "    y_pred_XGB = model_XGB_opt.predict(X_test)\n",
    "    \n",
    "    # Precisión en partición de test\n",
    "    accuracy = accuracy_score(y_test, y_pred_XGB)\n",
    "    \n",
    "    return accuracy, grid_search_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d9aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(accuracy, param_grid):\n",
    "    print(\"Parámetros óptimos:\", grid.best_params_)\n",
    "    print(\"Modelo óptimo:\", grid.best_estimator_)\n",
    "    print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96418c",
   "metadata": {},
   "source": [
    "# Sin preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fade9e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.001, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "accuracy, grid = train_model()\n",
    "print_results(accuracy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f7bca",
   "metadata": {},
   "source": [
    "# Escalado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2f181bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.001, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "preprocess = StandardScaler()\n",
    "\n",
    "X_train_processed = preprocess.fit_transform(X_train)\n",
    "X_test_processed = preprocess.fit_transform(X_test)\n",
    "\n",
    "accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "print_results(accuracy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819915b",
   "metadata": {},
   "source": [
    "# Normalize\n",
    "\n",
    "Datos con norma unitaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc88974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.001, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n",
      "Resultado obtenido usando la norma l1.\n"
     ]
    }
   ],
   "source": [
    "norm_types = [\"l1\", \"l2\", \"max\"]\n",
    "acc = 0\n",
    "\n",
    "for norm in norm_types:\n",
    "    X_train_processed = normalize(X_train, norm)\n",
    "    X_test_processed = normalize(X_test, norm)\n",
    "    \n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_norm = norm\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "\n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando la norma {}.\".format(best_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf473af",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a89a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gbtree', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              eval_metric='logloss', gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.001, max_delta_step=0,\n",
      "              max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy: 66.67%\n",
      "Resultado obtenido usando  16 componentes principales.\n"
     ]
    }
   ],
   "source": [
    "# NOTA: la dimensionalidad del espacio reducido del método PCA (paquete sklearn) en python tiene como tamaño máximo el mínimo\n",
    "# entre el número de variables y el número de muestras. Como en este caso nuestro conjunto de datos es pequeño, el número \n",
    "# máximo de componentes será precisamente el número de muestras en el conjunto de test.\n",
    "n_components_range = list(range(2, X_test.shape[0], 2))\n",
    "acc = 0\n",
    "\n",
    "for n_components in n_components_range:\n",
    "    preprocess = PCA(n_components=n_components)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test)\n",
    "\n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_n_components = n_components\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "        \n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando {:3d} componentes principales.\".format(best_n_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5074e9a",
   "metadata": {},
   "source": [
    "# SelectKBest\n",
    "\n",
    "Documentación scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)\n",
    "\n",
    "Este método selecciona las k mejores variables en base a la puntuación que estas reciben de acuerdo a una función que toma como parámetro (test estadísticos). \n",
    "\n",
    "La función que utiliza por defecto y con la que probaremos inicialmente en el siguiente código el método es ``f_classif``. Esta función calcula el ANOVA F-valor entre etiquetas y características para problemas de clasificación.\n",
    "\n",
    "_NOTA: ANalysis Of VAriance: método estadístico que permite descubrir si los resultados de una prueba son significativos._\n",
    "\n",
    "_NOTA: distribución F o de Fisher-Snedecor es una distribución de probabilidad continua, especialmente aplicada en el análisis de la varianza-_\n",
    "\n",
    "Como hay que indicar un parámetro ``k`` que será el número de variables seleccionadas, probaremos varios valores para ver con cual se obtiene mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b5255a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.001, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n",
      "Resultado obtenido usando las 410 mejores componentes.\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(10, 450, 40))\n",
    "acc = 0\n",
    "\n",
    "for k in k_range:\n",
    "    preprocess = SelectKBest(k=k)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_k = k\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "        \n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando las {:3d} mejores componentes.\".format(best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05a367",
   "metadata": {},
   "source": [
    "A continuación, probamos los resultados del código anterior, utilizando una función de score distinta y apropiada para clasificación.\n",
    "\n",
    "### mutual_info_classif: \n",
    "\n",
    "Mutual Information (MI) es un criterio de estimación de mide la dependencia entre dos variables (en este caso para una variable objetivo discreta). Su valor es no negativo y vale cero las dos variables son totalmente independientes, por tanto, cuanto más alto es su valor, mayor es la dependencia.\n",
    "\n",
    "Su implementación en sklearn se apoya en métodos no-paramétricos, basados en la estimación de la entropía de las distancias de los k-vecinos más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8f5d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.001, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n",
      "Resultado obtenido usando las  10 mejores componentes.\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for k in k_range:\n",
    "    preprocess = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "\n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_k = k\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "        \n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando las {:3d} mejores componentes.\".format(best_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db083d",
   "metadata": {},
   "source": [
    "El resto de funciones implementadas en sklearn son para regresión o no válidas en nuestro conjunto de datos (chi2 no admite valores negativos).\n",
    "\n",
    "# SelectPercentile\n",
    "\n",
    "Documentación scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html?highlight=select%20percentile#sklearn.feature_selection.SelectPercentile)\n",
    "\n",
    "Método muy similar al anterior ``SelectKBest`` pero que hace la selección de las variables esta vez de acuerdo a un percentil de las puntuaciones más altas. También utiliza las mismas funciones de score y seguiremos el mismo procedimiento.\n",
    "\n",
    "### f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d4b4868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.001, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 88.89%\n",
      "Resultado obtenido de acuerdo al percentil 10.\n"
     ]
    }
   ],
   "source": [
    "percentile_range = list(range(10, 100, 10))\n",
    "acc = 0\n",
    "\n",
    "for percent in percentile_range:\n",
    "    preprocess = SelectPercentile(percentile=percent)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_percentile = percent\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "\n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido de acuerdo al percentil {:2d}.\".format(best_percentile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f445a4bb",
   "metadata": {},
   "source": [
    "### mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a5b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.5}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 66.67%\n",
      "Resultado obtenido de acuerdo al percentil 60.\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for percent in percentile_range:\n",
    "    preprocess = SelectPercentile(score_func=mutual_info_classif, percentile=percent)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_percentile = percent\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "\n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido de acuerdo al percentil {:2d}.\".format(best_percentile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be6c94",
   "metadata": {},
   "source": [
    "# RFE\n",
    "\n",
    "Documentación scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html?highlight=rfe#sklearn.feature_selection.RFE)\n",
    "\n",
    "RFE = Recursive Feature Elimination.\n",
    "\n",
    "Dado un estimador que asigna pesos a las variables (por ejemplos los coeficientes de un modelo lineal), el método elimina de manera recursiva  variables, considerando cada vez conjuntos más pequeños de acuerdo a estos pesos. Inicialmente se entrena el estimador sobre el conjunto original de variables y se obtiene la importancia de cada variable. Acto seguido se podan las variables menos importantes del conjunto. Este proceso se repite de manera recursiva sobre los conjuntos podados que se van generando hasta que se alcanza el número de variables deseado.\n",
    "\n",
    "### Estimador SVC (Support Vector Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30030230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.5}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 72.22%\n",
      "Resultado obtenido usando las  10 componentes más significativas y el kernel ''linear''.\n"
     ]
    }
   ],
   "source": [
    "num_features_range = list(range(10, 450, 40))\n",
    "# kernel_types = [\"linear\", \"rbf\"]\n",
    "kernel_types = [\"linear\"]\n",
    "# NO FUNCIONA SI USO RBF O POLY\n",
    "acc = 0\n",
    "\n",
    "for num_features in num_features_range:\n",
    "    for kernel in kernel_types:\n",
    "        estimator = SVC(kernel=kernel)\n",
    "        preprocess = RFE(estimator, n_features_to_select=num_features)\n",
    "\n",
    "        X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "        X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "        \n",
    "        accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "        if accuracy > acc:\n",
    "            best_num_features = num_features\n",
    "            best_kernel = kernel\n",
    "            grid = grid\n",
    "            acc = accuracy\n",
    "            \n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando las {:3d} componentes más significativas y el kernel ''{}''.\"\n",
    "      .format(best_num_features, best_kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76349e",
   "metadata": {},
   "source": [
    "### Estimador LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a46d6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.5}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n",
      "Resultado obtenido usando las 370 componentes más significativas.\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for num_features in num_features_range:\n",
    "    estimator = LinearSVC()\n",
    "    preprocess = RFE(estimator, n_features_to_select=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_num_features = num_features\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "\n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando las {:3d} componentes más significativas.\".format(best_num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce9081",
   "metadata": {},
   "source": [
    "### Estimador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdb8ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.001, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n",
      "Resultado obtenido usando las 410 componentes más significativas.\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for num_features in num_features_range:\n",
    "    estimator = RandomForestClassifier(random_state=0)\n",
    "    preprocess = RFE(estimator, n_features_to_select=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_num_features = num_features\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "\n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando las {:3d} componentes más significativas.\".format(best_num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6803bc1",
   "metadata": {},
   "source": [
    "# SelectFromModel\n",
    "\n",
    "Método muy similar al anterior, se apoya en el uso de otros estimadores para asignar pesos a las variables del conjunto para eliminar aquellas que considera menos significativas.\n",
    "\n",
    "### Estimador SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67ec0ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.5}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 72.22%\n",
      "Resultado obtenido usando las 410 componentes más significativas.\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for num_features in num_features_range:\n",
    "    estimator = SVC(kernel=\"linear\")\n",
    "    preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_num_features = num_features\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "\n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando las {:3d} componentes más significativas.\".format(best_num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d75f84",
   "metadata": {},
   "source": [
    "### Estimador LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ac15096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.5}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n",
      "Resultado obtenido usando las  90 componentes más significativas.\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for num_features in num_features_range:\n",
    "    estimator = LinearSVC()\n",
    "    preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_num_features = num_features\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "\n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando las {:3d} componentes más significativas.\".format(best_num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7dd9c",
   "metadata": {},
   "source": [
    "### Estimador RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d6eb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'learning_rate': 0.001}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=None,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.001, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 83.33%\n",
      "Resultado obtenido usando las 410 componentes más significativas.\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "for num_features in num_features_range:\n",
    "    estimator = RandomForestClassifier(random_state=0)\n",
    "    preprocess = SelectFromModel(estimator, threshold=-np.inf, max_features=num_features)\n",
    "\n",
    "    X_train_processed = preprocess.fit_transform(X_train, y_train)\n",
    "    X_test_processed = preprocess.fit_transform(X_test, y_test)\n",
    "    \n",
    "    accuracy, grid = train_model(X_train_processed, X_test_processed)\n",
    "    if accuracy > acc:\n",
    "        best_num_features = num_features\n",
    "        grid = grid\n",
    "        acc = accuracy\n",
    "\n",
    "print_results(acc, grid)\n",
    "print(\"Resultado obtenido usando las {:3d} componentes más significativas.\".format(best_num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7d2b3",
   "metadata": {},
   "source": [
    "# Resultados (accuracy):\n",
    "\n",
    "* SelectPercentile (con función de clasificación por defecto \"f_classif\") y percentil 10: 88.89%\n",
    "<br><br />\n",
    "* Normalizar (escalado norma unitaria), usando la norma \"L1\": 83.33%\n",
    "* SelectKBest (con función de clasificación por defecto \"f_classif\") y 410 componentes: 83.33%\n",
    "* SelectKBest (con función de clasificación \"mutual_info_classif\") y 10 componentes: 83.33%\n",
    "* Sin preprocesado: 83.33%\n",
    "* StandardScaler (escalado media=0, std=1): 83.33%\n",
    "* RFE con el estimador LinearSVC y 370 componentes más significativas: 83.33%\n",
    "* RFE con el estimador RandomForestClassifier y 410 componentes más significativas: 83.33%\n",
    "* SelectFromModel con el estimador LinearSVC y 90 componentes más significativas: 83.33%\n",
    "* SelectFromModel con el estimador RandomForest y 410 componentes más significativas: 83.33%\n",
    "<br><br />\n",
    "* SelectFromModel con el estimador SVC y 410 componentes más significativas: 72.22%\n",
    "* RFE con el estimador SVC (kernel lineal) y 10 componentes más significativas: 72.22%.\n",
    "<br><br />\n",
    "* SelectPercentile (con función de clasificación \"mutual_info_classif\") y percentil 60: 66.67%\n",
    "* PCA (con 16 componentes principales): 66.67%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
