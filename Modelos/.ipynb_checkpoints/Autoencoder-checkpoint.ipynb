{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37aec554",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Un modelo de autoencoder se descompone a su vez en dos modelos de redes neuronales. La primera, el encoder, tiene el objetivo de comprimir la información de los datos; la segunda, el decoder, trata de reconstruir la información original a partir de los datos comprimidos. \n",
    "\n",
    "La motivación para el estudio de un encoder en este problema es:\n",
    "1. Una vez entrenado el autoencoder completo, podemos separar las dos redes neuronales subyacentes y utilizar la parte encoder (con alguna modificación) para probar su rendimiento como modelo de red de clasificación.\n",
    "2. Para los datos de test proporcionados por la competición de Kaggle (no se dispone de la clasificación verdadera), el encoder puede ayudar a \"recrear\" sus etiquetas.\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1832fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models\n",
    "\n",
    "# Cargar los datos\n",
    "from data_and_submissions import *\n",
    "\n",
    "# Métodos para los entrenamientos con CV\n",
    "from train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74697a",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb1ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data()\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0241e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "preprocess = StandardScaler()\n",
    "\n",
    "X_train = preprocess.fit_transform(X_train)\n",
    "X_test = preprocess.fit_transform(X_test)\n",
    "test_kaggle = preprocess.fit_transform(test_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e95fe1",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "\n",
    "Para crear el autoencoder, se utilizarán redes simétricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6e6334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1404/1404 [==============================] - 9s 4ms/step - loss: 0.9612 - val_loss: 0.9479\n",
      "Epoch 2/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.9414 - val_loss: 0.9406\n",
      "Epoch 3/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.9366 - val_loss: 0.9420\n",
      "Epoch 4/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9341 - val_loss: 0.9389\n",
      "Epoch 5/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9316 - val_loss: 0.9388\n",
      "Epoch 6/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9295 - val_loss: 0.9366\n",
      "Epoch 7/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9277 - val_loss: 0.9372\n",
      "Epoch 8/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9257 - val_loss: 0.9341\n",
      "Epoch 9/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9237 - val_loss: 0.9338\n",
      "Epoch 10/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9221 - val_loss: 0.9340\n",
      "Epoch 11/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9207 - val_loss: 0.9317\n",
      "Epoch 12/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9194 - val_loss: 0.9316\n",
      "Epoch 13/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9184 - val_loss: 0.9299\n",
      "Epoch 14/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9175 - val_loss: 0.9299\n",
      "Epoch 15/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9167 - val_loss: 0.9254\n",
      "Epoch 16/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9160 - val_loss: 0.9279\n",
      "Epoch 17/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9151 - val_loss: 0.9290\n",
      "Epoch 18/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9136 - val_loss: 0.9249\n",
      "Epoch 19/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9127 - val_loss: 0.9255\n",
      "Epoch 20/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9119 - val_loss: 0.9237\n",
      "Epoch 21/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9112 - val_loss: 0.9232\n",
      "Epoch 22/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9105 - val_loss: 0.9207\n",
      "Epoch 23/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9098 - val_loss: 0.9222\n",
      "Epoch 24/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9090 - val_loss: 0.9240\n",
      "Epoch 25/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9083 - val_loss: 0.9218\n",
      "Epoch 26/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9076 - val_loss: 0.9192\n",
      "Epoch 27/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9068 - val_loss: 0.9224\n",
      "Epoch 28/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9061 - val_loss: 0.9231\n",
      "Epoch 29/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9053 - val_loss: 0.9180\n",
      "Epoch 30/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9046 - val_loss: 0.9179\n",
      "Epoch 31/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9040 - val_loss: 0.9175\n",
      "Epoch 32/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9033 - val_loss: 0.9194\n",
      "Epoch 33/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9027 - val_loss: 0.9155\n",
      "Epoch 34/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9021 - val_loss: 0.9148\n",
      "Epoch 35/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9016 - val_loss: 0.9126\n",
      "Epoch 36/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9010 - val_loss: 0.9177\n",
      "Epoch 37/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9005 - val_loss: 0.9123\n",
      "Epoch 38/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.9001 - val_loss: 0.9120\n",
      "Epoch 39/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8996 - val_loss: 0.9123\n",
      "Epoch 40/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8992 - val_loss: 0.9101\n",
      "Epoch 41/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8988 - val_loss: 0.9119\n",
      "Epoch 42/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8984 - val_loss: 0.9105\n",
      "Epoch 43/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8980 - val_loss: 0.9107\n",
      "Epoch 44/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8977 - val_loss: 0.9092\n",
      "Epoch 45/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8974 - val_loss: 0.9135\n",
      "Epoch 46/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8971 - val_loss: 0.9098\n",
      "Epoch 47/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8968 - val_loss: 0.9112\n",
      "Epoch 48/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8965 - val_loss: 0.9130\n",
      "Epoch 49/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8962 - val_loss: 0.9072\n",
      "Epoch 50/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8960 - val_loss: 0.9061\n",
      "Epoch 51/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8958 - val_loss: 0.9116\n",
      "Epoch 52/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8955 - val_loss: 0.9076\n",
      "Epoch 53/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8953 - val_loss: 0.9072\n",
      "Epoch 54/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8952 - val_loss: 0.9070\n",
      "Epoch 55/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.8950 - val_loss: 0.9062\n",
      "Epoch 56/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8948 - val_loss: 0.9071\n",
      "Epoch 57/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.8947 - val_loss: 0.9088\n",
      "Epoch 58/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8946 - val_loss: 0.9050\n",
      "Epoch 59/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8944 - val_loss: 0.9075\n",
      "Epoch 60/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8943 - val_loss: 0.9032\n",
      "Epoch 61/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8941 - val_loss: 0.9046\n",
      "Epoch 62/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8939 - val_loss: 0.9054\n",
      "Epoch 63/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8937 - val_loss: 0.9045\n",
      "Epoch 64/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.8935 - val_loss: 0.9032\n",
      "Epoch 65/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8933 - val_loss: 0.9036\n",
      "Epoch 66/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8931 - val_loss: 0.9045\n",
      "Epoch 67/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8930 - val_loss: 0.9045\n",
      "Epoch 68/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.8928 - val_loss: 0.9071\n",
      "Epoch 69/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.8927 - val_loss: 0.9019\n",
      "Epoch 70/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8925 - val_loss: 0.9007\n",
      "Epoch 71/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8923 - val_loss: 0.8999\n",
      "Epoch 72/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8922 - val_loss: 0.9042\n",
      "Epoch 73/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8920 - val_loss: 0.8995\n",
      "Epoch 74/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.8919 - val_loss: 0.9091\n",
      "Epoch 75/100\n",
      "1404/1404 [==============================] - 7s 5ms/step - loss: 0.8918 - val_loss: 0.9041\n",
      "Epoch 76/100\n",
      "1404/1404 [==============================] - 6s 5ms/step - loss: 0.8916 - val_loss: 0.8996\n",
      "Epoch 77/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8915 - val_loss: 0.9043\n",
      "Epoch 78/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8914 - val_loss: 0.9022\n",
      "Epoch 79/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8913 - val_loss: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8913 - val_loss: 0.9033\n",
      "Epoch 81/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8912 - val_loss: 0.9032\n",
      "Epoch 82/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8911 - val_loss: 0.9012\n",
      "Epoch 83/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8910 - val_loss: 0.9030\n",
      "Epoch 84/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.8910 - val_loss: 0.9030\n",
      "Epoch 85/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8909 - val_loss: 0.9032\n",
      "Epoch 86/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8908 - val_loss: 0.9054\n",
      "Epoch 87/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8908 - val_loss: 0.9022\n",
      "Epoch 88/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8908 - val_loss: 0.9013\n",
      "Epoch 89/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.8908 - val_loss: 0.9007\n",
      "Epoch 90/100\n",
      "1404/1404 [==============================] - 5s 4ms/step - loss: 0.8907 - val_loss: 0.9002\n",
      "Epoch 91/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8907 - val_loss: 0.9019\n",
      "Epoch 92/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8906 - val_loss: 0.9016\n",
      "Epoch 93/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8905 - val_loss: 0.9027\n",
      "Epoch 94/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8905 - val_loss: 0.9035\n",
      "Epoch 95/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8906 - val_loss: 0.9019\n",
      "Epoch 96/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8905 - val_loss: 0.9028\n",
      "Epoch 97/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8905 - val_loss: 0.9024\n",
      "Epoch 98/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8904 - val_loss: 0.9012\n",
      "Epoch 99/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8904 - val_loss: 0.9010\n",
      "Epoch 100/100\n",
      "1404/1404 [==============================] - 6s 4ms/step - loss: 0.8904 - val_loss: 0.9015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b62c2a7700>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "input_layer = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded = layers.Dense(200, activation=\"relu\")(input_layer)\n",
    "encoded = layers.Dense(100, activation=\"relu\")(encoded)\n",
    "encoded = layers.Dense(50, activation=\"relu\")(encoded)\n",
    "# Capas red decoder\n",
    "decoded = layers.Dense(50, activation=\"relu\")(encoded)\n",
    "decoded = layers.Dense(100, activation=\"relu\")(decoded)\n",
    "decoded = layers.Dense(200, activation=\"relu\")(decoded)\n",
    "decoded = layers.Dense(410, activation=\"linear\")(decoded)\n",
    "\n",
    "# Encoder\n",
    "encoder = models.Model(input_layer, encoded)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = models.Model(input_layer, decoded)\n",
    "\n",
    "# Compilar y entrenar el autoencoder\n",
    "autoencoder.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "autoencoder.fit(test_kaggle, test_kaggle, epochs=100, batch_size=64, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c774fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747650e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = models.load_model(\"autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946dc7",
   "metadata": {},
   "source": [
    "Evaluación del autoencoder, se utilizarán métricas como:\n",
    "\n",
    "* MSE = $\\frac{1}{n} \\sum_{i=1}^{n} (Y_{true}^{i} - Y_{pred}^{i})^{2}$\n",
    "* MAPE = $\\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{Y_{true}^{i} - Y_{pred}^{i}}{Y_{true}^{i}} \\right|$\n",
    "\n",
    "donde $Y_{true}$ es el valor real, $Y_{pred}$ el valor de la predicción y $n$ el número de predicciones.\n",
    "\n",
    "La anterior fórmula realiza el cálculo para dos \"listas de valores\", por ejemplo, podemos calcular el error MAPE por muestra o por feature. Para el valor del error de la predicción total, se debe promediar el error obtenido para todas las filas/columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbc232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import MeanSquaredError, MeanAbsolutePercentageError\n",
    "\n",
    "# Definición de las métricas\n",
    "mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "mape = MeanAbsolutePercentageError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a20e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: tf.Tensor(217.3718, shape=(), dtype=float32)\n",
      "MSE: tf.Tensor(0.8956139, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ERROR SOBRE X_train (etiquetados)\n",
    "X_train_pred = autoencoder.predict(X_train)\n",
    "\n",
    "print(\"MAPE:\", mape(X_train, X_train_pred))\n",
    "print(\"MSE:\", mse(X_train, X_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1e672",
   "metadata": {},
   "source": [
    "El error es bastante elevado. Vamos a comprobar cómo se distribuyen los valores de error MAPE en cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e45bf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 410)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_tmp = np.abs((X_train - X_train_pred) / X_train)\n",
    "mape_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "532afe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(mape_tmp.mean(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a96a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02195121951219512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mape_tmp.mean(axis=0) < 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dace6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_tmp.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd17d6",
   "metadata": {},
   "source": [
    "La anterior expresión indica que únicamente en torno al 2% de las variables en X_train, tienen un error de MAPE que es inferior al 100%. \n",
    "\n",
    "Podíamos pensar que la primera barra en el anterior histograma esconde una gran concentración de valores con errores inferiores al 100% y que el valor final queda desviado por aquellos con valores muy superiores, sin embargo, esta última comprobación lo desmiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b52107fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: tf.Tensor(355.8933, shape=(), dtype=float32)\n",
      "MSE: tf.Tensor(0.8929279, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ERROR SOBRE test_kaggle (no etiquetados)\n",
    "test_kaggle_pred = autoencoder.predict(test_kaggle)\n",
    "\n",
    "print(\"MAPE:\", mape(test_kaggle, test_kaggle_pred))\n",
    "print(\"MSE:\", mse(test_kaggle, test_kaggle_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90c952",
   "metadata": {},
   "source": [
    "Sobre el conjunto de entrenamiento ``test_kaggle``, vamos a seleccionar 100 veces 68 muestras y a promediar los valores de desviación típica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f9d3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 320.42169189453125 +- 179.11102294921875\n"
     ]
    }
   ],
   "source": [
    "samples_num = 100\n",
    "mape_samples = []\n",
    "\n",
    "for _ in range(samples_num):\n",
    "    \n",
    "    args = np.random.choice(a=np.arange(0, test_kaggle.shape[0]), size=68, replace=False)\n",
    "\n",
    "    test_kaggle_reduc = test_kaggle[args, :]\n",
    "\n",
    "    y_pred_kaggle_reduc = autoencoder.predict(test_kaggle_reduc)\n",
    "    tmp_mape = mape(test_kaggle_reduc, y_pred_kaggle_reduc)\n",
    "    mape_samples.append(tmp_mape)\n",
    "    \n",
    "print(f'MAPE: {np.mean(mape_samples)} +- {np.std(mape_samples)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692b393",
   "metadata": {},
   "source": [
    "El valor del MAPE en ``test_kaggle`` es también muy elevado, con grandes desviaciones entre muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c74a80",
   "metadata": {},
   "source": [
    "Pasamos al problema de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4813a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = layers.Input(shape=(410,))\n",
    "encoder = encoder_input\n",
    "for layer in autoencoder.layers[1:4]:\n",
    "    encoder = layer(encoder)\n",
    "encoder = models.Model(inputs=encoder_input, outputs=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "462c9a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 410)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               82200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,350\n",
      "Trainable params: 107,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa99fd",
   "metadata": {},
   "source": [
    "Una vez hemos entrenado la red autoencoder, el componente encoder de la misma ya contará con unos pesos entrenados con el objetivo de comprimir los datos de entrada. Por tanto, podemos considerar de manera independiente esta red encoder y volver a entrenarla como una red para clasificación, con la ventaja de que se parte de un modelo inicializado no con unos pesos aleatorios, sino unos pesos optimizados para un problema similar.\n",
    "\n",
    "Para hacer esto es necesario añadir previamente una capa final de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ec1b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_encoder = encoder # loading the previously saved model.\n",
    "\n",
    "new_encoder = models.Sequential()\n",
    "new_encoder.add(prev_encoder)\n",
    "new_encoder.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9630a1",
   "metadata": {},
   "source": [
    "Incluso es posible congelar los pesos de todas las capas del encoder original, ya entrenados \"para un problema similar\", y modificar solamente los pesos de la capa final de clasificación, utilizando los datos de train (etiquetados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96a1a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 169ms/step - loss: 0.7253 - acc: 0.4118 - val_loss: 0.7816 - val_acc: 0.4706\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7225 - acc: 0.4118 - val_loss: 0.7793 - val_acc: 0.4706\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7194 - acc: 0.4706 - val_loss: 0.7785 - val_acc: 0.4706\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7178 - acc: 0.4706 - val_loss: 0.7770 - val_acc: 0.4706\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7175 - acc: 0.4510 - val_loss: 0.7754 - val_acc: 0.4706\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7156 - acc: 0.4706 - val_loss: 0.7744 - val_acc: 0.4706\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7201 - acc: 0.4706 - val_loss: 0.7744 - val_acc: 0.4706\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7142 - acc: 0.4706 - val_loss: 0.7737 - val_acc: 0.4706\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7149 - acc: 0.4902 - val_loss: 0.7737 - val_acc: 0.4706\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7130 - acc: 0.4706 - val_loss: 0.7733 - val_acc: 0.4706\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7123 - acc: 0.4706 - val_loss: 0.7726 - val_acc: 0.4706\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7124 - acc: 0.4706 - val_loss: 0.7715 - val_acc: 0.4706\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7131 - acc: 0.5098 - val_loss: 0.7717 - val_acc: 0.4706\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7104 - acc: 0.4902 - val_loss: 0.7711 - val_acc: 0.4706\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7100 - acc: 0.5098 - val_loss: 0.7708 - val_acc: 0.4706\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.7093 - acc: 0.5098 - val_loss: 0.7704 - val_acc: 0.4706\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7116 - acc: 0.4902 - val_loss: 0.7692 - val_acc: 0.4706\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7091 - acc: 0.4902 - val_loss: 0.7683 - val_acc: 0.4706\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7079 - acc: 0.5294 - val_loss: 0.7676 - val_acc: 0.4706\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7074 - acc: 0.5098 - val_loss: 0.7669 - val_acc: 0.4706\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7073 - acc: 0.5098 - val_loss: 0.7662 - val_acc: 0.4706\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7058 - acc: 0.4902 - val_loss: 0.7658 - val_acc: 0.4706\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7052 - acc: 0.4902 - val_loss: 0.7654 - val_acc: 0.4706\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7059 - acc: 0.5294 - val_loss: 0.7647 - val_acc: 0.4706\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7040 - acc: 0.4902 - val_loss: 0.7643 - val_acc: 0.4706\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7033 - acc: 0.4902 - val_loss: 0.7638 - val_acc: 0.4706\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7032 - acc: 0.4902 - val_loss: 0.7631 - val_acc: 0.4706\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7022 - acc: 0.4902 - val_loss: 0.7624 - val_acc: 0.4118\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7014 - acc: 0.5098 - val_loss: 0.7621 - val_acc: 0.4706\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7010 - acc: 0.4902 - val_loss: 0.7614 - val_acc: 0.4706\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7014 - acc: 0.4902 - val_loss: 0.7613 - val_acc: 0.4706\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6993 - acc: 0.5098 - val_loss: 0.7609 - val_acc: 0.4706\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7011 - acc: 0.5098 - val_loss: 0.7610 - val_acc: 0.4706\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6982 - acc: 0.5294 - val_loss: 0.7608 - val_acc: 0.4706\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6973 - acc: 0.5294 - val_loss: 0.7600 - val_acc: 0.4706\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6966 - acc: 0.5294 - val_loss: 0.7594 - val_acc: 0.4706\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6959 - acc: 0.5294 - val_loss: 0.7587 - val_acc: 0.4706\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6956 - acc: 0.5490 - val_loss: 0.7578 - val_acc: 0.4706\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6947 - acc: 0.5098 - val_loss: 0.7571 - val_acc: 0.4706\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6943 - acc: 0.5490 - val_loss: 0.7562 - val_acc: 0.4706\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6933 - acc: 0.4902 - val_loss: 0.7560 - val_acc: 0.4706\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6922 - acc: 0.5294 - val_loss: 0.7555 - val_acc: 0.4706\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6921 - acc: 0.5490 - val_loss: 0.7546 - val_acc: 0.4706\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6918 - acc: 0.5294 - val_loss: 0.7537 - val_acc: 0.4706\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6922 - acc: 0.4902 - val_loss: 0.7530 - val_acc: 0.4118\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6901 - acc: 0.5294 - val_loss: 0.7525 - val_acc: 0.4118\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6893 - acc: 0.5098 - val_loss: 0.7523 - val_acc: 0.4706\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6896 - acc: 0.5490 - val_loss: 0.7516 - val_acc: 0.4118\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6878 - acc: 0.5294 - val_loss: 0.7512 - val_acc: 0.4706\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6872 - acc: 0.5294 - val_loss: 0.7507 - val_acc: 0.4706\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6876 - acc: 0.5294 - val_loss: 0.7500 - val_acc: 0.4118\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6869 - acc: 0.5294 - val_loss: 0.7499 - val_acc: 0.4706\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6865 - acc: 0.5294 - val_loss: 0.7492 - val_acc: 0.4706\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6848 - acc: 0.5294 - val_loss: 0.7489 - val_acc: 0.4706\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6850 - acc: 0.5490 - val_loss: 0.7482 - val_acc: 0.4706\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6838 - acc: 0.5294 - val_loss: 0.7480 - val_acc: 0.4706\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6829 - acc: 0.5490 - val_loss: 0.7475 - val_acc: 0.4706\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6830 - acc: 0.5294 - val_loss: 0.7468 - val_acc: 0.4706\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6816 - acc: 0.5294 - val_loss: 0.7463 - val_acc: 0.4706\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6835 - acc: 0.5294 - val_loss: 0.7455 - val_acc: 0.4118\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6805 - acc: 0.5294 - val_loss: 0.7451 - val_acc: 0.4706\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6812 - acc: 0.5294 - val_loss: 0.7445 - val_acc: 0.4118\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6801 - acc: 0.5294 - val_loss: 0.7440 - val_acc: 0.4118\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6797 - acc: 0.5294 - val_loss: 0.7439 - val_acc: 0.4706\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6784 - acc: 0.5294 - val_loss: 0.7434 - val_acc: 0.4706\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6777 - acc: 0.5294 - val_loss: 0.7429 - val_acc: 0.4706\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6770 - acc: 0.5294 - val_loss: 0.7424 - val_acc: 0.4706\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6764 - acc: 0.5490 - val_loss: 0.7420 - val_acc: 0.4706\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6757 - acc: 0.5490 - val_loss: 0.7416 - val_acc: 0.4706\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6749 - acc: 0.5294 - val_loss: 0.7411 - val_acc: 0.4706\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6751 - acc: 0.5490 - val_loss: 0.7403 - val_acc: 0.4706\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6736 - acc: 0.5294 - val_loss: 0.7396 - val_acc: 0.4706\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6729 - acc: 0.5490 - val_loss: 0.7390 - val_acc: 0.4706\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6723 - acc: 0.5490 - val_loss: 0.7387 - val_acc: 0.4706\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6713 - acc: 0.5490 - val_loss: 0.7381 - val_acc: 0.4706\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6705 - acc: 0.5490 - val_loss: 0.7376 - val_acc: 0.4706\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6710 - acc: 0.5490 - val_loss: 0.7375 - val_acc: 0.4706\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6690 - acc: 0.5686 - val_loss: 0.7366 - val_acc: 0.4706\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6682 - acc: 0.5686 - val_loss: 0.7361 - val_acc: 0.4706\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6691 - acc: 0.5686 - val_loss: 0.7360 - val_acc: 0.4706\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6669 - acc: 0.5686 - val_loss: 0.7355 - val_acc: 0.4706\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6662 - acc: 0.5686 - val_loss: 0.7346 - val_acc: 0.4706\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6682 - acc: 0.5490 - val_loss: 0.7346 - val_acc: 0.4706\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6659 - acc: 0.5686 - val_loss: 0.7336 - val_acc: 0.4706\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6651 - acc: 0.5686 - val_loss: 0.7329 - val_acc: 0.4706\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6638 - acc: 0.5686 - val_loss: 0.7324 - val_acc: 0.4706\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6646 - acc: 0.5686 - val_loss: 0.7317 - val_acc: 0.4706\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6628 - acc: 0.5686 - val_loss: 0.7312 - val_acc: 0.4706\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6623 - acc: 0.5686 - val_loss: 0.7308 - val_acc: 0.4706\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6618 - acc: 0.5686 - val_loss: 0.7304 - val_acc: 0.4706\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6610 - acc: 0.5882 - val_loss: 0.7299 - val_acc: 0.4706\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6609 - acc: 0.5686 - val_loss: 0.7292 - val_acc: 0.4706\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6636 - acc: 0.5882 - val_loss: 0.7285 - val_acc: 0.4706\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6601 - acc: 0.5882 - val_loss: 0.7284 - val_acc: 0.4706\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6599 - acc: 0.5882 - val_loss: 0.7284 - val_acc: 0.4706\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6585 - acc: 0.5686 - val_loss: 0.7279 - val_acc: 0.4706\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6580 - acc: 0.5686 - val_loss: 0.7275 - val_acc: 0.4706\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6605 - acc: 0.5686 - val_loss: 0.7268 - val_acc: 0.4706\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6575 - acc: 0.5882 - val_loss: 0.7262 - val_acc: 0.4706\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6573 - acc: 0.5882 - val_loss: 0.7261 - val_acc: 0.4706\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6953 - acc: 0.5556\n",
      "Accuracy: 55.56%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Congelar los pesos de todas las capas a excepción de la última\n",
    "for layer in new_encoder.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Entrenar el modelo\n",
    "new_encoder.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "new_encoder.fit(X_train, y_train, epochs=100, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = new_encoder.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1913fc",
   "metadata": {},
   "source": [
    "Tras unas pocas iteraciones, descongelamos todas las capas y hacemos unas pocas épocas más entrenando y actualizando los pesos para el modelo completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f79e6127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2/2 [==============================] - 1s 145ms/step - loss: 0.6497 - acc: 0.5882 - val_loss: 0.6712 - val_acc: 0.5882\n",
      "Epoch 2/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4456 - acc: 0.9020 - val_loss: 0.6395 - val_acc: 0.6471\n",
      "Epoch 3/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3010 - acc: 1.0000 - val_loss: 0.6127 - val_acc: 0.6471\n",
      "Epoch 4/15\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1978 - acc: 1.0000 - val_loss: 0.6085 - val_acc: 0.6471\n",
      "Epoch 5/15\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1325 - acc: 1.0000 - val_loss: 0.6328 - val_acc: 0.6471\n",
      "Epoch 6/15\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0882 - acc: 1.0000 - val_loss: 0.6038 - val_acc: 0.6471\n",
      "Epoch 7/15\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0605 - acc: 1.0000 - val_loss: 0.5902 - val_acc: 0.6471\n",
      "Epoch 8/15\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 0.6471\n",
      "Epoch 9/15\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.6306 - val_acc: 0.6471\n",
      "Epoch 10/15\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6462 - val_acc: 0.6471\n",
      "Epoch 11/15\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6632 - val_acc: 0.6471\n",
      "Epoch 12/15\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.6847 - val_acc: 0.6471\n",
      "Epoch 13/15\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.7059\n",
      "Epoch 14/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.6924 - val_acc: 0.7059\n",
      "Epoch 15/15\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.7030 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0607 - acc: 0.5000\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Descongelar los pesos de todas las capas a excepción de la última\n",
    "for layer in new_encoder.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Entrenar el modelo\n",
    "new_encoder.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "new_encoder.fit(X_train, y_train, epochs=15, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = new_encoder.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86d4c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_encoder.save(\"encoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69276e22",
   "metadata": {},
   "source": [
    "El objetivo es poder comparar con la misma configuración de red que la encoder sin utilizar los pesos pre-entrenados de esta y observar si hay mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c906d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/115\n",
      "2/2 [==============================] - 1s 142ms/step - loss: 0.6692 - acc: 0.6078 - val_loss: 0.6577 - val_acc: 0.7647\n",
      "Epoch 2/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2336 - acc: 0.9608 - val_loss: 0.6330 - val_acc: 0.8235\n",
      "Epoch 3/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1029 - acc: 1.0000 - val_loss: 0.6246 - val_acc: 0.8235\n",
      "Epoch 4/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0547 - acc: 1.0000 - val_loss: 0.6593 - val_acc: 0.8235\n",
      "Epoch 5/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.6744 - val_acc: 0.8235\n",
      "Epoch 6/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.7647\n",
      "Epoch 7/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6710 - val_acc: 0.7647\n",
      "Epoch 8/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7184 - val_acc: 0.7647\n",
      "Epoch 9/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 0.7647\n",
      "Epoch 10/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.7568 - val_acc: 0.7647\n",
      "Epoch 11/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.7808 - val_acc: 0.7647\n",
      "Epoch 12/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8111 - val_acc: 0.7647\n",
      "Epoch 13/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8182 - val_acc: 0.7647\n",
      "Epoch 14/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8349 - val_acc: 0.7647\n",
      "Epoch 15/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.8509 - val_acc: 0.7647\n",
      "Epoch 16/115\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.8708 - val_acc: 0.7647\n",
      "Epoch 17/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8928 - val_acc: 0.7647\n",
      "Epoch 18/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9056 - val_acc: 0.7647\n",
      "Epoch 19/115\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9190 - val_acc: 0.7647\n",
      "Epoch 20/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.9354 - val_acc: 0.7647\n",
      "Epoch 21/115\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 8.6060e-04 - acc: 1.0000 - val_loss: 0.9565 - val_acc: 0.7647\n",
      "Epoch 22/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 7.3657e-04 - acc: 1.0000 - val_loss: 0.9662 - val_acc: 0.7647\n",
      "Epoch 23/115\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 6.3063e-04 - acc: 1.0000 - val_loss: 0.9732 - val_acc: 0.7647\n",
      "Epoch 24/115\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.4043e-04 - acc: 1.0000 - val_loss: 0.9932 - val_acc: 0.7647\n",
      "Epoch 25/115\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 4.5978e-04 - acc: 1.0000 - val_loss: 1.0074 - val_acc: 0.7647\n",
      "Epoch 26/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.9500e-04 - acc: 1.0000 - val_loss: 1.0185 - val_acc: 0.7647\n",
      "Epoch 27/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.3958e-04 - acc: 1.0000 - val_loss: 1.0399 - val_acc: 0.7647\n",
      "Epoch 28/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.8996e-04 - acc: 1.0000 - val_loss: 1.0569 - val_acc: 0.7647\n",
      "Epoch 29/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.4937e-04 - acc: 1.0000 - val_loss: 1.0725 - val_acc: 0.7647\n",
      "Epoch 30/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.1616e-04 - acc: 1.0000 - val_loss: 1.0837 - val_acc: 0.7647\n",
      "Epoch 31/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.8743e-04 - acc: 1.0000 - val_loss: 1.0933 - val_acc: 0.7647\n",
      "Epoch 32/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6111e-04 - acc: 1.0000 - val_loss: 1.1124 - val_acc: 0.7647\n",
      "Epoch 33/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4063e-04 - acc: 1.0000 - val_loss: 1.1242 - val_acc: 0.7647\n",
      "Epoch 34/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2263e-04 - acc: 1.0000 - val_loss: 1.1376 - val_acc: 0.7647\n",
      "Epoch 35/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0717e-04 - acc: 1.0000 - val_loss: 1.1562 - val_acc: 0.7647\n",
      "Epoch 36/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 9.3457e-05 - acc: 1.0000 - val_loss: 1.1690 - val_acc: 0.7647\n",
      "Epoch 37/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 8.1818e-05 - acc: 1.0000 - val_loss: 1.1767 - val_acc: 0.7647\n",
      "Epoch 38/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 7.1423e-05 - acc: 1.0000 - val_loss: 1.1933 - val_acc: 0.7647\n",
      "Epoch 39/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 6.2580e-05 - acc: 1.0000 - val_loss: 1.2070 - val_acc: 0.7647\n",
      "Epoch 40/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 5.5064e-05 - acc: 1.0000 - val_loss: 1.2213 - val_acc: 0.7647\n",
      "Epoch 41/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.8535e-05 - acc: 1.0000 - val_loss: 1.2338 - val_acc: 0.7647\n",
      "Epoch 42/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 4.2698e-05 - acc: 1.0000 - val_loss: 1.2474 - val_acc: 0.7647\n",
      "Epoch 43/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.7546e-05 - acc: 1.0000 - val_loss: 1.2539 - val_acc: 0.7647\n",
      "Epoch 44/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.2676e-05 - acc: 1.0000 - val_loss: 1.2681 - val_acc: 0.7647\n",
      "Epoch 45/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.8614e-05 - acc: 1.0000 - val_loss: 1.2876 - val_acc: 0.7647\n",
      "Epoch 46/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.5057e-05 - acc: 1.0000 - val_loss: 1.2979 - val_acc: 0.7647\n",
      "Epoch 47/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.1897e-05 - acc: 1.0000 - val_loss: 1.3091 - val_acc: 0.7647\n",
      "Epoch 48/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.9217e-05 - acc: 1.0000 - val_loss: 1.3270 - val_acc: 0.7647\n",
      "Epoch 49/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.6748e-05 - acc: 1.0000 - val_loss: 1.3402 - val_acc: 0.7647\n",
      "Epoch 50/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.4709e-05 - acc: 1.0000 - val_loss: 1.3505 - val_acc: 0.7647\n",
      "Epoch 51/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2934e-05 - acc: 1.0000 - val_loss: 1.3647 - val_acc: 0.7647\n",
      "Epoch 52/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1330e-05 - acc: 1.0000 - val_loss: 1.3781 - val_acc: 0.7647\n",
      "Epoch 53/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0005e-05 - acc: 1.0000 - val_loss: 1.3932 - val_acc: 0.7647\n",
      "Epoch 54/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.8357e-06 - acc: 1.0000 - val_loss: 1.4027 - val_acc: 0.7647\n",
      "Epoch 55/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 7.7556e-06 - acc: 1.0000 - val_loss: 1.4203 - val_acc: 0.7647\n",
      "Epoch 56/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 6.8110e-06 - acc: 1.0000 - val_loss: 1.4311 - val_acc: 0.7647\n",
      "Epoch 57/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.9826e-06 - acc: 1.0000 - val_loss: 1.4450 - val_acc: 0.7647\n",
      "Epoch 58/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 5.2654e-06 - acc: 1.0000 - val_loss: 1.4636 - val_acc: 0.7647\n",
      "Epoch 59/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.6504e-06 - acc: 1.0000 - val_loss: 1.4715 - val_acc: 0.7647\n",
      "Epoch 60/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.1192e-06 - acc: 1.0000 - val_loss: 1.4900 - val_acc: 0.7647\n",
      "Epoch 61/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.6297e-06 - acc: 1.0000 - val_loss: 1.5045 - val_acc: 0.7647\n",
      "Epoch 62/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 3.2213e-06 - acc: 1.0000 - val_loss: 1.5180 - val_acc: 0.7647\n",
      "Epoch 63/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.8532e-06 - acc: 1.0000 - val_loss: 1.5325 - val_acc: 0.7647\n",
      "Epoch 64/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.5229e-06 - acc: 1.0000 - val_loss: 1.5448 - val_acc: 0.7647\n",
      "Epoch 65/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.2306e-06 - acc: 1.0000 - val_loss: 1.5593 - val_acc: 0.7647\n",
      "Epoch 66/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9779e-06 - acc: 1.0000 - val_loss: 1.5730 - val_acc: 0.7647\n",
      "Epoch 67/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.7591e-06 - acc: 1.0000 - val_loss: 1.5851 - val_acc: 0.7647\n",
      "Epoch 68/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.5592e-06 - acc: 1.0000 - val_loss: 1.5968 - val_acc: 0.7647\n",
      "Epoch 69/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3813e-06 - acc: 1.0000 - val_loss: 1.6088 - val_acc: 0.7647\n",
      "Epoch 70/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2282e-06 - acc: 1.0000 - val_loss: 1.6210 - val_acc: 0.7647\n",
      "Epoch 71/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0965e-06 - acc: 1.0000 - val_loss: 1.6370 - val_acc: 0.7647\n",
      "Epoch 72/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 9.7264e-07 - acc: 1.0000 - val_loss: 1.6459 - val_acc: 0.7647\n",
      "Epoch 73/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.6487e-07 - acc: 1.0000 - val_loss: 1.6567 - val_acc: 0.7647\n",
      "Epoch 74/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 7.6885e-07 - acc: 1.0000 - val_loss: 1.6692 - val_acc: 0.7647\n",
      "Epoch 75/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 6.8759e-07 - acc: 1.0000 - val_loss: 1.6821 - val_acc: 0.7647\n",
      "Epoch 76/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 6.1454e-07 - acc: 1.0000 - val_loss: 1.6950 - val_acc: 0.7647\n",
      "Epoch 77/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.4821e-07 - acc: 1.0000 - val_loss: 1.7059 - val_acc: 0.7647\n",
      "Epoch 78/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.9023e-07 - acc: 1.0000 - val_loss: 1.7183 - val_acc: 0.7647\n",
      "Epoch 79/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.3798e-07 - acc: 1.0000 - val_loss: 1.7290 - val_acc: 0.7647\n",
      "Epoch 80/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.9338e-07 - acc: 1.0000 - val_loss: 1.7403 - val_acc: 0.7647\n",
      "Epoch 81/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.5079e-07 - acc: 1.0000 - val_loss: 1.7534 - val_acc: 0.7647\n",
      "Epoch 82/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.1449e-07 - acc: 1.0000 - val_loss: 1.7667 - val_acc: 0.7647\n",
      "Epoch 83/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.8299e-07 - acc: 1.0000 - val_loss: 1.7786 - val_acc: 0.7647\n",
      "Epoch 84/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.5356e-07 - acc: 1.0000 - val_loss: 1.7930 - val_acc: 0.7647\n",
      "Epoch 85/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.2875e-07 - acc: 1.0000 - val_loss: 1.8059 - val_acc: 0.7647\n",
      "Epoch 86/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0506e-07 - acc: 1.0000 - val_loss: 1.8163 - val_acc: 0.7647\n",
      "Epoch 87/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8592e-07 - acc: 1.0000 - val_loss: 1.8313 - val_acc: 0.7647\n",
      "Epoch 88/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6679e-07 - acc: 1.0000 - val_loss: 1.8407 - val_acc: 0.7647\n",
      "Epoch 89/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.5031e-07 - acc: 1.0000 - val_loss: 1.8522 - val_acc: 0.7647\n",
      "Epoch 90/115\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3630e-07 - acc: 1.0000 - val_loss: 1.8638 - val_acc: 0.7647\n",
      "Epoch 91/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2326e-07 - acc: 1.0000 - val_loss: 1.8756 - val_acc: 0.7647\n",
      "Epoch 92/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1201e-07 - acc: 1.0000 - val_loss: 1.8865 - val_acc: 0.7647\n",
      "Epoch 93/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0236e-07 - acc: 1.0000 - val_loss: 1.8978 - val_acc: 0.7647\n",
      "Epoch 94/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 9.3184e-08 - acc: 1.0000 - val_loss: 1.9030 - val_acc: 0.7647\n",
      "Epoch 95/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 8.4780e-08 - acc: 1.0000 - val_loss: 1.9116 - val_acc: 0.7647\n",
      "Epoch 96/115\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 7.6702e-08 - acc: 1.0000 - val_loss: 1.9219 - val_acc: 0.7647\n",
      "Epoch 97/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 7.0087e-08 - acc: 1.0000 - val_loss: 1.9325 - val_acc: 0.7647\n",
      "Epoch 98/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 6.4363e-08 - acc: 1.0000 - val_loss: 1.9446 - val_acc: 0.7647\n",
      "Epoch 99/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 5.8635e-08 - acc: 1.0000 - val_loss: 1.9547 - val_acc: 0.7647\n",
      "Epoch 100/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.4427e-08 - acc: 1.0000 - val_loss: 1.9605 - val_acc: 0.7647\n",
      "Epoch 101/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.9430e-08 - acc: 1.0000 - val_loss: 1.9705 - val_acc: 0.7647\n",
      "Epoch 102/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.5539e-08 - acc: 1.0000 - val_loss: 1.9811 - val_acc: 0.7647\n",
      "Epoch 103/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.2067e-08 - acc: 1.0000 - val_loss: 1.9893 - val_acc: 0.7647\n",
      "Epoch 104/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.8967e-08 - acc: 1.0000 - val_loss: 1.9960 - val_acc: 0.7647\n",
      "Epoch 105/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.6046e-08 - acc: 1.0000 - val_loss: 2.0066 - val_acc: 0.7647\n",
      "Epoch 106/115\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.3426e-08 - acc: 1.0000 - val_loss: 2.0163 - val_acc: 0.7647\n",
      "Epoch 107/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.1217e-08 - acc: 1.0000 - val_loss: 2.0245 - val_acc: 0.7647\n",
      "Epoch 108/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.9442e-08 - acc: 1.0000 - val_loss: 2.0311 - val_acc: 0.7647\n",
      "Epoch 109/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.7401e-08 - acc: 1.0000 - val_loss: 2.0399 - val_acc: 0.7647\n",
      "Epoch 110/115\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.5918e-08 - acc: 1.0000 - val_loss: 2.0482 - val_acc: 0.7647\n",
      "Epoch 111/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.4486e-08 - acc: 1.0000 - val_loss: 2.0576 - val_acc: 0.7647\n",
      "Epoch 112/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.3133e-08 - acc: 1.0000 - val_loss: 2.0636 - val_acc: 0.7647\n",
      "Epoch 113/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.1858e-08 - acc: 1.0000 - val_loss: 2.0710 - val_acc: 0.7647\n",
      "Epoch 114/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0852e-08 - acc: 1.0000 - val_loss: 2.0802 - val_acc: 0.7647\n",
      "Epoch 115/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.9948e-08 - acc: 1.0000 - val_loss: 2.0860 - val_acc: 0.7647\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.3948 - acc: 0.6667\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "input_layer2 = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded2 = layers.Dense(200, activation=\"relu\")(input_layer2)\n",
    "encoded2 = layers.Dense(100, activation=\"relu\")(encoded2)\n",
    "encoded2 = layers.Dense(50, activation=\"relu\")(encoded2)\n",
    "encoded2 = layers.Dense(1, activation=\"sigmoid\")(encoded2)\n",
    "\n",
    "encoder2 = models.Model(input_layer2, encoded2)\n",
    "\n",
    "# Entrenar el modelo\n",
    "encoder2.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "encoder2.fit(X_train, y_train, epochs=115, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = encoder2.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364e970",
   "metadata": {},
   "source": [
    "**Vamos a probar con una configuración de autoencoder más compleja**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4a3da54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1404/1404 [==============================] - 11s 7ms/step - loss: 0.9924 - val_loss: 0.9892\n",
      "Epoch 2/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9837 - val_loss: 0.9809\n",
      "Epoch 3/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9772 - val_loss: 0.9785\n",
      "Epoch 4/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9732 - val_loss: 0.9748\n",
      "Epoch 5/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9702 - val_loss: 0.9728\n",
      "Epoch 6/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9683 - val_loss: 0.9725\n",
      "Epoch 7/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9668 - val_loss: 0.9727\n",
      "Epoch 8/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9652 - val_loss: 0.9710\n",
      "Epoch 9/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9638 - val_loss: 0.9708\n",
      "Epoch 10/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9626 - val_loss: 0.9704\n",
      "Epoch 11/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9613 - val_loss: 0.9714\n",
      "Epoch 12/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9602 - val_loss: 0.9677\n",
      "Epoch 13/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9593 - val_loss: 0.9681\n",
      "Epoch 14/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9585 - val_loss: 0.9674\n",
      "Epoch 15/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9578 - val_loss: 0.9681\n",
      "Epoch 16/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9572 - val_loss: 0.9686\n",
      "Epoch 17/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9566 - val_loss: 0.9670\n",
      "Epoch 18/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9560 - val_loss: 0.9683\n",
      "Epoch 19/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9555 - val_loss: 0.9671\n",
      "Epoch 20/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9550 - val_loss: 0.9669\n",
      "Epoch 21/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9545 - val_loss: 0.9681\n",
      "Epoch 22/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9540 - val_loss: 0.9673\n",
      "Epoch 23/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9536 - val_loss: 0.9667\n",
      "Epoch 24/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9532 - val_loss: 0.9660\n",
      "Epoch 25/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9528 - val_loss: 0.9682\n",
      "Epoch 26/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9524 - val_loss: 0.9664\n",
      "Epoch 27/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9521 - val_loss: 0.9659\n",
      "Epoch 28/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9517 - val_loss: 0.9660\n",
      "Epoch 29/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9514 - val_loss: 0.9676\n",
      "Epoch 30/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9510 - val_loss: 0.9658\n",
      "Epoch 31/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9508 - val_loss: 0.9666\n",
      "Epoch 32/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9504 - val_loss: 0.9667\n",
      "Epoch 33/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9502 - val_loss: 0.9671\n",
      "Epoch 34/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9499 - val_loss: 0.9669\n",
      "Epoch 35/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9496 - val_loss: 0.9667\n",
      "Epoch 36/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9494 - val_loss: 0.9674\n",
      "Epoch 37/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9491 - val_loss: 0.9658\n",
      "Epoch 38/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9489 - val_loss: 0.9655\n",
      "Epoch 39/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9487 - val_loss: 0.9652\n",
      "Epoch 40/200\n",
      "1404/1404 [==============================] - 16s 12ms/step - loss: 0.9485 - val_loss: 0.9672\n",
      "Epoch 41/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9482 - val_loss: 0.9653\n",
      "Epoch 42/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9480 - val_loss: 0.9658\n",
      "Epoch 43/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9479 - val_loss: 0.9657\n",
      "Epoch 44/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9477 - val_loss: 0.9657\n",
      "Epoch 45/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9475 - val_loss: 0.9656\n",
      "Epoch 46/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9473 - val_loss: 0.9657\n",
      "Epoch 47/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9471 - val_loss: 0.9665\n",
      "Epoch 48/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9470 - val_loss: 0.9655\n",
      "Epoch 49/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9468 - val_loss: 0.9642\n",
      "Epoch 50/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9467 - val_loss: 0.9655\n",
      "Epoch 51/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9466 - val_loss: 0.9661\n",
      "Epoch 52/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9464 - val_loss: 0.9650\n",
      "Epoch 53/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9463 - val_loss: 0.9668\n",
      "Epoch 54/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9461 - val_loss: 0.9648\n",
      "Epoch 55/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9460 - val_loss: 0.9649\n",
      "Epoch 56/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9459 - val_loss: 0.9669\n",
      "Epoch 57/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9457 - val_loss: 0.9651\n",
      "Epoch 58/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9456 - val_loss: 0.9640\n",
      "Epoch 59/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9455 - val_loss: 0.9647\n",
      "Epoch 60/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9454 - val_loss: 0.9661\n",
      "Epoch 61/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9453 - val_loss: 0.9655\n",
      "Epoch 62/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9452 - val_loss: 0.9649\n",
      "Epoch 63/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9451 - val_loss: 0.9648\n",
      "Epoch 64/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9451 - val_loss: 0.9650\n",
      "Epoch 65/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9450 - val_loss: 0.9657\n",
      "Epoch 66/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9449 - val_loss: 0.9637\n",
      "Epoch 67/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9449 - val_loss: 0.9653\n",
      "Epoch 68/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9448 - val_loss: 0.9657\n",
      "Epoch 69/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9447 - val_loss: 0.9641\n",
      "Epoch 70/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9446 - val_loss: 0.9637\n",
      "Epoch 71/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9446 - val_loss: 0.9647\n",
      "Epoch 72/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9445 - val_loss: 0.9642\n",
      "Epoch 73/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9445 - val_loss: 0.9632\n",
      "Epoch 74/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9444 - val_loss: 0.9631\n",
      "Epoch 75/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9444 - val_loss: 0.9638\n",
      "Epoch 76/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9443 - val_loss: 0.9633\n",
      "Epoch 77/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9443 - val_loss: 0.9638\n",
      "Epoch 78/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9442 - val_loss: 0.9635\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9442 - val_loss: 0.9632\n",
      "Epoch 80/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9441 - val_loss: 0.9628\n",
      "Epoch 81/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9441 - val_loss: 0.9628\n",
      "Epoch 82/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9441 - val_loss: 0.9636\n",
      "Epoch 83/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9440 - val_loss: 0.9624\n",
      "Epoch 84/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9440 - val_loss: 0.9636\n",
      "Epoch 85/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9439 - val_loss: 0.9634\n",
      "Epoch 86/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9439 - val_loss: 0.9623\n",
      "Epoch 87/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9440 - val_loss: 0.9633\n",
      "Epoch 88/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9439 - val_loss: 0.9650\n",
      "Epoch 89/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9438 - val_loss: 0.9640\n",
      "Epoch 90/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9438 - val_loss: 0.9639\n",
      "Epoch 91/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9438 - val_loss: 0.9637\n",
      "Epoch 92/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9438 - val_loss: 0.9621\n",
      "Epoch 93/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9438 - val_loss: 0.9635\n",
      "Epoch 94/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9437 - val_loss: 0.9625\n",
      "Epoch 95/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9437 - val_loss: 0.9630\n",
      "Epoch 96/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9437 - val_loss: 0.9621\n",
      "Epoch 97/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9437 - val_loss: 0.9629\n",
      "Epoch 98/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9437 - val_loss: 0.9624\n",
      "Epoch 99/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9437 - val_loss: 0.9622\n",
      "Epoch 100/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9437 - val_loss: 0.9625\n",
      "Epoch 101/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9438 - val_loss: 0.9615\n",
      "Epoch 102/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9438 - val_loss: 0.9643\n",
      "Epoch 103/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9439 - val_loss: 0.9616\n",
      "Epoch 104/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9438 - val_loss: 0.9629\n",
      "Epoch 105/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9439 - val_loss: 0.9618\n",
      "Epoch 106/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9439 - val_loss: 0.9635\n",
      "Epoch 107/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9438 - val_loss: 0.9613\n",
      "Epoch 108/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9438 - val_loss: 0.9610\n",
      "Epoch 109/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9438 - val_loss: 0.9605\n",
      "Epoch 110/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9441 - val_loss: 0.9638\n",
      "Epoch 111/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9442 - val_loss: 0.9614\n",
      "Epoch 112/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9440 - val_loss: 0.9616\n",
      "Epoch 113/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9440 - val_loss: 0.9637\n",
      "Epoch 114/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9441 - val_loss: 0.9619\n",
      "Epoch 115/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9441 - val_loss: 0.9620\n",
      "Epoch 116/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9442 - val_loss: 0.9616\n",
      "Epoch 117/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9441 - val_loss: 0.9626\n",
      "Epoch 118/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9442 - val_loss: 0.9617\n",
      "Epoch 119/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9442 - val_loss: 0.9611\n",
      "Epoch 120/200\n",
      "1404/1404 [==============================] - 11s 8ms/step - loss: 0.9444 - val_loss: 0.9617\n",
      "Epoch 121/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9443 - val_loss: 0.9609\n",
      "Epoch 122/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9445 - val_loss: 0.9616\n",
      "Epoch 123/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9446 - val_loss: 0.9629\n",
      "Epoch 124/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9447 - val_loss: 0.9614\n",
      "Epoch 125/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9447 - val_loss: 0.9604\n",
      "Epoch 126/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9449 - val_loss: 0.9633\n",
      "Epoch 127/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9450 - val_loss: 0.9619\n",
      "Epoch 128/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9452 - val_loss: 0.9599\n",
      "Epoch 129/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9452 - val_loss: 0.9620\n",
      "Epoch 130/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9452 - val_loss: 0.9603\n",
      "Epoch 131/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9452 - val_loss: 0.9621\n",
      "Epoch 132/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9454 - val_loss: 0.9601\n",
      "Epoch 133/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9454 - val_loss: 0.9600\n",
      "Epoch 134/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9455 - val_loss: 0.9612\n",
      "Epoch 135/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9457 - val_loss: 0.9607\n",
      "Epoch 136/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9458 - val_loss: 0.9598\n",
      "Epoch 137/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9460 - val_loss: 0.9616\n",
      "Epoch 138/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9458 - val_loss: 0.9625\n",
      "Epoch 139/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9458 - val_loss: 0.9615\n",
      "Epoch 140/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9460 - val_loss: 0.9598\n",
      "Epoch 141/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9462 - val_loss: 0.9621\n",
      "Epoch 142/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9466 - val_loss: 0.9610\n",
      "Epoch 143/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9469 - val_loss: 0.9621\n",
      "Epoch 144/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9470 - val_loss: 0.9606\n",
      "Epoch 145/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9467 - val_loss: 0.9607\n",
      "Epoch 146/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9467 - val_loss: 0.9611\n",
      "Epoch 147/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9468 - val_loss: 0.9611\n",
      "Epoch 148/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9470 - val_loss: 0.9605\n",
      "Epoch 149/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9469 - val_loss: 0.9593\n",
      "Epoch 150/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9467 - val_loss: 0.9605\n",
      "Epoch 151/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9466 - val_loss: 0.9614\n",
      "Epoch 152/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.9467 - val_loss: 0.9600\n",
      "Epoch 153/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9466 - val_loss: 0.9603\n",
      "Epoch 154/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9468 - val_loss: 0.9603\n",
      "Epoch 155/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9466 - val_loss: 0.9614\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9467 - val_loss: 0.9594\n",
      "Epoch 157/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9470 - val_loss: 0.9615\n",
      "Epoch 158/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9472 - val_loss: 0.9616\n",
      "Epoch 159/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9470 - val_loss: 0.9609\n",
      "Epoch 160/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9465 - val_loss: 0.9600\n",
      "Epoch 161/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9469 - val_loss: 0.9611\n",
      "Epoch 162/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9470 - val_loss: 0.9596\n",
      "Epoch 163/200\n",
      "1404/1404 [==============================] - 12s 8ms/step - loss: 0.9469 - val_loss: 0.9587\n",
      "Epoch 164/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9471 - val_loss: 0.9597\n",
      "Epoch 165/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9473 - val_loss: 0.9590\n",
      "Epoch 166/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9473 - val_loss: 0.9589\n",
      "Epoch 167/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9475 - val_loss: 0.9601\n",
      "Epoch 168/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9473 - val_loss: 0.9637\n",
      "Epoch 169/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9474 - val_loss: 0.9590\n",
      "Epoch 170/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9475 - val_loss: 0.9593\n",
      "Epoch 171/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9475 - val_loss: 0.9608\n",
      "Epoch 172/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9476 - val_loss: 0.9596\n",
      "Epoch 173/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9472 - val_loss: 0.9609\n",
      "Epoch 174/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9474 - val_loss: 0.9592\n",
      "Epoch 175/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9472 - val_loss: 0.9612\n",
      "Epoch 176/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9475 - val_loss: 0.9584\n",
      "Epoch 177/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9480 - val_loss: 0.9584\n",
      "Epoch 178/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9478 - val_loss: 0.9606\n",
      "Epoch 179/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9479 - val_loss: 0.9601\n",
      "Epoch 180/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9478 - val_loss: 0.9602\n",
      "Epoch 181/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9478 - val_loss: 0.9584\n",
      "Epoch 182/200\n",
      "1404/1404 [==============================] - 15s 10ms/step - loss: 0.9477 - val_loss: 0.9605\n",
      "Epoch 183/200\n",
      "1404/1404 [==============================] - 14s 10ms/step - loss: 0.9481 - val_loss: 0.9607\n",
      "Epoch 184/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9485 - val_loss: 0.9590\n",
      "Epoch 185/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9481 - val_loss: 0.9606\n",
      "Epoch 186/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9482 - val_loss: 0.9604\n",
      "Epoch 187/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9482 - val_loss: 0.9618\n",
      "Epoch 188/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9485 - val_loss: 0.9612\n",
      "Epoch 189/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9488 - val_loss: 0.9588\n",
      "Epoch 190/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9484 - val_loss: 0.9613\n",
      "Epoch 191/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9486 - val_loss: 0.9596\n",
      "Epoch 192/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9484 - val_loss: 0.9578\n",
      "Epoch 193/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9487 - val_loss: 0.9600\n",
      "Epoch 194/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9488 - val_loss: 0.9584\n",
      "Epoch 195/200\n",
      "1404/1404 [==============================] - 13s 10ms/step - loss: 0.9491 - val_loss: 0.9608\n",
      "Epoch 196/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9487 - val_loss: 0.9620\n",
      "Epoch 197/200\n",
      "1404/1404 [==============================] - 12s 9ms/step - loss: 0.9489 - val_loss: 0.9601\n",
      "Epoch 198/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9488 - val_loss: 0.9596\n",
      "Epoch 199/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9492 - val_loss: 0.9593\n",
      "Epoch 200/200\n",
      "1404/1404 [==============================] - 13s 9ms/step - loss: 0.9493 - val_loss: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b62f6b2a60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "input_layer3 = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded3 = layers.Dense(300, activation=\"relu\")(input_layer3)\n",
    "encoded3 = layers.Dense(250, activation=\"relu\")(encoded3)\n",
    "encoded3 = layers.Dense(200, activation=\"relu\")(encoded3)\n",
    "encoded3 = layers.Dense(150, activation=\"relu\")(encoded3)\n",
    "encoded3 = layers.Dense(100, activation=\"relu\")(encoded3)\n",
    "encoded3 = layers.Dense(50, activation=\"relu\")(encoded3)\n",
    "# Capas red decoder\n",
    "decoded3 = layers.Dense(50, activation=\"relu\")(encoded3)\n",
    "decoded3 = layers.Dense(100, activation=\"relu\")(decoded3)\n",
    "decoded3 = layers.Dense(150, activation=\"relu\")(decoded3)\n",
    "decoded3 = layers.Dense(200, activation=\"relu\")(decoded3)\n",
    "decoded3 = layers.Dense(250, activation=\"relu\")(decoded3)\n",
    "decoded3 = layers.Dense(300, activation=\"relu\")(decoded3)\n",
    "decoded3 = layers.Dense(410, activation=\"linear\")(decoded3)\n",
    "\n",
    "# Encoder\n",
    "encoder3 = models.Model(input_layer3, encoded3)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder3 = models.Model(input_layer3, decoded3)\n",
    "\n",
    "# Compilar y entrenar el autoencoder\n",
    "autoencoder3.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "autoencoder3.fit(test_kaggle, test_kaggle, epochs=200, batch_size=64, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cac4d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder3.save(\"autoencoder3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b26090fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: tf.Tensor(194.89369, shape=(), dtype=float32)\n",
      "MSE: tf.Tensor(0.9512661, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ERROR SOBRE X_train (etiquetados)\n",
    "X_train_pred = autoencoder3.predict(X_train)\n",
    "\n",
    "print(\"MAPE:\", mape(X_train, X_train_pred))\n",
    "print(\"MSE:\", mse(X_train, X_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5379c7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: tf.Tensor(276.24133, shape=(), dtype=float32)\n",
      "MSE: tf.Tensor(0.9518892, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ERROR SOBRE X_train (etiquetados)\n",
    "test_kaggle_pred = autoencoder3.predict(test_kaggle)\n",
    "\n",
    "print(\"MAPE:\", mape(test_kaggle, test_kaggle_pred))\n",
    "print(\"MSE:\", mse(test_kaggle, test_kaggle_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7608b",
   "metadata": {},
   "source": [
    "En este caso, aumentar la complejidad del autoencoder apenas mejora los resultados.\n",
    "\n",
    "Vamos a ver si se observa algún tipo de mejoría en los resultados de la red de clasificación (encoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebcb4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input3 = layers.Input(shape=(410,))\n",
    "encoder3 = encoder_input3\n",
    "for layer in autoencoder3.layers[1:7]:\n",
    "    encoder3 = layer(encoder3)\n",
    "encoder3 = models.Model(inputs=encoder_input3, outputs=encoder3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88afd9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 410)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               123300    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 250)               75250     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 200)               50200     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,050\n",
      "Trainable params: 299,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f591180",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_encoder3 = encoder3 # loading the previously saved model.\n",
    "\n",
    "new_encoder3 = models.Sequential()\n",
    "new_encoder3.add(prev_encoder3)\n",
    "new_encoder3.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3e3d717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 639ms/step - loss: 2.9597 - acc: 0.4706 - val_loss: 3.3962 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 2.8545 - acc: 0.4706 - val_loss: 3.3204 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.7850 - acc: 0.4902 - val_loss: 3.2607 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.7272 - acc: 0.4902 - val_loss: 3.2058 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.6751 - acc: 0.4706 - val_loss: 3.1561 - val_acc: 0.5882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.6277 - acc: 0.4706 - val_loss: 3.1090 - val_acc: 0.5882\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.5855 - acc: 0.4314 - val_loss: 3.0588 - val_acc: 0.5882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.5405 - acc: 0.4314 - val_loss: 3.0242 - val_acc: 0.5882\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.5055 - acc: 0.4314 - val_loss: 2.9836 - val_acc: 0.5882\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.4682 - acc: 0.4314 - val_loss: 2.9506 - val_acc: 0.5882\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.4364 - acc: 0.4314 - val_loss: 2.9169 - val_acc: 0.5882\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.4079 - acc: 0.4314 - val_loss: 2.8911 - val_acc: 0.5882\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.3777 - acc: 0.4314 - val_loss: 2.8539 - val_acc: 0.5294\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.3432 - acc: 0.4314 - val_loss: 2.8234 - val_acc: 0.5294\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.3131 - acc: 0.4314 - val_loss: 2.7918 - val_acc: 0.5294\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.2834 - acc: 0.4314 - val_loss: 2.7597 - val_acc: 0.5294\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.2571 - acc: 0.3922 - val_loss: 2.7366 - val_acc: 0.5294\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.2330 - acc: 0.4118 - val_loss: 2.7134 - val_acc: 0.5294\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.2034 - acc: 0.4118 - val_loss: 2.6855 - val_acc: 0.4706\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.1759 - acc: 0.4118 - val_loss: 2.6598 - val_acc: 0.4706\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1496 - acc: 0.4118 - val_loss: 2.6334 - val_acc: 0.4706\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.1221 - acc: 0.4118 - val_loss: 2.6025 - val_acc: 0.4706\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0934 - acc: 0.4314 - val_loss: 2.5721 - val_acc: 0.4706\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.0675 - acc: 0.4314 - val_loss: 2.5488 - val_acc: 0.4706\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0408 - acc: 0.4314 - val_loss: 2.5202 - val_acc: 0.4706\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.0137 - acc: 0.4314 - val_loss: 2.4878 - val_acc: 0.4706\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.9872 - acc: 0.4314 - val_loss: 2.4685 - val_acc: 0.4706\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.9634 - acc: 0.4510 - val_loss: 2.4466 - val_acc: 0.4706\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.9386 - acc: 0.4510 - val_loss: 2.4216 - val_acc: 0.4706\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.9137 - acc: 0.4314 - val_loss: 2.3970 - val_acc: 0.4706\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.8868 - acc: 0.4314 - val_loss: 2.3696 - val_acc: 0.4706\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.8613 - acc: 0.4314 - val_loss: 2.3453 - val_acc: 0.4706\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.8372 - acc: 0.4314 - val_loss: 2.3161 - val_acc: 0.4706\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.8099 - acc: 0.4314 - val_loss: 2.2890 - val_acc: 0.4706\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.7879 - acc: 0.4314 - val_loss: 2.2692 - val_acc: 0.4706\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.7638 - acc: 0.4314 - val_loss: 2.2453 - val_acc: 0.4706\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.7396 - acc: 0.4314 - val_loss: 2.2228 - val_acc: 0.4706\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.7169 - acc: 0.4510 - val_loss: 2.1994 - val_acc: 0.4706\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.6932 - acc: 0.4902 - val_loss: 2.1773 - val_acc: 0.4706\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.6728 - acc: 0.4902 - val_loss: 2.1569 - val_acc: 0.4706\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.6496 - acc: 0.5098 - val_loss: 2.1371 - val_acc: 0.4706\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.6284 - acc: 0.5098 - val_loss: 2.1156 - val_acc: 0.4706\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.6069 - acc: 0.5098 - val_loss: 2.0957 - val_acc: 0.4706\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.5862 - acc: 0.5098 - val_loss: 2.0774 - val_acc: 0.4706\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.5674 - acc: 0.5098 - val_loss: 2.0605 - val_acc: 0.4706\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5462 - acc: 0.5098 - val_loss: 2.0423 - val_acc: 0.4118\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.5262 - acc: 0.5098 - val_loss: 2.0211 - val_acc: 0.4118\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.5056 - acc: 0.5098 - val_loss: 2.0032 - val_acc: 0.4118\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4848 - acc: 0.5098 - val_loss: 1.9838 - val_acc: 0.4118\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.4655 - acc: 0.5098 - val_loss: 1.9635 - val_acc: 0.4118\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.4453 - acc: 0.5098 - val_loss: 1.9431 - val_acc: 0.4118\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.4253 - acc: 0.5294 - val_loss: 1.9215 - val_acc: 0.4118\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.4070 - acc: 0.4902 - val_loss: 1.9073 - val_acc: 0.4118\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.3866 - acc: 0.5294 - val_loss: 1.8847 - val_acc: 0.4118\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3664 - acc: 0.5098 - val_loss: 1.8693 - val_acc: 0.4118\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.3458 - acc: 0.5294 - val_loss: 1.8491 - val_acc: 0.4118\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.3266 - acc: 0.5490 - val_loss: 1.8289 - val_acc: 0.4118\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3107 - acc: 0.5098 - val_loss: 1.8178 - val_acc: 0.4118\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.2896 - acc: 0.5490 - val_loss: 1.7991 - val_acc: 0.4118\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.2719 - acc: 0.5490 - val_loss: 1.7843 - val_acc: 0.4118\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2557 - acc: 0.5490 - val_loss: 1.7679 - val_acc: 0.4118\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.2430 - acc: 0.5490 - val_loss: 1.7553 - val_acc: 0.4118\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 31ms/step - loss: 1.2240 - acc: 0.5686 - val_loss: 1.7412 - val_acc: 0.4118\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2057 - acc: 0.5686 - val_loss: 1.7218 - val_acc: 0.4118\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1874 - acc: 0.5686 - val_loss: 1.7064 - val_acc: 0.4118\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1715 - acc: 0.5686 - val_loss: 1.6892 - val_acc: 0.4118\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1563 - acc: 0.5882 - val_loss: 1.6774 - val_acc: 0.4118\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1400 - acc: 0.5882 - val_loss: 1.6592 - val_acc: 0.4118\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1.1227 - acc: 0.5882 - val_loss: 1.6443 - val_acc: 0.4118\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1054 - acc: 0.5882 - val_loss: 1.6304 - val_acc: 0.4118\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0893 - acc: 0.5882 - val_loss: 1.6167 - val_acc: 0.4118\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0733 - acc: 0.5882 - val_loss: 1.5984 - val_acc: 0.4118\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0561 - acc: 0.5882 - val_loss: 1.5854 - val_acc: 0.4118\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0403 - acc: 0.5882 - val_loss: 1.5717 - val_acc: 0.4118\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0255 - acc: 0.5882 - val_loss: 1.5591 - val_acc: 0.4118\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0119 - acc: 0.5686 - val_loss: 1.5469 - val_acc: 0.4706\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.9962 - acc: 0.5686 - val_loss: 1.5304 - val_acc: 0.4706\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.9802 - acc: 0.5686 - val_loss: 1.5178 - val_acc: 0.4706\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.9661 - acc: 0.5686 - val_loss: 1.5012 - val_acc: 0.4706\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9517 - acc: 0.5686 - val_loss: 1.4840 - val_acc: 0.4706\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.9339 - acc: 0.5686 - val_loss: 1.4710 - val_acc: 0.4706\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9208 - acc: 0.5686 - val_loss: 1.4624 - val_acc: 0.4706\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.9098 - acc: 0.5686 - val_loss: 1.4471 - val_acc: 0.4706\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8944 - acc: 0.5686 - val_loss: 1.4358 - val_acc: 0.4706\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8845 - acc: 0.5686 - val_loss: 1.4290 - val_acc: 0.4706\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8695 - acc: 0.5686 - val_loss: 1.4171 - val_acc: 0.4706\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8589 - acc: 0.5686 - val_loss: 1.4083 - val_acc: 0.4706\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8460 - acc: 0.5686 - val_loss: 1.4004 - val_acc: 0.4706\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8353 - acc: 0.5686 - val_loss: 1.3910 - val_acc: 0.4706\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8219 - acc: 0.5686 - val_loss: 1.3769 - val_acc: 0.4706\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8090 - acc: 0.5490 - val_loss: 1.3643 - val_acc: 0.4118\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7992 - acc: 0.5490 - val_loss: 1.3578 - val_acc: 0.4706\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7909 - acc: 0.5490 - val_loss: 1.3516 - val_acc: 0.4706\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7813 - acc: 0.5490 - val_loss: 1.3379 - val_acc: 0.4118\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7706 - acc: 0.5686 - val_loss: 1.3254 - val_acc: 0.4118\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7569 - acc: 0.5686 - val_loss: 1.3146 - val_acc: 0.4118\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7465 - acc: 0.5686 - val_loss: 1.3051 - val_acc: 0.4118\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7394 - acc: 0.5686 - val_loss: 1.3013 - val_acc: 0.4118\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 239ms/step - loss: 0.7283 - acc: 0.5686 - val_loss: 1.2928 - val_acc: 0.4706\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7200 - acc: 0.5686 - val_loss: 1.2806 - val_acc: 0.4118\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5421 - acc: 0.5000\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Congelar los pesos de todas las capas a excepción de la última\n",
    "for layer in new_encoder3.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Entrenar el modelo\n",
    "new_encoder3.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "new_encoder3.fit(X_train, y_train, epochs=100, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = new_encoder3.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef566bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2/2 [==============================] - 8s 172ms/step - loss: 0.6574 - acc: 0.6275 - val_loss: 0.9287 - val_acc: 0.6471\n",
      "Epoch 2/15\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2716 - acc: 0.8824 - val_loss: 0.8215 - val_acc: 0.5294\n",
      "Epoch 3/15\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1306 - acc: 0.9804 - val_loss: 0.7821 - val_acc: 0.6471\n",
      "Epoch 4/15\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0807 - acc: 1.0000 - val_loss: 0.8131 - val_acc: 0.6471\n",
      "Epoch 5/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0536 - acc: 1.0000 - val_loss: 0.8580 - val_acc: 0.5882\n",
      "Epoch 6/15\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.8129 - val_acc: 0.7059\n",
      "Epoch 7/15\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.7860 - val_acc: 0.7059\n",
      "Epoch 8/15\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.8157 - val_acc: 0.7059\n",
      "Epoch 9/15\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.8184 - val_acc: 0.7059\n",
      "Epoch 10/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.8237 - val_acc: 0.7059\n",
      "Epoch 11/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.8260 - val_acc: 0.7059\n",
      "Epoch 12/15\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.8445 - val_acc: 0.7059\n",
      "Epoch 13/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.8374 - val_acc: 0.7059\n",
      "Epoch 14/15\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.8535 - val_acc: 0.7059\n",
      "Epoch 15/15\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.8515 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.8312 - acc: 0.5000\n",
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Descongelar los pesos de todas las capas a excepción de la última\n",
    "for layer in new_encoder3.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Entrenar el modelo\n",
    "new_encoder3.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "new_encoder3.fit(X_train, y_train, epochs=15, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = new_encoder3.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "358a4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_encoder3.save(\"encoder3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8ec5fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/115\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 0.6755 - acc: 0.5882 - val_loss: 0.6710 - val_acc: 0.7059\n",
      "Epoch 2/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3437 - acc: 0.8824 - val_loss: 0.7513 - val_acc: 0.7647\n",
      "Epoch 3/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0859 - acc: 0.9804 - val_loss: 1.7384 - val_acc: 0.5882\n",
      "Epoch 4/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2443 - acc: 0.9412 - val_loss: 0.8544 - val_acc: 0.7647\n",
      "Epoch 5/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.8227 - val_acc: 0.8235\n",
      "Epoch 6/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.8533 - val_acc: 0.8235\n",
      "Epoch 7/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.8755 - val_acc: 0.8235\n",
      "Epoch 8/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.9049 - val_acc: 0.8235\n",
      "Epoch 9/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.9323 - val_acc: 0.8235\n",
      "Epoch 10/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9565 - val_acc: 0.8235\n",
      "Epoch 11/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.9822 - val_acc: 0.8235\n",
      "Epoch 12/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0117 - val_acc: 0.8235\n",
      "Epoch 13/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.0354 - val_acc: 0.8235\n",
      "Epoch 14/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 8.1135e-04 - acc: 1.0000 - val_loss: 1.0588 - val_acc: 0.8235\n",
      "Epoch 15/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 6.5987e-04 - acc: 1.0000 - val_loss: 1.0819 - val_acc: 0.8235\n",
      "Epoch 16/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.3672e-04 - acc: 1.0000 - val_loss: 1.1042 - val_acc: 0.8235\n",
      "Epoch 17/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.4313e-04 - acc: 1.0000 - val_loss: 1.1298 - val_acc: 0.8235\n",
      "Epoch 18/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.6163e-04 - acc: 1.0000 - val_loss: 1.1525 - val_acc: 0.8235\n",
      "Epoch 19/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.9667e-04 - acc: 1.0000 - val_loss: 1.1737 - val_acc: 0.8235\n",
      "Epoch 20/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.4696e-04 - acc: 1.0000 - val_loss: 1.1960 - val_acc: 0.8235\n",
      "Epoch 21/115\n",
      "2/2 [==============================] - 1s 984ms/step - loss: 2.0462e-04 - acc: 1.0000 - val_loss: 1.2188 - val_acc: 0.8235\n",
      "Epoch 22/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7023e-04 - acc: 1.0000 - val_loss: 1.2390 - val_acc: 0.8235\n",
      "Epoch 23/115\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.4151e-04 - acc: 1.0000 - val_loss: 1.2567 - val_acc: 0.8235\n",
      "Epoch 24/115\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1839e-04 - acc: 1.0000 - val_loss: 1.2784 - val_acc: 0.8235\n",
      "Epoch 25/115\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9.8109e-05 - acc: 1.0000 - val_loss: 1.2964 - val_acc: 0.8235\n",
      "Epoch 26/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 8.2558e-05 - acc: 1.0000 - val_loss: 1.3124 - val_acc: 0.8235\n",
      "Epoch 27/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 6.9319e-05 - acc: 1.0000 - val_loss: 1.3319 - val_acc: 0.8235\n",
      "Epoch 28/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 5.8634e-05 - acc: 1.0000 - val_loss: 1.3501 - val_acc: 0.8235\n",
      "Epoch 29/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.9470e-05 - acc: 1.0000 - val_loss: 1.3677 - val_acc: 0.8235\n",
      "Epoch 30/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 4.2004e-05 - acc: 1.0000 - val_loss: 1.3878 - val_acc: 0.8235\n",
      "Epoch 31/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.5388e-05 - acc: 1.0000 - val_loss: 1.4042 - val_acc: 0.8235\n",
      "Epoch 32/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.9855e-05 - acc: 1.0000 - val_loss: 1.4233 - val_acc: 0.8235\n",
      "Epoch 33/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.5447e-05 - acc: 1.0000 - val_loss: 1.4413 - val_acc: 0.8235\n",
      "Epoch 34/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.1576e-05 - acc: 1.0000 - val_loss: 1.4603 - val_acc: 0.8235\n",
      "Epoch 35/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.8436e-05 - acc: 1.0000 - val_loss: 1.4807 - val_acc: 0.8235\n",
      "Epoch 36/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.5711e-05 - acc: 1.0000 - val_loss: 1.4996 - val_acc: 0.8235\n",
      "Epoch 37/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.3446e-05 - acc: 1.0000 - val_loss: 1.5154 - val_acc: 0.8235\n",
      "Epoch 38/115\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1432e-05 - acc: 1.0000 - val_loss: 1.5372 - val_acc: 0.8235\n",
      "Epoch 39/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 9.7598e-06 - acc: 1.0000 - val_loss: 1.5552 - val_acc: 0.8235\n",
      "Epoch 40/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 8.4250e-06 - acc: 1.0000 - val_loss: 1.5715 - val_acc: 0.8235\n",
      "Epoch 41/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 7.3294e-06 - acc: 1.0000 - val_loss: 1.5892 - val_acc: 0.8235\n",
      "Epoch 42/115\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 6.3445e-06 - acc: 1.0000 - val_loss: 1.6077 - val_acc: 0.8235\n",
      "Epoch 43/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.4825e-06 - acc: 1.0000 - val_loss: 1.6265 - val_acc: 0.8235\n",
      "Epoch 44/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 4.7287e-06 - acc: 1.0000 - val_loss: 1.6473 - val_acc: 0.8235\n",
      "Epoch 45/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.0414e-06 - acc: 1.0000 - val_loss: 1.6659 - val_acc: 0.8235\n",
      "Epoch 46/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.5160e-06 - acc: 1.0000 - val_loss: 1.6847 - val_acc: 0.8235\n",
      "Epoch 47/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.0459e-06 - acc: 1.0000 - val_loss: 1.7015 - val_acc: 0.8235\n",
      "Epoch 48/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.6594e-06 - acc: 1.0000 - val_loss: 1.7211 - val_acc: 0.8235\n",
      "Epoch 49/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.3103e-06 - acc: 1.0000 - val_loss: 1.7402 - val_acc: 0.8235\n",
      "Epoch 50/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0052e-06 - acc: 1.0000 - val_loss: 1.7577 - val_acc: 0.8235\n",
      "Epoch 51/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.7569e-06 - acc: 1.0000 - val_loss: 1.7727 - val_acc: 0.8235\n",
      "Epoch 52/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.5448e-06 - acc: 1.0000 - val_loss: 1.7899 - val_acc: 0.8235\n",
      "Epoch 53/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.3573e-06 - acc: 1.0000 - val_loss: 1.8075 - val_acc: 0.8235\n",
      "Epoch 54/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1840e-06 - acc: 1.0000 - val_loss: 1.8238 - val_acc: 0.8235\n",
      "Epoch 55/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0347e-06 - acc: 1.0000 - val_loss: 1.8416 - val_acc: 0.8235\n",
      "Epoch 56/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 9.0479e-07 - acc: 1.0000 - val_loss: 1.8572 - val_acc: 0.8235\n",
      "Epoch 57/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 7.8759e-07 - acc: 1.0000 - val_loss: 1.8719 - val_acc: 0.8235\n",
      "Epoch 58/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 6.8707e-07 - acc: 1.0000 - val_loss: 1.8900 - val_acc: 0.8235\n",
      "Epoch 59/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 6.0313e-07 - acc: 1.0000 - val_loss: 1.9036 - val_acc: 0.8235\n",
      "Epoch 60/115\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.3211e-07 - acc: 1.0000 - val_loss: 1.9235 - val_acc: 0.8235\n",
      "Epoch 61/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.6518e-07 - acc: 1.0000 - val_loss: 1.9378 - val_acc: 0.8235\n",
      "Epoch 62/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step - loss: 4.1236e-07 - acc: 1.0000 - val_loss: 1.9559 - val_acc: 0.8235\n",
      "Epoch 63/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.6325e-07 - acc: 1.0000 - val_loss: 1.9725 - val_acc: 0.8235\n",
      "Epoch 64/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.2404e-07 - acc: 1.0000 - val_loss: 1.9840 - val_acc: 0.8235\n",
      "Epoch 65/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.8882e-07 - acc: 1.0000 - val_loss: 2.0010 - val_acc: 0.8235\n",
      "Epoch 66/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.5654e-07 - acc: 1.0000 - val_loss: 2.0178 - val_acc: 0.8235\n",
      "Epoch 67/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.2762e-07 - acc: 1.0000 - val_loss: 2.0313 - val_acc: 0.8235\n",
      "Epoch 68/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0260e-07 - acc: 1.0000 - val_loss: 2.0441 - val_acc: 0.8235\n",
      "Epoch 69/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.8126e-07 - acc: 1.0000 - val_loss: 2.0595 - val_acc: 0.8235\n",
      "Epoch 70/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.6142e-07 - acc: 1.0000 - val_loss: 2.0732 - val_acc: 0.8235\n",
      "Epoch 71/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.4483e-07 - acc: 1.0000 - val_loss: 2.0898 - val_acc: 0.8235\n",
      "Epoch 72/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2844e-07 - acc: 1.0000 - val_loss: 2.1039 - val_acc: 0.8235\n",
      "Epoch 73/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1393e-07 - acc: 1.0000 - val_loss: 2.1170 - val_acc: 0.8235\n",
      "Epoch 74/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0233e-07 - acc: 1.0000 - val_loss: 2.1285 - val_acc: 0.8235\n",
      "Epoch 75/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 9.2224e-08 - acc: 1.0000 - val_loss: 2.1402 - val_acc: 0.8235\n",
      "Epoch 76/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 8.3591e-08 - acc: 1.0000 - val_loss: 2.1522 - val_acc: 0.8235\n",
      "Epoch 77/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7.5536e-08 - acc: 1.0000 - val_loss: 2.1638 - val_acc: 0.8235\n",
      "Epoch 78/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 6.8487e-08 - acc: 1.0000 - val_loss: 2.1739 - val_acc: 0.8235\n",
      "Epoch 79/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.1905e-08 - acc: 1.0000 - val_loss: 2.1849 - val_acc: 0.8235\n",
      "Epoch 80/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.6360e-08 - acc: 1.0000 - val_loss: 2.1938 - val_acc: 0.8235\n",
      "Epoch 81/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 5.0738e-08 - acc: 1.0000 - val_loss: 2.2057 - val_acc: 0.8235\n",
      "Epoch 82/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 4.6473e-08 - acc: 1.0000 - val_loss: 2.2186 - val_acc: 0.8235\n",
      "Epoch 83/115\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.2086e-08 - acc: 1.0000 - val_loss: 2.2300 - val_acc: 0.8235\n",
      "Epoch 84/115\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.8579e-08 - acc: 1.0000 - val_loss: 2.2430 - val_acc: 0.8235\n",
      "Epoch 85/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.5106e-08 - acc: 1.0000 - val_loss: 2.2563 - val_acc: 0.8235\n",
      "Epoch 86/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.1898e-08 - acc: 1.0000 - val_loss: 2.2696 - val_acc: 0.8235\n",
      "Epoch 87/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.9324e-08 - acc: 1.0000 - val_loss: 2.2822 - val_acc: 0.8235\n",
      "Epoch 88/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.6876e-08 - acc: 1.0000 - val_loss: 2.2936 - val_acc: 0.8235\n",
      "Epoch 89/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.4789e-08 - acc: 1.0000 - val_loss: 2.3050 - val_acc: 0.8235\n",
      "Epoch 90/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.3140e-08 - acc: 1.0000 - val_loss: 2.3167 - val_acc: 0.8235\n",
      "Epoch 91/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.1497e-08 - acc: 1.0000 - val_loss: 2.3283 - val_acc: 0.8235\n",
      "Epoch 92/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.0148e-08 - acc: 1.0000 - val_loss: 2.3406 - val_acc: 0.8235\n",
      "Epoch 93/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.8867e-08 - acc: 1.0000 - val_loss: 2.3516 - val_acc: 0.8235\n",
      "Epoch 94/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.7847e-08 - acc: 1.0000 - val_loss: 2.3576 - val_acc: 0.8235\n",
      "Epoch 95/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.6340e-08 - acc: 1.0000 - val_loss: 2.3636 - val_acc: 0.8235\n",
      "Epoch 96/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.4993e-08 - acc: 1.0000 - val_loss: 2.3741 - val_acc: 0.8235\n",
      "Epoch 97/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.4174e-08 - acc: 1.0000 - val_loss: 2.3827 - val_acc: 0.8235\n",
      "Epoch 98/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3215e-08 - acc: 1.0000 - val_loss: 2.3927 - val_acc: 0.8235\n",
      "Epoch 99/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2238e-08 - acc: 1.0000 - val_loss: 2.4043 - val_acc: 0.8235\n",
      "Epoch 100/115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1664e-08 - acc: 1.0000 - val_loss: 2.4105 - val_acc: 0.8235\n",
      "Epoch 101/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0828e-08 - acc: 1.0000 - val_loss: 2.4168 - val_acc: 0.8235\n",
      "Epoch 102/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0015e-08 - acc: 1.0000 - val_loss: 2.4302 - val_acc: 0.8235\n",
      "Epoch 103/115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 9.4968e-09 - acc: 1.0000 - val_loss: 2.4387 - val_acc: 0.8235\n",
      "Epoch 104/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.9970e-09 - acc: 1.0000 - val_loss: 2.4495 - val_acc: 0.8235\n",
      "Epoch 105/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 8.5988e-09 - acc: 1.0000 - val_loss: 2.4586 - val_acc: 0.8235\n",
      "Epoch 106/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 8.1504e-09 - acc: 1.0000 - val_loss: 2.4705 - val_acc: 0.8235\n",
      "Epoch 107/115\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 7.8615e-09 - acc: 1.0000 - val_loss: 2.4815 - val_acc: 0.8235\n",
      "Epoch 108/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7.6211e-09 - acc: 1.0000 - val_loss: 2.4933 - val_acc: 0.8235\n",
      "Epoch 109/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7.4439e-09 - acc: 1.0000 - val_loss: 2.5025 - val_acc: 0.8235\n",
      "Epoch 110/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 7.2461e-09 - acc: 1.0000 - val_loss: 2.5136 - val_acc: 0.8235\n",
      "Epoch 111/115\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7.0872e-09 - acc: 1.0000 - val_loss: 2.5236 - val_acc: 0.8235\n",
      "Epoch 112/115\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 6.8638e-09 - acc: 1.0000 - val_loss: 2.5329 - val_acc: 0.8235\n",
      "Epoch 113/115\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 6.6972e-09 - acc: 1.0000 - val_loss: 2.5430 - val_acc: 0.8235\n",
      "Epoch 114/115\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 6.5959e-09 - acc: 1.0000 - val_loss: 2.5523 - val_acc: 0.8235\n",
      "Epoch 115/115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 6.4308e-09 - acc: 1.0000 - val_loss: 2.5622 - val_acc: 0.8235\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.1188 - acc: 0.6111\n",
      "Accuracy: 61.11%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "input_layer4 = layers.Input(shape=(410,))\n",
    "# Capas red encoder\n",
    "encoded4 = layers.Dense(300, activation=\"relu\")(input_layer4)\n",
    "encoded4 = layers.Dense(250, activation=\"relu\")(encoded4)\n",
    "encoded4 = layers.Dense(200, activation=\"relu\")(encoded4)\n",
    "encoded4 = layers.Dense(150, activation=\"relu\")(encoded4)\n",
    "encoded4 = layers.Dense(100, activation=\"relu\")(encoded4)\n",
    "encoded4 = layers.Dense(50, activation=\"relu\")(encoded4)\n",
    "encoded4 = layers.Dense(1, activation=\"sigmoid\")(encoded4)\n",
    "\n",
    "encoder4 = models.Model(input_layer4, encoded4)\n",
    "\n",
    "# Entrenar el modelo\n",
    "encoder4.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "encoder4.fit(X_train, y_train, epochs=115, validation_split=0.25)\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy = encoder4.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
