{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60455127",
   "metadata": {},
   "source": [
    "# Optimización de un modelo de XGBoost\n",
    "\n",
    "Este notebook recoge los resultados de la búsqueda del mejor modelo de clasificación mediante XGBoost (= eXtreme Gradient Boosting). Se trata de un método de boosting, por tanto, la idea es generar un modelo robusto a partir de varios modelos \"débiles\". Sin embargo, se le considera extreme gradient boosting ya que es generalmente bastante más rápido que otras implementaciones de gradient boosting y suele tener un buen rendimiento sobre datos estructurados.\n",
    "\n",
    "Para buscar el mejor modelo posible, se tratará de buscar los mejores hiperparámetros para:\n",
    "\n",
    "* El tipo de booster que se va a utilizar.\n",
    "* El paso del método de boosting.\n",
    "* La mínima reducción de loss exigida para hacer una nueva partición de una rama cuando el booster sea de tal tipo.\n",
    "* La profundidad máxima de los árboles cuando el booster sea de tal tipo.\n",
    "\n",
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dea3bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saral\\miniconda3\\envs\\TFM\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data partition\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Parameter tunning libraries\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Accuracy function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Model\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9721bec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245850</td>\n",
       "      <td>0.216620</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.353800</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>-0.133020</td>\n",
       "      <td>-0.035222</td>\n",
       "      <td>0.259040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257114</td>\n",
       "      <td>0.597229</td>\n",
       "      <td>1.220756</td>\n",
       "      <td>-0.059213</td>\n",
       "      <td>-0.435494</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>1.090910</td>\n",
       "      <td>-0.448562</td>\n",
       "      <td>-0.508497</td>\n",
       "      <td>0.350434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.410730</td>\n",
       "      <td>-0.031925</td>\n",
       "      <td>0.210700</td>\n",
       "      <td>0.242260</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>-0.419290</td>\n",
       "      <td>-0.187140</td>\n",
       "      <td>0.168450</td>\n",
       "      <td>0.599790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050862</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>0.609465</td>\n",
       "      <td>1.181878</td>\n",
       "      <td>-2.279469</td>\n",
       "      <td>-0.013484</td>\n",
       "      <td>-0.012693</td>\n",
       "      <td>-1.244346</td>\n",
       "      <td>-1.080442</td>\n",
       "      <td>-0.788502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.019158</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>-0.032022</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.318170</td>\n",
       "      <td>0.212550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.539922</td>\n",
       "      <td>-1.495822</td>\n",
       "      <td>1.643866</td>\n",
       "      <td>1.687780</td>\n",
       "      <td>1.521086</td>\n",
       "      <td>-1.988432</td>\n",
       "      <td>-0.267471</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>1.104566</td>\n",
       "      <td>-1.067206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087377</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>-0.112830</td>\n",
       "      <td>0.389380</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>-0.080568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077353</td>\n",
       "      <td>-0.459463</td>\n",
       "      <td>-0.204328</td>\n",
       "      <td>-0.619508</td>\n",
       "      <td>-1.410523</td>\n",
       "      <td>-0.304622</td>\n",
       "      <td>-1.521928</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.073638</td>\n",
       "      <td>-0.260920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0.202750</td>\n",
       "      <td>0.191420</td>\n",
       "      <td>-0.056662</td>\n",
       "      <td>-0.157780</td>\n",
       "      <td>0.244040</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.048222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.593326</td>\n",
       "      <td>1.063052</td>\n",
       "      <td>0.434726</td>\n",
       "      <td>1.604964</td>\n",
       "      <td>-0.359736</td>\n",
       "      <td>0.210107</td>\n",
       "      <td>0.355922</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>-0.323557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "2       0  0.245850  0.216620 -0.124680 -0.353800  0.161500 -0.002032   \n",
       "13      1  0.410730 -0.031925  0.210700  0.242260  0.320100 -0.419290   \n",
       "53      1  0.070919  0.034179 -0.011755  0.019158  0.024645 -0.032022   \n",
       "41      0  0.087377 -0.052462 -0.007835 -0.112830  0.389380  0.216080   \n",
       "74      0  0.202750  0.191420 -0.056662 -0.157780  0.244040  0.039780   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "2  -0.133020 -0.035222  0.259040  ...  -0.257114   0.597229   1.220756   \n",
       "13 -0.187140  0.168450  0.599790  ...  -0.050862   0.870602   0.609465   \n",
       "53  0.004620  0.318170  0.212550  ...  -1.539922  -1.495822   1.643866   \n",
       "41  0.063572 -0.251230 -0.080568  ...  -0.077353  -0.459463  -0.204328   \n",
       "74 -0.001503  0.001056 -0.048222  ...   0.044457   0.593326   1.063052   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "2   -0.059213  -0.435494  -0.092971   1.090910  -0.448562  -0.508497   \n",
       "13   1.181878  -2.279469  -0.013484  -0.012693  -1.244346  -1.080442   \n",
       "53   1.687780   1.521086  -1.988432  -0.267471   0.510576   1.104566   \n",
       "41  -0.619508  -1.410523  -0.304622  -1.521928   0.593691   0.073638   \n",
       "74   0.434726   1.604964  -0.359736   0.210107   0.355922   0.730287   \n",
       "\n",
       "    SBM_map75  \n",
       "2    0.350434  \n",
       "13  -0.788502  \n",
       "53  -1.067206  \n",
       "41  -0.260920  \n",
       "74  -0.323557  \n",
       "\n",
       "[5 rows x 411 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de entrenamiento\n",
    "trainFNC = pd.read_csv(\"../data/train_FNC.csv\")\n",
    "trainSBM = pd.read_csv(\"../data/train_SBM.csv\")\n",
    "train_labels = pd.read_csv(\"../data/train_labels.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "train = pd.merge(left=trainFNC, right=trainSBM, left_on=\"Id\", right_on=\"Id\")\n",
    "data = pd.merge(left=train_labels, right=train, left_on=\"Id\", right_on=\"Id\")\n",
    "data.drop(\"Id\", inplace=True, axis=1)\n",
    "\n",
    "# Shuffle de los datos de train\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5575f",
   "metadata": {},
   "source": [
    "Vamos a usar la siguiente partición de los datos:\n",
    "\n",
    "* 60% train $\\sim$ 50 datos\n",
    "* 20% validation $\\sim$ 18 datos (se define al aplicar cross-validación en el ajuste)\n",
    "* 20% test $\\sim$ 18 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24ffb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c8f3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>FNC10</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.476127</td>\n",
       "      <td>0.064466</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>-0.608133</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>-0.637038</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>-0.192434</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.060474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451994</td>\n",
       "      <td>1.123770</td>\n",
       "      <td>2.083006</td>\n",
       "      <td>1.145440</td>\n",
       "      <td>-0.067608</td>\n",
       "      <td>1.202529</td>\n",
       "      <td>0.851587</td>\n",
       "      <td>0.451583</td>\n",
       "      <td>-0.159739</td>\n",
       "      <td>0.192076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.267183</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>-0.261327</td>\n",
       "      <td>0.191869</td>\n",
       "      <td>0.406493</td>\n",
       "      <td>0.088761</td>\n",
       "      <td>0.177048</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696987</td>\n",
       "      <td>1.397832</td>\n",
       "      <td>1.046136</td>\n",
       "      <td>-0.191733</td>\n",
       "      <td>-2.192023</td>\n",
       "      <td>-0.369276</td>\n",
       "      <td>0.822225</td>\n",
       "      <td>-0.109342</td>\n",
       "      <td>-0.580476</td>\n",
       "      <td>0.174160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.435452</td>\n",
       "      <td>0.046780</td>\n",
       "      <td>0.243742</td>\n",
       "      <td>0.397030</td>\n",
       "      <td>-0.147821</td>\n",
       "      <td>0.173620</td>\n",
       "      <td>-0.461963</td>\n",
       "      <td>-0.610736</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.400985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160145</td>\n",
       "      <td>1.906989</td>\n",
       "      <td>-2.661633</td>\n",
       "      <td>-0.193911</td>\n",
       "      <td>0.440873</td>\n",
       "      <td>0.641739</td>\n",
       "      <td>0.918397</td>\n",
       "      <td>-0.758046</td>\n",
       "      <td>0.154701</td>\n",
       "      <td>-0.476647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.204510</td>\n",
       "      <td>-0.036735</td>\n",
       "      <td>-0.760705</td>\n",
       "      <td>-0.740495</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>0.349926</td>\n",
       "      <td>-0.273826</td>\n",
       "      <td>-0.174384</td>\n",
       "      <td>-0.120248</td>\n",
       "      <td>0.175618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974828</td>\n",
       "      <td>-1.997087</td>\n",
       "      <td>-2.083782</td>\n",
       "      <td>1.154107</td>\n",
       "      <td>-0.643947</td>\n",
       "      <td>2.332424</td>\n",
       "      <td>0.659124</td>\n",
       "      <td>-0.809445</td>\n",
       "      <td>0.558960</td>\n",
       "      <td>2.790871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599435</td>\n",
       "      <td>-0.166441</td>\n",
       "      <td>0.122431</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.346906</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.274734</td>\n",
       "      <td>0.211510</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-0.033434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.789153</td>\n",
       "      <td>1.578984</td>\n",
       "      <td>1.402592</td>\n",
       "      <td>-1.230440</td>\n",
       "      <td>0.296686</td>\n",
       "      <td>2.806314</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>-0.240682</td>\n",
       "      <td>-0.196948</td>\n",
       "      <td>-1.544345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FNC1      FNC2      FNC3      FNC4      FNC5      FNC6      FNC7  \\\n",
       "0  0.476127  0.064466  0.053238 -0.608133  0.073988 -0.637038  0.113556   \n",
       "1  0.013833  0.267183  0.232178 -0.167151 -0.261327  0.191869  0.406493   \n",
       "2 -0.435452  0.046780  0.243742  0.397030 -0.147821  0.173620 -0.461963   \n",
       "3 -0.204510 -0.036735 -0.760705 -0.740495  0.064668  0.349926 -0.273826   \n",
       "4  0.599435 -0.166441  0.122431  0.011539  0.346906 -0.017430 -0.274734   \n",
       "\n",
       "       FNC8      FNC9     FNC10  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "0 -0.192434 -0.004025 -0.060474  ...  -0.451994   1.123770   2.083006   \n",
       "1  0.088761  0.177048  0.036718  ...   0.696987   1.397832   1.046136   \n",
       "2 -0.610736  0.419753  0.400985  ...   0.160145   1.906989  -2.661633   \n",
       "3 -0.174384 -0.120248  0.175618  ...   0.974828  -1.997087  -2.083782   \n",
       "4  0.211510  0.151012 -0.033434  ...  -0.789153   1.578984   1.402592   \n",
       "\n",
       "   SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  SBM_map75  \n",
       "0   1.145440  -0.067608   1.202529   0.851587   0.451583  -0.159739   0.192076  \n",
       "1  -0.191733  -2.192023  -0.369276   0.822225  -0.109342  -0.580476   0.174160  \n",
       "2  -0.193911   0.440873   0.641739   0.918397  -0.758046   0.154701  -0.476647  \n",
       "3   1.154107  -0.643947   2.332424   0.659124  -0.809445   0.558960   2.790871  \n",
       "4  -1.230440   0.296686   2.806314   0.427184  -0.240682  -0.196948  -1.544345  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de test\n",
    "testFNC = pd.read_csv(\"../data/test_FNC.csv\")\n",
    "testSBM = pd.read_csv(\"../data/test_SBM.csv\")\n",
    "\n",
    "# DataFrame con ambas fuentes de datos\n",
    "test_kaggle = pd.merge(left=testFNC, right=testSBM, left_on=\"Id\", right_on=\"Id\")\n",
    "test_kaggle.drop(\"Id\", inplace=True, axis=1)\n",
    "test_kaggle.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad5e66",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e12703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, param_grid):\n",
    "    '''Función para realizar el entrenamiento y la búsqueda de hiperparámetros'''\n",
    "    np.random.seed()\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=4)\n",
    "    # cv = 4 porque así: el conjunto de validation tiene un 0.25 del tamaño de train y: 0.25 * 0.8 = 0.2 ~ 20% datos\n",
    "    #                    el conjunto de train tiene un 0.75 del tamaño de train y: 0.75 * 0.8 = 0.6 ~60% datos\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Parámetros óptimos:\", grid_search.best_params_)\n",
    "    print(\"Modelo óptimo:\", grid_search.best_estimator_)\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e149b6",
   "metadata": {},
   "source": [
    "Búsqueda de hiperparámetros mediante ``GridSearchCV`` de ``sklearn``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77bbef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos: {'booster': 'gblinear', 'gamma': 0.001, 'learning_rate': 1, 'max_depth': 1}\n",
      "Modelo óptimo: XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='logloss', gamma=0.001,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=1, max_delta_step=None, max_depth=1,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=None)\n",
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Suprimir warning de versiones\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "model_XGB = XGBClassifier(eval_metric=\"logloss\", random_state=0, use_label_encoder=False)\n",
    "param_grid_XGB = {\n",
    "    \"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.3, 0.5, 1],\n",
    "    \"gamma\": [0, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    \"max_depth\": range(0, 21) # 0 = ninguna restricción\n",
    "}\n",
    "model_XGB_opt = train_model(model_XGB, param_grid_XGB)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_XGB = model_XGB_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_XGB)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96bbee4",
   "metadata": {},
   "source": [
    "Búsqueda mediante la librería ``optuna`` probando 2 métodos de búsqueda de hiperparámetros:\n",
    "\n",
    "* **GridSampler:** equivalente a la anterior búsqueda de grid de sklearn. Lo usaremos para que los resultados sean comparables.\n",
    "* **TPE:** algoritmo para hacer una \"búsqueda inteligente\" de hiperparámetros. Debería ahorrar intentos de combinaciones haciendo una selección inteligente de las pruebas. En nuestro caso le permitiremos probar un 10% del número de combinaciones posibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9182eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveXGBoost_Grid(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo GridSampler.\n",
    "    En este caso se trata de maximizar el accuracy\n",
    "    '''\n",
    "    booster = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0, 1)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0, 1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 0, 20)\n",
    "    \n",
    "    modelXGBoost_optuna = XGBClassifier(eval_metric=\"logloss\", booster=booster, learning_rate=learning_rate, gamma=gamma,\n",
    "                                        max_depth=max_depth, random_state=0, use_label_encoder=False)\n",
    "    \n",
    "    modelXGBoost_optuna.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_XGBoost_optuna = modelXGBoost_optuna.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_XGBoost_optuna)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2965528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba con GridSampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "search_space = {\"booster\": [\"gbtree\", \"gblinear\", \"dart\"], \n",
    "                \"learning_rate\": np.arange(0.001, 1, 0.1665),\n",
    "                \"gamma\": np.arange(0, 0.1, 0.025),\n",
    "                \"max_depth\": range(0, 20, 2)\n",
    "               }\n",
    "sampler = optuna.samplers.GridSampler(search_space)\n",
    "study_Grid = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_Grid.optimize(objectiveXGBoost_Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d69f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, values=[0.8333333333333334], datetime_start=datetime.datetime(2022, 6, 11, 23, 12, 52, 659897), datetime_complete=datetime.datetime(2022, 6, 11, 23, 12, 53, 550274), params={'booster': 'gblinear', 'learning_rate': 0.001, 'gamma': 0.05, 'max_depth': 18}, distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear', 'dart')), 'learning_rate': UniformDistribution(high=1.0, low=0.0), 'gamma': UniformDistribution(high=1.0, low=0.0), 'max_depth': IntUniformDistribution(high=20, low=0, step=1)}, user_attrs={}, system_attrs={'search_space': OrderedDict([('booster', ['dart', 'gblinear', 'gbtree']), ('gamma', [0.0, 0.025, 0.05, 0.07500000000000001]), ('learning_rate', [0.001, 0.1675, 0.334, 0.5005000000000001, 0.667, 0.8335]), ('max_depth', [0, 2, 4, 6, 8, 10, 12, 14, 16, 18])]), 'grid_id': 369}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_Grid.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd4f97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelXGBoost_optuna_Grid = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.001, gamma=0.05,\n",
    "                                         max_depth=18, random_state=0, use_label_encoder=False)  \n",
    "modelXGBoost_optuna_Grid.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_XGBoost_optuna_Grid = modelXGBoost_optuna_Grid.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_XGBoost_optuna_Grid)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7aad65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveXGBoost_TPE(trial):\n",
    "    '''\n",
    "    Define la función a optimizar por medio de un sampler de tipo TPE.\n",
    "    En este caso se trata de maximizar el accuracy\n",
    "    '''\n",
    "    booster = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1, step=0.1665)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0, 0.1, step=0.025)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 0, 20, 2)\n",
    "    \n",
    "    modelXGBoost_optuna = XGBClassifier(eval_metric=\"logloss\", booster=booster, learning_rate=learning_rate, gamma=gamma,\n",
    "                                        max_depth=max_depth, random_state=0, use_label_encoder=False)\n",
    "    \n",
    "    modelXGBoost_optuna.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_XGBoost_optuna = modelXGBoost_optuna.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_XGBoost_optuna)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4d7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba con TPE\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0)  # Asegurar los reproducibilidad de los resultados\n",
    "study_TPE = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_TPE.optimize(objectiveXGBoost_TPE, n_trials=80)\n",
    "# n_trials = (3 x 6 x 4 x 11) * 0.1 = 79.2 ~ 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "443ec2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=2, values=[0.8333333333333334], datetime_start=datetime.datetime(2022, 6, 10, 19, 5, 30, 272856), datetime_complete=datetime.datetime(2022, 6, 10, 19, 5, 30, 499449), params={'booster': 'gblinear', 'learning_rate': 0.001, 'gamma': 0.0, 'max_depth': 18}, distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear', 'dart')), 'learning_rate': DiscreteUniformDistribution(high=1.0, low=0.001, q=0.1665), 'gamma': DiscreteUniformDistribution(high=0.1, low=0.0, q=0.025), 'max_depth': IntUniformDistribution(high=20, low=0, step=2)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=2, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_TPE.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17a7d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "modelXGBoost_optuna_TPE = XGBClassifier(eval_metric=\"logloss\", booster=\"gblinear\", learning_rate=0.001, gamma=0,\n",
    "                                        max_depth=18, random_state=0, use_label_encoder=False) \n",
    "modelXGBoost_optuna_TPE.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_XGBoost_optuna_TPE = modelXGBoost_optuna_TPE.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_XGBoost_optuna_TPE)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00092052",
   "metadata": {},
   "source": [
    "Búsqueda mediante ``optuna`` con ``OptunaSearchCV``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a61aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptunaSearchCV(cv=4,\n",
       "               estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                       colsample_bylevel=None,\n",
       "                                       colsample_bynode=None,\n",
       "                                       colsample_bytree=None,\n",
       "                                       enable_categorical=False,\n",
       "                                       eval_metric='logloss', gamma=None,\n",
       "                                       gpu_id=None, importance_type=None,\n",
       "                                       interaction_constraints=None,\n",
       "                                       learning_rate=None, max_delta_step=None,\n",
       "                                       max_depth=None, min_child_weight=None,\n",
       "                                       missing=nan, mo...\n",
       "                                       validate_parameters=None,\n",
       "                                       verbosity=None),\n",
       "               n_trials=792,\n",
       "               param_distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear', 'dart')),\n",
       "                                    'gamma': DiscreteUniformDistribution(high=0.1, low=0.0, q=0.025),\n",
       "                                    'learning_rate': DiscreteUniformDistribution(high=1.0, low=0.001, q=0.1665),\n",
       "                                    'max_depth': IntUniformDistribution(high=20, low=0, step=2)},\n",
       "               random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "model_XGB = XGBClassifier(eval_metric=\"logloss\", random_state=0, use_label_encoder=False)\n",
    "param_grid_XGB = {\n",
    "    \"booster\": optuna.distributions.CategoricalDistribution([\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "    \"learning_rate\": optuna.distributions.DiscreteUniformDistribution(0.001, 1, 0.1665),\n",
    "    \"gamma\": optuna.distributions.DiscreteUniformDistribution(0, 0.1, 0.025),\n",
    "    \"max_depth\": optuna.distributions.IntUniformDistribution(0, 20, 2) # 0 = ninguna restricción\n",
    "}\n",
    "# Probamos también 6 valores de learning_rate, aunque ahora el paso entre uno y otro es necesariamente el mismo\n",
    "\n",
    "optuna_search = optuna.integration.OptunaSearchCV(model_XGB, param_grid_XGB, cv=4, n_trials=792, refit=True, random_state=0)\n",
    "# n_trials = 3 x 6 x 4 x 11 = 792\n",
    "optuna_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06ef6032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, eval_metric='logloss', gamma=0.025,\n",
       "              gpu_id=-1, importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=1.0, max_delta_step=None, max_depth=10,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=None,\n",
       "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
       "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optunaCV_opt = optuna_search.best_estimator_\n",
    "optunaCV_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6b02f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.11%\n"
     ]
    }
   ],
   "source": [
    "optunaCV_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_XGB_optuna = optunaCV_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_XGB_optuna)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053259d7",
   "metadata": {},
   "source": [
    "# Create submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "\n",
    "def create_submission(pred, test_id=testFNC[\"Id\"]):\n",
    "    '''\n",
    "    Función para generar un csv con las predicciones de un modelo para participar en la competición de Kaggle\n",
    "    '''\n",
    "    submissionDF = pd.DataFrame(list(zip(test_id, pred)), columns=[\"Id\", \"Probability\"])\n",
    "    print(submissionDF.shape) # Comprobación del tamaño, debe ser: (119748, 2)\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y_%Hh%Mmin\")\n",
    "    current_path = pathlib.Path().resolve()\n",
    "    parent_path = current_path.parent\n",
    "    submissionDF.to_csv(f\"{parent_path}\\submissions\\MLSP_submission_XGBoost_{current_time}.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
