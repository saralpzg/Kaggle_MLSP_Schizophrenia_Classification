{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70addaeb",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Uno de los principales obstáculos que se encuentran al intentar hallar la major solución al problema de clasificación, es la escasez de datos para el entrenamiento de los modelos.\n",
    "\n",
    "Este notebook tiene como objetivo implementar y comparar los resultados obtenidos implementando técnicas de Data Augmentation para crear datos sintéticos y poder operar sobre un mayor volumen de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989e8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructuras de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Cargar los datos\n",
    "from Modelos.data_and_submissions import *\n",
    "# Métodos para los entrenamientos con CV\n",
    "from Modelos.train_cv_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72411cba",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3c3352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de train: (68, 410)\n",
      "Tamaño del dataset de test: (18, 410)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, test_kaggle = load_data(True)\n",
    "print(\"Tamaño del dataset de train:\", X_train.shape)\n",
    "print(\"Tamaño del dataset de test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d83db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_partition(data_augmented):\n",
    "    X = data_augmented.iloc[:, 1:]\n",
    "    Y = data_augmented.iloc[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bba535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119834, 410)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.concat((y_train, y_test), axis=0)\n",
    "features = pd.concat((X_train, X_test), axis=0)\n",
    "features_tot = pd.concat((features, test_kaggle), axis=0)\n",
    "print(features_tot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90d87f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>0.435160</td>\n",
       "      <td>0.225050</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>-0.353480</td>\n",
       "      <td>0.447420</td>\n",
       "      <td>0.183180</td>\n",
       "      <td>0.122420</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.404830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314668</td>\n",
       "      <td>-0.114078</td>\n",
       "      <td>-0.476524</td>\n",
       "      <td>-0.556896</td>\n",
       "      <td>0.505738</td>\n",
       "      <td>0.873278</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.211690</td>\n",
       "      <td>0.536933</td>\n",
       "      <td>-0.424864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0.468280</td>\n",
       "      <td>0.108890</td>\n",
       "      <td>0.072178</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.266450</td>\n",
       "      <td>0.350770</td>\n",
       "      <td>-0.210100</td>\n",
       "      <td>-0.089635</td>\n",
       "      <td>-0.140530</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200450</td>\n",
       "      <td>1.817908</td>\n",
       "      <td>-0.299583</td>\n",
       "      <td>0.740836</td>\n",
       "      <td>1.491966</td>\n",
       "      <td>0.993555</td>\n",
       "      <td>-0.043188</td>\n",
       "      <td>0.564047</td>\n",
       "      <td>-0.916360</td>\n",
       "      <td>2.771659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137060</td>\n",
       "      <td>-0.188670</td>\n",
       "      <td>-0.160220</td>\n",
       "      <td>-0.152680</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.142780</td>\n",
       "      <td>0.349660</td>\n",
       "      <td>-0.046245</td>\n",
       "      <td>-0.133690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922012</td>\n",
       "      <td>-0.197890</td>\n",
       "      <td>1.585873</td>\n",
       "      <td>-0.056353</td>\n",
       "      <td>0.806093</td>\n",
       "      <td>-1.517281</td>\n",
       "      <td>1.672678</td>\n",
       "      <td>-0.376343</td>\n",
       "      <td>-0.061299</td>\n",
       "      <td>-0.945018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.366770</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>-0.085309</td>\n",
       "      <td>-0.295600</td>\n",
       "      <td>0.311750</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200334</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>1.149330</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.729352</td>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.210830</td>\n",
       "      <td>0.423430</td>\n",
       "      <td>0.263870</td>\n",
       "      <td>0.298310</td>\n",
       "      <td>-0.088201</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266496</td>\n",
       "      <td>-1.527078</td>\n",
       "      <td>-1.028776</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>-0.938700</td>\n",
       "      <td>0.215549</td>\n",
       "      <td>-0.575946</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.619411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>-0.313110</td>\n",
       "      <td>-0.702080</td>\n",
       "      <td>-0.626550</td>\n",
       "      <td>-0.490060</td>\n",
       "      <td>-0.432500</td>\n",
       "      <td>-0.538550</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>0.198530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969872</td>\n",
       "      <td>0.470231</td>\n",
       "      <td>-0.319118</td>\n",
       "      <td>-0.160328</td>\n",
       "      <td>0.632695</td>\n",
       "      <td>-1.015545</td>\n",
       "      <td>-0.633930</td>\n",
       "      <td>0.683149</td>\n",
       "      <td>0.720507</td>\n",
       "      <td>1.369418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.189330</td>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.312910</td>\n",
       "      <td>0.245270</td>\n",
       "      <td>-0.226630</td>\n",
       "      <td>-0.130830</td>\n",
       "      <td>0.077108</td>\n",
       "      <td>-0.046652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.774058</td>\n",
       "      <td>1.739382</td>\n",
       "      <td>-1.845892</td>\n",
       "      <td>-1.522856</td>\n",
       "      <td>-1.344479</td>\n",
       "      <td>0.008769</td>\n",
       "      <td>0.898490</td>\n",
       "      <td>-0.164422</td>\n",
       "      <td>-0.050235</td>\n",
       "      <td>1.367143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>0.314770</td>\n",
       "      <td>0.295030</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.274070</td>\n",
       "      <td>0.396880</td>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.127860</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.126330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626300</td>\n",
       "      <td>-0.241099</td>\n",
       "      <td>-0.354035</td>\n",
       "      <td>-0.405403</td>\n",
       "      <td>-0.544734</td>\n",
       "      <td>-0.164949</td>\n",
       "      <td>0.659083</td>\n",
       "      <td>-0.868930</td>\n",
       "      <td>-0.530455</td>\n",
       "      <td>-0.722450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.128630</td>\n",
       "      <td>-0.290760</td>\n",
       "      <td>-0.505190</td>\n",
       "      <td>-0.554770</td>\n",
       "      <td>-0.275930</td>\n",
       "      <td>-0.026265</td>\n",
       "      <td>-0.418280</td>\n",
       "      <td>-0.527620</td>\n",
       "      <td>-0.381970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623423</td>\n",
       "      <td>0.509388</td>\n",
       "      <td>0.728753</td>\n",
       "      <td>-0.151419</td>\n",
       "      <td>1.698903</td>\n",
       "      <td>0.460504</td>\n",
       "      <td>-0.599519</td>\n",
       "      <td>1.229305</td>\n",
       "      <td>0.998584</td>\n",
       "      <td>0.043127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "83      1  0.435160  0.225050  0.057172 -0.353480  0.447420  0.183180   \n",
       "40      0  0.468280  0.108890  0.072178  0.002432  0.266450  0.350770   \n",
       "60      0  0.137060 -0.188670 -0.160220 -0.152680  0.143570  0.142780   \n",
       "45      1 -0.174850 -0.119840 -0.366770 -0.354050  0.065508 -0.085309   \n",
       "73      1 -0.020630  0.250100  0.210830  0.423430  0.263870  0.298310   \n",
       "34      0  0.037074 -0.313110 -0.702080 -0.626550 -0.490060 -0.432500   \n",
       "20      0  0.328300  0.189330  0.027821  0.312910  0.245270 -0.226630   \n",
       "10      1  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "70      0  0.314770  0.295030  0.002139  0.274070  0.396880  0.078688   \n",
       "12      1 -0.128630 -0.290760 -0.505190 -0.554770 -0.275930 -0.026265   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "83  0.122420  0.024561  0.404830  ...   0.314668  -0.114078  -0.476524   \n",
       "40 -0.210100 -0.089635 -0.140530  ...   1.200450   1.817908  -0.299583   \n",
       "60  0.349660 -0.046245 -0.133690  ...  -0.922012  -0.197890   1.585873   \n",
       "45 -0.295600  0.311750 -0.013669  ...   1.200334   0.313340   0.287729   \n",
       "73 -0.088201  0.081132 -0.025001  ...  -0.266496  -1.527078  -1.028776   \n",
       "34 -0.538550  0.023721  0.198530  ...   0.969872   0.470231  -0.319118   \n",
       "20 -0.130830  0.077108 -0.046652  ...  -0.774058   1.739382  -1.845892   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "70  0.127860  0.011281  0.126330  ...  -0.626300  -0.241099  -0.354035   \n",
       "12 -0.418280 -0.527620 -0.381970  ...   0.623423   0.509388   0.728753   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "83  -0.556896   0.505738   0.873278   0.040048   0.211690   0.536933   \n",
       "40   0.740836   1.491966   0.993555  -0.043188   0.564047  -0.916360   \n",
       "60  -0.056353   0.806093  -1.517281   1.672678  -0.376343  -0.061299   \n",
       "45  -0.370420   0.224179   1.149330   1.842975   1.458239   0.729352   \n",
       "73   0.437655  -0.938700   0.215549  -0.575946   0.804762   1.351451   \n",
       "34  -0.160328   0.632695  -1.015545  -0.633930   0.683149   0.720507   \n",
       "20  -1.522856  -1.344479   0.008769   0.898490  -0.164422  -0.050235   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "70  -0.405403  -0.544734  -0.164949   0.659083  -0.868930  -0.530455   \n",
       "12  -0.151419   1.698903   0.460504  -0.599519   1.229305   0.998584   \n",
       "\n",
       "    SBM_map75  \n",
       "83  -0.424864  \n",
       "40   2.771659  \n",
       "60  -0.945018  \n",
       "45   0.522059  \n",
       "73   0.619411  \n",
       "34   1.369418  \n",
       "20   1.367143  \n",
       "10   1.003364  \n",
       "70  -0.722450  \n",
       "12   0.043127  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((labels, features), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea0b5c",
   "metadata": {},
   "source": [
    "# Random noise\n",
    "\n",
    "**Precisión de un modelo de Random Forest sobre el conjunto original de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447b1eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 750},\n",
       " {'criterion': 'entropy', 'max_depth': 400, 'n_estimators': 750}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(random_state=0)\n",
    "param_grid_RF = {\n",
    "    \"n_estimators\": [100, 250, 500, 750, 1000],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [10, 50, 100, 200, 400]\n",
    "}\n",
    "\n",
    "no_data_aug = train_GridSearchCV(model_RF, param_grid_RF, X_train, X_test, y_train, y_test)\n",
    "top_acc = top_acc_GridSearchCV(no_data_aug[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(no_data_aug, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2139dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "no_data_aug_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=400, n_estimators=750, random_state=0)  \n",
    "no_data_aug_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_no_data_aug = no_data_aug_opt.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_no_data_aug = accuracy_score(y_test, y_pred_no_data_aug)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_no_data_aug * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010d2b1",
   "metadata": {},
   "source": [
    "### Ruido gaussiano\n",
    "\n",
    "Una primera prueba de introducción de ruido artificial se basará en añadir a los datos originales, valores (ruido) que se tomarán de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de valores para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c268e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del intervalo)\n",
    "max_per_var = features_tot.max(axis=0)\n",
    "min_per_var = features_tot.min(axis=0)\n",
    "std_per_var = (max_per_var - min_per_var) * 0.1\n",
    "std_per_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "304cc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232200</td>\n",
       "      <td>-0.042566</td>\n",
       "      <td>-0.791727</td>\n",
       "      <td>-0.772790</td>\n",
       "      <td>-0.346480</td>\n",
       "      <td>-0.117090</td>\n",
       "      <td>-0.509645</td>\n",
       "      <td>-0.336619</td>\n",
       "      <td>0.797302</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.222112</td>\n",
       "      <td>-1.402231</td>\n",
       "      <td>1.920834</td>\n",
       "      <td>1.026937</td>\n",
       "      <td>-1.144009</td>\n",
       "      <td>-2.123258</td>\n",
       "      <td>-1.525115</td>\n",
       "      <td>-1.448959</td>\n",
       "      <td>-2.371252</td>\n",
       "      <td>-0.894455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>-0.303637</td>\n",
       "      <td>-0.227025</td>\n",
       "      <td>-0.235851</td>\n",
       "      <td>0.187904</td>\n",
       "      <td>-0.334999</td>\n",
       "      <td>0.293302</td>\n",
       "      <td>0.586997</td>\n",
       "      <td>0.407761</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001576</td>\n",
       "      <td>0.855035</td>\n",
       "      <td>0.711041</td>\n",
       "      <td>-0.935583</td>\n",
       "      <td>0.473294</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>-0.780473</td>\n",
       "      <td>-0.661480</td>\n",
       "      <td>2.054732</td>\n",
       "      <td>0.556554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.603918</td>\n",
       "      <td>-0.138133</td>\n",
       "      <td>-0.615962</td>\n",
       "      <td>-0.481932</td>\n",
       "      <td>-0.475437</td>\n",
       "      <td>-0.487702</td>\n",
       "      <td>-0.444205</td>\n",
       "      <td>-0.522006</td>\n",
       "      <td>-0.332678</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.920996</td>\n",
       "      <td>-1.332419</td>\n",
       "      <td>0.839660</td>\n",
       "      <td>0.103529</td>\n",
       "      <td>1.004458</td>\n",
       "      <td>-3.103754</td>\n",
       "      <td>1.742597</td>\n",
       "      <td>-1.272035</td>\n",
       "      <td>-0.018540</td>\n",
       "      <td>1.237611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119350</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.300453</td>\n",
       "      <td>0.223938</td>\n",
       "      <td>-0.018287</td>\n",
       "      <td>0.282171</td>\n",
       "      <td>0.039545</td>\n",
       "      <td>-0.361698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991947</td>\n",
       "      <td>-2.944841</td>\n",
       "      <td>1.107726</td>\n",
       "      <td>2.932836</td>\n",
       "      <td>1.460491</td>\n",
       "      <td>0.621709</td>\n",
       "      <td>-2.899831</td>\n",
       "      <td>-0.278128</td>\n",
       "      <td>-1.450732</td>\n",
       "      <td>-2.987256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318331</td>\n",
       "      <td>0.094148</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>-0.388997</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>-0.188975</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.799038</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370051</td>\n",
       "      <td>-1.407210</td>\n",
       "      <td>0.437209</td>\n",
       "      <td>0.150966</td>\n",
       "      <td>0.458162</td>\n",
       "      <td>0.662532</td>\n",
       "      <td>-1.468774</td>\n",
       "      <td>-0.648076</td>\n",
       "      <td>-1.144024</td>\n",
       "      <td>-0.057911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>-0.050827</td>\n",
       "      <td>-0.481793</td>\n",
       "      <td>-0.077876</td>\n",
       "      <td>-0.149324</td>\n",
       "      <td>-0.301414</td>\n",
       "      <td>-0.158155</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>-0.092545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.305155</td>\n",
       "      <td>0.150132</td>\n",
       "      <td>0.607371</td>\n",
       "      <td>-0.224237</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>1.183815</td>\n",
       "      <td>1.897722</td>\n",
       "      <td>0.304188</td>\n",
       "      <td>-0.171216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.232200 -0.042566 -0.791727 -0.772790 -0.346480 -0.117090   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.262460 -0.303637 -0.227025 -0.235851  0.187904 -0.334999   \n",
       "14    0.0 -0.603918 -0.138133 -0.615962 -0.481932 -0.475437 -0.487702   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.119350  0.115388  0.071737  0.300453  0.223938 -0.018287   \n",
       "18    0.0  0.318331  0.094148  0.007068 -0.388997  0.378600 -0.188975   \n",
       "3     1.0 -0.013986 -0.050827 -0.481793 -0.077876 -0.149324 -0.301414   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.509645 -0.336619  0.797302  ...  -3.222112  -1.402231   1.920834   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39  0.293302  0.586997  0.407761  ...   1.001576   0.855035   0.711041   \n",
       "14 -0.444205 -0.522006 -0.332678  ...  -1.920996  -1.332419   0.839660   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.282171  0.039545 -0.361698  ...   0.991947  -2.944841   1.107726   \n",
       "18  0.168999  0.799038  0.101366  ...   1.370051  -1.407210   0.437209   \n",
       "3  -0.158155  0.343952 -0.092545  ...   1.305155   0.150132   0.607371   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60   1.026937  -1.144009  -2.123258  -1.525115  -1.448959  -2.371252   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39  -0.935583   0.473294   0.998934  -0.780473  -0.661480   2.054732   \n",
       "14   0.103529   1.004458  -3.103754   1.742597  -1.272035  -0.018540   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   2.932836   1.460491   0.621709  -2.899831  -0.278128  -1.450732   \n",
       "18   0.150966   0.458162   0.662532  -1.468774  -0.648076  -1.144024   \n",
       "3   -0.224237   0.018921   0.976853   1.183815   1.897722   0.304188   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -0.894455  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.556554  \n",
       "14   1.237611  \n",
       "10   1.003364  \n",
       "69  -2.987256  \n",
       "18  -0.057911  \n",
       "3   -0.171216  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% del rango de la variable\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_gaussian[i, :] = generate_noisy_sample_gaussian(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian = np.c_[labels, noisy_features_gaussian]\n",
    "\n",
    "noisy_data_gaussian = pd.concat([data, pd.DataFrame(noisy_features_gaussian, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian = noisy_data_gaussian.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian.shape))\n",
    "noisy_data_gaussian.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9dee9",
   "metadata": {},
   "source": [
    "Precisión del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "726e40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_gaussian, X_test_gaussian, y_train_gaussian, y_test_gaussian) = data_partition(noisy_data_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "901beed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 250},\n",
       " {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 250},\n",
       " {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 250},\n",
       " {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 250},\n",
       " {'criterion': 'entropy', 'max_depth': 400, 'n_estimators': 250}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_gaussian = train_GridSearchCV(model_RF, param_grid_RF, X_train_gaussian, X_test_gaussian, \n",
    "                                       y_train_gaussian, y_test_gaussian)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_gaussian[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_gaussian, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "430961ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.57%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_gaussian_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=400, n_estimators=250, random_state=0)  \n",
    "data_aug_gaussian_opt.fit(X_train_gaussian, y_train_gaussian)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_gaussian = data_aug_gaussian_opt.predict(X_test_gaussian)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_gaussian = accuracy_score(y_test_gaussian, y_pred_data_aug_gaussian)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_gaussian * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0657d5e7",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{ANTERIOR}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6449defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 91.43%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_gaussian)\n",
    "\n",
    "grid_search_RF_gaussian = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF_gaussian.fit(X_train, y_train)\n",
    "model_RF_opt_gaussian = grid_search_RF_gaussian.best_estimator_\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF_gaussian = model_RF_opt_gaussian.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_gaussian)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e989c1",
   "metadata": {},
   "source": [
    "Vamos a modificar ahora el método, de modo que los valores generados de ruido se tomen de una distribución gaussiana de media = 0 y desviación típica = 10% del rango de la diferencia entre la media de las variables para pacientes con esquizofrenia y la media de las variables de los individuos de control.\n",
    "\n",
    "La motivación para introducir esta modificación es que podría ser que las distribuciones que definen cada variable sean diferentes cuando se considera a un individuo sano (etiqueta 0) y a un individuo enfermo (etiqueta 1). Si estas distribuciones están lo suficientemente cercanas, introducir un ruido aparentemente pequeño podría modificar una muestra originalmente correspondiente a una clase y generar otra de manera artificial con la misma etiqueta pero que se solapa con la distribución de la etiqueta opuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9c990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = data[data[\"Class\"] == 0]\n",
    "sick = data[data[\"Class\"] == 0]\n",
    "\n",
    "labels_control = control_group.iloc[:, 0]\n",
    "features_control = np.array(control_group.iloc[:, 1:])\n",
    "labels_sick = sick.iloc[:, 0]\n",
    "features_sick = np.array(sick.iloc[:, 1:])\n",
    "\n",
    "# Para cada variable en el conjunto de datos, calculamos la desviación típica que usaremos (10% del rango de la diferencia)\n",
    "avg_per_var_control = features_control.mean(axis=0)\n",
    "avg_per_var_sick = features_sick.mean(axis=0)\n",
    "std_per_var = abs((avg_per_var_control - avg_per_var_sick)) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "330f58d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.343140</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>-0.547010</td>\n",
       "      <td>-0.652910</td>\n",
       "      <td>-0.226870</td>\n",
       "      <td>-0.354650</td>\n",
       "      <td>-0.630850</td>\n",
       "      <td>-0.189460</td>\n",
       "      <td>0.704020</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.424498</td>\n",
       "      <td>-1.512935</td>\n",
       "      <td>1.480432</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-1.151279</td>\n",
       "      <td>-2.123389</td>\n",
       "      <td>-0.962200</td>\n",
       "      <td>-0.524886</td>\n",
       "      <td>-2.310918</td>\n",
       "      <td>-1.740839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>-0.196510</td>\n",
       "      <td>-0.245280</td>\n",
       "      <td>-0.083840</td>\n",
       "      <td>0.304210</td>\n",
       "      <td>-0.180270</td>\n",
       "      <td>-0.008647</td>\n",
       "      <td>0.384610</td>\n",
       "      <td>0.300520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464108</td>\n",
       "      <td>1.135537</td>\n",
       "      <td>-0.256829</td>\n",
       "      <td>0.222902</td>\n",
       "      <td>0.528734</td>\n",
       "      <td>1.098908</td>\n",
       "      <td>-1.239779</td>\n",
       "      <td>-0.421480</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>0.325227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.391350</td>\n",
       "      <td>-0.284360</td>\n",
       "      <td>-0.655090</td>\n",
       "      <td>-0.645960</td>\n",
       "      <td>-0.241020</td>\n",
       "      <td>-0.352420</td>\n",
       "      <td>-0.480940</td>\n",
       "      <td>-0.393730</td>\n",
       "      <td>-0.277160</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.180108</td>\n",
       "      <td>-0.404150</td>\n",
       "      <td>0.358206</td>\n",
       "      <td>0.285097</td>\n",
       "      <td>0.955665</td>\n",
       "      <td>-3.015051</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>-1.158544</td>\n",
       "      <td>-0.694036</td>\n",
       "      <td>-0.540947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.319650</td>\n",
       "      <td>0.099134</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.120010</td>\n",
       "      <td>0.088958</td>\n",
       "      <td>0.171350</td>\n",
       "      <td>-0.117730</td>\n",
       "      <td>-0.263870</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240290</td>\n",
       "      <td>-2.316457</td>\n",
       "      <td>0.115988</td>\n",
       "      <td>1.992077</td>\n",
       "      <td>1.094181</td>\n",
       "      <td>0.362267</td>\n",
       "      <td>-1.395818</td>\n",
       "      <td>-0.647623</td>\n",
       "      <td>-0.699748</td>\n",
       "      <td>-2.677100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263490</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>-0.367170</td>\n",
       "      <td>0.300860</td>\n",
       "      <td>-0.016165</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.370830</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781677</td>\n",
       "      <td>-0.535058</td>\n",
       "      <td>0.034981</td>\n",
       "      <td>-0.853332</td>\n",
       "      <td>0.965745</td>\n",
       "      <td>1.067908</td>\n",
       "      <td>-0.563230</td>\n",
       "      <td>-1.104692</td>\n",
       "      <td>-1.118982</td>\n",
       "      <td>-0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.119840</td>\n",
       "      <td>-0.366770</td>\n",
       "      <td>-0.354050</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>-0.085309</td>\n",
       "      <td>-0.295600</td>\n",
       "      <td>0.311750</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200334</td>\n",
       "      <td>0.313340</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>-0.370420</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>1.149330</td>\n",
       "      <td>1.842975</td>\n",
       "      <td>1.458239</td>\n",
       "      <td>0.729352</td>\n",
       "      <td>0.522059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.343140  0.020893 -0.547010 -0.652910 -0.226870 -0.354650   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.026362 -0.196510 -0.245280 -0.083840  0.304210 -0.180270   \n",
       "14    0.0 -0.391350 -0.284360 -0.655090 -0.645960 -0.241020 -0.352420   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.319650  0.099134  0.010361  0.004176  0.120010  0.088958   \n",
       "18    0.0  0.263490  0.022323  0.043017 -0.367170  0.300860 -0.016165   \n",
       "3     1.0 -0.174850 -0.119840 -0.366770 -0.354050  0.065508 -0.085309   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.630850 -0.189460  0.704020  ...  -3.424498  -1.512935   1.480432   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39 -0.008647  0.384610  0.300520  ...   0.464108   1.135537  -0.256829   \n",
       "14 -0.480940 -0.393730 -0.277160  ...  -2.180108  -0.404150   0.358206   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.171350 -0.117730 -0.263870  ...   1.240290  -2.316457   0.115988   \n",
       "18  0.100220  0.370830  0.123080  ...   0.781677  -0.535058   0.034981   \n",
       "3  -0.295600  0.311750 -0.013669  ...   1.200334   0.313340   0.287729   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60  -0.012000  -1.151279  -2.123389  -0.962200  -0.524886  -2.310918   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39   0.222902   0.528734   1.098908  -1.239779  -0.421480   1.130700   \n",
       "14   0.285097   0.955665  -3.015051   0.024974  -1.158544  -0.694036   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   1.992077   1.094181   0.362267  -1.395818  -0.647623  -0.699748   \n",
       "18  -0.853332   0.965745   1.067908  -0.563230  -1.104692  -1.118982   \n",
       "3   -0.370420   0.224179   1.149330   1.842975   1.458239   0.729352   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -1.740839  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.325227  \n",
       "14  -0.540947  \n",
       "10   1.003364  \n",
       "69  -2.677100  \n",
       "18  -0.037143  \n",
       "3    0.522059  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_gaussian2(original_sample, data=data, std_per_var=std_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución gaussiana de media 0 y \n",
    "    desviación típica = 10% de la diferencia entre la media de la variable para cada clase\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.normal(0, std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_gaussian_2 = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_gaussian_2[i, :] = generate_noisy_sample_gaussian2(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_gaussian_2 = np.c_[labels, noisy_features_gaussian_2]\n",
    "\n",
    "noisy_data_gaussian_2 = pd.concat([data, pd.DataFrame(noisy_features_gaussian_2, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_gaussian_2 = noisy_data_gaussian_2.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_gaussian_2.shape))\n",
    "noisy_data_gaussian_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f12f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_gaussian2, X_test_gaussian2, y_train_gaussian2, y_test_gaussian2) = data_partition(noisy_data_gaussian_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f11370e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 100, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 200, 'n_estimators': 500},\n",
       " {'criterion': 'gini', 'max_depth': 400, 'n_estimators': 500}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_gaussian2 = train_GridSearchCV(model_RF, param_grid_RF, X_train_gaussian2, X_test_gaussian2, \n",
    "                                        y_train_gaussian2, y_test_gaussian2)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_gaussian2[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_gaussian2, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "755ba791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.57%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_gaussian_opt2 = RandomForestClassifier(criterion=\"entropy\", max_depth=400, n_estimators=500, random_state=0)  \n",
    "data_aug_gaussian_opt2.fit(X_train_gaussian2, y_train_gaussian2)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_gaussian2 = data_aug_gaussian_opt2.predict(X_test_gaussian2)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_gaussian2 = accuracy_score(y_test_gaussian2, y_pred_data_aug_gaussian2)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_gaussian2 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0b340",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{ANTERIOR}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca27980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 100.00%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_gaussian_2)\n",
    "\n",
    "grid_search_RF_gaussian2 = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF_gaussian2.fit(X_train, y_train)\n",
    "model_RF_opt_gaussian2 = grid_search_RF_gaussian2.best_estimator_\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF_gaussian2 = model_RF_opt_gaussian2.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_gaussian2)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8603",
   "metadata": {},
   "source": [
    "### Ruido uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "724ab306",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_per_var = features_tot.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10a75640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño DataFrame original: (86, 411)\n",
      "Tamaño DataFrame tras añadir el ruido: (172, 411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>FNC1</th>\n",
       "      <th>FNC2</th>\n",
       "      <th>FNC3</th>\n",
       "      <th>FNC4</th>\n",
       "      <th>FNC5</th>\n",
       "      <th>FNC6</th>\n",
       "      <th>FNC7</th>\n",
       "      <th>FNC8</th>\n",
       "      <th>FNC9</th>\n",
       "      <th>...</th>\n",
       "      <th>SBM_map55</th>\n",
       "      <th>SBM_map61</th>\n",
       "      <th>SBM_map64</th>\n",
       "      <th>SBM_map67</th>\n",
       "      <th>SBM_map69</th>\n",
       "      <th>SBM_map71</th>\n",
       "      <th>SBM_map72</th>\n",
       "      <th>SBM_map73</th>\n",
       "      <th>SBM_map74</th>\n",
       "      <th>SBM_map75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148470</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>-0.474630</td>\n",
       "      <td>-0.532530</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.544720</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>0.156540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>0.826910</td>\n",
       "      <td>-0.225792</td>\n",
       "      <td>0.369724</td>\n",
       "      <td>-0.565693</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>1.094329</td>\n",
       "      <td>-0.345906</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.567717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0.143325</td>\n",
       "      <td>-0.607460</td>\n",
       "      <td>-0.668581</td>\n",
       "      <td>-0.043226</td>\n",
       "      <td>-0.299202</td>\n",
       "      <td>-0.731040</td>\n",
       "      <td>-0.240142</td>\n",
       "      <td>0.768622</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.499343</td>\n",
       "      <td>-1.440684</td>\n",
       "      <td>1.418062</td>\n",
       "      <td>-0.112408</td>\n",
       "      <td>-1.172020</td>\n",
       "      <td>-1.980269</td>\n",
       "      <td>-0.910399</td>\n",
       "      <td>-0.415231</td>\n",
       "      <td>-2.311371</td>\n",
       "      <td>-1.608504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820240</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.588390</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>0.612370</td>\n",
       "      <td>0.059279</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.465429</td>\n",
       "      <td>-0.935685</td>\n",
       "      <td>1.415247</td>\n",
       "      <td>-0.097483</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>-2.566518</td>\n",
       "      <td>0.117317</td>\n",
       "      <td>-0.249365</td>\n",
       "      <td>-0.409918</td>\n",
       "      <td>-0.384427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146210</td>\n",
       "      <td>-0.468630</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>-0.503810</td>\n",
       "      <td>-0.510520</td>\n",
       "      <td>-0.029113</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.342273</td>\n",
       "      <td>-0.978412</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.889753</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.475415</td>\n",
       "      <td>2.340384</td>\n",
       "      <td>2.516038</td>\n",
       "      <td>-0.551440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249280</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>-0.305730</td>\n",
       "      <td>-0.099511</td>\n",
       "      <td>0.487854</td>\n",
       "      <td>-0.124822</td>\n",
       "      <td>-0.108838</td>\n",
       "      <td>0.333928</td>\n",
       "      <td>0.365122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389263</td>\n",
       "      <td>1.207788</td>\n",
       "      <td>-0.319200</td>\n",
       "      <td>0.122495</td>\n",
       "      <td>0.507993</td>\n",
       "      <td>1.242028</td>\n",
       "      <td>-1.187978</td>\n",
       "      <td>-0.311825</td>\n",
       "      <td>1.130247</td>\n",
       "      <td>0.457562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.168432</td>\n",
       "      <td>-0.161928</td>\n",
       "      <td>-0.715540</td>\n",
       "      <td>-0.661631</td>\n",
       "      <td>-0.057376</td>\n",
       "      <td>-0.296972</td>\n",
       "      <td>-0.581130</td>\n",
       "      <td>-0.444412</td>\n",
       "      <td>-0.212558</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.254953</td>\n",
       "      <td>-0.331899</td>\n",
       "      <td>0.295836</td>\n",
       "      <td>0.184689</td>\n",
       "      <td>0.934924</td>\n",
       "      <td>-2.871931</td>\n",
       "      <td>0.076776</td>\n",
       "      <td>-1.048889</td>\n",
       "      <td>-0.694488</td>\n",
       "      <td>-0.408612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124670</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>-0.130660</td>\n",
       "      <td>-0.141850</td>\n",
       "      <td>-0.148490</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>-0.312300</td>\n",
       "      <td>-0.136070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897078</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>-0.435161</td>\n",
       "      <td>-0.541126</td>\n",
       "      <td>0.363668</td>\n",
       "      <td>-0.545821</td>\n",
       "      <td>-0.868450</td>\n",
       "      <td>0.367415</td>\n",
       "      <td>-0.038803</td>\n",
       "      <td>1.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542568</td>\n",
       "      <td>0.221566</td>\n",
       "      <td>-0.050089</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.303654</td>\n",
       "      <td>0.144406</td>\n",
       "      <td>0.071160</td>\n",
       "      <td>-0.168412</td>\n",
       "      <td>-0.199268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.165445</td>\n",
       "      <td>-2.244207</td>\n",
       "      <td>0.053618</td>\n",
       "      <td>1.891669</td>\n",
       "      <td>1.073441</td>\n",
       "      <td>0.505387</td>\n",
       "      <td>-1.344017</td>\n",
       "      <td>-0.537968</td>\n",
       "      <td>-0.700200</td>\n",
       "      <td>-2.544765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486408</td>\n",
       "      <td>0.144755</td>\n",
       "      <td>-0.017433</td>\n",
       "      <td>-0.382841</td>\n",
       "      <td>0.484504</td>\n",
       "      <td>0.039283</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.320148</td>\n",
       "      <td>0.187682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.706832</td>\n",
       "      <td>-0.462807</td>\n",
       "      <td>-0.027389</td>\n",
       "      <td>-0.953739</td>\n",
       "      <td>0.945004</td>\n",
       "      <td>1.211029</td>\n",
       "      <td>-0.511429</td>\n",
       "      <td>-0.995037</td>\n",
       "      <td>-1.119434</td>\n",
       "      <td>0.095193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048068</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>-0.427220</td>\n",
       "      <td>-0.369721</td>\n",
       "      <td>0.249152</td>\n",
       "      <td>-0.029861</td>\n",
       "      <td>-0.395790</td>\n",
       "      <td>0.261068</td>\n",
       "      <td>0.050933</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125489</td>\n",
       "      <td>0.385591</td>\n",
       "      <td>0.225359</td>\n",
       "      <td>-0.470828</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>1.292451</td>\n",
       "      <td>1.894776</td>\n",
       "      <td>1.567895</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>0.654394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class      FNC1      FNC2      FNC3      FNC4      FNC5      FNC6  \\\n",
       "81    0.0 -0.148470 -0.401520 -0.474630 -0.532530  0.293510 -0.111720   \n",
       "60    1.0 -0.120222  0.143325 -0.607460 -0.668581 -0.043226 -0.299202   \n",
       "67    1.0  0.820240  0.766600  0.588390  0.731570  0.763950  0.607150   \n",
       "4     1.0 -0.146210 -0.468630 -0.528800 -0.503810 -0.510520 -0.029113   \n",
       "39    0.0  0.249280 -0.074078 -0.305730 -0.099511  0.487854 -0.124822   \n",
       "14    0.0 -0.168432 -0.161928 -0.715540 -0.661631 -0.057376 -0.296972   \n",
       "10    1.0  0.124670 -0.049878 -0.130660 -0.141850 -0.148490 -0.085769   \n",
       "69    1.0  0.542568  0.221566 -0.050089 -0.011495  0.303654  0.144406   \n",
       "18    0.0  0.486408  0.144755 -0.017433 -0.382841  0.484504  0.039283   \n",
       "3     1.0  0.048068  0.002592 -0.427220 -0.369721  0.249152 -0.029861   \n",
       "\n",
       "        FNC7      FNC8      FNC9  ...  SBM_map55  SBM_map61  SBM_map64  \\\n",
       "81 -0.544720  0.240320  0.156540  ...   0.512424   0.826910  -0.225792   \n",
       "60 -0.731040 -0.240142  0.768622  ...  -3.499343  -1.440684   1.418062   \n",
       "67  0.612370  0.059279  0.729200  ...  -2.465429  -0.935685   1.415247   \n",
       "4  -0.015192  0.360170  0.005944  ...   1.342273  -0.978412   0.158492   \n",
       "39 -0.108838  0.333928  0.365122  ...   0.389263   1.207788  -0.319200   \n",
       "14 -0.581130 -0.444412 -0.212558  ...  -2.254953  -0.331899   0.295836   \n",
       "10 -0.127710 -0.312300 -0.136070  ...  -0.897078   0.359318  -0.435161   \n",
       "69  0.071160 -0.168412 -0.199268  ...   1.165445  -2.244207   0.053618   \n",
       "18  0.000030  0.320148  0.187682  ...   0.706832  -0.462807  -0.027389   \n",
       "3  -0.395790  0.261068  0.050933  ...   1.125489   0.385591   0.225359   \n",
       "\n",
       "    SBM_map67  SBM_map69  SBM_map71  SBM_map72  SBM_map73  SBM_map74  \\\n",
       "81   0.369724  -0.565693  -0.045074   1.094329  -0.345906  -0.014453   \n",
       "60  -0.112408  -1.172020  -1.980269  -0.910399  -0.415231  -2.311371   \n",
       "67  -0.097483   0.073954  -2.566518   0.117317  -0.249365  -0.409918   \n",
       "4    0.889753   0.795368   0.738788   0.475415   2.340384   2.516038   \n",
       "39   0.122495   0.507993   1.242028  -1.187978  -0.311825   1.130247   \n",
       "14   0.184689   0.934924  -2.871931   0.076776  -1.048889  -0.694488   \n",
       "10  -0.541126   0.363668  -0.545821  -0.868450   0.367415  -0.038803   \n",
       "69   1.891669   1.073441   0.505387  -1.344017  -0.537968  -0.700200   \n",
       "18  -0.953739   0.945004   1.211029  -0.511429  -0.995037  -1.119434   \n",
       "3   -0.470828   0.203439   1.292451   1.894776   1.567895   0.728900   \n",
       "\n",
       "    SBM_map75  \n",
       "81   0.567717  \n",
       "60  -1.608504  \n",
       "67  -0.384427  \n",
       "4   -0.551440  \n",
       "39   0.457562  \n",
       "14  -0.408612  \n",
       "10   1.003364  \n",
       "69  -2.544765  \n",
       "18   0.095193  \n",
       "3    0.654394  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0) # Reproducibilidad de resultados\n",
    "\n",
    "def generate_noisy_sample_uniform(original_sample, data=data, std_per_var=std_per_var, avg_per_var=avg_per_var):\n",
    "    '''\n",
    "    Función para generar valores de ruido a partir de una distribución uniforme\n",
    "    '''\n",
    "    noisy_sample = np.empty((len(std_per_var),))\n",
    "    for j, var in enumerate(data.columns[1:]):\n",
    "        noisy_sample[j] = original_sample[j] + np.random.uniform(avg_per_var[j]-std_per_var[j], avg_per_var[j]+std_per_var[j])         \n",
    "    return noisy_sample\n",
    "\n",
    "# Para cada muestra conocida (y etiquetada), generaremos una muestra sintética con ruido\n",
    "noisy_features_uniform = np.empty(features.shape)\n",
    "for i, sample in enumerate(features.to_numpy()):\n",
    "    noisy_features_uniform[i, :] = generate_noisy_sample_uniform(sample)\n",
    "    \n",
    "# Volvemos a asignar las etiquetas correspondientes a cada fila\n",
    "noisy_features_uniform = np.c_[labels, noisy_features_uniform]\n",
    "\n",
    "noisy_data_uniform = pd.concat([data, pd.DataFrame(noisy_features_uniform, columns=data.columns)], axis=0)\n",
    "# Shuffle de los datos con ruido\n",
    "noisy_data_uniform = noisy_data_uniform.sample(frac=1, random_state=0)\n",
    "\n",
    "print(\"Tamaño DataFrame original: {}\".format(data.shape))\n",
    "print(\"Tamaño DataFrame tras añadir el ruido: {}\".format(noisy_data_uniform.shape))\n",
    "noisy_data_uniform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31db9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_uniform, X_test_uniform, y_train_uniform, y_test_uniform) = data_partition(noisy_data_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7512601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 100, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 200, 'n_estimators': 1000},\n",
       " {'criterion': 'entropy', 'max_depth': 400, 'n_estimators': 1000}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aug_uniform = train_GridSearchCV(model_RF, param_grid_RF, X_train_uniform, X_test, y_train, y_test)\n",
    "top_acc = top_acc_GridSearchCV(data_aug_uniform[\"mean_test_score\"])\n",
    "models_same_acc_GridSearchCV(data_aug_uniform, top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46bb5a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.71%\n"
     ]
    }
   ],
   "source": [
    "# Definir y entrenar el modelo\n",
    "data_aug_uniform_opt = RandomForestClassifier(criterion=\"entropy\", max_depth=400, n_estimators=500, random_state=0)  \n",
    "data_aug_uniform_opt.fit(X_train_uniform, y_train_uniform)\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_data_aug_uniform = data_aug_uniform_opt.predict(X_test_uniform)\n",
    "\n",
    "# Precisión en partición de test\n",
    "acc_data_aug_uniform = accuracy_score(y_test_uniform, y_pred_data_aug_uniform)\n",
    "print(\"Accuracy: {:0.2f}%\".format(acc_data_aug_uniform * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10db33d",
   "metadata": {},
   "source": [
    "$\\color{red}{\\text{ANTERIOR}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6615e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Data Augmentation: 91.43%\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = data_partition(noisy_data_uniform)\n",
    "\n",
    "grid_search_RF_uniform = GridSearchCV(estimator=model_RF, param_grid=param_grid_RF, cv=4)\n",
    "\n",
    "grid_search_RF_uniform.fit(X_train, y_train)\n",
    "model_RF_opt_uniform = grid_search_RF_uniform.best_estimator_\n",
    "\n",
    "# Predicción en partición de test\n",
    "y_pred_RF_uniform = model_RF_opt_uniform.predict(X_test)\n",
    "\n",
    "# Precisión en partición de test\n",
    "accuracy = accuracy_score(y_test, y_pred_RF_uniform)\n",
    "print(\"Accuracy with Data Augmentation: {:0.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe059ea4",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Otra posibilidad para hacer Data Augmentation es, dado que se dispone de un gran volumen de datos no etiquetados, obtener una estimación lo más acertada posible de las etiquetas a las que estarían asociados estos datos. En este caso, podríamos plantearnos repetir algún entrenamiento, esta vez sobre un conjunto de datos mucho mayor.\n",
    "\n",
    "El modelo en base al cual vamos a generar estas predicciones va a ser el encoder ya visto anteriormente. Ya que como se ha explicado, se genera a partir de una red autoencoder que ha entrenado sobre el conjunto de datos completo que queremos etiquetar aquí y posteriormente ha adaptado sus pesos en la parte encoder al problema de clasificación que nos interesa aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8409ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, optimizers, callbacks, backend, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38bb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.load_model(\"Modelos/encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922cfa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119816, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_kaggle = encoder.predict(test_kaggle)\n",
    "\n",
    "labels_tot = np.concatenate((np.reshape(y_train.to_numpy(), (68, 1)), y_test_kaggle), axis=0)\n",
    "labels_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a5e4f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119816, 410)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tot = np.concatenate((X_train, test_kaggle))\n",
    "features_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2052d",
   "metadata": {},
   "source": [
    "Vamos a repetir el entrenamiento con una de las configuraciones de red neuronal que ha alcanzado los mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a873f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# En primer lugar, hay que adaptar los datos\n",
    "NUM_CLASSES = 2\n",
    "y_train_softmax = np_utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_softmax = np_utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2069b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 201ms/step - loss: 0.6826 - acc: 0.5686 - val_loss: 0.6321 - val_acc: 0.5882\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5491 - acc: 0.7255 - val_loss: 0.5449 - val_acc: 0.8235\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2874 - acc: 0.9608 - val_loss: 0.4808 - val_acc: 0.8235\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2832 - acc: 0.8824 - val_loss: 1.4154 - val_acc: 0.5882\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4606 - acc: 0.8431 - val_loss: 0.4541 - val_acc: 0.7059\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.4503 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.4612 - val_acc: 0.7059\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4476 - acc: 0.8889\n",
      "Accuracy: 88.89%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_enc = models.Sequential()\n",
    "modelFC_enc.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_enc.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_enc.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_enc.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_enc.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_enc.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_enc.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_enc.fit(X_train, y_train_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy_enc = modelFC_enc.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy_enc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34502514",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "labels_tot_softmax = np_utils.to_categorical(labels_tot, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b9f0848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2809/2809 [==============================] - 9s 3ms/step - loss: 0.0058 - acc: 0.9997 - val_loss: 3.3326e-07 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "2809/2809 [==============================] - 8s 3ms/step - loss: 0.0050 - acc: 0.9997 - val_loss: 1.1798e-10 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "2809/2809 [==============================] - 9s 3ms/step - loss: 0.0051 - acc: 0.9997 - val_loss: 1.2482e-05 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "2809/2809 [==============================] - 9s 3ms/step - loss: 0.0043 - acc: 0.9997 - val_loss: 2.5638e-08 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "2809/2809 [==============================] - 8s 3ms/step - loss: 0.0047 - acc: 0.9997 - val_loss: 2.2233e-05 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "2809/2809 [==============================] - 9s 3ms/step - loss: 0.0048 - acc: 0.9997 - val_loss: 1.0438e-08 - val_acc: 1.0000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 12.5449 - acc: 0.4444\n",
      "Accuracy: 44.44%\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(0)\n",
    "\n",
    "# Definir y entrenar el modelo\n",
    "modelFC_enc2 = models.Sequential()\n",
    "modelFC_enc2.add(layers.Dense(150, activation=\"relu\", input_shape=(410,)))\n",
    "modelFC_enc2.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_enc2.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_enc2.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_enc2.add(layers.Dense(150, activation=\"relu\"))\n",
    "modelFC_enc2.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "modelFC_enc2.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "es = callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.01, patience=5)\n",
    "modelFC_enc2.fit(features_tot, labels_tot_softmax, epochs=100, validation_split=0.25, callbacks=[es])\n",
    "\n",
    "# Precisión en partición de test\n",
    "loss, accuracy_enc2 = modelFC_enc2.evaluate(X_test, y_test_softmax)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy_enc2 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea7227",
   "metadata": {},
   "source": [
    "# Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "198c17e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_acc = [acc_data_aug_gaussian, acc_data_aug_gaussian2, acc_data_aug_uniform, accuracy_pl, accuracy_enc2]\n",
    "original_acc = [acc_no_data_aug] * 3\n",
    "original_acc.append(accuracyFC)\n",
    "original_acc.append(accuracy_enc)\n",
    "xaxis = [\"Ruido gaussiano I\", \"Ruido gaussiano II\", \"Ruido uniforme\", \"Pseudo-labels\", \"Autoencoder\"]\n",
    "x = np.arange(len(xaxis))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(x-0.1, results_acc, width=0.2, label=\"Accuracy tras Data Augmentation\")\n",
    "plt.bar(x+0.1, original_acc, width=0.2,  label=\"Accuracy sin Data Augmentation\")\n",
    "plt.xticks(range(0, len(xaxis)), xaxis, rotation=0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
